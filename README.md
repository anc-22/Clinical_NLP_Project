# Clinical NLP Pipeline: From Weak Supervision to Emergency Triage

An educational project implementing weak supervision for clinical NLP. Integrated labeling functions, BioClinicalBERT fine-tuning, and ESI-based triage rules. This project helped me understand modern NLP pipelines and their healthcare applications. Built with guidance from research papers and AI assistance.

## ğŸ¯ Project Overview

This project implements a scalable approach to clinical NLP that:
- Extracts medical entities without manual annotation using weak supervision
- Trains a BioClinicalBERT NER model on automatically generated "silver" training data
- Implements clinical triage rules based on Emergency Severity Index (ESI) standards
- Provides actionable insights for healthcare workflows

## ğŸ“Š Dataset

**Source**: Augmented Clinical Notes from Hugging Face
- **Size**: 30,000 clinical note triplets
- **Components**:
  - Real clinical notes from PMC-Patients dataset
  - Synthetic patient-doctor dialogues (generated via GPT-3.5)
  - Structured patient summaries (generated via GPT-4)
- **Repository**: [EPFL-IC-Make-Team/ClinicalNotes](https://huggingface.co/datasets/EPFL-IC-Make-Team/augmented-clinical-notes)
- **Paper**: MediNote: Automated Clinical Notes
- **Language**: English

## ğŸ”§ Pipeline Architecture

### Stage 1: Data Preprocessing
- **JSON Parsing**: Complex nested JSON structures are flattened into manageable CSV formats
- **Text Normalization**: Standardized text processing for downstream tasks
- **Data Explosion**: Nested structures (surgeries, symptoms, diagnoses) expanded into separate tables

Example transformation:
```
Original: 'summary': {"visit motivation": "Mass in right thigh", "admission": [...]}
â†’ Parsed: Individual fields extracted and normalized
```

### Stage 2: Weak Supervision & Labeling Functions

#### Row-Level Labels
Created domain-specific labeling functions (LFs) that generate weak labels:
- **Surgery LFs**: Detect emergency procedures, specific surgeries (hip/knee replacement)
- **Symptom LFs**: Identify acute onset, pain severity, bilateral symptoms
- **Diagnosis LFs**: Flag critical findings, imaging results
- **Treatment LFs**: Mark emergency treatments, specific medications

Output: `lf_signals_index.parquet` containing boolean flags per note

#### Span-Level Labels
Generate silver NER training data through:
1. Entity normalization to standard medical schema
2. Dictionary-based spanning with fuzzy matching
3. Confidence scoring based on frequency and context
4. BIO tagging for transformer training

### Stage 3: NER Model Training
- **Model**: BioClinicalBERT fine-tuned for token classification
- **Training Data**: Silver-labeled spans from weak supervision
- **Features**: 
  - Windowed inference for long documents
  - Confidence-based filtering
  - Multiple entity type support

### Stage 4: Clinical Triage System

Implements Emergency Severity Index (ESI) classification:

#### ESI Levels
- **ESI 1** (Immediate): Life-threatening conditions requiring immediate intervention
- **ESI 2** (Emergency): High risk of deterioration, time-critical
- **ESI 3** (Urgent): Stable but needs prompt assessment  
- **ESI 4** (Non-urgent): Can wait extended period
- **ESI 5** (Minor): No acute threat

#### Key Features
- **Multi-source Integration**: Combines NER outputs with labeling function signals
- **Contextual Rules**: Considers entity combinations, negation, proximity
- **Confidence Weighting**: Prioritizes high-confidence predictions
- **Provenance Tracking**: Records which entities triggered each rule

#### Rule Examples
- Cardiac emergency: "chest pain" + acute onset + high severity
- Neurological emergency: focal weakness + laterality + acute presentation
- Critical findings: hemorrhage/embolism + acute temporal pattern

## ğŸ“ Project Structure

```
project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/           # Original augmented clinical notes
â”‚   â”œâ”€â”€ clean/         # Processed CSV files
â”‚   â””â”€â”€ entities/      # Extracted entities
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ models/        # Trained NER models
â”‚   â”œâ”€â”€ signals/       # Labeling function outputs
â”‚   â””â”€â”€ triage/        # Triage alerts and diagnostics
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing/ # Data cleaning scripts
â”‚   â”œâ”€â”€ labeling/      # Labeling functions
â”‚   â”œâ”€â”€ ner/           # NER training/inference
â”‚   â””â”€â”€ triage/        # ESI rule engine
â””â”€â”€ notebooks/         # Analysis and examples
```

## ğŸš€ Usage

### 1. Data Preprocessing
```python
# Clean and explode nested JSON structures
python src/preprocessing/clean_clinical_notes.py

# Generate entity tables from domain-specific data
python src/preprocessing/create_entity_tables.py
```

### 2. Generate Training Data
```python
# Run labeling functions
python src/labeling/run_labeling_functions.py

# Create silver NER spans
python src/labeling/create_silver_spans.py
```

### 3. Train NER Model
```python
# Fine-tune BioClinicalBERT
python src/ner/train_ner.py --config configs/ner_config.yaml
```

### 4. Run Triage System
```python
# Generate triage alerts
python src/triage/run_triage_alerts.py

# Outputs:
# - triage_alerts_top.csv: Highest priority alert per note
# - triage_alerts_all.csv: All fired rules
# - triage_diagnostics.xlsx: Detailed analytics
```

## ğŸ“ˆ Evaluation & Results

### NER Performance
- Precision, Recall, F1 scores per entity type
- Comparison of silver vs. manually annotated test set

### Triage Validation
- ESI distribution analysis
- Rule coverage statistics
- Entity source attribution (NER vs. LF vs. combined)

### Feedback Loop
The system generates actionable feedback for improvement:
- High-priority cases with few extracted entities
- Terms frequently in critical cases but missing from lexicons
- Rules dependent solely on NER (suggesting LF gaps)

## ğŸ”„ Continuous Improvement

The pipeline supports iterative enhancement through:
1. **Labeling Function Refinement**: Based on triage feedback
2. **Active Learning**: Focus annotation on high-uncertainty cases
3. **Rule Adjustment**: Tune ESI thresholds based on clinical feedback
4. **Model Updates**: Retrain with improved silver labels

## ğŸ› ï¸ Requirements

```
transformers>=4.30.0
torch>=2.0.0
pandas>=1.5.0
numpy>=1.24.0
scikit-learn>=1.2.0
spacy>=3.5.0
seqeval>=1.2.2
```


## ğŸ™ Acknowledgments

- EPFL-IC-Make-Team for the Augmented Clinical Notes dataset
- Hugging Face for hosting and infrastructure
- BioClinicalBERT authors for the pre-trained model
