{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "viVUeCs_w87G"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sys\n",
        "import gc\n",
        "import os\n",
        "import spacy\n",
        "import scispacy\n",
        "from dateutil import parser\n",
        "from spacy.matcher import Matcher\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import json\n",
        "import os, gc, json, re, joblib, warnings\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from rapidfuzz import fuzz\n",
        "\n",
        "# HF / seqeval / sklearn\n",
        "import datasets as ds\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForTokenClassification,\n",
        "    DataCollatorForTokenClassification,\n",
        "    TrainingArguments, Trainer, EarlyStoppingCallback, pipeline\n",
        ")\n",
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report as skl_report\n",
        "\n",
        "import torch\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.4.4\n",
            "0.5.1\n",
            "3.4.0\n",
            "/opt/anaconda3/envs/nlp_clinical/bin/python\n"
          ]
        }
      ],
      "source": [
        "print(spacy.__version__)\n",
        "print(scispacy.__version__)\n",
        "import en_core_web_sm\n",
        "print(en_core_web_sm.__version__)\n",
        "import sys\n",
        "print(sys.executable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_data_path(filename):\n",
        "    \"\"\"\n",
        "    Returns the path to a file in the data/clean directory.\n",
        "    \n",
        "    Args:\n",
        "        filename (str): Name of the file (including extension)\n",
        "    \n",
        "    Returns:\n",
        "        str: Full path to the file\n",
        "    \"\"\"\n",
        "    cwd = os.getcwd()\n",
        "    parent_dir = os.path.dirname(cwd)\n",
        "    file_path = os.path.join(parent_dir, 'data', 'clean', filename)\n",
        "    return file_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MW9AtVsMxHf2"
      },
      "outputs": [],
      "source": [
        "df_medical_expanded = get_data_path('df_medical_expanded.csv')\n",
        "df_medical = pd.read_csv(df_medical_expanded, index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "e83tzaAQyjT0"
      },
      "outputs": [],
      "source": [
        "df_diagnosis_expanded = get_data_path('df_diagnosis_expanded.csv')\n",
        "df_diagnosis = pd.read_csv(df_diagnosis_expanded, index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "o_wuhPP_ynrx"
      },
      "outputs": [],
      "source": [
        "df_surgery_expanded = get_data_path('df_surgery_expanded.csv')\n",
        "df_surgery = pd.read_csv(df_surgery_expanded, index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OA923I2boKGO"
      },
      "outputs": [],
      "source": [
        "df_symptoms_expanded = get_data_path('df_symptoms_expanded.csv')\n",
        "df_symptoms = pd.read_csv(df_symptoms_expanded, index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_treatments_expanded = get_data_path('df_treatments_expanded.csv')\n",
        "df_treatments = pd.read_csv(df_treatments_expanded, index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_info_expanded = get_data_path('df_info_expanded.csv')\n",
        "df_info = pd.read_csv(df_info_expanded, index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV6EH4ZwyfA2"
      },
      "source": [
        "### Medical Entity Extractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MedicalEntityExtractor:\n",
        "    def __init__(self, model_name=\"en_core_sci_sm\", batch_size=500):\n",
        "        \"\"\"\n",
        "        Initialize the medical entity extractor.\n",
        "\n",
        "        Args:\n",
        "            model_name: ScispaCy model to use. Options:\n",
        "                       - \"en_core_sci_sm\" (smaller, faster, generic entities)\n",
        "                       - \"en_core_sci_md\" (medium)\n",
        "                       - \"en_ner_bc5cdr_md\" (disease/chemical focused - BEST FOR MEDICAL)\n",
        "                       - \"en_ner_bionlp13cg_md\" (multiple bio entity types)\n",
        "            batch_size: Number of texts to process at once\n",
        "        \"\"\"\n",
        "        self.batch_size = batch_size\n",
        "        self.model_name = model_name\n",
        "        self.nlp = None\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"# Load a spaCy language model and assign it to self.nlp\"\"\"\n",
        "        print(f\"Loading {self.model_name}...\")\n",
        "        try:\n",
        "            self.nlp = spacy.load(self.model_name)\n",
        "        except:\n",
        "            print(f\"Model {self.model_name} not found. Installing...\")\n",
        "            import os\n",
        "            # Fallback to install the appropriate model if fail to load\n",
        "            if self.model_name == \"en_ner_bc5cdr_md\":\n",
        "                os.system(\"pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bc5cdr_md-0.5.1.tar.gz\")\n",
        "            elif self.model_name == \"en_ner_bionlp13cg_md\":\n",
        "                os.system(\"pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bionlp13cg_md-0.5.1.tar.gz\")\n",
        "            else:\n",
        "                os.system(f\"pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/{self.model_name}-0.5.1.tar.gz\")\n",
        "            self.nlp = spacy.load(self.model_name)\n",
        "\n",
        "        # Disable unnecessary pipeline components to save memory\n",
        "        pipes_to_disable = [\"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"]\n",
        "        for pipe in pipes_to_disable:\n",
        "            if pipe in self.nlp.pipe_names:\n",
        "                self.nlp.disable_pipe(pipe)\n",
        "\n",
        "        print(f\"Model loaded. Active pipes: {self.nlp.pipe_names}\")\n",
        "\n",
        "    def process_batch(self, texts, ids):  \n",
        "        batch_results = []\n",
        "        docs = list(self.nlp.pipe(texts, batch_size=50)) # Stream & batch process with nlp.pipe is faster than looped nlp(text)\n",
        "        for doc, original_text, rid in zip(docs, texts, ids):\n",
        "            for ent in doc.ents: # doc.ents yields entity objects\n",
        "                batch_results.append({\n",
        "                    'text': ent.text,\n",
        "                    'label': ent.label_,\n",
        "                    'start': ent.start_char,\n",
        "                    'end': ent.end_char,\n",
        "                    'original_text': original_text,\n",
        "                    'row_idx': rid,  \n",
        "                })\n",
        "        # Drop large list, nudge Python’s garbage collector \n",
        "        del docs \n",
        "        gc.collect()\n",
        "        return batch_results\n",
        "\n",
        "    def extract_entities_from_df(\n",
        "        self, df, text_column, *, # * forces keyword-only args after it\n",
        "        save_checkpoints=True, checkpoint_dir='./ner_checkpoints',\n",
        "        id_column='idx'                    \n",
        "    ):\n",
        "        if self.nlp is None:\n",
        "            self.load_model()\n",
        "\n",
        "        texts = df[text_column].fillna('').astype(str).tolist()\n",
        "\n",
        "        # --- Choose row IDs from the given column; fallback to df.index ---\n",
        "        if id_column is not None and id_column in df.columns:\n",
        "            ids_series = df[id_column]\n",
        "            # if there are NaNs in idx, fall back to positional index for those rows\n",
        "            ids_series = ids_series.where(pd.notna(ids_series), df.index)\n",
        "            ids = ids_series.tolist()\n",
        "            print(f\"Stamping row identifier from column: '{id_column}'\")\n",
        "        else:\n",
        "            ids = df.index.tolist()\n",
        "            print(\"Stamping row identifier from DataFrame index\")\n",
        "\n",
        "        total_batches = (len(texts) + self.batch_size - 1) // self.batch_size # Ceiling division: compute total batch count without importing math\n",
        "        all_results = []\n",
        "\n",
        "        if save_checkpoints:\n",
        "            import os\n",
        "            os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "        print(f\"Processing {len(texts)} texts in {total_batches} batches...\")\n",
        "        print(f\"Using model: {self.model_name} for column: {text_column}\")\n",
        "\n",
        "        # Status bar with tqdm\n",
        "        for batch_start in tqdm(range(0, len(texts), self.batch_size), desc=\"Processing batches\"):\n",
        "            batch_end   = batch_start + self.batch_size\n",
        "            batch_texts = texts[batch_start:batch_end]\n",
        "            batch_ids   = ids[batch_start:batch_end]\n",
        "\n",
        "            try:\n",
        "                batch_results = self.process_batch(batch_texts, batch_ids)\n",
        "                all_results.extend(batch_results)\n",
        "                # # Periodic checkpoints: every 10th batch (0-based), write all results so far to CSV\n",
        "                if save_checkpoints and ((batch_start // self.batch_size) % 10 == 0): \n",
        "                    checkpoint_df = pd.DataFrame(all_results)\n",
        "                    safe_column_name = text_column.replace(' ', '_').replace('/', '_')\n",
        "                    checkpoint_df.to_csv(\n",
        "                        f\"{checkpoint_dir}/checkpoint_{safe_column_name}_{batch_start}.csv\",\n",
        "                        index=False\n",
        "                    )\n",
        "                    print(f\"\\nCheckpoint saved at batch {batch_start}\")\n",
        "            except Exception as e:\n",
        "                print(f\"\\nError processing batch {batch_start}: {e}\")\n",
        "                continue\n",
        "\n",
        "            if (batch_start // self.batch_size) % 5 == 0:\n",
        "                gc.collect() # Occasional GC hint (every 5 batches) to keep memory tidy\n",
        "\n",
        "        results_df = pd.DataFrame(all_results)\n",
        "        results_df['source_column'] = text_column\n",
        "        return results_df\n",
        "\n",
        "    def get_entity_summary(self, entities_df):\n",
        "        \"\"\"Generate summary statistics of extracted entities.\"\"\"\n",
        "        summary = {\n",
        "            'total_entities': len(entities_df),\n",
        "            'unique_entities': entities_df['text'].nunique(),\n",
        "            'entity_types': entities_df['label'].value_counts().to_dict(),\n",
        "            'top_entities': entities_df['text'].value_counts().head(20).to_dict()\n",
        "        }\n",
        "        return summary\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FMIFtI9oxaEr"
      },
      "outputs": [],
      "source": [
        "# Helper functions for analysis\n",
        "def analyze_medical_entities(entities_df, min_frequency=5):\n",
        "    \"\"\"Analyze extracted entities and create labeling functions.\"\"\"\n",
        "    \n",
        "    # Find frequent medical conditions\n",
        "    frequent_entities = entities_df['text'].value_counts()\n",
        "    frequent_entities = frequent_entities[frequent_entities >= min_frequency]\n",
        "    \n",
        "    print(f\"Found {len(frequent_entities)} entities appearing >= {min_frequency} times\")\n",
        "    \n",
        "    # Group by entity type\n",
        "    entity_groups = {}\n",
        "    for label in entities_df['label'].unique():\n",
        "        label_entities = entities_df[entities_df['label'] == label]['text'].value_counts()\n",
        "        entity_groups[label] = label_entities.head(10).to_dict()\n",
        "    \n",
        "    return frequent_entities, entity_groups\n",
        "\n",
        "def create_entity_based_rules(entities_df, target_labels=['DISEASE', 'CHEMICAL'], source_column=None):\n",
        "    \"\"\"Create labeling functions based on extracted entities.\"\"\"\n",
        "    \n",
        "    # Get the source column from the entities_df if not provided\n",
        "    if source_column is None:\n",
        "        if 'source_column' in entities_df.columns:\n",
        "            source_column = entities_df['source_column'].iloc[0]\n",
        "        else:\n",
        "            raise ValueError(\"source_column must be provided or available in entities_df\")\n",
        "    \n",
        "    # Get top entities for each label type\n",
        "    rules = {}\n",
        "    \n",
        "    for label in target_labels:\n",
        "        if label in entities_df['label'].unique():\n",
        "            top_entities = entities_df[entities_df['label'] == label]['text'].value_counts().head(20)\n",
        "            \n",
        "            # Create a labeling function for this entity type\n",
        "            def make_labeling_function(entity_list, label_name, column_name):\n",
        "                def lf(row):\n",
        "                    # Handle column names with spaces\n",
        "                    if column_name in row:\n",
        "                        text = str(row[column_name]).lower()\n",
        "                    else:\n",
        "                        # # Try alternative column names\n",
        "                        # alt_column = column_name.replace('_', ' ')\n",
        "                        # if alt_column in row:\n",
        "                        #     text = str(row[alt_column]).lower()\n",
        "                        # else:\n",
        "                            return 'ABSTAIN'\n",
        "                    \n",
        "                    for entity in entity_list:\n",
        "                        if entity.lower() in text:\n",
        "                            return label_name\n",
        "                    return 'ABSTAIN'\n",
        "                \n",
        "                # Create safe function name\n",
        "                safe_column_name = column_name.replace(' ', '_').replace('/', '_')\n",
        "                lf.__name__ = f\"lf_{label_name.lower()}_{safe_column_name}\"\n",
        "                return lf\n",
        "            \n",
        "            rules[f'lf_{label.lower()}_{source_column.replace(\" \", \"_\")}'] = make_labeling_function(\n",
        "                top_entities.index.tolist(),\n",
        "                label,\n",
        "                source_column\n",
        "            )\n",
        "    \n",
        "    return rules\n",
        "\n",
        "# Main execution function for single column\n",
        "def run_medical_ner_extraction(df, text_column,\n",
        "                               model_name=\"en_ner_bc5cdr_md\", batch_size=500,id_column='idx'):\n",
        "    \"\"\"\n",
        "    Complete pipeline to extract medical entities from dataframe.\n",
        "    \n",
        "    Args:\n",
        "        df: dataframe with medical text\n",
        "        text_column: Column containing the text (NOW REQUIRED, NO DEFAULT)\n",
        "        model_name: Which ScispaCy model to use\n",
        "        batch_size: Batch size for processing\n",
        "    \n",
        "    Returns:\n",
        "        entities_df: DataFrame with all extracted entities\n",
        "        summary: Summary statistics\n",
        "        rules: Generated labeling functions\n",
        "    \"\"\"\n",
        "\n",
        "    if text_column not in df.columns:\n",
        "        raise ValueError(f\"Column '{text_column}' not found in dataframe.\")\n",
        "    # Wire stages together: instantiate, extract, summarize, build rules, return\n",
        "    extractor = MedicalEntityExtractor(model_name=model_name, batch_size=batch_size)\n",
        "    entities_df = extractor.extract_entities_from_df(\n",
        "        df, text_column, id_column=id_column\n",
        "    )\n",
        "    summary = extractor.get_entity_summary(entities_df)\n",
        "    frequent_entities, entity_groups = analyze_medical_entities(entities_df)\n",
        "    rules = create_entity_based_rules(entities_df, source_column=text_column)\n",
        "    return entities_df, summary, rules\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXFksOxYy3nJ"
      },
      "source": [
        "#### Extracting Entities From Patient Medical Record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        },
        "id": "AGXyAGvVGsRo",
        "outputId": "c2c61f27-c2c1-4b3f-bdfe-d1c19d76075e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>has_medical_history</th>\n",
              "      <th>physiological context</th>\n",
              "      <th>psychological context</th>\n",
              "      <th>vaccination history</th>\n",
              "      <th>allergies</th>\n",
              "      <th>exercise frequency</th>\n",
              "      <th>nutrition</th>\n",
              "      <th>sexual history</th>\n",
              "      <th>alcohol consumption</th>\n",
              "      <th>drug usage</th>\n",
              "      <th>smoking status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155216</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Diagnosed with bipolar affective disorder at t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133948</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Intensifying feelings of helplessness</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80176</td>\n",
              "      <td>True</td>\n",
              "      <td>History of left elbow arthrodesis performed fo...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72232</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>31864</td>\n",
              "      <td>True</td>\n",
              "      <td>Inability to walk since babyhood, did not walk...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Got married at the age of 15 and became pregna...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>26809</td>\n",
              "      <td>True</td>\n",
              "      <td>Normal Apgar score, no resuscitation required ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>149866</td>\n",
              "      <td>True</td>\n",
              "      <td>Coxa vara deformity of bilateral hips, bilater...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>87064</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Patient could not realize that his symptoms mi...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>123006</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>119317</td>\n",
              "      <td>True</td>\n",
              "      <td>Born at full term by spontaneous vaginal deliv...</td>\n",
              "      <td>Mentally healthy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>92167</td>\n",
              "      <td>True</td>\n",
              "      <td>Colorectal carcinoma treated by rectum and ile...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>42234</td>\n",
              "      <td>True</td>\n",
              "      <td>Healthy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>92105</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>89665</td>\n",
              "      <td>True</td>\n",
              "      <td>Hypertension, Hyperlipidaemia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>149815</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>91779</td>\n",
              "      <td>True</td>\n",
              "      <td>Nondiabetic and nonhypertensive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>146172</td>\n",
              "      <td>True</td>\n",
              "      <td>Otherwise healthy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>89642</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>90928</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Parental distress</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>43555</td>\n",
              "      <td>True</td>\n",
              "      <td>Past medical history significant for RCC, init...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>129465</td>\n",
              "      <td>True</td>\n",
              "      <td>Hypertension, type 2 diabetes, invasive ductal...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>80892</td>\n",
              "      <td>True</td>\n",
              "      <td>Diagnosed with a type of muscular dystrophy at...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>80727</td>\n",
              "      <td>True</td>\n",
              "      <td>Complete heart block, had dual chamber pacemak...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>49286</td>\n",
              "      <td>True</td>\n",
              "      <td>Hypertension, dyslipidemia, traumatic lumbar f...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>159059</td>\n",
              "      <td>True</td>\n",
              "      <td>Born at full term with normal delivery, normal...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>18630</td>\n",
              "      <td>True</td>\n",
              "      <td>gravidity 3, parity 2, no medical problems dur...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>168381</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>45433</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Known to local mental health services for 20 y...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>76225</td>\n",
              "      <td>True</td>\n",
              "      <td>Diagnosed with a left ICA occlusion at an oute...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>88707</td>\n",
              "      <td>True</td>\n",
              "      <td>Three separate left breast biopsies in the pas...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       idx  has_medical_history  \\\n",
              "0   155216                 True   \n",
              "2   133948                 True   \n",
              "3    80176                 True   \n",
              "4    72232                 True   \n",
              "5    31864                 True   \n",
              "6    26809                 True   \n",
              "7   149866                 True   \n",
              "8    87064                 True   \n",
              "9   123006                 True   \n",
              "10  119317                 True   \n",
              "11   92167                 True   \n",
              "12   42234                 True   \n",
              "13   92105                 True   \n",
              "14   89665                 True   \n",
              "15  149815                 True   \n",
              "16   91779                 True   \n",
              "17  146172                 True   \n",
              "18   89642                 True   \n",
              "19   90928                 True   \n",
              "20   43555                 True   \n",
              "21  129465                 True   \n",
              "22   80892                 True   \n",
              "23   80727                 True   \n",
              "24   49286                 True   \n",
              "25  159059                 True   \n",
              "26   18630                 True   \n",
              "27  168381                 True   \n",
              "28   45433                 True   \n",
              "29   76225                 True   \n",
              "30   88707                 True   \n",
              "\n",
              "                                physiological context  \\\n",
              "0                                                 NaN   \n",
              "2                                                 NaN   \n",
              "3   History of left elbow arthrodesis performed fo...   \n",
              "4                                                 NaN   \n",
              "5   Inability to walk since babyhood, did not walk...   \n",
              "6   Normal Apgar score, no resuscitation required ...   \n",
              "7   Coxa vara deformity of bilateral hips, bilater...   \n",
              "8                                                 NaN   \n",
              "9                                                 NaN   \n",
              "10  Born at full term by spontaneous vaginal deliv...   \n",
              "11  Colorectal carcinoma treated by rectum and ile...   \n",
              "12                                            Healthy   \n",
              "13                                                NaN   \n",
              "14                      Hypertension, Hyperlipidaemia   \n",
              "15                                                NaN   \n",
              "16                    Nondiabetic and nonhypertensive   \n",
              "17                                  Otherwise healthy   \n",
              "18                                                NaN   \n",
              "19                                                NaN   \n",
              "20  Past medical history significant for RCC, init...   \n",
              "21  Hypertension, type 2 diabetes, invasive ductal...   \n",
              "22  Diagnosed with a type of muscular dystrophy at...   \n",
              "23  Complete heart block, had dual chamber pacemak...   \n",
              "24  Hypertension, dyslipidemia, traumatic lumbar f...   \n",
              "25  Born at full term with normal delivery, normal...   \n",
              "26  gravidity 3, parity 2, no medical problems dur...   \n",
              "27                                                NaN   \n",
              "28                                                NaN   \n",
              "29  Diagnosed with a left ICA occlusion at an oute...   \n",
              "30  Three separate left breast biopsies in the pas...   \n",
              "\n",
              "                                psychological context vaccination history  \\\n",
              "0   Diagnosed with bipolar affective disorder at t...                 NaN   \n",
              "2               Intensifying feelings of helplessness                 NaN   \n",
              "3                                                 NaN                 NaN   \n",
              "4                                                 NaN                 NaN   \n",
              "5                                                 NaN                 NaN   \n",
              "6                                                 NaN                 NaN   \n",
              "7                                                 NaN                 NaN   \n",
              "8   Patient could not realize that his symptoms mi...                 NaN   \n",
              "9                                                 NaN                 NaN   \n",
              "10                                   Mentally healthy                 NaN   \n",
              "11                                                NaN                 NaN   \n",
              "12                                                NaN                 NaN   \n",
              "13                                                NaN                 NaN   \n",
              "14                                                NaN                 NaN   \n",
              "15                                                NaN                 NaN   \n",
              "16                                                NaN                 NaN   \n",
              "17                                                NaN                 NaN   \n",
              "18                                                NaN                 NaN   \n",
              "19                                  Parental distress                 NaN   \n",
              "20                                                NaN                 NaN   \n",
              "21                                                NaN                 NaN   \n",
              "22                                                NaN                 NaN   \n",
              "23                                                NaN                 NaN   \n",
              "24                                                NaN                 NaN   \n",
              "25                                                NaN                 NaN   \n",
              "26                                                NaN                 NaN   \n",
              "27                                                NaN                 NaN   \n",
              "28  Known to local mental health services for 20 y...                 NaN   \n",
              "29                                                NaN                 NaN   \n",
              "30                                                NaN                 NaN   \n",
              "\n",
              "   allergies exercise frequency nutrition  \\\n",
              "0        NaN                NaN       NaN   \n",
              "2        NaN                NaN       NaN   \n",
              "3        NaN                NaN       NaN   \n",
              "4        NaN                NaN       NaN   \n",
              "5        NaN                NaN       NaN   \n",
              "6        NaN                NaN       NaN   \n",
              "7        NaN                NaN       NaN   \n",
              "8        NaN                NaN       NaN   \n",
              "9        NaN                NaN       NaN   \n",
              "10       NaN                NaN       NaN   \n",
              "11       NaN                NaN       NaN   \n",
              "12       NaN                NaN       NaN   \n",
              "13       NaN                NaN       NaN   \n",
              "14       NaN                NaN       NaN   \n",
              "15       NaN                NaN       NaN   \n",
              "16       NaN                NaN       NaN   \n",
              "17       NaN                NaN       NaN   \n",
              "18       NaN                NaN       NaN   \n",
              "19       NaN                NaN       NaN   \n",
              "20       NaN                NaN       NaN   \n",
              "21       NaN                NaN       NaN   \n",
              "22       NaN                NaN       NaN   \n",
              "23       NaN                NaN       NaN   \n",
              "24       NaN                NaN       NaN   \n",
              "25       NaN                NaN       NaN   \n",
              "26       NaN                NaN       NaN   \n",
              "27       NaN                NaN       NaN   \n",
              "28       NaN                NaN       NaN   \n",
              "29       NaN                NaN       NaN   \n",
              "30       NaN                NaN       NaN   \n",
              "\n",
              "                                       sexual history alcohol consumption  \\\n",
              "0                                                 NaN                 NaN   \n",
              "2                                                 NaN                 NaN   \n",
              "3                                                 NaN                 NaN   \n",
              "4                                                 NaN                 NaN   \n",
              "5   Got married at the age of 15 and became pregna...                 NaN   \n",
              "6                                                 NaN                 NaN   \n",
              "7                                                 NaN                 NaN   \n",
              "8                                                 NaN                 NaN   \n",
              "9                                                 NaN                 NaN   \n",
              "10                                                NaN                 NaN   \n",
              "11                                                NaN                 NaN   \n",
              "12                                                NaN                 NaN   \n",
              "13                                                NaN                 NaN   \n",
              "14                                                NaN                 NaN   \n",
              "15                                                NaN                 NaN   \n",
              "16                                                NaN                 NaN   \n",
              "17                                                NaN                 NaN   \n",
              "18                                                NaN                 NaN   \n",
              "19                                                NaN                 NaN   \n",
              "20                                                NaN                 NaN   \n",
              "21                                                NaN                 NaN   \n",
              "22                                                NaN                 NaN   \n",
              "23                                                NaN                 NaN   \n",
              "24                                                NaN                 NaN   \n",
              "25                                                NaN                 NaN   \n",
              "26                                                NaN                 NaN   \n",
              "27                                                NaN                 NaN   \n",
              "28                                                NaN                 NaN   \n",
              "29                                                NaN                 NaN   \n",
              "30                                                NaN                 NaN   \n",
              "\n",
              "   drug usage smoking status  \n",
              "0         NaN            NaN  \n",
              "2         NaN            NaN  \n",
              "3         NaN            NaN  \n",
              "4         NaN            NaN  \n",
              "5         NaN            NaN  \n",
              "6         NaN            NaN  \n",
              "7         NaN            NaN  \n",
              "8         NaN            NaN  \n",
              "9         NaN            NaN  \n",
              "10        NaN            NaN  \n",
              "11        NaN            NaN  \n",
              "12        NaN            NaN  \n",
              "13        NaN            NaN  \n",
              "14        NaN            NaN  \n",
              "15        NaN            NaN  \n",
              "16        NaN            NaN  \n",
              "17        NaN            NaN  \n",
              "18        NaN            NaN  \n",
              "19        NaN            NaN  \n",
              "20        NaN            NaN  \n",
              "21        NaN            NaN  \n",
              "22        NaN            NaN  \n",
              "23        NaN            NaN  \n",
              "24        NaN            NaN  \n",
              "25        NaN            NaN  \n",
              "26        NaN            NaN  \n",
              "27        NaN            NaN  \n",
              "28        NaN            NaN  \n",
              "29        NaN            NaN  \n",
              "30        NaN            NaN  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_medical.head(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "psychological context\n",
              "Depression                                                               85\n",
              "Bipolar disorder                                                         30\n",
              "Schizophrenia                                                            29\n",
              "Anxiety                                                                  27\n",
              "No significant psychosocial history                                      14\n",
              "                                                                         ..\n",
              "Paranoid schizophrenia and bipolar disorder                               1\n",
              "Mentally retarded with aggressive behavior                                1\n",
              "Mental retardation grade 2, intelligence quotient of 23                   1\n",
              "mild phantom limb pain and very frequent nonpainful phantom sensation     1\n",
              "Exhibiting a tortured expression                                          1\n",
              "Name: count, Length: 2231, dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_medical['psychological context'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lrp60uMUy-bz"
      },
      "source": [
        "##### Physiological Contexts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading en_ner_bc5cdr_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 29755 texts in 60 batches...\n",
            "Using model: en_ner_bc5cdr_md for column: physiological context\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   2%|▏         | 1/60 [00:01<01:15,  1.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  18%|█▊        | 11/60 [00:11<00:49,  1.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 5000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  35%|███▌      | 21/60 [00:20<00:38,  1.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 10000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  52%|█████▏    | 31/60 [00:30<00:28,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  68%|██████▊   | 41/60 [00:42<00:27,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 20000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  85%|████████▌ | 51/60 [00:53<00:09,  1.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 25000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 60/60 [01:00<00:00,  1.01s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1249 entities appearing >= 5 times\n",
            "\n",
            "Testing generated labeling functions on df_physiological...\n",
            "lf_disease_physiological_context applied to row 0: ABSTAIN\n",
            "lf_chemical_physiological_context applied to row 0: ABSTAIN\n",
            "\n",
            "=== DEBUG: Check extracted entities dataframe ===\n",
            "Shape of df_physiological_entities: (36272, 7)\n",
            "\n",
            "Column names: ['text', 'label', 'start', 'end', 'original_text', 'row_idx', 'source_column']\n",
            "\n",
            "First few rows:\n",
            "                      text    label  start  end  \\\n",
            "0  posttraumatic arthritis  DISEASE     48   71   \n",
            "1                     pain  DISEASE    116  120   \n",
            "2                 fracture  DISEASE    151  159   \n",
            "3      Coxa vara deformity  DISEASE      0   19   \n",
            "4                 fracture  DISEASE     75   83   \n",
            "\n",
            "                                       original_text  row_idx  \\\n",
            "0  History of left elbow arthrodesis performed fo...    80176   \n",
            "1  Inability to walk since babyhood, did not walk...    31864   \n",
            "2  Inability to walk since babyhood, did not walk...    31864   \n",
            "3  Coxa vara deformity of bilateral hips, bilater...   149866   \n",
            "4  Coxa vara deformity of bilateral hips, bilater...   149866   \n",
            "\n",
            "           source_column  \n",
            "0  physiological context  \n",
            "1  physiological context  \n",
            "2  physiological context  \n",
            "3  physiological context  \n",
            "4  physiological context  \n",
            "\n",
            "=== Entity Labels Found in df_physiological_entities ===\n",
            "label\n",
            "DISEASE     34647\n",
            "CHEMICAL     1625\n",
            "Name: count, dtype: int64\n",
            "\n",
            "============================================================\n",
            "CUSTOM ANATOMY EXTRACTION FOR PHYSIOLOGICAL CONTEXT\n",
            "============================================================\n",
            "\n",
            "Extracting anatomy entities...\n",
            "\n",
            "Custom anatomy extraction found 23931 anatomy mentions\n",
            "\n",
            "=== Anatomy Entity Distribution ===\n",
            "label\n",
            "ANATOMY                                  20851\n",
            "ANATOMY_WITH_LATERALITY                   2576\n",
            "ANATOMY_WITH_DIRECTION                     438\n",
            "ANATOMY_WITH_LATERALITY_AND_DIRECTION       66\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Anatomy Terms ===\n",
            "text\n",
            "back          1631\n",
            "pulmonary     1524\n",
            "artery        1298\n",
            "kidney        1209\n",
            "heart         1204\n",
            "abdominal     1157\n",
            "liver          877\n",
            "valve          689\n",
            "lung           605\n",
            "neck           456\n",
            "skin           441\n",
            "cardiac        424\n",
            "blood          419\n",
            "knee           416\n",
            "bladder        409\n",
            "colon          381\n",
            "cerebral       380\n",
            "prostate       376\n",
            "bone           370\n",
            "coronary       342\n",
            "thyroid        339\n",
            "left eye       310\n",
            "limb           296\n",
            "joint          267\n",
            "chest          253\n",
            "brain          219\n",
            "hip            219\n",
            "lymph node     198\n",
            "lobe           196\n",
            "spine          195\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Anatomy by Category ===\n",
            "category\n",
            "organs            7529\n",
            "cardiovascular    5363\n",
            "joints            4388\n",
            "tissues           1605\n",
            "muscles           1587\n",
            "bones             1567\n",
            "regions           1016\n",
            "neurological       876\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Examples of Anatomy with Laterality ===\n",
            "          text laterality anatomy\n",
            "0   left elbow       left   elbow\n",
            "1   left elbow       left   elbow\n",
            "2   left elbow       left   elbow\n",
            "35   right eye      right     eye\n",
            "36    left hip       left     hip\n",
            "42    left hip       left     hip\n",
            "43    left hip       left     hip\n",
            "44    left hip       left     hip\n",
            "46   left knee       left    knee\n",
            "47    left hip       left     hip\n",
            "\n",
            "=== COMBINING BC5CDR AND CUSTOM ENTITIES ===\n",
            "\n",
            "Total combined entities: 60203\n",
            "\n",
            "Combined entity distribution:\n",
            "label\n",
            "DISEASE                                  34647\n",
            "ANATOMY                                  20851\n",
            "ANATOMY_WITH_LATERALITY                   2576\n",
            "CHEMICAL                                  1625\n",
            "ANATOMY_WITH_DIRECTION                     438\n",
            "ANATOMY_WITH_LATERALITY_AND_DIRECTION       66\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Creating Anatomy-Specific Labeling Functions ===\n",
            "\n",
            "Testing anatomy labeling functions:\n",
            "\n",
            "Applying labeling functions to all rows...\n",
            "\n",
            "cardiac_anatomy:\n",
            "  - Total labeled: 2013\n",
            "  - Distribution: {'CARDIAC_ANATOMY': 2013}\n",
            "\n",
            "musculoskeletal:\n",
            "  - Total labeled: 1039\n",
            "  - Distribution: {'MUSCULOSKELETAL': 1039}\n",
            "\n",
            "bilateral_anatomy:\n",
            "  - Total labeled: 539\n",
            "  - Distribution: {'BILATERAL_CONDITION': 539}\n",
            "\n",
            "neurological_anatomy:\n",
            "  - Total labeled: 629\n",
            "  - Distribution: {'NEUROLOGICAL_ANATOMY': 629}\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Run extraction for the 'physiological context' column\n",
        "    df_physiological_entities, disease_summary, rules = run_medical_ner_extraction(\n",
        "        df_medical,\n",
        "        text_column='physiological context',\n",
        "        model_name=\"en_ner_bc5cdr_md\",\n",
        "        batch_size=500,\n",
        "        id_column='idx')\n",
        "    \n",
        "    # Test the generated rules\n",
        "    print(\"\\nTesting generated labeling functions on df_physiological...\")\n",
        "    \n",
        "    # Select a sample row from the original df_medical to test the rules\n",
        "    # Ensure df_medical is not empty before accessing iloc[0]\n",
        "    if not df_medical.empty:\n",
        "        sample_row = df_medical.iloc[0]\n",
        "        \n",
        "        for rule_name, rule_func in rules.items():\n",
        "            # Apply the rule function to a row from the original df_medical\n",
        "            try:\n",
        "                test_result = rule_func(sample_row)\n",
        "                print(f\"{rule_name} applied to row 0: {test_result}\")\n",
        "            except KeyError as e:\n",
        "                print(f\"Error applying rule {rule_name}: {e}. Make sure the column '{e}' exists in df_medical.\")\n",
        "    else:\n",
        "        print(\"df_medical is empty, cannot test rules.\")\n",
        "    \n",
        "    print(\"\\n=== DEBUG: Check extracted entities dataframe ===\")\n",
        "    print(f\"Shape of df_physiological_entities: {df_physiological_entities.shape}\")\n",
        "    print(f\"\\nColumn names: {df_physiological_entities.columns.tolist()}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(df_physiological_entities.head())\n",
        "    \n",
        "    # Check what labels ScispaCy actually found in the entities dataframe\n",
        "    print(\"\\n=== Entity Labels Found in df_physiological_entities ===\")\n",
        "    if not df_physiological_entities.empty:\n",
        "        print(df_physiological_entities['label'].value_counts())\n",
        "    else:\n",
        "        print(\"df_physiological_entities is empty.\")\n",
        "    \n",
        "    # ============= CUSTOM ANATOMY EXTRACTION =============\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"CUSTOM ANATOMY EXTRACTION FOR PHYSIOLOGICAL CONTEXT\")\n",
        "    print(\"=\"*60)\n",
        "    # Comprehensive anatomy patterns\n",
        "    anatomy_patterns = {\n",
        "            'organs': [\n",
        "                'heart', 'lung', 'lungs', 'liver', 'kidney', 'kidneys', 'brain', \n",
        "                'pancreas', 'spleen', 'stomach', 'intestine', 'colon', 'bladder',\n",
        "                'gallbladder', 'thyroid', 'prostate', 'uterus', 'ovary', 'ovaries','esophagus',\n",
        "                'trachea','larynx','pharynx','adrenal glands','pituitary','hypothalamus','pineal gland',\n",
        "                'testes','appendix','rectum','ear','eye'\n",
        "            ],\n",
        "            'bones': [\n",
        "                'bone', 'femur', 'tibia', 'fibula', 'humerus', 'radius', 'ulna',\n",
        "                'skull', 'spine', 'vertebra', 'vertebrae', 'rib', 'ribs', 'pelvis',\n",
        "                'clavicle', 'scapula', 'sternum', 'patella','metacarpal','metatarsal','phalanges','mandible','maxilla',\n",
        "                'sacrum','coccyx','carpals','tarsals'\n",
        "            ],\n",
        "            'joints': [\n",
        "                'joint', 'hip', 'knee', 'shoulder', 'elbow', 'wrist', 'ankle',\n",
        "                'knuckle', 'finger', 'toe', 'neck', 'back'\n",
        "            ],\n",
        "            'cardiovascular': [\n",
        "                'artery', 'arteries', 'vein', 'veins', 'vessel', 'vessels',\n",
        "                'aorta', 'carotid', 'coronary', 'pulmonary', 'cardiac',\n",
        "                'ventricle', 'atrium', 'valve','capillary','myocardium','pericardium','endocardium','septum',\n",
        "                'vena cava', 'jugular','femoral','subclavian'\n",
        "            ],\n",
        "            'neurological': [\n",
        "                'nerve', 'nerves', 'neural', 'spinal cord', 'brainstem',\n",
        "                'cerebral', 'cerebellum', 'cortex', 'lobe', 'ganglion','neuron','axon','dendrite','hypothalamus','thalamus','hippocampus',\n",
        "                'plexus','peripheral nerve','mengines','dura', 'pia mater'\n",
        "            ],\n",
        "            'muscles': [\n",
        "                'muscle', 'muscles', 'tendon', 'ligament', 'fascia',\n",
        "                'biceps', 'triceps', 'quadriceps', 'hamstring','deltoid','pectoral','gluteus','abdominal','calf','gastrocnemius','diaphragm','flexor','extensor'\n",
        "            ],\n",
        "            'regions': [\n",
        "                'chest', 'abdomen', 'pelvis', 'thorax', 'cranium',\n",
        "                'extremity', 'limb', 'upper extremity', 'lower extremity','groin','axilla','mediastinum','peritoneum','retroperitoneum'\n",
        "            ],\n",
        "            'tissues': [\n",
        "                'skin', 'tissue', 'membrane', 'mucosa', 'epithelium',\n",
        "                'cartilage', 'marrow', 'lymph node', 'gland','blood',\n",
        "                'plasma','connective tissue','adipose','fascia'\n",
        "            ]\n",
        "        }\n",
        "    # Laterality terms\n",
        "    laterality_terms = ['left', 'right', 'bilateral', 'unilateral']\n",
        "    # Direction terms\n",
        "    direction_terms = ['anterior', 'posterior', 'superior', 'inferior', 'medial', 'lateral', 'proximal', 'distal','ventral', 'dorsal', \n",
        "        'cranial', 'caudal', 'superficial', 'deep', 'central', 'peripheral']    \n",
        "    def extract_anatomy_from_physiological_context(df_medical, text_column, id_column='idx'):\n",
        "        \"\"\"Hard-coded weak labelers: Extract anatomy entities from physiological context that BC5CDR might miss\"\"\"\n",
        "         # build the id series once\n",
        "        if id_column is not None and id_column in df_medical.columns:\n",
        "            ids_series = df_medical[id_column].where(pd.notna(df_medical[id_column]), df_medical.index)\n",
        "        else:\n",
        "            ids_series = df_medical.index\n",
        "\n",
        "        texts = df_medical[text_column].fillna('').astype(str)\n",
        "        all_anatomy = []\n",
        "        for category, terms in anatomy_patterns.items():\n",
        "            # add all terms to anatomy list & sort by length\n",
        "            all_anatomy.extend(terms)\n",
        "        all_anatomy.sort(key=len, reverse=True)\n",
        "        # Build pattern components\n",
        "        lat_pattern = '|'.join(laterality_terms) # Escape special regex characters and join with |\n",
        "        dir_pattern = '|'.join(direction_terms)\n",
        "    \n",
        "        # Handle multi-word anatomy terms\n",
        "        anatomy_pattern = '|'.join(re.escape(term).replace(r'\\ ', r'\\s+') for term in all_anatomy)\n",
        "        # Build comprehensive regex patterns\n",
        "        combined_pattern_regex = re.compile(rf'\\b(({lat_pattern})\\s+)?(({dir_pattern})\\s+)?({anatomy_pattern})\\b', re.IGNORECASE)        \n",
        "\n",
        "        # Process each row\n",
        "        anatomy_entities = []\n",
        "        for (df_index, text_original), idx in zip(texts.items(), ids_series): # Parallel iteration: texts.items() yields (index, value) pairs. Paired with the IDs via zip\n",
        "            if text_original:\n",
        "                text = text_original.lower()\n",
        "\n",
        "                # Extract anatomy terms\n",
        "                for match in combined_pattern_regex.finditer(text): \n",
        "                    full_term = match.group(0)\n",
        "                    laterality = match.group(2)  # Laterality\n",
        "                    direction = match.group(4)  # Direction\n",
        "\n",
        "                # Normalize multi-space anatomy terms\n",
        "                anatomy = match.group(5)  \n",
        "                anatomy_normalized = ' '.join(anatomy.split())\n",
        "\n",
        "                # Determine category\n",
        "                category = None\n",
        "                for cat, terms in anatomy_patterns.items():\n",
        "                    if any(anatomy_normalized == term.lower() for term in terms):\n",
        "                        category = cat\n",
        "                        break\n",
        "                \n",
        "                # Determine label based on modifiers present\n",
        "                if laterality and direction:\n",
        "                    label = 'ANATOMY_WITH_LATERALITY_AND_DIRECTION'\n",
        "                elif laterality:\n",
        "                    label = 'ANATOMY_WITH_LATERALITY'\n",
        "                elif direction:\n",
        "                    label = 'ANATOMY_WITH_DIRECTION'\n",
        "                else:\n",
        "                    label = 'ANATOMY'\n",
        "                \n",
        "                # Build entity record\n",
        "                entity = {\n",
        "                    'text': full_term,\n",
        "                    'label': label,\n",
        "                    'category': category,\n",
        "                    'anatomy': anatomy_normalized,\n",
        "                    'start': match.start(),\n",
        "                    'end': match.end(),\n",
        "                    'original_text': text_original,  # Use original case\n",
        "                    'source': 'custom_anatomy_extraction',\n",
        "                    'row_idx': idx\n",
        "                }\n",
        "                \n",
        "                # Add modifiers if present\n",
        "                if laterality:\n",
        "                    entity['laterality'] = laterality\n",
        "                if direction:\n",
        "                    entity['direction'] = direction\n",
        "                \n",
        "                anatomy_entities.append(entity)\n",
        "    \n",
        "        return pd.DataFrame(anatomy_entities)\n",
        "\n",
        "                            \n",
        "    \n",
        "    # Extract custom anatomy entities\n",
        "    print(\"\\nExtracting anatomy entities...\")\n",
        "    df_anatomy_custom = extract_anatomy_from_physiological_context(df_medical, text_column='physiological context', id_column='idx')\n",
        "    \n",
        "    print(f\"\\nCustom anatomy extraction found {len(df_anatomy_custom)} anatomy mentions\")\n",
        "    \n",
        "    if not df_anatomy_custom.empty:\n",
        "        print(\"\\n=== Anatomy Entity Distribution ===\")\n",
        "        print(df_anatomy_custom['label'].value_counts())\n",
        "        \n",
        "        print(\"\\n=== Top Anatomy Terms ===\")\n",
        "        print(df_anatomy_custom['text'].value_counts().head(30))\n",
        "        \n",
        "        print(\"\\n=== Anatomy by Category ===\")\n",
        "        print(df_anatomy_custom['category'].value_counts())\n",
        "        \n",
        "        # Show examples of laterality\n",
        "        laterality_examples = df_anatomy_custom[df_anatomy_custom['label'] == 'ANATOMY_WITH_LATERALITY']\n",
        "        if not laterality_examples.empty:\n",
        "            print(\"\\n=== Examples of Anatomy with Laterality ===\")\n",
        "            print(laterality_examples[['text', 'laterality', 'anatomy']].head(10))\n",
        "    \n",
        "    # Combine BC5CDR entities with custom anatomy entities\n",
        "    print(\"\\n=== COMBINING BC5CDR AND CUSTOM ENTITIES ===\")\n",
        "    df_all_physiological_entities = pd.concat([\n",
        "        df_physiological_entities,\n",
        "        df_anatomy_custom[['text', 'label', 'start', 'end', 'original_text']]\n",
        "    ], ignore_index=True)\n",
        "    \n",
        "    print(f\"\\nTotal combined entities: {len(df_all_physiological_entities)}\")\n",
        "    print(\"\\nCombined entity distribution:\")\n",
        "    print(df_all_physiological_entities['label'].value_counts())\n",
        "    \n",
        "    # Create anatomy-specific labeling functions\n",
        "    print(\"\\n=== Creating Anatomy-Specific Labeling Functions ===\")\n",
        "    \n",
        "    def create_anatomy_labeling_functions():\n",
        "        \"\"\"Create labeling functions for anatomy patterns\"\"\"\n",
        "        cardiac_terms = anatomy_patterns['cardiovascular']\n",
        "        msk_terms = anatomy_patterns['muscles'] + anatomy_patterns['bones'] + anatomy_patterns['joints']\n",
        "        neuro_terms = anatomy_patterns['neurological']  \n",
        "        laterality = laterality_terms\n",
        "        def lf_cardiac_anatomy(row):\n",
        "            text = str(row.get('physiological context', '')).lower()\n",
        "            if any(term in text for term in cardiac_terms):\n",
        "                return 'CARDIAC_ANATOMY'\n",
        "            return 'ABSTAIN'\n",
        "        \n",
        "        def lf_musculoskeletal(row):\n",
        "            text = str(row.get('physiological context', '')).lower()\n",
        "            msk_terms = ['bone', 'joint', 'muscle', 'tendon', 'ligament', 'cartilage', 'diaphysis', 'femur', 'tibia', 'fibula', 'humerus', 'radius', 'ulna', 'skull', \n",
        "            'spine', 'vertebra', 'vertebrae', 'rib', 'ribs', 'pelvis', 'flexor', 'extensor', 'meniscus']\n",
        "            if any(term in text for term in msk_terms):\n",
        "                return 'MUSCULOSKELETAL'\n",
        "            return 'ABSTAIN'\n",
        "        \n",
        "        def lf_bilateral_anatomy(row):\n",
        "            text = str(row.get('physiological context', '')).lower()\n",
        "            if 'bilateral' in text:\n",
        "                return 'BILATERAL_CONDITION'\n",
        "            return 'ABSTAIN'\n",
        "        \n",
        "        def lf_neurological_anatomy(row):\n",
        "            text = str(row.get('physiological context', '')).lower()\n",
        "            neuro_terms = ['brain', 'nerve', 'neural', 'spinal', 'cerebral', 'cerebrum', 'brainstem', 'neuron', 'lobe', 'cerebellum', 'cortex', 'ganglion']\n",
        "            if any(term in text for term in neuro_terms):\n",
        "                return 'NEUROLOGICAL_ANATOMY'\n",
        "            return 'ABSTAIN'\n",
        "        \n",
        "        return [lf_cardiac_anatomy, lf_musculoskeletal, lf_bilateral_anatomy, lf_neurological_anatomy]\n",
        "    \n",
        "    # Test anatomy labeling functions\n",
        "    anatomy_lfs = create_anatomy_labeling_functions()\n",
        "    \n",
        "    print(\"\\nTesting anatomy labeling functions:\")\n",
        "if not df_medical.empty:\n",
        "    print(\"\\nApplying labeling functions to all rows...\")\n",
        "    \n",
        "    for lf in anatomy_lfs:\n",
        "        # Create cleaner column name\n",
        "        label_name = lf.__name__.replace('lf_', '')\n",
        "        \n",
        "        # Apply to all rows\n",
        "        df_medical[label_name] = df_medical.apply(lf, axis=1)\n",
        "        \n",
        "        # Show statistics\n",
        "        value_counts = df_medical[label_name].value_counts()\n",
        "        non_abstain = value_counts.drop('ABSTAIN', errors='ignore')\n",
        "        \n",
        "        if not non_abstain.empty:\n",
        "            print(f\"\\n{label_name}:\")\n",
        "            print(f\"  - Total labeled: {non_abstain.sum()}\")\n",
        "            print(f\"  - Distribution: {non_abstain.to_dict()}\")\n",
        "    keep_cols = ['text','label','start','end','original_text','row_idx','category']\n",
        "    df_all_physiological_entities = pd.concat(\n",
        "    [df_physiological_entities, df_anatomy_custom[keep_cols]],\n",
        "    ignore_index=True\n",
        ")\n",
        "    \n",
        "    # Save combined results\n",
        "    df_all_physiological_entities.to_csv('physiological_entities_comprehensive.csv', index=False)\n",
        "    df_anatomy_custom.to_csv('anatomy_entities_detailed.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _first_hit(text, terms, case_sensitive=False, word_boundaries=True):\n",
        "    \"\"\"Helper function to find first matching term in text\"\"\"\n",
        "    if not case_sensitive:\n",
        "        text = text.lower()\n",
        "        terms = [t.lower() for t in terms]\n",
        "    \n",
        "    for t in terms:\n",
        "        if word_boundaries:\n",
        "            import re\n",
        "            pattern = r'\\b' + re.escape(t) + r'\\b'\n",
        "            if re.search(pattern, text):\n",
        "                return t\n",
        "        else:\n",
        "            if t in text:\n",
        "                return t\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting anatomy entities...\n",
            "\n",
            "Custom anatomy extraction found 11614 anatomy mentions\n",
            "\n",
            "=== Creating and Applying Labeling Functions ===\n",
            "\n",
            "Labeling functions generated 3873 span entities\n",
            "\n",
            "=== LF-Generated Spans Distribution ===\n",
            "label\n",
            "CARDIAC_ANATOMY         1971\n",
            "MUSCULOSKELETAL          802\n",
            "NEUROLOGICAL_ANATOMY     567\n",
            "BILATERAL_CONDITION      533\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Sample LF Spans ===\n",
            "             text                label                   source\n",
            "0           femur      MUSCULOSKELETAL    lf:lf_musculoskeletal\n",
            "1  bilateral hips  BILATERAL_CONDITION  lf:lf_bilateral_anatomy\n",
            "2          muscle      MUSCULOSKELETAL    lf:lf_musculoskeletal\n",
            "3           heart      CARDIAC_ANATOMY    lf:lf_cardiac_anatomy\n",
            "4           heart      CARDIAC_ANATOMY    lf:lf_cardiac_anatomy\n",
            "5           spine      MUSCULOSKELETAL    lf:lf_musculoskeletal\n",
            "6        Coronary      CARDIAC_ANATOMY    lf:lf_cardiac_anatomy\n",
            "7        coronary      CARDIAC_ANATOMY    lf:lf_cardiac_anatomy\n",
            "8        coronary      CARDIAC_ANATOMY    lf:lf_cardiac_anatomy\n",
            "9        coronary      CARDIAC_ANATOMY    lf:lf_cardiac_anatomy\n",
            "\n",
            "=== Row-Level Analysis from Labeling Functions ===\n",
            "\n",
            "Labeling function coverage:\n",
            "  lf_cardiac_anatomy: 1741 rows (5.9% coverage)\n",
            "  lf_musculoskeletal: 757 rows (2.5% coverage)\n",
            "  lf_bilateral_anatomy: 539 rows (1.8% coverage)\n",
            "  lf_neurological_anatomy: 538 rows (1.8% coverage)\n",
            "\n",
            "=== COMBINING ALL ENTITY SOURCES ===\n",
            "\n",
            "Total combined entities: 51759\n",
            "\n",
            "Combined entity distribution by label:\n",
            "label\n",
            "DISEASE                                  34647\n",
            "ANATOMY                                  10046\n",
            "CARDIAC_ANATOMY                           1971\n",
            "CHEMICAL                                  1625\n",
            "ANATOMY_WITH_LATERALITY                   1289\n",
            "MUSCULOSKELETAL                            802\n",
            "NEUROLOGICAL_ANATOMY                       567\n",
            "BILATERAL_CONDITION                        533\n",
            "ANATOMY_WITH_DIRECTION                     227\n",
            "ANATOMY_WITH_LATERALITY_AND_DIRECTION       52\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Combined entity distribution by source:\n",
            "source\n",
            "bc5cdr                        36272\n",
            "custom_anatomy_extraction     11614\n",
            "lf:lf_cardiac_anatomy          1971\n",
            "lf:lf_musculoskeletal           802\n",
            "lf:lf_neurological_anatomy      567\n",
            "lf:lf_bilateral_anatomy         533\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Analysis by Entity Type ===\n",
            "\n",
            "=== CARDIAC_ANATOMY Analysis ===\n",
            "Total mentions: 1971\n",
            "Unique terms: 18\n",
            "\n",
            "Top cardiac terms:\n",
            "text\n",
            "heart        588\n",
            "coronary     486\n",
            "valve        245\n",
            "cardiac      159\n",
            "vein         133\n",
            "artery       127\n",
            "Coronary      92\n",
            "ventricle     31\n",
            "aorta         26\n",
            "veins         25\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== MUSCULOSKELETAL Analysis ===\n",
            "Total mentions: 802\n",
            "Unique terms: 26\n",
            "\n",
            "Top musculoskeletal terms:\n",
            "text\n",
            "bone        192\n",
            "joint       112\n",
            "muscle       96\n",
            "femur        83\n",
            "spine        63\n",
            "tibia        42\n",
            "tendon       30\n",
            "ligament     30\n",
            "pelvis       27\n",
            "rib          25\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Entity Source Comparison ===\n",
            "label                       ANATOMY  ANATOMY_WITH_DIRECTION  \\\n",
            "source                                                        \n",
            "bc5cdr                            0                       0   \n",
            "custom_anatomy_extraction     10046                     227   \n",
            "lf:lf_bilateral_anatomy           0                       0   \n",
            "lf:lf_cardiac_anatomy             0                       0   \n",
            "lf:lf_musculoskeletal             0                       0   \n",
            "lf:lf_neurological_anatomy        0                       0   \n",
            "\n",
            "label                       ANATOMY_WITH_LATERALITY  \\\n",
            "source                                                \n",
            "bc5cdr                                            0   \n",
            "custom_anatomy_extraction                      1289   \n",
            "lf:lf_bilateral_anatomy                           0   \n",
            "lf:lf_cardiac_anatomy                             0   \n",
            "lf:lf_musculoskeletal                             0   \n",
            "lf:lf_neurological_anatomy                        0   \n",
            "\n",
            "label                       ANATOMY_WITH_LATERALITY_AND_DIRECTION  \\\n",
            "source                                                              \n",
            "bc5cdr                                                          0   \n",
            "custom_anatomy_extraction                                      52   \n",
            "lf:lf_bilateral_anatomy                                         0   \n",
            "lf:lf_cardiac_anatomy                                           0   \n",
            "lf:lf_musculoskeletal                                           0   \n",
            "lf:lf_neurological_anatomy                                      0   \n",
            "\n",
            "label                       BILATERAL_CONDITION  CARDIAC_ANATOMY  CHEMICAL  \\\n",
            "source                                                                       \n",
            "bc5cdr                                        0                0      1625   \n",
            "custom_anatomy_extraction                     0                0         0   \n",
            "lf:lf_bilateral_anatomy                     533                0         0   \n",
            "lf:lf_cardiac_anatomy                         0             1971         0   \n",
            "lf:lf_musculoskeletal                         0                0         0   \n",
            "lf:lf_neurological_anatomy                    0                0         0   \n",
            "\n",
            "label                       DISEASE  MUSCULOSKELETAL  NEUROLOGICAL_ANATOMY  \n",
            "source                                                                      \n",
            "bc5cdr                        34647                0                     0  \n",
            "custom_anatomy_extraction         0                0                     0  \n",
            "lf:lf_bilateral_anatomy           0                0                     0  \n",
            "lf:lf_cardiac_anatomy             0                0                     0  \n",
            "lf:lf_musculoskeletal             0              802                     0  \n",
            "lf:lf_neurological_anatomy        0                0                   567  \n",
            "\n",
            "=== Adding Row-Level Phenotypes ===\n",
            "\n",
            "Row-level phenotypes added:\n",
            "  has_medical_history: 29752 rows\n",
            "  has_cardiac_anatomy: 1741 rows\n",
            "  has_musculoskeletal: 757 rows\n",
            "  has_bilateral_anatomy: 539 rows\n",
            "  has_neurological_anatomy: 538 rows\n",
            "\n",
            "\n",
            "Anatomy entity extraction complete!\n",
            "Total entities extracted: 51759\n",
            "  - BC5CDR: 36272\n",
            "  - Custom extraction: 11614\n",
            "  - LF-generated: 3873\n",
            "\n",
            "Row-level phenotypes added: 5\n",
            "\n",
            "All results saved to CSV files.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def extract_anatomy_from_physiological_context(df_medical, text_column, id_column='idx'):\n",
        "    \"\"\"Extract anatomy entities from physiological context\"\"\"\n",
        "    \n",
        "    # Build the id series once\n",
        "    if id_column is not None and id_column in df_medical.columns:\n",
        "        ids_series = df_medical[id_column].where(pd.notna(df_medical[id_column]), df_medical.index)\n",
        "    else:\n",
        "        ids_series = df_medical.index\n",
        "\n",
        "    texts = df_medical[text_column].fillna('').astype(str)\n",
        "    \n",
        "    # Comprehensive anatomy patterns\n",
        "    anatomy_patterns = {\n",
        "        'organs': [\n",
        "            'heart', 'lung', 'lungs', 'liver', 'kidney', 'kidneys', 'brain', \n",
        "            'pancreas', 'spleen', 'stomach', 'intestine', 'colon', 'bladder',\n",
        "            'gallbladder', 'thyroid', 'prostate', 'uterus', 'ovary', 'ovaries','esophagus',\n",
        "            'trachea','larynx','pharynx','adrenal glands','pituitary','hypothalamus','pineal gland',\n",
        "            'testes','appendix','rectum','ear','eye', 'spinal cord', 'lymph node'\n",
        "        ],\n",
        "        'bones': [\n",
        "            'bone', 'femur', 'tibia', 'fibula', 'humerus', 'radius', 'ulna',\n",
        "            'skull', 'spine', 'vertebra', 'vertebrae', 'rib', 'ribs', 'pelvis',\n",
        "            'clavicle', 'scapula', 'sternum', 'patella','metacarpal','metatarsal','phalanges',\n",
        "            'mandible','maxilla', 'sacrum','coccyx','carpals','tarsals'\n",
        "        ],\n",
        "        'joints': [\n",
        "            'joint', 'hip', 'knee', 'shoulder', 'elbow', 'wrist', 'ankle',\n",
        "            'knuckle', 'finger', 'toe', 'neck', 'back'\n",
        "        ],\n",
        "        'cardiovascular': [\n",
        "            'artery', 'arteries', 'vein', 'veins', 'vessel', 'vessels',\n",
        "            'aorta', 'carotid', 'coronary', 'pulmonary', 'cardiac',\n",
        "            'ventricle', 'atrium', 'valve','capillary','myocardium','pericardium',\n",
        "            'endocardium','septum', 'vena cava', 'jugular','femoral','subclavian'\n",
        "        ],\n",
        "        'neurological': [\n",
        "            'nerve', 'nerves', 'neural', 'brainstem', 'cerebral', 'cerebellum', \n",
        "            'cortex', 'lobe', 'ganglion','neuron','axon','dendrite','hypothalamus',\n",
        "            'thalamus','hippocampus', 'plexus','peripheral nerve','meninges','dura', 'pia mater'\n",
        "        ],\n",
        "        'muscles': [\n",
        "            'muscle', 'muscles', 'tendon', 'ligament', 'fascia',\n",
        "            'biceps', 'triceps', 'quadriceps', 'hamstring','deltoid','pectoral',\n",
        "            'gluteus','abdominal','calf','gastrocnemius','diaphragm','flexor','extensor'\n",
        "        ],\n",
        "        'regions': [\n",
        "            'chest', 'abdomen', 'pelvis', 'thorax', 'cranium', 'chest wall',\n",
        "            'extremity', 'limb', 'upper extremity', 'lower extremity','groin',\n",
        "            'axilla','mediastinum','peritoneum','retroperitoneum'\n",
        "        ],\n",
        "        'tissues': [\n",
        "            'skin', 'tissue', 'membrane', 'mucosa', 'epithelium',\n",
        "            'cartilage', 'marrow', 'gland','blood',\n",
        "            'plasma','connective tissue','adipose'\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    # Modifier terms\n",
        "    laterality_terms = ['left', 'right', 'bilateral', 'unilateral']\n",
        "    direction_terms = ['anterior', 'posterior', 'superior', 'inferior', 'medial', \n",
        "                    'lateral', 'proximal', 'distal','ventral', 'dorsal', \n",
        "                    'cranial', 'caudal', 'superficial', 'deep', 'central', 'peripheral']\n",
        "    \n",
        "    # Build comprehensive patterns \n",
        "    all_anatomy = []\n",
        "    for category, terms in anatomy_patterns.items():\n",
        "        all_anatomy.extend(terms)\n",
        "    all_anatomy.sort(key=len, reverse=True)\n",
        "    \n",
        "    # Build pattern components\n",
        "    lat_pattern = '|'.join(laterality_terms)\n",
        "    dir_pattern = '|'.join(direction_terms)\n",
        "    \n",
        "    # Handle multi-word anatomy terms\n",
        "    anatomy_pattern = '|'.join(re.escape(term).replace(r'\\ ', r'\\s+') for term in all_anatomy)\n",
        "    \n",
        "    # Build comprehensive regex pattern with named groups\n",
        "    combined_pattern_regex = re.compile(\n",
        "        rf'\\b(?:(?P<lat>{lat_pattern})\\s+)?(?:(?P<dir>{dir_pattern})\\s+)?(?P<anatomy>{anatomy_pattern})\\b', \n",
        "        re.IGNORECASE\n",
        "    )\n",
        "    \n",
        "    # Process each row\n",
        "    anatomy_entities = []\n",
        "    \n",
        "    for (df_index, text_original), idx in zip(texts.items(), ids_series):\n",
        "        if text_original:\n",
        "            text = text_original.lower()\n",
        "            \n",
        "            # Extract anatomy terms\n",
        "            for match in combined_pattern_regex.finditer(text):\n",
        "                full_term = match.group(0)\n",
        "                laterality = match.group('lat')\n",
        "                direction = match.group('dir')\n",
        "                anatomy = match.group('anatomy')\n",
        "                \n",
        "                # Normalize multi-space anatomy terms\n",
        "                anatomy_normalized = ' '.join(anatomy.split())\n",
        "                \n",
        "                # Determine category\n",
        "                category = None\n",
        "                for cat, terms in anatomy_patterns.items():\n",
        "                    if any(anatomy_normalized == term.lower() for term in terms):\n",
        "                        category = cat\n",
        "                        break\n",
        "                \n",
        "                # Determine label based on modifiers present\n",
        "                if laterality and direction:\n",
        "                    label = 'ANATOMY_WITH_LATERALITY_AND_DIRECTION'\n",
        "                elif laterality:\n",
        "                    label = 'ANATOMY_WITH_LATERALITY'\n",
        "                elif direction:\n",
        "                    label = 'ANATOMY_WITH_DIRECTION'\n",
        "                else:\n",
        "                    label = 'ANATOMY'\n",
        "                \n",
        "                # Build entity record\n",
        "                entity = {\n",
        "                    'text': full_term,\n",
        "                    'label': label,\n",
        "                    'category': category,\n",
        "                    'anatomy': anatomy_normalized,\n",
        "                    'start': match.start(),\n",
        "                    'end': match.end(),\n",
        "                    'original_text': text_original,\n",
        "                    'source': 'custom_anatomy_extraction',\n",
        "                    'row_idx': idx\n",
        "                }\n",
        "                \n",
        "                # Add modifiers if present\n",
        "                if laterality:\n",
        "                    entity['laterality'] = laterality\n",
        "                if direction:\n",
        "                    entity['direction'] = direction\n",
        "                \n",
        "                anatomy_entities.append(entity)\n",
        "    \n",
        "    return pd.DataFrame(anatomy_entities)\n",
        "\n",
        "\n",
        "def create_anatomy_labeling_functions():\n",
        "    \"\"\"Create labeling functions that return evidence for span creation\"\"\"\n",
        "    \n",
        "    def lf_cardiac_anatomy(row):\n",
        "        text = str(row.get('physiological context', '')).lower()\n",
        "        cardiac_terms = ['heart', 'cardiac', 'coronary', 'ventricle', 'atrium', 'valve', 'aorta', \n",
        "                        'artery', 'arteries', 'vein', 'veins', 'vessel', 'vessels', \n",
        "                        'myocardium', 'pericardium', 'endocardium']\n",
        "        \n",
        "        hit = _first_hit(text, cardiac_terms)\n",
        "        return {\n",
        "            'label': 'CARDIAC_ANATOMY',\n",
        "            'column': 'physiological context',\n",
        "            'match': hit,\n",
        "            'category': 'cardiovascular'\n",
        "        } if hit else {'label': 'ABSTAIN'}\n",
        "    \n",
        "    \n",
        "    def lf_musculoskeletal(row):\n",
        "        text = str(row.get('physiological context', '')).lower()\n",
        "        msk_terms = ['bone', 'joint', 'muscle', 'tendon', 'ligament', 'cartilage', 'diaphysis', \n",
        "                    'femur', 'tibia', 'fibula', 'humerus', 'radius', 'ulna', 'skull', \n",
        "                    'spine', 'vertebra', 'vertebrae', 'rib', 'ribs', 'pelvis', \n",
        "                    'flexor', 'extensor', 'meniscus']\n",
        "        \n",
        "        hit = _first_hit(text,  msk_terms)\n",
        "        return {\n",
        "            'label': 'MUSCULOSKELETAL',\n",
        "            'column': 'physiological context',\n",
        "            'match': hit,\n",
        "            'category': 'musculoskeletal'\n",
        "        } if hit else {'label': 'ABSTAIN'}\n",
        "    \n",
        "    def lf_bilateral_anatomy(row):\n",
        "        text = str(row.get('physiological context', '')).lower()\n",
        "        if 'bilateral' in text:\n",
        "            # Find what follows bilateral\n",
        "            bilateral_pattern = r'bilateral\\s+(\\w+)'\n",
        "            match = re.search(bilateral_pattern, text)\n",
        "            if match:\n",
        "                return {\n",
        "                    'label': 'BILATERAL_CONDITION',\n",
        "                    'column': 'physiological context',\n",
        "                    'match': f'bilateral {match.group(1)}',\n",
        "                    'category': 'laterality'\n",
        "                }\n",
        "            else:\n",
        "                return {\n",
        "                    'label': 'BILATERAL_CONDITION',\n",
        "                    'column': 'physiological context',\n",
        "                    'match': 'bilateral',\n",
        "                    'category': 'laterality'\n",
        "                }\n",
        "        return {'label': 'ABSTAIN'}\n",
        "        \n",
        "    def lf_neurological_anatomy(row):\n",
        "        text = str(row.get('physiological context', '')).lower()\n",
        "        neuro_terms = ['brain', 'nerve', 'neural', 'spinal', 'cerebral', 'cerebrum', 'brainstem', \n",
        "                    'neuron', 'lobe', 'cerebellum', 'cortex', 'ganglion']\n",
        "        \n",
        "        hit = _first_hit(text,  neuro_terms)\n",
        "        return {\n",
        "            'label': 'NEUROLOGICAL_ANATOMY',\n",
        "            'column': 'physiological context',\n",
        "            'match': hit,\n",
        "            'category': 'neurological'\n",
        "        } if hit else {'label': 'ABSTAIN'}\n",
        "    \n",
        "    return [lf_cardiac_anatomy, lf_musculoskeletal, lf_bilateral_anatomy, lf_neurological_anatomy]\n",
        "\n",
        "\n",
        "def materialize_lf_spans(df, labeling_functions, id_column='idx'):\n",
        "    \"\"\"Convert labeling function results into span entities\"\"\"\n",
        "    lf_entities = []\n",
        "    \n",
        "    # Build the id series once\n",
        "    if id_column is not None and id_column in df.columns:\n",
        "        ids_series = df[id_column].where(pd.notna(df[id_column]), df.index)\n",
        "    else:\n",
        "        ids_series = df.index\n",
        "    \n",
        "    for (df_index, row), idx in zip(df.iterrows(), ids_series):\n",
        "        for lf in labeling_functions:\n",
        "            result = lf(row)\n",
        "            \n",
        "            if result.get('label') != 'ABSTAIN':\n",
        "                # Get the text from the specified column\n",
        "                column_name = result.get('column', 'physiological context')\n",
        "                full_text = str(row.get(column_name, ''))\n",
        "                match_term = result['match']\n",
        "                \n",
        "                # Find all occurrences of the match term\n",
        "                pattern = r'\\b' + re.escape(match_term) + r'\\b'\n",
        "                \n",
        "                for match in re.finditer(pattern, full_text.lower()):\n",
        "                    # Extract the actual text (preserving original case)\n",
        "                    actual_text = full_text[match.start():match.end()]\n",
        "                    \n",
        "                    lf_entities.append({\n",
        "                        'text': actual_text,\n",
        "                        'label': result['label'],\n",
        "                        'category': result.get('category', 'unknown'),\n",
        "                        'start': match.start(),\n",
        "                        'end': match.end(),\n",
        "                        'original_text': full_text,\n",
        "                        'source': f'lf:{lf.__name__}',\n",
        "                        'row_idx': idx\n",
        "                    })\n",
        "    \n",
        "    return pd.DataFrame(lf_entities)\n",
        "\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Extract custom anatomy entities using regex patterns\n",
        "    print(\"\\nExtracting anatomy entities...\")\n",
        "    df_anatomy_custom = extract_anatomy_from_physiological_context(\n",
        "        df_medical, \n",
        "        text_column='physiological context', \n",
        "        id_column='idx'\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nCustom anatomy extraction found {len(df_anatomy_custom)} anatomy mentions\")\n",
        "    \n",
        "    # Create and apply labeling functions to generate additional spans\n",
        "    print(\"\\n=== Creating and Applying Labeling Functions ===\")\n",
        "    anatomy_lfs = create_anatomy_labeling_functions()\n",
        "    \n",
        "    # Materialize spans from labeling functions\n",
        "    df_physiological_lf_spans = materialize_lf_spans(df_medical, anatomy_lfs, id_column='idx')\n",
        "    print(f\"\\nLabeling functions generated {len(df_physiological_lf_spans)} span entities\")\n",
        "    \n",
        "    if not df_physiological_lf_spans.empty:\n",
        "        print(\"\\n=== LF-Generated Spans Distribution ===\")\n",
        "        print(df_physiological_lf_spans['label'].value_counts())\n",
        "        print(\"\\n=== Sample LF Spans ===\")\n",
        "        print(df_physiological_lf_spans[['text', 'label', 'source']].head(10))\n",
        "    \n",
        "    # Also apply labeling functions for row-level analysis\n",
        "    print(\"\\n=== Row-Level Analysis from Labeling Functions ===\")\n",
        "    coverage_results = {}\n",
        "    for lf in anatomy_lfs:\n",
        "        labeled_count = 0\n",
        "        for _, row in df_medical.iterrows():\n",
        "            result = lf(row)\n",
        "            if result.get('label') != 'ABSTAIN':\n",
        "                labeled_count += 1\n",
        "        \n",
        "        coverage = (labeled_count / len(df_medical) * 100) if len(df_medical) > 0 else 0\n",
        "        coverage_results[lf.__name__] = {\n",
        "            'labeled': labeled_count,\n",
        "            'coverage': coverage\n",
        "        }\n",
        "    \n",
        "    print(\"\\nLabeling function coverage:\")\n",
        "    for lf_name, stats in sorted(coverage_results.items(), key=lambda x: x[1]['coverage'], reverse=True):\n",
        "        print(f\"  {lf_name}: {stats['labeled']} rows ({stats['coverage']:.1f}% coverage)\")\n",
        "    \n",
        "    # Combine all entity sources\n",
        "    print(\"\\n=== COMBINING ALL ENTITY SOURCES ===\")\n",
        "    \n",
        "    # Prepare common columns for concatenation\n",
        "    common_columns = ['text', 'label', 'start', 'end', 'original_text', 'source']\n",
        "    if 'row_idx' in df_anatomy_custom.columns:\n",
        "        common_columns.append('row_idx')\n",
        "    if 'category' in df_anatomy_custom.columns:\n",
        "        common_columns.append('category')\n",
        "    \n",
        "    # Ensure all dataframes have required columns\n",
        "    for col in common_columns:\n",
        "        if col not in df_physiological_entities.columns:\n",
        "            df_physiological_entities[col] = 'bc5cdr' if col == 'source' else None\n",
        "        if col not in df_anatomy_custom.columns:\n",
        "            df_anatomy_custom[col] = 'custom_extraction' if col == 'source' else None\n",
        "        if col not in df_physiological_lf_spans.columns:\n",
        "            df_physiological_lf_spans[col] = None\n",
        "    \n",
        "    df_all_physiological_entities = pd.concat([\n",
        "        df_physiological_entities[common_columns],     # BC5CDR entities\n",
        "        df_anatomy_custom[common_columns],             # Custom regex extraction\n",
        "        df_physiological_lf_spans[common_columns]                    # LF-generated spans\n",
        "    ], ignore_index=True)\n",
        "    \n",
        "    print(f\"\\nTotal combined entities: {len(df_all_physiological_entities)}\")\n",
        "    print(\"\\nCombined entity distribution by label:\")\n",
        "    print(df_all_physiological_entities['label'].value_counts())\n",
        "    print(\"\\nCombined entity distribution by source:\")\n",
        "    print(df_all_physiological_entities['source'].value_counts())\n",
        "    \n",
        "    # Analysis of different entity types\n",
        "    if not df_all_physiological_entities.empty:\n",
        "        print(\"\\n=== Analysis by Entity Type ===\")\n",
        "        \n",
        "        # Analyze CARDIAC_ANATOMY entities\n",
        "        cardiac = df_all_physiological_entities[\n",
        "            df_all_physiological_entities['label'] == 'CARDIAC_ANATOMY'\n",
        "        ]\n",
        "        if not cardiac.empty:\n",
        "            print(f\"\\n=== CARDIAC_ANATOMY Analysis ===\")\n",
        "            print(f\"Total mentions: {len(cardiac)}\")\n",
        "            print(f\"Unique terms: {cardiac['text'].nunique()}\")\n",
        "            print(\"\\nTop cardiac terms:\")\n",
        "            print(cardiac['text'].value_counts().head(10))\n",
        "        \n",
        "        # Analyze MUSCULOSKELETAL entities\n",
        "        msk = df_all_physiological_entities[\n",
        "            df_all_physiological_entities['label'] == 'MUSCULOSKELETAL'\n",
        "        ]\n",
        "        if not msk.empty:\n",
        "            print(f\"\\n=== MUSCULOSKELETAL Analysis ===\")\n",
        "            print(f\"Total mentions: {len(msk)}\")\n",
        "            print(f\"Unique terms: {msk['text'].nunique()}\")\n",
        "            print(\"\\nTop musculoskeletal terms:\")\n",
        "            print(msk['text'].value_counts().head(10))\n",
        "        \n",
        "        # Compare sources\n",
        "        print(\"\\n=== Entity Source Comparison ===\")\n",
        "        source_label_dist = pd.crosstab(\n",
        "            df_all_physiological_entities['source'],\n",
        "            df_all_physiological_entities['label']\n",
        "        )\n",
        "        print(source_label_dist)\n",
        "    \n",
        "    # Optional: Add row-level phenotypes to original dataframe\n",
        "    print(\"\\n=== Adding Row-Level Phenotypes ===\")\n",
        "    for lf in anatomy_lfs:\n",
        "        phenotype_name = f\"has_{lf.__name__.replace('lf_', '')}\"\n",
        "        df_medical[phenotype_name] = df_medical.apply(\n",
        "            lambda row: lf(row).get('label') != 'ABSTAIN',\n",
        "            axis=1\n",
        "        )\n",
        "    \n",
        "    # Show phenotype distribution\n",
        "    phenotype_cols = [col for col in df_medical.columns if col.startswith('has_')]\n",
        "    if phenotype_cols:\n",
        "        print(\"\\nRow-level phenotypes added:\")\n",
        "        for col in phenotype_cols:\n",
        "            true_count = df_medical[col].sum()\n",
        "            print(f\"  {col}: {true_count} rows\")\n",
        "    \n",
        "    # Save results\n",
        "    df_all_physiological_entities.to_csv('physiological_entities_comprehensive.csv', index=False)\n",
        "    df_anatomy_custom.to_csv('anatomy_entities_detailed.csv', index=False)\n",
        "    df_physiological_lf_spans.to_csv('physiological_lf_generated_spans.csv', index=False)\n",
        "    \n",
        "    # Save dataframe with phenotypes\n",
        "    df_medical.to_csv('medical_data_with_phenotypes.csv', index=False)\n",
        "    \n",
        "    print(\"\\n\\nAnatomy entity extraction complete!\")\n",
        "    print(f\"Total entities extracted: {len(df_all_physiological_entities)}\")\n",
        "    print(f\"  - BC5CDR: {len(df_physiological_entities)}\")\n",
        "    print(f\"  - Custom extraction: {len(df_anatomy_custom)}\")\n",
        "    print(f\"  - LF-generated: {len(df_physiological_lf_spans)}\")\n",
        "    print(f\"\\nRow-level phenotypes added: {len(phenotype_cols)}\")\n",
        "    print(\"\\nAll results saved to CSV files.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>category</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>source</th>\n",
              "      <th>row_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>femur</td>\n",
              "      <td>MUSCULOSKELETAL</td>\n",
              "      <td>musculoskeletal</td>\n",
              "      <td>87</td>\n",
              "      <td>92</td>\n",
              "      <td>Coxa vara deformity of bilateral hips, bilater...</td>\n",
              "      <td>lf:lf_musculoskeletal</td>\n",
              "      <td>149866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bilateral hips</td>\n",
              "      <td>BILATERAL_CONDITION</td>\n",
              "      <td>laterality</td>\n",
              "      <td>23</td>\n",
              "      <td>37</td>\n",
              "      <td>Coxa vara deformity of bilateral hips, bilater...</td>\n",
              "      <td>lf:lf_bilateral_anatomy</td>\n",
              "      <td>149866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>muscle</td>\n",
              "      <td>MUSCULOSKELETAL</td>\n",
              "      <td>musculoskeletal</td>\n",
              "      <td>75</td>\n",
              "      <td>81</td>\n",
              "      <td>Diagnosed with a type of muscular dystrophy at...</td>\n",
              "      <td>lf:lf_musculoskeletal</td>\n",
              "      <td>80892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>heart</td>\n",
              "      <td>CARDIAC_ANATOMY</td>\n",
              "      <td>cardiovascular</td>\n",
              "      <td>9</td>\n",
              "      <td>14</td>\n",
              "      <td>Complete heart block, had dual chamber pacemak...</td>\n",
              "      <td>lf:lf_cardiac_anatomy</td>\n",
              "      <td>80727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>heart</td>\n",
              "      <td>CARDIAC_ANATOMY</td>\n",
              "      <td>cardiovascular</td>\n",
              "      <td>88</td>\n",
              "      <td>93</td>\n",
              "      <td>Complete heart block, had dual chamber pacemak...</td>\n",
              "      <td>lf:lf_cardiac_anatomy</td>\n",
              "      <td>80727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3868</th>\n",
              "      <td>cerebral</td>\n",
              "      <td>NEUROLOGICAL_ANATOMY</td>\n",
              "      <td>neurological</td>\n",
              "      <td>88</td>\n",
              "      <td>96</td>\n",
              "      <td>Chronic rheumatic heart disease, atrial fibril...</td>\n",
              "      <td>lf:lf_neurological_anatomy</td>\n",
              "      <td>132307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3869</th>\n",
              "      <td>vein</td>\n",
              "      <td>CARDIAC_ANATOMY</td>\n",
              "      <td>cardiovascular</td>\n",
              "      <td>52</td>\n",
              "      <td>56</td>\n",
              "      <td>Gastroesophageal reflux disease, hypertension,...</td>\n",
              "      <td>lf:lf_cardiac_anatomy</td>\n",
              "      <td>114112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3870</th>\n",
              "      <td>Coronary</td>\n",
              "      <td>CARDIAC_ANATOMY</td>\n",
              "      <td>cardiovascular</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>Coronary arteriosclerosis, spinal canal stenos...</td>\n",
              "      <td>lf:lf_cardiac_anatomy</td>\n",
              "      <td>86992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3871</th>\n",
              "      <td>spinal</td>\n",
              "      <td>NEUROLOGICAL_ANATOMY</td>\n",
              "      <td>neurological</td>\n",
              "      <td>27</td>\n",
              "      <td>33</td>\n",
              "      <td>Coronary arteriosclerosis, spinal canal stenos...</td>\n",
              "      <td>lf:lf_neurological_anatomy</td>\n",
              "      <td>86992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3872</th>\n",
              "      <td>spinal</td>\n",
              "      <td>NEUROLOGICAL_ANATOMY</td>\n",
              "      <td>neurological</td>\n",
              "      <td>74</td>\n",
              "      <td>80</td>\n",
              "      <td>Atrial fibrillation, Parkinson's disease, prev...</td>\n",
              "      <td>lf:lf_neurological_anatomy</td>\n",
              "      <td>137017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3873 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                text                 label         category  start  end  \\\n",
              "0              femur       MUSCULOSKELETAL  musculoskeletal     87   92   \n",
              "1     bilateral hips   BILATERAL_CONDITION       laterality     23   37   \n",
              "2             muscle       MUSCULOSKELETAL  musculoskeletal     75   81   \n",
              "3              heart       CARDIAC_ANATOMY   cardiovascular      9   14   \n",
              "4              heart       CARDIAC_ANATOMY   cardiovascular     88   93   \n",
              "...              ...                   ...              ...    ...  ...   \n",
              "3868        cerebral  NEUROLOGICAL_ANATOMY     neurological     88   96   \n",
              "3869            vein       CARDIAC_ANATOMY   cardiovascular     52   56   \n",
              "3870        Coronary       CARDIAC_ANATOMY   cardiovascular      0    8   \n",
              "3871          spinal  NEUROLOGICAL_ANATOMY     neurological     27   33   \n",
              "3872          spinal  NEUROLOGICAL_ANATOMY     neurological     74   80   \n",
              "\n",
              "                                          original_text  \\\n",
              "0     Coxa vara deformity of bilateral hips, bilater...   \n",
              "1     Coxa vara deformity of bilateral hips, bilater...   \n",
              "2     Diagnosed with a type of muscular dystrophy at...   \n",
              "3     Complete heart block, had dual chamber pacemak...   \n",
              "4     Complete heart block, had dual chamber pacemak...   \n",
              "...                                                 ...   \n",
              "3868  Chronic rheumatic heart disease, atrial fibril...   \n",
              "3869  Gastroesophageal reflux disease, hypertension,...   \n",
              "3870  Coronary arteriosclerosis, spinal canal stenos...   \n",
              "3871  Coronary arteriosclerosis, spinal canal stenos...   \n",
              "3872  Atrial fibrillation, Parkinson's disease, prev...   \n",
              "\n",
              "                          source  row_idx  \n",
              "0          lf:lf_musculoskeletal   149866  \n",
              "1        lf:lf_bilateral_anatomy   149866  \n",
              "2          lf:lf_musculoskeletal    80892  \n",
              "3          lf:lf_cardiac_anatomy    80727  \n",
              "4          lf:lf_cardiac_anatomy    80727  \n",
              "...                          ...      ...  \n",
              "3868  lf:lf_neurological_anatomy   132307  \n",
              "3869       lf:lf_cardiac_anatomy   114112  \n",
              "3870       lf:lf_cardiac_anatomy    86992  \n",
              "3871  lf:lf_neurological_anatomy    86992  \n",
              "3872  lf:lf_neurological_anatomy   137017  \n",
              "\n",
              "[3873 rows x 8 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_physiological_lf_spans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>category</th>\n",
              "      <th>anatomy</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>source</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>laterality</th>\n",
              "      <th>direction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>left elbow</td>\n",
              "      <td>ANATOMY_WITH_LATERALITY</td>\n",
              "      <td>joints</td>\n",
              "      <td>elbow</td>\n",
              "      <td>11</td>\n",
              "      <td>21</td>\n",
              "      <td>History of left elbow arthrodesis performed fo...</td>\n",
              "      <td>custom_anatomy_extraction</td>\n",
              "      <td>80176</td>\n",
              "      <td>left</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>femur</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>bones</td>\n",
              "      <td>femur</td>\n",
              "      <td>87</td>\n",
              "      <td>92</td>\n",
              "      <td>Coxa vara deformity of bilateral hips, bilater...</td>\n",
              "      <td>custom_anatomy_extraction</td>\n",
              "      <td>149866</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neck</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>joints</td>\n",
              "      <td>neck</td>\n",
              "      <td>93</td>\n",
              "      <td>97</td>\n",
              "      <td>Coxa vara deformity of bilateral hips, bilater...</td>\n",
              "      <td>custom_anatomy_extraction</td>\n",
              "      <td>149866</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rectum</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>organs</td>\n",
              "      <td>rectum</td>\n",
              "      <td>32</td>\n",
              "      <td>38</td>\n",
              "      <td>Colorectal carcinoma treated by rectum and ile...</td>\n",
              "      <td>custom_anatomy_extraction</td>\n",
              "      <td>92167</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pancreas</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>organs</td>\n",
              "      <td>pancreas</td>\n",
              "      <td>144</td>\n",
              "      <td>152</td>\n",
              "      <td>Past medical history significant for RCC, init...</td>\n",
              "      <td>custom_anatomy_extraction</td>\n",
              "      <td>43555</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11609</th>\n",
              "      <td>colon</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>organs</td>\n",
              "      <td>colon</td>\n",
              "      <td>61</td>\n",
              "      <td>66</td>\n",
              "      <td>Coronary arteriosclerosis, spinal canal stenos...</td>\n",
              "      <td>custom_anatomy_extraction</td>\n",
              "      <td>86992</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11610</th>\n",
              "      <td>kidney</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>organs</td>\n",
              "      <td>kidney</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>Kidney stone lithotripsy, hypertension treated...</td>\n",
              "      <td>custom_anatomy_extraction</td>\n",
              "      <td>157822</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11611</th>\n",
              "      <td>pulmonary</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>cardiovascular</td>\n",
              "      <td>pulmonary</td>\n",
              "      <td>20</td>\n",
              "      <td>29</td>\n",
              "      <td>Chronic obstructive pulmonary disease, high bl...</td>\n",
              "      <td>custom_anatomy_extraction</td>\n",
              "      <td>77450</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11612</th>\n",
              "      <td>blood</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>tissues</td>\n",
              "      <td>blood</td>\n",
              "      <td>44</td>\n",
              "      <td>49</td>\n",
              "      <td>Chronic obstructive pulmonary disease, high bl...</td>\n",
              "      <td>custom_anatomy_extraction</td>\n",
              "      <td>77450</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11613</th>\n",
              "      <td>prostate</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>organs</td>\n",
              "      <td>prostate</td>\n",
              "      <td>51</td>\n",
              "      <td>59</td>\n",
              "      <td>Atrial fibrillation, Parkinson's disease, prev...</td>\n",
              "      <td>custom_anatomy_extraction</td>\n",
              "      <td>137017</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11614 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             text                    label        category    anatomy  start  \\\n",
              "0      left elbow  ANATOMY_WITH_LATERALITY          joints      elbow     11   \n",
              "1           femur                  ANATOMY           bones      femur     87   \n",
              "2            neck                  ANATOMY          joints       neck     93   \n",
              "3          rectum                  ANATOMY          organs     rectum     32   \n",
              "4        pancreas                  ANATOMY          organs   pancreas    144   \n",
              "...           ...                      ...             ...        ...    ...   \n",
              "11609       colon                  ANATOMY          organs      colon     61   \n",
              "11610      kidney                  ANATOMY          organs     kidney      0   \n",
              "11611   pulmonary                  ANATOMY  cardiovascular  pulmonary     20   \n",
              "11612       blood                  ANATOMY         tissues      blood     44   \n",
              "11613    prostate                  ANATOMY          organs   prostate     51   \n",
              "\n",
              "       end                                      original_text  \\\n",
              "0       21  History of left elbow arthrodesis performed fo...   \n",
              "1       92  Coxa vara deformity of bilateral hips, bilater...   \n",
              "2       97  Coxa vara deformity of bilateral hips, bilater...   \n",
              "3       38  Colorectal carcinoma treated by rectum and ile...   \n",
              "4      152  Past medical history significant for RCC, init...   \n",
              "...    ...                                                ...   \n",
              "11609   66  Coronary arteriosclerosis, spinal canal stenos...   \n",
              "11610    6  Kidney stone lithotripsy, hypertension treated...   \n",
              "11611   29  Chronic obstructive pulmonary disease, high bl...   \n",
              "11612   49  Chronic obstructive pulmonary disease, high bl...   \n",
              "11613   59  Atrial fibrillation, Parkinson's disease, prev...   \n",
              "\n",
              "                          source  row_idx laterality direction  \n",
              "0      custom_anatomy_extraction    80176       left       NaN  \n",
              "1      custom_anatomy_extraction   149866        NaN       NaN  \n",
              "2      custom_anatomy_extraction   149866        NaN       NaN  \n",
              "3      custom_anatomy_extraction    92167        NaN       NaN  \n",
              "4      custom_anatomy_extraction    43555        NaN       NaN  \n",
              "...                          ...      ...        ...       ...  \n",
              "11609  custom_anatomy_extraction    86992        NaN       NaN  \n",
              "11610  custom_anatomy_extraction   157822        NaN       NaN  \n",
              "11611  custom_anatomy_extraction    77450        NaN       NaN  \n",
              "11612  custom_anatomy_extraction    77450        NaN       NaN  \n",
              "11613  custom_anatomy_extraction   137017        NaN       NaN  \n",
              "\n",
              "[11614 rows x 11 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_anatomy_custom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>source</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>posttraumatic arthritis</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>48</td>\n",
              "      <td>71</td>\n",
              "      <td>History of left elbow arthrodesis performed fo...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>80176</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pain</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>116</td>\n",
              "      <td>120</td>\n",
              "      <td>Inability to walk since babyhood, did not walk...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>31864</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fracture</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>151</td>\n",
              "      <td>159</td>\n",
              "      <td>Inability to walk since babyhood, did not walk...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>31864</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Coxa vara deformity</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>Coxa vara deformity of bilateral hips, bilater...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>149866</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fracture</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>75</td>\n",
              "      <td>83</td>\n",
              "      <td>Coxa vara deformity of bilateral hips, bilater...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>149866</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51754</th>\n",
              "      <td>cerebral</td>\n",
              "      <td>NEUROLOGICAL_ANATOMY</td>\n",
              "      <td>88</td>\n",
              "      <td>96</td>\n",
              "      <td>Chronic rheumatic heart disease, atrial fibril...</td>\n",
              "      <td>lf:lf_neurological_anatomy</td>\n",
              "      <td>132307</td>\n",
              "      <td>neurological</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51755</th>\n",
              "      <td>vein</td>\n",
              "      <td>CARDIAC_ANATOMY</td>\n",
              "      <td>52</td>\n",
              "      <td>56</td>\n",
              "      <td>Gastroesophageal reflux disease, hypertension,...</td>\n",
              "      <td>lf:lf_cardiac_anatomy</td>\n",
              "      <td>114112</td>\n",
              "      <td>cardiovascular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51756</th>\n",
              "      <td>Coronary</td>\n",
              "      <td>CARDIAC_ANATOMY</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>Coronary arteriosclerosis, spinal canal stenos...</td>\n",
              "      <td>lf:lf_cardiac_anatomy</td>\n",
              "      <td>86992</td>\n",
              "      <td>cardiovascular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51757</th>\n",
              "      <td>spinal</td>\n",
              "      <td>NEUROLOGICAL_ANATOMY</td>\n",
              "      <td>27</td>\n",
              "      <td>33</td>\n",
              "      <td>Coronary arteriosclerosis, spinal canal stenos...</td>\n",
              "      <td>lf:lf_neurological_anatomy</td>\n",
              "      <td>86992</td>\n",
              "      <td>neurological</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51758</th>\n",
              "      <td>spinal</td>\n",
              "      <td>NEUROLOGICAL_ANATOMY</td>\n",
              "      <td>74</td>\n",
              "      <td>80</td>\n",
              "      <td>Atrial fibrillation, Parkinson's disease, prev...</td>\n",
              "      <td>lf:lf_neurological_anatomy</td>\n",
              "      <td>137017</td>\n",
              "      <td>neurological</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>51759 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                          text                 label  start  end  \\\n",
              "0      posttraumatic arthritis               DISEASE     48   71   \n",
              "1                         pain               DISEASE    116  120   \n",
              "2                     fracture               DISEASE    151  159   \n",
              "3          Coxa vara deformity               DISEASE      0   19   \n",
              "4                     fracture               DISEASE     75   83   \n",
              "...                        ...                   ...    ...  ...   \n",
              "51754                 cerebral  NEUROLOGICAL_ANATOMY     88   96   \n",
              "51755                     vein       CARDIAC_ANATOMY     52   56   \n",
              "51756                 Coronary       CARDIAC_ANATOMY      0    8   \n",
              "51757                   spinal  NEUROLOGICAL_ANATOMY     27   33   \n",
              "51758                   spinal  NEUROLOGICAL_ANATOMY     74   80   \n",
              "\n",
              "                                           original_text  \\\n",
              "0      History of left elbow arthrodesis performed fo...   \n",
              "1      Inability to walk since babyhood, did not walk...   \n",
              "2      Inability to walk since babyhood, did not walk...   \n",
              "3      Coxa vara deformity of bilateral hips, bilater...   \n",
              "4      Coxa vara deformity of bilateral hips, bilater...   \n",
              "...                                                  ...   \n",
              "51754  Chronic rheumatic heart disease, atrial fibril...   \n",
              "51755  Gastroesophageal reflux disease, hypertension,...   \n",
              "51756  Coronary arteriosclerosis, spinal canal stenos...   \n",
              "51757  Coronary arteriosclerosis, spinal canal stenos...   \n",
              "51758  Atrial fibrillation, Parkinson's disease, prev...   \n",
              "\n",
              "                           source  row_idx        category  \n",
              "0                          bc5cdr    80176            None  \n",
              "1                          bc5cdr    31864            None  \n",
              "2                          bc5cdr    31864            None  \n",
              "3                          bc5cdr   149866            None  \n",
              "4                          bc5cdr   149866            None  \n",
              "...                           ...      ...             ...  \n",
              "51754  lf:lf_neurological_anatomy   132307    neurological  \n",
              "51755       lf:lf_cardiac_anatomy   114112  cardiovascular  \n",
              "51756       lf:lf_cardiac_anatomy    86992  cardiovascular  \n",
              "51757  lf:lf_neurological_anatomy    86992    neurological  \n",
              "51758  lf:lf_neurological_anatomy   137017    neurological  \n",
              "\n",
              "[51759 rows x 8 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_all_physiological_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Irq6-yqQD4Qr"
      },
      "source": [
        "##### Psychological Contexts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading en_ner_bc5cdr_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 29755 texts in 60 batches...\n",
            "Using model: en_ner_bc5cdr_md for column: psychological context\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   2%|▏         | 1/60 [00:01<00:59,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  18%|█▊        | 11/60 [00:03<00:13,  3.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 5000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  35%|███▌      | 21/60 [00:05<00:10,  3.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 10000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  52%|█████▏    | 31/60 [00:08<00:07,  3.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  68%|██████▊   | 41/60 [00:11<00:05,  3.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 20000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  85%|████████▌ | 51/60 [00:13<00:02,  3.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 25000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 60/60 [00:15<00:00,  3.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 136 entities appearing >= 5 times\n",
            "\n",
            "Testing BC5CDR-generated labeling functions on df_medical...\n",
            "\n",
            "=== BC5CDR Extraction Results ===\n",
            "Shape of df_psychological_entities: (3402, 7)\n",
            "\n",
            "Column names: ['text', 'label', 'start', 'end', 'original_text', 'row_idx', 'source_column']\n",
            "\n",
            "=== BC5CDR Entity Labels Found ===\n",
            "label\n",
            "DISEASE     3240\n",
            "CHEMICAL     162\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== CUSTOM PSYCHOLOGICAL ENTITY EXTRACTION ===\n",
            "\n",
            "Custom extraction found 1107 psychological entities\n",
            "\n",
            "=== Custom Entity Distribution ===\n",
            "label\n",
            "PSYCHOLOGICAL_CONDITION    1107\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Custom Entity Categories ===\n",
            "category\n",
            "mood          848\n",
            "behavioral     71\n",
            "psychotic      59\n",
            "cognitive      53\n",
            "sleep          46\n",
            "trauma         30\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Creating and Applying Psychological Labeling Functions ===\n",
            "\n",
            "Labeling functions generated 1174 span entities\n",
            "\n",
            "=== LF-Generated Spans Distribution ===\n",
            "label\n",
            "MOOD_DISORDER           931\n",
            "PSYCHOTIC_SYMPTOMS       99\n",
            "COGNITIVE_IMPAIRMENT     57\n",
            "SLEEP_DISORDER           47\n",
            "TRAUMA_RELATED           40\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Sample LF Spans ===\n",
            "         text          label               source\n",
            "0     bipolar  MOOD_DISORDER  lf:lf_mood_disorder\n",
            "1  depression  MOOD_DISORDER  lf:lf_mood_disorder\n",
            "2     anxiety  MOOD_DISORDER  lf:lf_mood_disorder\n",
            "3  depression  MOOD_DISORDER  lf:lf_mood_disorder\n",
            "4     anxiety  MOOD_DISORDER  lf:lf_mood_disorder\n",
            "5     Anxiety  MOOD_DISORDER  lf:lf_mood_disorder\n",
            "6  Depression  MOOD_DISORDER  lf:lf_mood_disorder\n",
            "7  Depression  MOOD_DISORDER  lf:lf_mood_disorder\n",
            "8     Anxiety  MOOD_DISORDER  lf:lf_mood_disorder\n",
            "9  depression  MOOD_DISORDER  lf:lf_mood_disorder\n",
            "\n",
            "=== Row-Level Coverage Analysis ===\n",
            "\n",
            "Labeling function coverage:\n",
            "  lf_mood_disorder: 913 rows (3.1% coverage)\n",
            "  lf_psychotic_symptoms: 99 rows (0.3% coverage)\n",
            "  lf_cognitive_impairment: 57 rows (0.2% coverage)\n",
            "  lf_sleep_disorder: 47 rows (0.2% coverage)\n",
            "  lf_trauma_related: 40 rows (0.1% coverage)\n",
            "\n",
            "=== COMBINING ALL PSYCHOLOGICAL ENTITY SOURCES ===\n",
            "\n",
            "Total combined entities: 5683\n",
            "\n",
            "Combined entity distribution by label:\n",
            "label\n",
            "DISEASE                    3240\n",
            "PSYCHOLOGICAL_CONDITION    1107\n",
            "MOOD_DISORDER               931\n",
            "CHEMICAL                    162\n",
            "PSYCHOTIC_SYMPTOMS           99\n",
            "COGNITIVE_IMPAIRMENT         57\n",
            "SLEEP_DISORDER               47\n",
            "TRAUMA_RELATED               40\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Combined entity distribution by source:\n",
            "source\n",
            "bc5cdr                             3402\n",
            "custom_psychological_extraction    1107\n",
            "lf:lf_mood_disorder                 931\n",
            "lf:lf_psychotic_symptoms             99\n",
            "lf:lf_cognitive_impairment           57\n",
            "lf:lf_sleep_disorder                 47\n",
            "lf:lf_trauma_related                 40\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Analysis by Psychological Category ===\n",
            "\n",
            "=== Mood-Related Terms ===\n",
            "Total mentions: 1779\n",
            "Top terms:\n",
            "text\n",
            "depression      558\n",
            "anxiety         444\n",
            "Depression      300\n",
            "Anxiety         159\n",
            "Bipolar          55\n",
            "bipolar          52\n",
            "anxious          44\n",
            "depressed        40\n",
            "irritability     38\n",
            "manic            22\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Cognitive Impairment Terms ===\n",
            "Total mentions: 57\n",
            "Top terms:\n",
            "text\n",
            "Dementia             12\n",
            "dementia             12\n",
            "confusion             9\n",
            "memory loss           6\n",
            "amnesia               5\n",
            "Disoriented           5\n",
            "Alzheimer             4\n",
            "disoriented           1\n",
            "cognitive decline     1\n",
            "Cognitive decline     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Adding Row-Level Psychological Phenotypes ===\n",
            "\n",
            "Psychological phenotypes added:\n",
            "  has_mood_disorder: 913 rows\n",
            "  has_cognitive_impairment: 57 rows\n",
            "  has_psychotic_symptoms: 99 rows\n",
            "  has_trauma_related: 40 rows\n",
            "  has_sleep_disorder: 47 rows\n",
            "\n",
            "\n",
            "Psychological entity extraction complete!\n",
            "Total entities extracted: 5683\n",
            "  - BC5CDR: 3402\n",
            "  - Custom extraction: 1107\n",
            "  - LF-generated: 1174\n",
            "\n",
            "All results saved to CSV files.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def extract_psychological_entities_custom(df_medical, text_column='psychological context', id_column='idx'):\n",
        "    \"\"\"Extract psychological-specific entities beyond what BC5CDR captures\"\"\"\n",
        "    \n",
        "    # Build the id series once\n",
        "    if id_column is not None and id_column in df_medical.columns:\n",
        "        ids_series = df_medical[id_column].where(pd.notna(df_medical[id_column]), df_medical.index)\n",
        "    else:\n",
        "        ids_series = df_medical.index\n",
        "    \n",
        "    texts = df_medical[text_column].fillna('').astype(str)\n",
        "    \n",
        "    # Psychological patterns\n",
        "    psychological_patterns = {\n",
        "        'mood': ['depression', 'anxiety', 'euphoria', 'dysphoria', 'irritability', 'apathy'],\n",
        "        'cognitive': ['confusion', 'disorientation', 'amnesia', 'dementia', 'delirium'],\n",
        "        'psychotic': ['hallucination', 'delusion', 'paranoia', 'psychosis'],\n",
        "        'behavioral': ['aggression', 'agitation', 'withdrawal', 'impulsivity'],\n",
        "        'sleep': ['insomnia', 'hypersomnia', 'nightmares', 'sleep disturbance'],\n",
        "        'trauma': ['ptsd', 'trauma', 'flashback', 'hypervigilance']\n",
        "    }\n",
        "    \n",
        "    psychological_entities = []\n",
        "    \n",
        "    for (df_index, text_original), idx in zip(texts.items(), ids_series):\n",
        "        if text_original:\n",
        "            text = text_original.lower()\n",
        "            \n",
        "            # Extract psychological terms\n",
        "            for category, terms in psychological_patterns.items():\n",
        "                for term in terms:\n",
        "                    pattern = r'\\b' + re.escape(term) + r'\\b'\n",
        "                    for match in re.finditer(pattern, text):\n",
        "                        psychological_entities.append({\n",
        "                            'text': text_original[match.start():match.end()],\n",
        "                            'label': 'PSYCHOLOGICAL_CONDITION',\n",
        "                            'category': category,\n",
        "                            'start': match.start(),\n",
        "                            'end': match.end(),\n",
        "                            'original_text': text_original,\n",
        "                            'source': 'custom_psychological_extraction',\n",
        "                            'row_idx': idx\n",
        "                        })\n",
        "    \n",
        "    return pd.DataFrame(psychological_entities)\n",
        "\n",
        "\n",
        "def create_psychological_labeling_functions():\n",
        "    \"\"\"Create labeling functions that return evidence for psychological span creation\"\"\"\n",
        "    \n",
        "    def lf_mood_disorder(row):\n",
        "            text = str(row.get('psychological context', ''))\n",
        "            mood_terms = ['depression', 'depressed', 'anxiety', 'anxious', 'manic', 'bipolar', \n",
        "                        'mood disorder', 'dysthymia', 'euphoria']\n",
        "            \n",
        "            hit = _first_hit(text, mood_terms)\n",
        "            return {\n",
        "                'label': 'MOOD_DISORDER',\n",
        "                'column': 'psychological context',\n",
        "                'match': hit,\n",
        "                'category': 'mood'\n",
        "            } if hit else {'label': 'ABSTAIN'}\n",
        "    \n",
        "    def lf_cognitive_impairment(row):\n",
        "        text = str(row.get('psychological context', ''))\n",
        "        cognitive_terms = ['memory loss', 'confusion', 'disoriented', 'cognitive decline', \n",
        "                          'dementia', 'alzheimer', 'amnesia', 'forgetful']\n",
        "        \n",
        "        hit = _first_hit(text, cognitive_terms)\n",
        "        return {\n",
        "            'label': 'COGNITIVE_IMPAIRMENT',\n",
        "            'column': 'psychological context',\n",
        "            'match': hit,\n",
        "            'category': 'cognitive'\n",
        "        } if hit else {'label': 'ABSTAIN'}\n",
        "    \n",
        "    def lf_psychotic_symptoms(row):\n",
        "        text = str(row.get('psychological context', '')).lower()\n",
        "        psychotic_terms = ['hallucination', 'delusion', 'paranoid', 'psychosis', 'psychotic',\n",
        "                        'hearing voices', 'seeing things']\n",
        "        \n",
        "        hit = _first_hit(text, psychotic_terms)\n",
        "        return {\n",
        "            'label': 'PSYCHOTIC_SYMPTOMS',\n",
        "            'column': 'psychological context',\n",
        "            'match': hit,\n",
        "            'category': 'psychotic'\n",
        "        } if hit else {'label': 'ABSTAIN'}\n",
        "    \n",
        "    def lf_trauma_related(row):\n",
        "        text = str(row.get('psychological context', '')).lower()\n",
        "        trauma_terms = ['ptsd', 'post-traumatic', 'trauma', 'flashback', 'nightmare',\n",
        "                    'hypervigilance', 'traumatic stress']\n",
        "        \n",
        "        hit = _first_hit(text, trauma_terms)\n",
        "        return {\n",
        "            'label': 'TRAUMA_RELATED',\n",
        "            'column': 'psychological context',\n",
        "            'match': hit,\n",
        "            'category': 'trauma'\n",
        "        } if hit else {'label': 'ABSTAIN'}\n",
        "    \n",
        "    def lf_sleep_disorder(row):\n",
        "        text = str(row.get('psychological context', '')).lower()\n",
        "        sleep_terms = ['insomnia', 'sleep disorder', 'cant sleep', 'sleep disturbance',\n",
        "                    'nightmares', 'night terrors', 'sleep apnea']\n",
        "        \n",
        "        hit = _first_hit(text, sleep_terms)\n",
        "        return {\n",
        "            'label': 'SLEEP_DISORDER',\n",
        "            'column': 'psychological context',\n",
        "            'match': hit,\n",
        "            'category': 'sleep'\n",
        "        } if hit else {'label': 'ABSTAIN'}\n",
        "    \n",
        "    \n",
        "    return [lf_mood_disorder, lf_cognitive_impairment, lf_psychotic_symptoms, \n",
        "            lf_trauma_related, lf_sleep_disorder]\n",
        "\n",
        "\n",
        "def materialize_psychological_lf_spans(df, labeling_functions, id_column='idx'):\n",
        "    \"\"\"Convert psychological labeling function results into span entities\"\"\"\n",
        "    lf_entities = []\n",
        "    \n",
        "    # Build the id series once\n",
        "    if id_column is not None and id_column in df.columns:\n",
        "        ids_series = df[id_column].where(pd.notna(df[id_column]), df.index)\n",
        "    else:\n",
        "        ids_series = df.index\n",
        "    \n",
        "    for (df_index, row), idx in zip(df.iterrows(), ids_series):\n",
        "        for lf in labeling_functions:\n",
        "            result = lf(row)\n",
        "            \n",
        "            if result.get('label') != 'ABSTAIN':\n",
        "                # Get the text from the specified column\n",
        "                column_name = result.get('column', 'psychological context')\n",
        "                full_text = str(row.get(column_name, ''))\n",
        "                match_term = result['match']\n",
        "                \n",
        "                # Find all occurrences of the match term\n",
        "                pattern = r'\\b' + re.escape(match_term) + r'\\b'\n",
        "                \n",
        "                for match in re.finditer(pattern, full_text.lower()):\n",
        "                    # Extract the actual text (preserving original case)\n",
        "                    actual_text = full_text[match.start():match.end()]\n",
        "                    \n",
        "                    lf_entities.append({\n",
        "                        'text': actual_text,\n",
        "                        'label': result['label'],\n",
        "                        'category': result.get('category', 'unknown'),\n",
        "                        'start': match.start(),\n",
        "                        'end': match.end(),\n",
        "                        'original_text': full_text,\n",
        "                        'source': f'lf:{lf.__name__}',\n",
        "                        'row_idx': idx\n",
        "                    })\n",
        "    \n",
        "    return pd.DataFrame(lf_entities)\n",
        "\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Run extraction for the 'psychological context' column with BC5CDR\n",
        "    df_psychological_entities, disease_summary, rules = run_medical_ner_extraction(\n",
        "        df_medical,\n",
        "        text_column='psychological context',\n",
        "        model_name=\"en_ner_bc5cdr_md\",\n",
        "        batch_size=500,\n",
        "        id_column='idx'\n",
        "    )\n",
        "    \n",
        "    # Test the generated rules from BC5CDR\n",
        "    print(\"\\nTesting BC5CDR-generated labeling functions on df_medical...\")\n",
        "    if not df_medical.empty:\n",
        "        sample_row = df_medical.iloc[0]\n",
        "        \n",
        "        for rule_name, rule_func in rules.items():\n",
        "            try:\n",
        "                test_result = rule_func(sample_row)\n",
        "                if test_result != 'ABSTAIN':\n",
        "                    print(f\"{rule_name} applied to row 0: {test_result}\")\n",
        "            except KeyError as e:\n",
        "                print(f\"Error applying rule {rule_name}: {e}. Make sure the column '{e}' exists in df_medical.\")\n",
        "    else:\n",
        "        print(\"df_medical is empty, cannot test rules.\")\n",
        "    \n",
        "    print(\"\\n=== BC5CDR Extraction Results ===\")\n",
        "    print(f\"Shape of df_psychological_entities: {df_psychological_entities.shape}\")\n",
        "    print(f\"\\nColumn names: {df_psychological_entities.columns.tolist()}\")\n",
        "    \n",
        "    if not df_psychological_entities.empty:\n",
        "        print(\"\\n=== BC5CDR Entity Labels Found ===\")\n",
        "        print(df_psychological_entities['label'].value_counts())\n",
        "    else:\n",
        "        print(\"df_psychological_entities is empty.\")\n",
        "    \n",
        "    # Extract custom psychological entities\n",
        "    print(\"\\n=== CUSTOM PSYCHOLOGICAL ENTITY EXTRACTION ===\")\n",
        "    df_custom_psychological = extract_psychological_entities_custom(\n",
        "        df_medical,\n",
        "        text_column='psychological context',\n",
        "        id_column='idx'\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nCustom extraction found {len(df_custom_psychological)} psychological entities\")\n",
        "    if not df_custom_psychological.empty:\n",
        "        print(\"\\n=== Custom Entity Distribution ===\")\n",
        "        print(df_custom_psychological['label'].value_counts())\n",
        "        print(\"\\n=== Custom Entity Categories ===\")\n",
        "        print(df_custom_psychological['category'].value_counts())\n",
        "    \n",
        "    # Create and apply psychological labeling functions\n",
        "    print(\"\\n=== Creating and Applying Psychological Labeling Functions ===\")\n",
        "    psychological_lfs = create_psychological_labeling_functions()\n",
        "    \n",
        "    # Materialize spans from labeling functions\n",
        "    df_psychological_lf_spans = materialize_psychological_lf_spans(\n",
        "        df_medical, \n",
        "        psychological_lfs, \n",
        "        id_column='idx'\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nLabeling functions generated {len(df_psychological_lf_spans)} span entities\")\n",
        "    \n",
        "    if not df_psychological_lf_spans.empty:\n",
        "        print(\"\\n=== LF-Generated Spans Distribution ===\")\n",
        "        print(df_psychological_lf_spans['label'].value_counts())\n",
        "        print(\"\\n=== Sample LF Spans ===\")\n",
        "        print(df_psychological_lf_spans[['text', 'label', 'source']].head(10))\n",
        "    \n",
        "    # Row-level coverage analysis\n",
        "    print(\"\\n=== Row-Level Coverage Analysis ===\")\n",
        "    coverage_results = {}\n",
        "    for lf in psychological_lfs:\n",
        "        labeled_count = 0\n",
        "        for _, row in df_medical.iterrows():\n",
        "            result = lf(row)\n",
        "            if result.get('label') != 'ABSTAIN':\n",
        "                labeled_count += 1\n",
        "        \n",
        "        coverage = (labeled_count / len(df_medical) * 100) if len(df_medical) > 0 else 0\n",
        "        coverage_results[lf.__name__] = {\n",
        "            'labeled': labeled_count,\n",
        "            'coverage': coverage\n",
        "        }\n",
        "    \n",
        "    print(\"\\nLabeling function coverage:\")\n",
        "    for lf_name, stats in sorted(coverage_results.items(), key=lambda x: x[1]['coverage'], reverse=True):\n",
        "        print(f\"  {lf_name}: {stats['labeled']} rows ({stats['coverage']:.1f}% coverage)\")\n",
        "    \n",
        "    # Combine all sources\n",
        "    print(\"\\n=== COMBINING ALL PSYCHOLOGICAL ENTITY SOURCES ===\")\n",
        "    \n",
        "    # Prepare common columns\n",
        "    common_columns = ['text', 'label', 'start', 'end', 'original_text', 'source']\n",
        "    if 'row_idx' in df_psychological_entities.columns:\n",
        "        common_columns.append('row_idx')\n",
        "    if 'category' in df_custom_psychological.columns:\n",
        "        common_columns.append('category')\n",
        "    \n",
        "    # Ensure all dataframes have required columns\n",
        "    for col in common_columns:\n",
        "        if col not in df_psychological_entities.columns:\n",
        "            df_psychological_entities[col] = 'bc5cdr' if col == 'source' else None\n",
        "        if col not in df_custom_psychological.columns:\n",
        "            df_custom_psychological[col] = 'custom_extraction' if col == 'source' else None\n",
        "        if col not in df_psychological_lf_spans.columns:\n",
        "            df_psychological_lf_spans[col] = None\n",
        "    \n",
        "    df_all_psychological_entities = pd.concat([\n",
        "        df_psychological_entities[common_columns],\n",
        "        df_custom_psychological[common_columns],\n",
        "        df_psychological_lf_spans[common_columns]\n",
        "    ], ignore_index=True)\n",
        "    \n",
        "    print(f\"\\nTotal combined entities: {len(df_all_psychological_entities)}\")\n",
        "    print(\"\\nCombined entity distribution by label:\")\n",
        "    print(df_all_psychological_entities['label'].value_counts())\n",
        "    print(\"\\nCombined entity distribution by source:\")\n",
        "    print(df_all_psychological_entities['source'].value_counts())\n",
        "    \n",
        "    # Analysis by psychological categories\n",
        "    if not df_all_psychological_entities.empty:\n",
        "        print(\"\\n=== Analysis by Psychological Category ===\")\n",
        "        \n",
        "        # Mood disorders\n",
        "        mood_entities = df_all_psychological_entities[\n",
        "            df_all_psychological_entities['label'].isin(['MOOD_DISORDER', 'PSYCHOLOGICAL_CONDITION'])\n",
        "        ]\n",
        "        if not mood_entities.empty and 'category' in mood_entities.columns:\n",
        "            mood_specific = mood_entities[mood_entities['category'] == 'mood']\n",
        "            if not mood_specific.empty:\n",
        "                print(f\"\\n=== Mood-Related Terms ===\")\n",
        "                print(f\"Total mentions: {len(mood_specific)}\")\n",
        "                print(\"Top terms:\")\n",
        "                print(mood_specific['text'].value_counts().head(10))\n",
        "        \n",
        "        # Cognitive issues\n",
        "        cognitive_entities = df_all_psychological_entities[\n",
        "            df_all_psychological_entities['label'] == 'COGNITIVE_IMPAIRMENT'\n",
        "        ]\n",
        "        if not cognitive_entities.empty:\n",
        "            print(f\"\\n=== Cognitive Impairment Terms ===\")\n",
        "            print(f\"Total mentions: {len(cognitive_entities)}\")\n",
        "            print(\"Top terms:\")\n",
        "            print(cognitive_entities['text'].value_counts().head(10))\n",
        "    \n",
        "    # Add row-level psychological phenotypes\n",
        "    print(\"\\n=== Adding Row-Level Psychological Phenotypes ===\")\n",
        "    for lf in psychological_lfs:\n",
        "        phenotype_name = f\"has_{lf.__name__.replace('lf_', '')}\"\n",
        "        df_medical[phenotype_name] = df_medical.apply(\n",
        "            lambda row: lf(row).get('label') != 'ABSTAIN',\n",
        "            axis=1\n",
        "        )\n",
        "    \n",
        "    # Show phenotype distribution\n",
        "    phenotype_cols = [col for col in df_medical.columns if col.startswith('has_') and 'mood' in col or 'cognitive' in col or 'psychotic' in col or 'trauma' in col or 'sleep' in col]\n",
        "    if phenotype_cols:\n",
        "        print(\"\\nPsychological phenotypes added:\")\n",
        "        for col in phenotype_cols:\n",
        "            true_count = df_medical[col].sum()\n",
        "            print(f\"  {col}: {true_count} rows\")\n",
        "    \n",
        "    # Save all results\n",
        "    df_all_psychological_entities.to_csv('psychological_entities_comprehensive.csv', index=False)\n",
        "    df_custom_psychological.to_csv('psychological_entities_custom.csv', index=False)\n",
        "    df_psychological_lf_spans.to_csv('psychological_lf_generated_spans.csv', index=False)\n",
        "    \n",
        "    print(\"\\n\\nPsychological entity extraction complete!\")\n",
        "    print(f\"Total entities extracted: {len(df_all_psychological_entities)}\")\n",
        "    print(f\"  - BC5CDR: {len(df_psychological_entities)}\")\n",
        "    print(f\"  - Custom extraction: {len(df_custom_psychological)}\")\n",
        "    print(f\"  - LF-generated: {len(df_psychological_lf_spans)}\")\n",
        "    print(\"\\nAll results saved to CSV files.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>source</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bipolar affective disorder</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>15</td>\n",
              "      <td>41</td>\n",
              "      <td>Diagnosed with bipolar affective disorder at t...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>155216</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mania</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>90</td>\n",
              "      <td>95</td>\n",
              "      <td>Diagnosed with bipolar affective disorder at t...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>155216</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Parental distress</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>Parental distress</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>90928</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>depression</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>68</td>\n",
              "      <td>78</td>\n",
              "      <td>Known to local mental health services for 20 y...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>45433</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>anxiety</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>83</td>\n",
              "      <td>90</td>\n",
              "      <td>Known to local mental health services for 20 y...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>45433</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5678</th>\n",
              "      <td>depression</td>\n",
              "      <td>MOOD_DISORDER</td>\n",
              "      <td>11</td>\n",
              "      <td>21</td>\n",
              "      <td>History of depression diagnosed about 2 years ...</td>\n",
              "      <td>lf:lf_mood_disorder</td>\n",
              "      <td>136465</td>\n",
              "      <td>mood</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5679</th>\n",
              "      <td>anxiety</td>\n",
              "      <td>MOOD_DISORDER</td>\n",
              "      <td>22</td>\n",
              "      <td>29</td>\n",
              "      <td>Developed generalized anxiety disorder</td>\n",
              "      <td>lf:lf_mood_disorder</td>\n",
              "      <td>76671</td>\n",
              "      <td>mood</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5680</th>\n",
              "      <td>Bipolar</td>\n",
              "      <td>MOOD_DISORDER</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>Bipolar disorder</td>\n",
              "      <td>lf:lf_mood_disorder</td>\n",
              "      <td>87937</td>\n",
              "      <td>mood</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5681</th>\n",
              "      <td>Bipolar</td>\n",
              "      <td>MOOD_DISORDER</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>Bipolar disorder</td>\n",
              "      <td>lf:lf_mood_disorder</td>\n",
              "      <td>113022</td>\n",
              "      <td>mood</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5682</th>\n",
              "      <td>Anxiety</td>\n",
              "      <td>MOOD_DISORDER</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>lf:lf_mood_disorder</td>\n",
              "      <td>60912</td>\n",
              "      <td>mood</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5683 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            text          label  start  end  \\\n",
              "0     bipolar affective disorder        DISEASE     15   41   \n",
              "1                          mania        DISEASE     90   95   \n",
              "2              Parental distress        DISEASE      0   17   \n",
              "3                     depression        DISEASE     68   78   \n",
              "4                        anxiety        DISEASE     83   90   \n",
              "...                          ...            ...    ...  ...   \n",
              "5678                  depression  MOOD_DISORDER     11   21   \n",
              "5679                     anxiety  MOOD_DISORDER     22   29   \n",
              "5680                     Bipolar  MOOD_DISORDER      0    7   \n",
              "5681                     Bipolar  MOOD_DISORDER      0    7   \n",
              "5682                     Anxiety  MOOD_DISORDER      0    7   \n",
              "\n",
              "                                          original_text               source  \\\n",
              "0     Diagnosed with bipolar affective disorder at t...               bc5cdr   \n",
              "1     Diagnosed with bipolar affective disorder at t...               bc5cdr   \n",
              "2                                     Parental distress               bc5cdr   \n",
              "3     Known to local mental health services for 20 y...               bc5cdr   \n",
              "4     Known to local mental health services for 20 y...               bc5cdr   \n",
              "...                                                 ...                  ...   \n",
              "5678  History of depression diagnosed about 2 years ...  lf:lf_mood_disorder   \n",
              "5679             Developed generalized anxiety disorder  lf:lf_mood_disorder   \n",
              "5680                                   Bipolar disorder  lf:lf_mood_disorder   \n",
              "5681                                   Bipolar disorder  lf:lf_mood_disorder   \n",
              "5682                                            Anxiety  lf:lf_mood_disorder   \n",
              "\n",
              "      row_idx category  \n",
              "0      155216     None  \n",
              "1      155216     None  \n",
              "2       90928     None  \n",
              "3       45433     None  \n",
              "4       45433     None  \n",
              "...       ...      ...  \n",
              "5678   136465     mood  \n",
              "5679    76671     mood  \n",
              "5680    87937     mood  \n",
              "5681   113022     mood  \n",
              "5682    60912     mood  \n",
              "\n",
              "[5683 rows x 8 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_all_psychological_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8eao_3OH9R4"
      },
      "source": [
        "##### Vaccination History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading en_ner_bc5cdr_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 29755 texts in 100 batches...\n",
            "Using model: en_ner_bc5cdr_md for column: vaccination history\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   2%|▏         | 2/100 [00:00<00:36,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  12%|█▏        | 12/100 [00:02<00:15,  5.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 3000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  22%|██▏       | 22/100 [00:03<00:12,  6.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 6000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  32%|███▏      | 32/100 [00:05<00:11,  5.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 9000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  42%|████▏     | 42/100 [00:07<00:09,  6.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 12000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  52%|█████▏    | 52/100 [00:08<00:07,  6.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  62%|██████▏   | 62/100 [00:10<00:06,  6.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 18000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  72%|███████▏  | 72/100 [00:11<00:04,  5.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 21000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  82%|████████▏ | 82/100 [00:13<00:02,  6.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 24000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  92%|█████████▏| 92/100 [00:14<00:01,  6.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 27000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 100/100 [00:16<00:00,  6.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6 entities appearing >= 5 times\n",
            "\n",
            "Testing generated labeling functions for vaccination history...\n",
            "\n",
            "=== BC5CDR Extraction Results ===\n",
            "Shape of df_vaccination_entities: (129, 7)\n",
            "\n",
            "Column names: ['text', 'label', 'start', 'end', 'original_text', 'row_idx', 'source_column']\n",
            "\n",
            "=== Entity Labels Found in Vaccination History ===\n",
            "label\n",
            "DISEASE     106\n",
            "CHEMICAL     23\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top CHEMICAL/Vaccine entities ===\n",
            "text\n",
            "vitamin K                6\n",
            "Calmette                 3\n",
            "Calmette-Guérin          2\n",
            "tetanus                  2\n",
            "Vitamin K                2\n",
            "Guérin                   2\n",
            "benzathine penicillin    1\n",
            "penicillin               1\n",
            "DTaP                     1\n",
            "DPT                      1\n",
            "Vaccine                  1\n",
            "diphtheria pertussis     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top DISEASE entities (conditions) ===\n",
            "text\n",
            "tetanus                     28\n",
            "Tetanus                     13\n",
            "hepatitis B                  8\n",
            "Anti-D                       5\n",
            "left buttock                 5\n",
            "varicella                    4\n",
            "fever                        3\n",
            "chickenpox                   3\n",
            "hepatitis A                  3\n",
            "poliomyelitis                2\n",
            "tuberculosis infection       2\n",
            "malaria                      2\n",
            "Fever                        1\n",
            "TB                           1\n",
            "Streptococcus pneumoniae     1\n",
            "Herpes simplex               1\n",
            "mumps infection              1\n",
            "COVID-19 infection           1\n",
            "encephalitis B               1\n",
            "zoster                       1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== CUSTOM VACCINATION ENTITY EXTRACTION ===\n",
            "\n",
            "Custom extraction found 363 vaccination entities\n",
            "\n",
            "=== Custom Entity Distribution by Label ===\n",
            "label\n",
            "VACCINE               212\n",
            "VACCINATION_STATUS    105\n",
            "VACCINE_DOSE           28\n",
            "VACCINATION_TIMING     18\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Custom Entity Distribution by Category ===\n",
            "category\n",
            "routine_vaccines    149\n",
            "up_to_date           81\n",
            "dosage               28\n",
            "adult_vaccines       28\n",
            "not_vaccinated       21\n",
            "temporal             18\n",
            "travel_vaccines      17\n",
            "covid_vaccines       17\n",
            "overdue               3\n",
            "vaccine_brands        1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Vaccine Names ===\n",
            "text\n",
            "tetanus         33\n",
            "BCG             32\n",
            "Tetanus         13\n",
            "pneumococcal    10\n",
            "measles         10\n",
            "hepatitis B      9\n",
            "rabies           7\n",
            "influenza        6\n",
            "varicella        6\n",
            "MMR              5\n",
            "diphtheria       5\n",
            "mumps            5\n",
            "COVID            5\n",
            "HPV              5\n",
            "chickenpox       5\n",
            "pertussis        4\n",
            "polio            4\n",
            "COVID-19         4\n",
            "rubella          3\n",
            "hepatitis A      3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== LF-Generated Vaccination Spans ===\n",
            "Total LF-generated spans: 323\n",
            "\n",
            "LF span distribution:\n",
            "label\n",
            "VACCINATION_TIMING     86\n",
            "CHILDHOOD_VACCINES     85\n",
            "TETANUS_VACCINE        47\n",
            "VACCINATION_HISTORY    33\n",
            "TRAVEL_VACCINES        13\n",
            "PNEUMO_VACCINE         13\n",
            "HEPATITIS_VACCINE      11\n",
            "COVID_VACCINE           8\n",
            "UNVACCINATED            8\n",
            "VACCINE_REACTION        8\n",
            "FLU_VACCINE             7\n",
            "RECENT_VACCINATION      4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Row-Level Coverage Analysis ===\n",
            "\n",
            "Labeling function coverage:\n",
            "  lf_vaccination_timing: 96 rows (0.3% coverage)\n",
            "  lf_childhood_vaccines: 84 rows (0.3% coverage)\n",
            "  lf_tetanus_vaccination: 45 rows (0.2% coverage)\n",
            "  lf_historical_vaccination: 31 rows (0.1% coverage)\n",
            "  lf_influenza_vaccination: 16 rows (0.1% coverage)\n",
            "  lf_pneumococcal_vaccination: 13 rows (0.0% coverage)\n",
            "  lf_travel_vaccines: 12 rows (0.0% coverage)\n",
            "  lf_hepatitis_vaccination: 11 rows (0.0% coverage)\n",
            "  lf_vaccine_reaction: 10 rows (0.0% coverage)\n",
            "  lf_no_vaccination: 9 rows (0.0% coverage)\n",
            "  lf_covid_vaccination: 8 rows (0.0% coverage)\n",
            "  lf_recent_vaccination: 4 rows (0.0% coverage)\n",
            "\n",
            "=== COMBINING ALL VACCINATION ENTITY SOURCES ===\n",
            "\n",
            "Total vaccination entities: 815\n",
            "  - BC5CDR: 129\n",
            "  - Custom extraction: 363\n",
            "  - LF-generated: 323\n",
            "\n",
            "Combined entity distribution by label:\n",
            "label\n",
            "VACCINE                212\n",
            "DISEASE                106\n",
            "VACCINATION_STATUS     105\n",
            "VACCINATION_TIMING     104\n",
            "CHILDHOOD_VACCINES      85\n",
            "TETANUS_VACCINE         47\n",
            "VACCINATION_HISTORY     33\n",
            "VACCINE_DOSE            28\n",
            "CHEMICAL                23\n",
            "TRAVEL_VACCINES         13\n",
            "PNEUMO_VACCINE          13\n",
            "HEPATITIS_VACCINE       11\n",
            "COVID_VACCINE            8\n",
            "UNVACCINATED             8\n",
            "VACCINE_REACTION         8\n",
            "FLU_VACCINE              7\n",
            "RECENT_VACCINATION       4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Combined entity distribution by source:\n",
            "source\n",
            "custom_vaccination_extraction     363\n",
            "bc5cdr                            129\n",
            "lf:lf_vaccination_timing           86\n",
            "lf:lf_childhood_vaccines           85\n",
            "lf:lf_tetanus_vaccination          47\n",
            "lf:lf_historical_vaccination       33\n",
            "lf:lf_travel_vaccines              13\n",
            "lf:lf_pneumococcal_vaccination     13\n",
            "lf:lf_hepatitis_vaccination        11\n",
            "lf:lf_covid_vaccination             8\n",
            "lf:lf_no_vaccination                8\n",
            "lf:lf_vaccine_reaction              8\n",
            "lf:lf_influenza_vaccination         7\n",
            "lf:lf_recent_vaccination            4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Vaccine Type Analysis ===\n",
            "\n",
            "=== COVID Vaccine Mentions ===\n",
            "Total: 17\n",
            "Top terms:\n",
            "text\n",
            "COVID          5\n",
            "COVID-19       4\n",
            "mRNA-1273      2\n",
            "Moderna        2\n",
            "coronavirus    1\n",
            "Pfizer         1\n",
            "SARS-CoV-2     1\n",
            "AstraZeneca    1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Adding Row-Level Vaccination Phenotypes ===\n",
            "\n",
            "Vaccination phenotypes added:\n",
            "  has_covid_vaccination: 8 rows\n",
            "  has_childhood_vaccines: 84 rows\n",
            "  has_influenza_vaccination: 16 rows\n",
            "  has_hepatitis_vaccination: 11 rows\n",
            "  has_tetanus_vaccination: 45 rows\n",
            "  has_pneumococcal_vaccination: 13 rows\n",
            "  has_travel_vaccines: 12 rows\n",
            "  has_vaccination_timing: 96 rows\n",
            "  has_no_vaccination: 9 rows\n",
            "  has_vaccine_reaction: 10 rows\n",
            "  has_recent_vaccination: 4 rows\n",
            "  has_historical_vaccination: 31 rows\n",
            "\n",
            "\n",
            "Vaccination entity extraction complete!\n",
            "All results saved to CSV files.\n"
          ]
        }
      ],
      "source": [
        "def extract_vaccination_entities_custom(df_medical, text_column='vaccination history', id_column='idx'):\n",
        "    \"\"\"Extract vaccination-specific entities beyond what BC5CDR captures\"\"\"\n",
        "    \n",
        "    # Build the id series once\n",
        "    if id_column is not None and id_column in df_medical.columns:\n",
        "        ids_series = df_medical[id_column].where(pd.notna(df_medical[id_column]), df_medical.index)\n",
        "    else:\n",
        "        ids_series = df_medical.index\n",
        "    \n",
        "    texts = df_medical[text_column].fillna('').astype(str)\n",
        "    \n",
        "    # Vaccination patterns\n",
        "    vaccination_patterns = {\n",
        "        'covid_vaccines': [\n",
        "            'covid', 'covid-19', 'coronavirus', 'sars-cov-2', 'pfizer', 'moderna',\n",
        "            'astrazeneca', 'johnson & johnson', 'j&j', 'mrna-1273', 'bnt162b2',\n",
        "            'covaxin', 'sputnik', 'sinovac', 'sinopharm'\n",
        "        ],\n",
        "        'routine_vaccines': [\n",
        "            'mmr', 'measles', 'mumps', 'rubella', 'varicella', 'chickenpox',\n",
        "            'polio', 'dtap', 'diphtheria', 'tetanus', 'pertussis', 'whooping cough',\n",
        "            'hib', 'hepatitis a', 'hepatitis b', 'hep a', 'hep b', 'rotavirus',\n",
        "            'pcv', 'ipv', 'opv', 'bcg', 'tuberculosis'\n",
        "        ],\n",
        "        'adult_vaccines': [\n",
        "            'influenza', 'flu vaccine', 'flu shot', 'pneumococcal', 'pneumonia vaccine',\n",
        "            'shingles', 'zoster', 'hpv', 'human papillomavirus', 'tdap', 'td'\n",
        "        ],\n",
        "        'travel_vaccines': [\n",
        "            'yellow fever', 'typhoid', 'japanese encephalitis', 'rabies',\n",
        "            'meningococcal', 'cholera', 'malaria prophylaxis'\n",
        "        ],\n",
        "        'vaccine_brands': [\n",
        "            'havrix', 'engerix', 'prevnar', 'pneumovax', 'fluzone', 'flumist',\n",
        "            'gardasil', 'cervarix', 'boostrix', 'adacel', 'shingrix', 'zostavax'\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    # Timing patterns\n",
        "    timing_patterns = [\n",
        "        r'\\d+\\s*(?:year|month|week|day)s?\\s*ago',\n",
        "        r'(?:last|this)\\s*(?:year|month|week)',\n",
        "        r'(?:january|february|march|april|may|june|july|august|september|october|november|december)\\s*\\d{4}',\n",
        "        r'\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}',\n",
        "        r'recently', r'childhood', r'infancy', r'adolescence'\n",
        "    ]\n",
        "    \n",
        "    # Dose patterns\n",
        "    dose_patterns = [\n",
        "        r'(?:first|second|third|1st|2nd|3rd)\\s*(?:dose|shot)',\n",
        "        r'booster\\s*(?:dose|shot)?',\n",
        "        r'single\\s*dose',\n",
        "        r'(?:completed|complete)\\s*series',\n",
        "        r'fully\\s*vaccinated',\n",
        "        r'partially\\s*vaccinated'\n",
        "    ]\n",
        "    \n",
        "    # Status patterns\n",
        "    status_patterns = {\n",
        "        'up_to_date': ['up to date', 'up-to-date', 'current', 'complete'],\n",
        "        'not_vaccinated': ['not vaccinated', 'unvaccinated', 'declined', 'refused', 'no history'],\n",
        "        'overdue': ['overdue', 'due for', 'needs', 'recommended'],\n",
        "        'contraindicated': ['contraindicated', 'allergic', 'cannot receive']\n",
        "    }\n",
        "    \n",
        "    vaccination_entities = []\n",
        "    \n",
        "    for (df_index, text_original), idx in zip(texts.items(), ids_series):\n",
        "        if text_original:\n",
        "            text = text_original.lower()\n",
        "            \n",
        "            # Extract vaccine names\n",
        "            for category, vaccines in vaccination_patterns.items():\n",
        "                for vaccine in vaccines:\n",
        "                    pattern = r'\\b' + re.escape(vaccine) + r'\\b'\n",
        "                    for match in re.finditer(pattern, text):\n",
        "                        vaccination_entities.append({\n",
        "                            'text': text_original[match.start():match.end()],\n",
        "                            'label': 'VACCINE',\n",
        "                            'category': category,\n",
        "                            'start': match.start(),\n",
        "                            'end': match.end(),\n",
        "                            'original_text': text_original,\n",
        "                            'source': 'custom_vaccination_extraction',\n",
        "                            'row_idx': idx\n",
        "                        })\n",
        "            \n",
        "            # Extract timing information\n",
        "            for pattern in timing_patterns:\n",
        "                for match in re.finditer(pattern, text, re.IGNORECASE):\n",
        "                    vaccination_entities.append({\n",
        "                        'text': text_original[match.start():match.end()],\n",
        "                        'label': 'VACCINATION_TIMING',\n",
        "                        'category': 'temporal',\n",
        "                        'start': match.start(),\n",
        "                        'end': match.end(),\n",
        "                        'original_text': text_original,\n",
        "                        'source': 'custom_vaccination_extraction',\n",
        "                        'row_idx': idx\n",
        "                    })\n",
        "            \n",
        "            # Extract dose information\n",
        "            for pattern in dose_patterns:\n",
        "                for match in re.finditer(pattern, text, re.IGNORECASE):\n",
        "                    vaccination_entities.append({\n",
        "                        'text': text_original[match.start():match.end()],\n",
        "                        'label': 'VACCINE_DOSE',\n",
        "                        'category': 'dosage',\n",
        "                        'start': match.start(),\n",
        "                        'end': match.end(),\n",
        "                        'original_text': text_original,\n",
        "                        'source': 'custom_vaccination_extraction',\n",
        "                        'row_idx': idx\n",
        "                    })\n",
        "            \n",
        "            # Extract vaccination status\n",
        "            for status_type, terms in status_patterns.items():\n",
        "                for term in terms:\n",
        "                    pattern = r'\\b' + re.escape(term) + r'\\b'\n",
        "                    for match in re.finditer(pattern, text):\n",
        "                        vaccination_entities.append({\n",
        "                            'text': text_original[match.start():match.end()],\n",
        "                            'label': 'VACCINATION_STATUS',\n",
        "                            'category': status_type,\n",
        "                            'start': match.start(),\n",
        "                            'end': match.end(),\n",
        "                            'original_text': text_original,\n",
        "                            'source': 'custom_vaccination_extraction',\n",
        "                            'row_idx': idx\n",
        "                        })\n",
        "    \n",
        "    return pd.DataFrame(vaccination_entities)\n",
        "\n",
        "\n",
        "def materialize_lf_spans(df, labeling_functions, id_column='idx'):\n",
        "    \"\"\"Convert labeling function results into span entities\"\"\"\n",
        "    lf_entities = []\n",
        "    \n",
        "    # Build the id series once\n",
        "    if id_column is not None and id_column in df.columns:\n",
        "        ids_series = df[id_column].where(pd.notna(df[id_column]), df.index)\n",
        "    else:\n",
        "        ids_series = df.index\n",
        "    \n",
        "    for (df_index, row), idx in zip(df.iterrows(), ids_series):\n",
        "        for lf in labeling_functions:\n",
        "            result = lf(row)\n",
        "            \n",
        "            if result.get('label') != 'ABSTAIN':\n",
        "                # Get the text from the specified column\n",
        "                column_name = result.get('column', 'vaccination history')\n",
        "                full_text = str(row.get(column_name, ''))\n",
        "                match_term = result.get('match')\n",
        "                \n",
        "                if match_term:\n",
        "                    # Find all occurrences of the match term\n",
        "                    pattern = r'\\b' + re.escape(match_term) + r'\\b'\n",
        "                    \n",
        "                    for match in re.finditer(pattern, full_text.lower()):\n",
        "                        # Extract the actual text (preserving original case)\n",
        "                        actual_text = full_text[match.start():match.end()]\n",
        "                        \n",
        "                        lf_entities.append({\n",
        "                            'text': actual_text,\n",
        "                            'label': result['label'],\n",
        "                            'category': result.get('category', 'unknown'),\n",
        "                            'start': match.start(),\n",
        "                            'end': match.end(),\n",
        "                            'original_text': full_text,\n",
        "                            'source': f'lf:{lf.__name__}',\n",
        "                            'row_idx': idx\n",
        "                        })\n",
        "    \n",
        "    return pd.DataFrame(lf_entities)\n",
        "\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # BC5CDR model will identify vaccines (CHEMICAL) and diseases (DISEASE)\n",
        "    df_vaccination_entities, vaccination_summary, vaccination_rules = run_medical_ner_extraction(\n",
        "        df_medical, \n",
        "        text_column='vaccination history',\n",
        "        model_name=\"en_ner_bc5cdr_md\",  # This model recognizes DISEASE and CHEMICAL entities\n",
        "        batch_size=300,\n",
        "        id_column='idx'  # Use 'idx' column for row identifiers\n",
        "    )\n",
        "\n",
        "    # Test the generated rules\n",
        "    print(\"\\nTesting generated labeling functions for vaccination history...\")\n",
        "\n",
        "    # Select a sample row from the original df_medical to test the rules\n",
        "    if not df_medical.empty:\n",
        "        sample_row = df_medical.iloc[0]\n",
        "\n",
        "        for rule_name, rule_func in vaccination_rules.items():\n",
        "            try:\n",
        "                test_result = rule_func(sample_row)\n",
        "                if test_result != 'ABSTAIN':\n",
        "                    print(f\"{rule_name} applied to row 0: {test_result}\")\n",
        "            except KeyError as e:\n",
        "                print(f\"Error applying rule {rule_name}: {e}. Make sure the column 'vaccination_history' exists in df_medical.\")\n",
        "    else:\n",
        "        print(\"df_medical is empty, cannot test rules.\")\n",
        "\n",
        "    # Debug: Check extracted entities\n",
        "    print(\"\\n=== BC5CDR Extraction Results ===\")\n",
        "    print(f\"Shape of df_vaccination_entities: {df_vaccination_entities.shape}\")\n",
        "    print(f\"\\nColumn names: {df_vaccination_entities.columns.tolist()}\")\n",
        "\n",
        "    # Check entity label distribution\n",
        "    print(\"\\n=== Entity Labels Found in Vaccination History ===\")\n",
        "    if not df_vaccination_entities.empty:\n",
        "        print(df_vaccination_entities['label'].value_counts())\n",
        "\n",
        "        # Look at CHEMICAL entities (likely vaccines)\n",
        "        if 'CHEMICAL' in df_vaccination_entities['label'].values:\n",
        "            print(\"\\n=== Top CHEMICAL/Vaccine entities ===\")\n",
        "            vaccine_entities = df_vaccination_entities[df_vaccination_entities['label'] == 'CHEMICAL']['text'].value_counts().head(20)\n",
        "            print(vaccine_entities)\n",
        "\n",
        "        # Look at DISEASE entities (conditions vaccines prevent)\n",
        "        if 'DISEASE' in df_vaccination_entities['label'].values:\n",
        "            print(\"\\n=== Top DISEASE entities (conditions) ===\")\n",
        "            disease_entities = df_vaccination_entities[df_vaccination_entities['label'] == 'DISEASE']['text'].value_counts().head(20)\n",
        "            print(disease_entities)\n",
        "    else:\n",
        "        print(\"df_vaccination_entities is empty.\")\n",
        "    \n",
        "    # Extract custom vaccination entities\n",
        "    print(\"\\n=== CUSTOM VACCINATION ENTITY EXTRACTION ===\")\n",
        "    df_custom_vaccination = extract_vaccination_entities_custom(\n",
        "        df_medical,\n",
        "        text_column='vaccination history',\n",
        "        id_column='idx'\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nCustom extraction found {len(df_custom_vaccination)} vaccination entities\")\n",
        "    if not df_custom_vaccination.empty:\n",
        "        print(\"\\n=== Custom Entity Distribution by Label ===\")\n",
        "        print(df_custom_vaccination['label'].value_counts())\n",
        "        print(\"\\n=== Custom Entity Distribution by Category ===\")\n",
        "        print(df_custom_vaccination['category'].value_counts())\n",
        "        print(\"\\n=== Top Vaccine Names ===\")\n",
        "        vaccine_names = df_custom_vaccination[df_custom_vaccination['label'] == 'VACCINE']\n",
        "        if not vaccine_names.empty:\n",
        "            print(vaccine_names['text'].value_counts().head(20))\n",
        "\n",
        "    # Create labeling functions\n",
        "    def create_vaccination_labeling_functions(entities_df: pd.DataFrame):\n",
        "        \"\"\"Spanified vaccination LFs: return {'label','column','match','category?'}.\"\"\"\n",
        "        COL = 'vaccination history'\n",
        "\n",
        "        _ = entities_df['text'].value_counts().head(50) if not entities_df.empty else pd.Series(dtype=int)\n",
        "\n",
        "        def _first_hit(text, terms):\n",
        "            text_l = text.lower()\n",
        "            for t in terms:\n",
        "                if t in text_l:\n",
        "                    return t\n",
        "            return None\n",
        "\n",
        "        def lf_covid_vaccination(row):\n",
        "            text = str(row.get(COL, ''))\n",
        "            terms = ['covid', 'coronavirus', 'sars-cov-2', 'pfizer', 'moderna',\n",
        "                    'astrazeneca', 'johnson', 'mrna-1273', 'bnt162b2']\n",
        "            hit = _first_hit(text, terms)\n",
        "            return {'label': 'COVID_VACCINE', 'column': COL, 'match': hit, 'category': 'vaccine'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_childhood_vaccines(row):\n",
        "            text = str(row.get(COL, ''))\n",
        "            terms = ['mmr', 'measles', 'mumps', 'rubella', 'varicella', 'chickenpox',\n",
        "                    'polio', 'dtap', 'diphtheria', 'tetanus', 'pertussis', 'whooping',\n",
        "                    'hib', 'hepatitis b', 'rotavirus', 'pcv', 'ipv']\n",
        "            hit = _first_hit(text, terms)\n",
        "            return {'label': 'CHILDHOOD_VACCINES', 'column': COL, 'match': hit, 'category': 'vaccine'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_influenza_vaccination(row):\n",
        "            text = str(row.get(COL, ''))\n",
        "            terms = ['influenza', 'flu vaccine', 'flu shot', 'seasonal flu', 'h1n1']\n",
        "            hit = _first_hit(text, terms)\n",
        "            return {'label': 'FLU_VACCINE', 'column': COL, 'match': hit, 'category': 'vaccine'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_hepatitis_vaccination(row):\n",
        "            text = str(row.get(COL, ''))\n",
        "            terms = ['hepatitis a', 'hepatitis b', 'hep a', 'hep b', 'havrix', 'engerix']\n",
        "            hit = _first_hit(text, terms)\n",
        "            return {'label': 'HEPATITIS_VACCINE', 'column': COL, 'match': hit, 'category': 'vaccine'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_tetanus_vaccination(row):\n",
        "            text = str(row.get(COL, ''))\n",
        "            terms = ['tetanus', 'tdap', 'td ', 'boostrix', 'adacel']\n",
        "            hit = _first_hit(text, terms)\n",
        "            return {'label': 'TETANUS_VACCINE', 'column': COL, 'match': hit, 'category': 'vaccine'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_pneumococcal_vaccination(row):\n",
        "            text = str(row.get(COL, ''))\n",
        "            terms = ['pneumococcal', 'pneumonia vaccine', 'prevnar', 'pneumovax']\n",
        "            hit = _first_hit(text, terms)\n",
        "            return {'label': 'PNEUMO_VACCINE', 'column': COL, 'match': hit, 'category': 'vaccine'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_travel_vaccines(row):\n",
        "            text = str(row.get(COL, ''))\n",
        "            terms = ['yellow fever', 'typhoid', 'japanese encephalitis', 'rabies', 'meningococcal', 'cholera']\n",
        "            hit = _first_hit(text, terms)\n",
        "            return {'label': 'TRAVEL_VACCINES', 'column': COL, 'match': hit, 'category': 'vaccine'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_vaccination_timing(row):\n",
        "            text = str(row.get(COL, ''))\n",
        "            terms = ['booster', 'dose', 'series', 'schedule', 'up to date',\n",
        "                    'fully vaccinated', 'partially vaccinated']\n",
        "            hit = _first_hit(text, terms)\n",
        "            return {'label': 'VACCINATION_TIMING', 'column': COL, 'match': hit, 'category': 'timing'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_no_vaccination(row):\n",
        "            text = str(row.get(COL, ''))\n",
        "            terms = ['no vaccination', 'not vaccinated', 'unvaccinated',\n",
        "                    'declined', 'refused', 'no history of vaccination']\n",
        "            hit = _first_hit(text, terms)\n",
        "            return {'label': 'UNVACCINATED', 'column': COL, 'match': hit, 'category': 'status'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_vaccine_reaction(row):\n",
        "            text = str(row.get(COL, ''))\n",
        "            terms = ['reaction', 'allergy', 'side effect', 'adverse', 'anaphylaxis']\n",
        "            hit = _first_hit(text, terms)\n",
        "            return {'label': 'VACCINE_REACTION', 'column': COL, 'match': hit, 'category': 'reaction'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_recent_vaccination(row):\n",
        "            text = str(row.get(COL, ''))\n",
        "            terms = ['weeks ago', 'months ago', 'recently', 'last month', 'last week', 'this year']\n",
        "            hit = _first_hit(text, terms)\n",
        "            return {'label': 'RECENT_VACCINATION', 'column': COL, 'match': hit, 'category': 'recency'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_historical_vaccination(row):\n",
        "            text = str(row.get(COL, ''))\n",
        "            if 'history' in text.lower() and any(k in text.lower() for k in ['vaccin', 'immuniz']):\n",
        "                return {'label': 'VACCINATION_HISTORY', 'column': COL, 'match': 'history', 'category': 'history'}\n",
        "            return {'label': 'ABSTAIN'}\n",
        "\n",
        "        return [\n",
        "            lf_covid_vaccination, lf_childhood_vaccines, lf_influenza_vaccination,\n",
        "            lf_hepatitis_vaccination, lf_tetanus_vaccination, lf_pneumococcal_vaccination,\n",
        "            lf_travel_vaccines, lf_vaccination_timing, lf_no_vaccination,\n",
        "            lf_vaccine_reaction, lf_recent_vaccination, lf_historical_vaccination\n",
        "        ]\n",
        "\n",
        "    # Apply labeling functions\n",
        "    vaccination_lfs = create_vaccination_labeling_functions(df_vaccination_entities)\n",
        "    \n",
        "    df_vaccination_lf_spans = materialize_lf_spans(df_medical, vaccination_lfs, id_column='idx')\n",
        "    print(f\"\\n=== LF-Generated Vaccination Spans ===\")\n",
        "    print(f\"Total LF-generated spans: {len(df_vaccination_lf_spans)}\")\n",
        "    if not df_vaccination_lf_spans.empty:\n",
        "        print(\"\\nLF span distribution:\")\n",
        "        print(df_vaccination_lf_spans['label'].value_counts())\n",
        "    \n",
        "    # Row-level coverage analysis\n",
        "    print(\"\\n=== Row-Level Coverage Analysis ===\")\n",
        "    coverage_results = {}\n",
        "    for lf in vaccination_lfs:\n",
        "        labeled_count = 0\n",
        "        for _, row in df_medical.iterrows():\n",
        "            result = lf(row)\n",
        "            if result.get('label') != 'ABSTAIN':\n",
        "                labeled_count += 1\n",
        "        \n",
        "        coverage = (labeled_count / len(df_medical) * 100) if len(df_medical) > 0 else 0\n",
        "        coverage_results[lf.__name__] = {\n",
        "            'labeled': labeled_count,\n",
        "            'coverage': coverage\n",
        "        }\n",
        "    \n",
        "    print(\"\\nLabeling function coverage:\")\n",
        "    for lf_name, stats in sorted(coverage_results.items(), key=lambda x: x[1]['coverage'], reverse=True):\n",
        "        print(f\"  {lf_name}: {stats['labeled']} rows ({stats['coverage']:.1f}% coverage)\")\n",
        "\n",
        "    # Combine all sources\n",
        "    print(\"\\n=== COMBINING ALL VACCINATION ENTITY SOURCES ===\")\n",
        "    \n",
        "    # Ensure common columns exist for concat\n",
        "    _v_cols = ['text','label','start','end','original_text','source','row_idx','category']\n",
        "    for col in _v_cols:\n",
        "        if col not in df_vaccination_entities.columns:\n",
        "            df_vaccination_entities[col] = 'bc5cdr' if col=='source' else None\n",
        "        if col not in df_custom_vaccination.columns:\n",
        "            df_custom_vaccination[col] = 'custom_extraction' if col=='source' else None\n",
        "        if col not in df_vaccination_lf_spans.columns:\n",
        "            df_vaccination_lf_spans[col] = None\n",
        "\n",
        "    df_all_vaccination_entities = pd.concat(\n",
        "        [df_vaccination_entities[_v_cols], \n",
        "         df_custom_vaccination[_v_cols],\n",
        "         df_vaccination_lf_spans[_v_cols]],\n",
        "        ignore_index=True\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nTotal vaccination entities: {len(df_all_vaccination_entities)}\")\n",
        "    print(f\"  - BC5CDR: {len(df_vaccination_entities)}\")\n",
        "    print(f\"  - Custom extraction: {len(df_custom_vaccination)}\")\n",
        "    print(f\"  - LF-generated: {len(df_vaccination_lf_spans)}\")\n",
        "    \n",
        "    print(\"\\nCombined entity distribution by label:\")\n",
        "    print(df_all_vaccination_entities['label'].value_counts())\n",
        "    print(\"\\nCombined entity distribution by source:\")\n",
        "    print(df_all_vaccination_entities['source'].value_counts())\n",
        "    \n",
        "    # Analysis by vaccine type\n",
        "    if not df_all_vaccination_entities.empty:\n",
        "        print(\"\\n=== Vaccine Type Analysis ===\")\n",
        "        \n",
        "        # COVID vaccines\n",
        "        covid_vaccines = df_all_vaccination_entities[\n",
        "            df_all_vaccination_entities['label'].isin(['COVID_VACCINE', 'VACCINE'])\n",
        "        ]\n",
        "        if not covid_vaccines.empty and 'category' in covid_vaccines.columns:\n",
        "            covid_specific = covid_vaccines[covid_vaccines['category'] == 'covid_vaccines']\n",
        "            if not covid_specific.empty:\n",
        "                print(f\"\\n=== COVID Vaccine Mentions ===\")\n",
        "                print(f\"Total: {len(covid_specific)}\")\n",
        "                print(\"Top terms:\")\n",
        "                print(covid_specific['text'].value_counts().head(10))\n",
        "    \n",
        "    # Add row-level vaccination phenotypes\n",
        "    print(\"\\n=== Adding Row-Level Vaccination Phenotypes ===\")\n",
        "    for lf in vaccination_lfs:\n",
        "        phenotype_name = f\"has_{lf.__name__.replace('lf_', '')}\"\n",
        "        df_medical[phenotype_name] = df_medical.apply(\n",
        "            lambda row: lf(row).get('label') != 'ABSTAIN',\n",
        "            axis=1\n",
        "        )\n",
        "    \n",
        "    # Show phenotype distribution\n",
        "    phenotype_cols = [col for col in df_medical.columns if col.startswith('has_') and ('vaccine' in col.lower() or 'vaccination' in col.lower())]\n",
        "    if phenotype_cols:\n",
        "        print(\"\\nVaccination phenotypes added:\")\n",
        "        for col in phenotype_cols:\n",
        "            true_count = df_medical[col].sum()\n",
        "            print(f\"  {col}: {true_count} rows\")\n",
        "    \n",
        "    # Save results\n",
        "    df_vaccination_lf_spans.to_csv('vaccination_lf_generated_spans.csv', index=False)\n",
        "    df_all_vaccination_entities.to_csv('vaccination_entities_comprehensive.csv', index=False)\n",
        "    df_custom_vaccination.to_csv('vaccination_entities_custom.csv', index=False)\n",
        "    \n",
        "    print(\"\\n\\nVaccination entity extraction complete!\")\n",
        "    print(\"All results saved to CSV files.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>category</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>source</th>\n",
              "      <th>row_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>history</td>\n",
              "      <td>VACCINATION_HISTORY</td>\n",
              "      <td>history</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>No history of recent vaccination</td>\n",
              "      <td>lf:lf_historical_vaccination</td>\n",
              "      <td>87135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rabies</td>\n",
              "      <td>TRAVEL_VACCINES</td>\n",
              "      <td>vaccine</td>\n",
              "      <td>11</td>\n",
              "      <td>17</td>\n",
              "      <td>Given anti rabies vaccine and immunoglobulin a...</td>\n",
              "      <td>lf:lf_travel_vaccines</td>\n",
              "      <td>132574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tetanus</td>\n",
              "      <td>CHILDHOOD_VACCINES</td>\n",
              "      <td>vaccine</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>Tetanus vaccination with tetanus immunoglobuli...</td>\n",
              "      <td>lf:lf_childhood_vaccines</td>\n",
              "      <td>119386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tetanus</td>\n",
              "      <td>CHILDHOOD_VACCINES</td>\n",
              "      <td>vaccine</td>\n",
              "      <td>25</td>\n",
              "      <td>32</td>\n",
              "      <td>Tetanus vaccination with tetanus immunoglobuli...</td>\n",
              "      <td>lf:lf_childhood_vaccines</td>\n",
              "      <td>119386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tetanus</td>\n",
              "      <td>TETANUS_VACCINE</td>\n",
              "      <td>vaccine</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>Tetanus vaccination with tetanus immunoglobuli...</td>\n",
              "      <td>lf:lf_tetanus_vaccination</td>\n",
              "      <td>119386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>Tetanus</td>\n",
              "      <td>CHILDHOOD_VACCINES</td>\n",
              "      <td>vaccine</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>Tetanus vaccination administered during curren...</td>\n",
              "      <td>lf:lf_childhood_vaccines</td>\n",
              "      <td>68442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>Tetanus</td>\n",
              "      <td>TETANUS_VACCINE</td>\n",
              "      <td>vaccine</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>Tetanus vaccination administered during curren...</td>\n",
              "      <td>lf:lf_tetanus_vaccination</td>\n",
              "      <td>68442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>history</td>\n",
              "      <td>VACCINATION_HISTORY</td>\n",
              "      <td>history</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>No history of any immunizations in the recent ...</td>\n",
              "      <td>lf:lf_historical_vaccination</td>\n",
              "      <td>156722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>influenza</td>\n",
              "      <td>FLU_VACCINE</td>\n",
              "      <td>vaccine</td>\n",
              "      <td>17</td>\n",
              "      <td>26</td>\n",
              "      <td>Lacked a current influenza vaccination, all ot...</td>\n",
              "      <td>lf:lf_influenza_vaccination</td>\n",
              "      <td>74172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322</th>\n",
              "      <td>up to date</td>\n",
              "      <td>VACCINATION_TIMING</td>\n",
              "      <td>timing</td>\n",
              "      <td>64</td>\n",
              "      <td>74</td>\n",
              "      <td>Lacked a current influenza vaccination, all ot...</td>\n",
              "      <td>lf:lf_vaccination_timing</td>\n",
              "      <td>74172</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>323 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           text                label category  start  end  \\\n",
              "0       history  VACCINATION_HISTORY  history      3   10   \n",
              "1        rabies      TRAVEL_VACCINES  vaccine     11   17   \n",
              "2       Tetanus   CHILDHOOD_VACCINES  vaccine      0    7   \n",
              "3       tetanus   CHILDHOOD_VACCINES  vaccine     25   32   \n",
              "4       Tetanus      TETANUS_VACCINE  vaccine      0    7   \n",
              "..          ...                  ...      ...    ...  ...   \n",
              "318     Tetanus   CHILDHOOD_VACCINES  vaccine      0    7   \n",
              "319     Tetanus      TETANUS_VACCINE  vaccine      0    7   \n",
              "320     history  VACCINATION_HISTORY  history      3   10   \n",
              "321   influenza          FLU_VACCINE  vaccine     17   26   \n",
              "322  up to date   VACCINATION_TIMING   timing     64   74   \n",
              "\n",
              "                                         original_text  \\\n",
              "0                     No history of recent vaccination   \n",
              "1    Given anti rabies vaccine and immunoglobulin a...   \n",
              "2    Tetanus vaccination with tetanus immunoglobuli...   \n",
              "3    Tetanus vaccination with tetanus immunoglobuli...   \n",
              "4    Tetanus vaccination with tetanus immunoglobuli...   \n",
              "..                                                 ...   \n",
              "318  Tetanus vaccination administered during curren...   \n",
              "319  Tetanus vaccination administered during curren...   \n",
              "320  No history of any immunizations in the recent ...   \n",
              "321  Lacked a current influenza vaccination, all ot...   \n",
              "322  Lacked a current influenza vaccination, all ot...   \n",
              "\n",
              "                           source  row_idx  \n",
              "0    lf:lf_historical_vaccination    87135  \n",
              "1           lf:lf_travel_vaccines   132574  \n",
              "2        lf:lf_childhood_vaccines   119386  \n",
              "3        lf:lf_childhood_vaccines   119386  \n",
              "4       lf:lf_tetanus_vaccination   119386  \n",
              "..                            ...      ...  \n",
              "318      lf:lf_childhood_vaccines    68442  \n",
              "319     lf:lf_tetanus_vaccination    68442  \n",
              "320  lf:lf_historical_vaccination   156722  \n",
              "321   lf:lf_influenza_vaccination    74172  \n",
              "322      lf:lf_vaccination_timing    74172  \n",
              "\n",
              "[323 rows x 8 columns]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_vaccination_lf_spans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>source</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tetanus</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>Tetanus vaccination with tetanus immunoglobuli...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>119386</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tetanus</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>25</td>\n",
              "      <td>32</td>\n",
              "      <td>Tetanus vaccination with tetanus immunoglobuli...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>119386</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hyposplenism</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>39</td>\n",
              "      <td>51</td>\n",
              "      <td>Vaccinated post-treatment for presumed hypospl...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>13774</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tetanus</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>14</td>\n",
              "      <td>21</td>\n",
              "      <td>No history of tetanus vaccination or tetanus i...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>157338</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tetanus infection</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>37</td>\n",
              "      <td>54</td>\n",
              "      <td>No history of tetanus vaccination or tetanus i...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>157338</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>810</th>\n",
              "      <td>Tetanus</td>\n",
              "      <td>CHILDHOOD_VACCINES</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>Tetanus vaccination administered during curren...</td>\n",
              "      <td>lf:lf_childhood_vaccines</td>\n",
              "      <td>68442</td>\n",
              "      <td>vaccine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>811</th>\n",
              "      <td>Tetanus</td>\n",
              "      <td>TETANUS_VACCINE</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>Tetanus vaccination administered during curren...</td>\n",
              "      <td>lf:lf_tetanus_vaccination</td>\n",
              "      <td>68442</td>\n",
              "      <td>vaccine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>812</th>\n",
              "      <td>history</td>\n",
              "      <td>VACCINATION_HISTORY</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>No history of any immunizations in the recent ...</td>\n",
              "      <td>lf:lf_historical_vaccination</td>\n",
              "      <td>156722</td>\n",
              "      <td>history</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>813</th>\n",
              "      <td>influenza</td>\n",
              "      <td>FLU_VACCINE</td>\n",
              "      <td>17</td>\n",
              "      <td>26</td>\n",
              "      <td>Lacked a current influenza vaccination, all ot...</td>\n",
              "      <td>lf:lf_influenza_vaccination</td>\n",
              "      <td>74172</td>\n",
              "      <td>vaccine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>814</th>\n",
              "      <td>up to date</td>\n",
              "      <td>VACCINATION_TIMING</td>\n",
              "      <td>64</td>\n",
              "      <td>74</td>\n",
              "      <td>Lacked a current influenza vaccination, all ot...</td>\n",
              "      <td>lf:lf_vaccination_timing</td>\n",
              "      <td>74172</td>\n",
              "      <td>timing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>815 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  text                label  start  end  \\\n",
              "0              Tetanus              DISEASE      0    7   \n",
              "1              tetanus              DISEASE     25   32   \n",
              "2         hyposplenism              DISEASE     39   51   \n",
              "3              tetanus              DISEASE     14   21   \n",
              "4    tetanus infection              DISEASE     37   54   \n",
              "..                 ...                  ...    ...  ...   \n",
              "810            Tetanus   CHILDHOOD_VACCINES      0    7   \n",
              "811            Tetanus      TETANUS_VACCINE      0    7   \n",
              "812            history  VACCINATION_HISTORY      3   10   \n",
              "813          influenza          FLU_VACCINE     17   26   \n",
              "814         up to date   VACCINATION_TIMING     64   74   \n",
              "\n",
              "                                         original_text  \\\n",
              "0    Tetanus vaccination with tetanus immunoglobuli...   \n",
              "1    Tetanus vaccination with tetanus immunoglobuli...   \n",
              "2    Vaccinated post-treatment for presumed hypospl...   \n",
              "3    No history of tetanus vaccination or tetanus i...   \n",
              "4    No history of tetanus vaccination or tetanus i...   \n",
              "..                                                 ...   \n",
              "810  Tetanus vaccination administered during curren...   \n",
              "811  Tetanus vaccination administered during curren...   \n",
              "812  No history of any immunizations in the recent ...   \n",
              "813  Lacked a current influenza vaccination, all ot...   \n",
              "814  Lacked a current influenza vaccination, all ot...   \n",
              "\n",
              "                           source  row_idx category  \n",
              "0                          bc5cdr   119386     None  \n",
              "1                          bc5cdr   119386     None  \n",
              "2                          bc5cdr    13774     None  \n",
              "3                          bc5cdr   157338     None  \n",
              "4                          bc5cdr   157338     None  \n",
              "..                            ...      ...      ...  \n",
              "810      lf:lf_childhood_vaccines    68442  vaccine  \n",
              "811     lf:lf_tetanus_vaccination    68442  vaccine  \n",
              "812  lf:lf_historical_vaccination   156722  history  \n",
              "813   lf:lf_influenza_vaccination    74172  vaccine  \n",
              "814      lf:lf_vaccination_timing    74172   timing  \n",
              "\n",
              "[815 rows x 8 columns]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_all_vaccination_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a1jNMwsRO5z"
      },
      "source": [
        "##### Allergies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymvhuE8cRUk9",
        "outputId": "020c83ca-765f-40ee-e857-69ed48147e9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading en_ner_bc5cdr_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 29755 texts in 100 batches...\n",
            "Using model: en_ner_bc5cdr_md for column: allergies\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   2%|▏         | 2/100 [00:00<00:38,  2.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  12%|█▏        | 12/100 [00:02<00:14,  5.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 3000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  22%|██▏       | 22/100 [00:04<00:12,  6.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 6000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  32%|███▏      | 32/100 [00:05<00:12,  5.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 9000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  41%|████      | 41/100 [00:07<00:10,  5.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 12000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  52%|█████▏    | 52/100 [00:09<00:08,  5.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  62%|██████▏   | 62/100 [00:11<00:07,  5.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 18000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  72%|███████▏  | 72/100 [00:12<00:05,  5.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 21000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  82%|████████▏ | 82/100 [00:14<00:03,  5.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 24000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  92%|█████████▏| 92/100 [00:16<00:01,  5.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 27000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 100/100 [00:17<00:00,  5.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 32 entities appearing >= 5 times\n",
            "\n",
            "Testing generated labeling functions for allergies...\n",
            "lf_disease_allergies applied to row 0: ABSTAIN\n",
            "lf_chemical_allergies applied to row 0: ABSTAIN\n",
            "\n",
            "=== DEBUG: Check extracted allergy entities ===\n",
            "Shape of df_allergies_entities: (934, 7)\n",
            "\n",
            "Column names: ['text', 'label', 'start', 'end', 'original_text', 'row_idx', 'source_column']\n",
            "\n",
            "First few rows:\n",
            "             text     label  start  end  \\\n",
            "0       allergies   DISEASE      9   18   \n",
            "1  drug allergies   DISEASE      9   23   \n",
            "2         allergy   DISEASE     18   25   \n",
            "3         Allergy   DISEASE      0    7   \n",
            "4     amoxicillin  CHEMICAL     11   22   \n",
            "\n",
            "                           original_text  row_idx source_column  \n",
            "0                     No known allergies    32488     allergies  \n",
            "1                No known drug allergies    77061     allergies  \n",
            "2  No sensitivity or allergy to any drug   149806     allergies  \n",
            "3                 Allergy to amoxicillin    83662     allergies  \n",
            "4                 Allergy to amoxicillin    83662     allergies  \n",
            "\n",
            "=== Entity Labels Found in Allergies ===\n",
            "label\n",
            "DISEASE     739\n",
            "CHEMICAL    195\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Allergy-related Entities ===\n",
            "text\n",
            "allergies                        291\n",
            "drug allergies                    92\n",
            "allergy                           73\n",
            "Allergy                           24\n",
            "penicillin                        24\n",
            "allergic reaction                 18\n",
            "Allergic                          16\n",
            "Penicillin                        16\n",
            "allergic                          14\n",
            "Allergic rhinitis                 12\n",
            "hypersensitivity                  12\n",
            "Seasonal allergies                11\n",
            "Allergic reaction                 10\n",
            "Penicillin allergy                 9\n",
            "allergic rhinitis                  9\n",
            "rash                               9\n",
            "anaphylaxis                        7\n",
            "vancomycin                         7\n",
            "penicillin allergy                 7\n",
            "paracetamol                        6\n",
            "trimethoprim/sulfamethoxazole      6\n",
            "Allergic reactions                 6\n",
            "Allergies                          6\n",
            "macrolide                          5\n",
            "drug intolerance                   5\n",
            "Calpol                             5\n",
            "angioedema                         5\n",
            "eczema                             5\n",
            "milk allergy                       5\n",
            "Allergic rhinoconjunctivitis       5\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Analyzing allergy entities for patterns...\n",
            "\n",
            "=== Testing Allergy Labeling Functions ===\n",
            "\n",
            "=== Allergy Labeling Function Coverage ===\n",
            "lf_drug_allergy: 12.9% coverage (106/819)\n",
            "lf_food_allergy: 10.7% coverage (88/819)\n",
            "lf_environmental_allergy: 9.0% coverage (74/819)\n",
            "lf_no_allergies: 31.3% coverage (256/819)\n",
            "lf_allergy_severity: 4.5% coverage (37/819)\n",
            "lf_allergy_reaction_type: 2.3% coverage (19/819)\n",
            "lf_seasonal_allergy: 1.8% coverage (15/819)\n",
            "lf_chemical_sensitivity: 0.1% coverage (1/819)\n",
            "lf_multiple_allergies: 6.3% coverage (52/819)\n",
            "lf_allergy_testing: 0.5% coverage (4/819)\n",
            "\n",
            "=== Common Allergy Patterns ===\n",
            "Penicillin allergy mentions: 56\n",
            "No known allergies mentions: 14\n",
            "Food allergy mentions: 19\n",
            "Total allergy records: 819\n",
            "\n",
            "=== Allergen Type Summary ===\n",
            "\n",
            "DRUGS: ['penicillin', 'Penicillin', 'Penicillin allergy', 'vancomycin', 'penicillin allergy', 'trimethoprim/sulfamethoxazole', 'clindamycin', 'amoxicillin', 'colomycin']\n",
            "\n",
            "FOODS: ['milk allergy']\n",
            "\n",
            "OTHER: ['allergies', 'drug allergies', 'allergy', 'Allergy', 'allergic reaction', 'Allergic', 'allergic', 'Allergic rhinitis', 'hypersensitivity', 'Seasonal allergies']\n"
          ]
        }
      ],
      "source": [
        "# Process allergies using BC5CDR model (recognizes DISEASE and CHEMICAL)\n",
        "if __name__ == \"__main__\":\n",
        "    # Run extraction for the 'allergies' column\n",
        "    # BC5CDR model will identify allergens (often CHEMICAL entities)\n",
        "    df_allergies_entities, allergies_summary, allergies_rules = run_medical_ner_extraction(\n",
        "        df_medical, \n",
        "        text_column='allergies',\n",
        "        model_name=\"en_ner_bc5cdr_md\",  # This model recognizes DISEASE and CHEMICAL entities\n",
        "        batch_size=300,\n",
        "        id_column='idx' \n",
        "    )\n",
        "\n",
        "    # Test the generated rules\n",
        "    print(\"\\nTesting generated labeling functions for allergies...\")\n",
        "\n",
        "    # Select a sample row from the original df_medical to test the rules\n",
        "    if not df_medical.empty:\n",
        "        sample_row = df_medical.iloc[0]\n",
        "\n",
        "        for rule_name, rule_func in allergies_rules.items():\n",
        "            try:\n",
        "                test_result = rule_func(sample_row)\n",
        "                print(f\"{rule_name} applied to row 0: {test_result}\")\n",
        "            except KeyError as e:\n",
        "                print(f\"Error applying rule {rule_name}: {e}. Make sure the column 'allergies' exists in df_medical.\")\n",
        "    else:\n",
        "        print(\"df_medical is empty, cannot test rules.\")\n",
        "\n",
        "    # Debug: Check extracted entities\n",
        "    print(\"\\n=== DEBUG: Check extracted allergy entities ===\")\n",
        "    print(f\"Shape of df_allergies_entities: {df_allergies_entities.shape}\")\n",
        "    print(f\"\\nColumn names: {df_allergies_entities.columns.tolist()}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(df_allergies_entities.head())\n",
        "\n",
        "    # Check entity label distribution\n",
        "    print(\"\\n=== Entity Labels Found in Allergies ===\")\n",
        "    if not df_allergies_entities.empty:\n",
        "        print(df_allergies_entities['label'].value_counts())\n",
        "\n",
        "        # Let's look at the top entities\n",
        "        print(\"\\n=== Top Allergy-related Entities ===\")\n",
        "        allergy_entities = df_allergies_entities['text'].value_counts().head(30)\n",
        "        print(allergy_entities)\n",
        "\n",
        "    # Create specific labeling functions for allergy data\n",
        "    def create_allergy_labeling_functions(entities_df):\n",
        "        \"\"\"Create specific labeling functions for allergies\"\"\"\n",
        "\n",
        "        # Analyze entities to understand patterns\n",
        "        top_entities = entities_df['text'].value_counts().head(100)\n",
        "        print(f\"\\nAnalyzing allergy entities for patterns...\")\n",
        "\n",
        "        # Common allergen categories\n",
        "        def lf_drug_allergy(row):\n",
        "            \"\"\"Detect drug/medication allergies\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            drug_patterns = [\n",
        "                'penicillin', 'amoxicillin', 'ampicillin', 'antibiotic',\n",
        "                'sulfa', 'aspirin', 'nsaid', 'ibuprofen', 'morphine',\n",
        "                'codeine', 'contrast', 'iodine', 'latex', 'adhesive'\n",
        "            ]\n",
        "            if any(drug in text for drug in drug_patterns):\n",
        "                return 'DRUG_ALLERGY'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_food_allergy(row):\n",
        "            \"\"\"Detect food allergies\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            food_patterns = [\n",
        "                'peanut', 'nut', 'shellfish', 'fish', 'milk', 'dairy',\n",
        "                'egg', 'wheat', 'gluten', 'soy', 'sesame', 'food'\n",
        "            ]\n",
        "            if any(food in text for food in food_patterns):\n",
        "                return 'FOOD_ALLERGY'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_environmental_allergy(row):\n",
        "            \"\"\"Detect environmental allergies\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            env_patterns = [\n",
        "                'pollen', 'dust', 'mold', 'grass', 'tree', 'ragweed',\n",
        "                'cat', 'dog', 'animal', 'dander', 'environmental'\n",
        "            ]\n",
        "            if any(env in text for env in env_patterns):\n",
        "                return 'ENVIRONMENTAL_ALLERGY'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_no_allergies(row):\n",
        "            \"\"\"Detect absence of allergies\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            no_allergy_patterns = [\n",
        "                'no known allergies', 'no allergies', 'nka', 'nkda',\n",
        "                'no known drug allergies', 'denies allergies', 'none'\n",
        "            ]\n",
        "            if any(pattern in text for pattern in no_allergy_patterns):\n",
        "                return 'NO_ALLERGIES'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_allergy_severity(row):\n",
        "            \"\"\"Detect severe allergic reactions\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            severity_patterns = [\n",
        "                'anaphylaxis', 'anaphylactic', 'severe', 'life-threatening',\n",
        "                'epipen', 'epinephrine', 'emergency'\n",
        "            ]\n",
        "            if any(pattern in text for pattern in severity_patterns):\n",
        "                return 'SEVERE_ALLERGY'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_allergy_reaction_type(row):\n",
        "            \"\"\"Detect specific reaction types\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            reaction_patterns = [\n",
        "                'rash', 'hives', 'swelling', 'itching', 'breathing',\n",
        "                'wheezing', 'nausea', 'vomiting', 'throat'\n",
        "            ]\n",
        "            if any(reaction in text for reaction in reaction_patterns):\n",
        "                return 'ALLERGIC_REACTION_DESCRIBED'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_seasonal_allergy(row):\n",
        "            \"\"\"Detect seasonal allergies\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            if any(season in text for season in ['seasonal', 'spring', 'fall', 'hay fever']):\n",
        "                return 'SEASONAL_ALLERGY'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_chemical_sensitivity(row):\n",
        "            \"\"\"Detect chemical sensitivities\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            chemical_patterns = [\n",
        "                'chemical', 'perfume', 'fragrance', 'smoke', 'detergent',\n",
        "                'cleaning', 'formaldehyde'\n",
        "            ]\n",
        "            if any(chem in text for chem in chemical_patterns):\n",
        "                return 'CHEMICAL_SENSITIVITY'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_multiple_allergies(row):\n",
        "            \"\"\"Detect multiple allergies\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            # Count commas or \"and\" as indicators of multiple allergies\n",
        "            if (text.count(',') >= 2 or text.count(' and ') >= 2) and 'no known' not in text:\n",
        "                return 'MULTIPLE_ALLERGIES'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_allergy_testing(row):\n",
        "            \"\"\"Detect allergy testing mentions\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            if any(test in text for test in ['tested', 'skin test', 'patch test', 'ige']):\n",
        "                return 'ALLERGY_TESTED'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        return [\n",
        "            lf_drug_allergy,\n",
        "            lf_food_allergy,\n",
        "            lf_environmental_allergy,\n",
        "            lf_no_allergies,\n",
        "            lf_allergy_severity,\n",
        "            lf_allergy_reaction_type,\n",
        "            lf_seasonal_allergy,\n",
        "            lf_chemical_sensitivity,\n",
        "            lf_multiple_allergies,\n",
        "            lf_allergy_testing\n",
        "        ]\n",
        "\n",
        "    # Apply the allergy-specific labeling functions\n",
        "    allergy_lfs = create_allergy_labeling_functions(df_allergies_entities)\n",
        "\n",
        "    print(\"\\n=== Testing Allergy Labeling Functions ===\")\n",
        "    if not df_medical.empty and 'allergies' in df_medical.columns:\n",
        "        # Test on multiple rows to see coverage\n",
        "        test_rows = min(10, len(df_medical))\n",
        "\n",
        "        for i in range(test_rows):\n",
        "            row = df_medical.iloc[i]\n",
        "            if pd.notna(row['allergies']):\n",
        "                print(f\"\\nRow {i} allergies: {row['allergies'][:100]}...\")\n",
        "                for lf in allergy_lfs:\n",
        "                    result = lf(row)\n",
        "                    if result != 'ABSTAIN':\n",
        "                        print(f\"  {lf.__name__}: {result}\")\n",
        "\n",
        "    # Analyze coverage\n",
        "    print(\"\\n=== Allergy Labeling Function Coverage ===\")\n",
        "    total_non_na = df_medical['allergies'].notna().sum()\n",
        "    for lf in allergy_lfs:\n",
        "        labeled_count = sum(lf(row) != 'ABSTAIN' for _, row in df_medical.iterrows()\n",
        "                           if pd.notna(row.get('allergies', '')))\n",
        "        coverage = (labeled_count / total_non_na * 100) if total_non_na > 0 else 0\n",
        "        print(f\"{lf.__name__}: {coverage:.1f}% coverage ({labeled_count}/{total_non_na})\")\n",
        "\n",
        "    # Analyze specific patterns in allergies\n",
        "    print(\"\\n=== Common Allergy Patterns ===\")\n",
        "    if 'allergies' in df_medical.columns:\n",
        "        # Count specific allergen mentions\n",
        "        penicillin_mentions = df_medical['allergies'].str.contains('penicillin|Penicillin', na=False).sum()\n",
        "        no_allergy_mentions = df_medical['allergies'].str.contains('no known|NKA|NKDA', na=False, regex=True).sum()\n",
        "        food_allergy_mentions = df_medical['allergies'].str.contains('peanut|shellfish|milk|egg', na=False, regex=True).sum()\n",
        "\n",
        "        print(f\"Penicillin allergy mentions: {penicillin_mentions}\")\n",
        "        print(f\"No known allergies mentions: {no_allergy_mentions}\")\n",
        "        print(f\"Food allergy mentions: {food_allergy_mentions}\")\n",
        "        print(f\"Total allergy records: {df_medical['allergies'].notna().sum()}\")\n",
        "\n",
        "    # Create a summary of allergen types found\n",
        "    print(\"\\n=== Allergen Type Summary ===\")\n",
        "    allergen_summary = {\n",
        "        'drugs': [],\n",
        "        'foods': [],\n",
        "        'environmental': [],\n",
        "        'other': []\n",
        "    }\n",
        "\n",
        "    # Categorize top entities\n",
        "    for entity, count in df_allergies_entities['text'].value_counts().head(50).items():\n",
        "        entity_lower = entity.lower()\n",
        "        if any(drug in entity_lower for drug in ['cillin', 'mycin', 'zole', 'statin']):\n",
        "            allergen_summary['drugs'].append(entity)\n",
        "        elif any(food in entity_lower for food in ['nut', 'milk', 'egg', 'fish']):\n",
        "            allergen_summary['foods'].append(entity)\n",
        "        elif any(env in entity_lower for env in ['pollen', 'dust', 'grass']):\n",
        "            allergen_summary['environmental'].append(entity)\n",
        "        else:\n",
        "            allergen_summary['other'].append(entity)\n",
        "\n",
        "    for category, items in allergen_summary.items():\n",
        "        if items:\n",
        "            print(f\"\\n{category.upper()}: {items[:10]}\")  # Show top 10 in each category\n",
        "# Save result\n",
        "df_allergies_entities.to_csv('allergies_entities_comprehensive.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading en_ner_bc5cdr_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 29755 texts in 100 batches...\n",
            "Using model: en_ner_bc5cdr_md for column: allergies\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   2%|▏         | 2/100 [00:00<00:38,  2.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  12%|█▏        | 12/100 [00:02<00:14,  6.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 3000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  22%|██▏       | 22/100 [00:04<00:12,  6.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 6000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  32%|███▏      | 32/100 [00:05<00:11,  6.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 9000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  42%|████▏     | 42/100 [00:07<00:09,  5.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 12000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  52%|█████▏    | 52/100 [00:08<00:08,  5.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  62%|██████▏   | 62/100 [00:10<00:07,  5.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 18000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  72%|███████▏  | 72/100 [00:12<00:05,  5.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 21000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  82%|████████▏ | 82/100 [00:14<00:03,  5.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 24000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  92%|█████████▏| 92/100 [00:15<00:01,  5.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 27000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 100/100 [00:17<00:00,  5.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 32 entities appearing >= 5 times\n",
            "\n",
            "Testing BC5CDR-generated labeling functions for allergies...\n",
            "\n",
            "=== BC5CDR Extraction Results ===\n",
            "Shape of df_allergies_entities: (934, 7)\n",
            "\n",
            "Entity Labels Found:\n",
            "label\n",
            "DISEASE     739\n",
            "CHEMICAL    195\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Top Entities:\n",
            "text\n",
            "allergies                        291\n",
            "drug allergies                    92\n",
            "allergy                           73\n",
            "Allergy                           24\n",
            "penicillin                        24\n",
            "allergic reaction                 18\n",
            "Allergic                          16\n",
            "Penicillin                        16\n",
            "allergic                          14\n",
            "Allergic rhinitis                 12\n",
            "hypersensitivity                  12\n",
            "Seasonal allergies                11\n",
            "Allergic reaction                 10\n",
            "Penicillin allergy                 9\n",
            "allergic rhinitis                  9\n",
            "rash                               9\n",
            "anaphylaxis                        7\n",
            "vancomycin                         7\n",
            "penicillin allergy                 7\n",
            "paracetamol                        6\n",
            "trimethoprim/sulfamethoxazole      6\n",
            "Allergic reactions                 6\n",
            "Allergies                          6\n",
            "macrolide                          5\n",
            "drug intolerance                   5\n",
            "Calpol                             5\n",
            "angioedema                         5\n",
            "eczema                             5\n",
            "milk allergy                       5\n",
            "Allergic rhinoconjunctivitis       5\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== CUSTOM ALLERGY ENTITY EXTRACTION ===\n",
            "\n",
            "Custom extraction found 539 allergy entities\n",
            "\n",
            "Custom Entity Distribution:\n",
            "label\n",
            "ALLERGY_STATUS       297\n",
            "ALLERGEN             204\n",
            "ALLERGIC_REACTION     38\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Custom Entity Categories:\n",
            "category\n",
            "no_allergies               256\n",
            "drug_allergens             123\n",
            "environmental_allergens     39\n",
            "reaction                    38\n",
            "severe                      37\n",
            "food_allergens              37\n",
            "other_allergens              5\n",
            "tested                       4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== LF-Generated Allergy Spans ===\n",
            "Total LF-generated spans: 552\n",
            "\n",
            "LF span distribution:\n",
            "label\n",
            "NO_ALLERGIES                   256\n",
            "DRUG_ALLERGY                    94\n",
            "FOOD_ALLERGY                    74\n",
            "SEVERE_ALLERGY                  38\n",
            "ENVIRONMENTAL_ALLERGY           35\n",
            "ALLERGIC_REACTION_DESCRIBED     19\n",
            "MULTIPLE_ALLERGIES              17\n",
            "SEASONAL_ALLERGY                15\n",
            "ALLERGY_TESTED                   3\n",
            "CHEMICAL_SENSITIVITY             1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Row-Level Coverage Analysis ===\n",
            "lf_drug_allergy: 11.4% coverage (93/819)\n",
            "lf_food_allergy: 9.0% coverage (74/819)\n",
            "lf_environmental_allergy: 4.3% coverage (35/819)\n",
            "lf_no_allergies: 31.3% coverage (256/819)\n",
            "lf_allergy_severity: 4.5% coverage (37/819)\n",
            "lf_allergy_reaction_type: 2.3% coverage (19/819)\n",
            "lf_seasonal_allergy: 1.8% coverage (15/819)\n",
            "lf_chemical_sensitivity: 0.1% coverage (1/819)\n",
            "lf_multiple_allergies: 6.3% coverage (52/819)\n",
            "lf_allergy_testing: 0.4% coverage (3/819)\n",
            "\n",
            "=== COMBINING ALL ALLERGY ENTITY SOURCES ===\n",
            "\n",
            "Total allergy entities: 2025\n",
            "  - BC5CDR: 934\n",
            "  - Custom extraction: 539\n",
            "  - LF-generated: 552\n",
            "\n",
            "Combined entity distribution by label:\n",
            "label\n",
            "DISEASE                        739\n",
            "ALLERGY_STATUS                 297\n",
            "NO_ALLERGIES                   256\n",
            "ALLERGEN                       204\n",
            "CHEMICAL                       195\n",
            "DRUG_ALLERGY                    94\n",
            "FOOD_ALLERGY                    74\n",
            "ALLERGIC_REACTION               38\n",
            "SEVERE_ALLERGY                  38\n",
            "ENVIRONMENTAL_ALLERGY           35\n",
            "ALLERGIC_REACTION_DESCRIBED     19\n",
            "MULTIPLE_ALLERGIES              17\n",
            "SEASONAL_ALLERGY                15\n",
            "ALLERGY_TESTED                   3\n",
            "CHEMICAL_SENSITIVITY             1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Combined entity distribution by source:\n",
            "source\n",
            "bc5cdr                         934\n",
            "custom_allergy_extraction      539\n",
            "lf:lf_no_allergies             256\n",
            "lf:lf_drug_allergy              94\n",
            "lf:lf_food_allergy              74\n",
            "lf:lf_allergy_severity          38\n",
            "lf:lf_environmental_allergy     35\n",
            "lf:lf_allergy_reaction_type     19\n",
            "lf:lf_multiple_allergies        17\n",
            "lf:lf_seasonal_allergy          15\n",
            "lf:lf_allergy_testing            3\n",
            "lf:lf_chemical_sensitivity       1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Allergens by Type ===\n",
            "\n",
            "DRUG_ALLERGENS:\n",
            "text\n",
            "penicillin          31\n",
            "Penicillin          26\n",
            "contrast            13\n",
            "vancomycin           7\n",
            "sulfamethoxazole     6\n",
            "cephalosporin        5\n",
            "Latex                5\n",
            "amoxicillin          4\n",
            "sulfa                4\n",
            "aspirin              3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "FOOD_ALLERGENS:\n",
            "text\n",
            "milk         9\n",
            "fish         7\n",
            "wheat        7\n",
            "egg          6\n",
            "Shellfish    2\n",
            "sesame       1\n",
            "tree nut     1\n",
            "Fish         1\n",
            "shellfish    1\n",
            "dairy        1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ENVIRONMENTAL_ALLERGENS:\n",
            "text\n",
            "dust           11\n",
            "dust mite       8\n",
            "pollen          7\n",
            "Dust            3\n",
            "tree pollen     3\n",
            "grass           2\n",
            "Pollen          2\n",
            "Wasp            1\n",
            "Cat             1\n",
            "insect          1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Adding Row-Level Allergy Phenotypes ===\n",
            "\n",
            "\n",
            "Allergy entity extraction complete!\n",
            "All results saved to CSV files.\n"
          ]
        }
      ],
      "source": [
        "def extract_allergy_entities_custom(df_medical, text_column='allergies', id_column='idx'):\n",
        "    \"\"\"Extract allergy-specific entities beyond what BC5CDR captures\"\"\"\n",
        "    \n",
        "    # Build the id series once\n",
        "    if id_column is not None and id_column in df_medical.columns:\n",
        "        ids_series = df_medical[id_column].where(pd.notna(df_medical[id_column]), df_medical.index)\n",
        "    else:\n",
        "        ids_series = df_medical.index\n",
        "    \n",
        "    texts = df_medical[text_column].fillna('').astype(str)\n",
        "    \n",
        "    # Allergy patterns\n",
        "    allergy_patterns = {\n",
        "        'drug_allergens': [\n",
        "            'penicillin', 'amoxicillin', 'ampicillin', 'antibiotic', 'cephalosporin',\n",
        "            'sulfa', 'sulfamethoxazole', 'bactrim', 'aspirin', 'nsaid', 'ibuprofen',\n",
        "            'morphine', 'codeine', 'opioid', 'contrast', 'iodine', 'latex',\n",
        "            'adhesive', 'lidocaine', 'vancomycin', 'tetracycline'\n",
        "        ],\n",
        "        'food_allergens': [\n",
        "            'peanut', 'tree nut', 'almond', 'cashew', 'walnut', 'shellfish',\n",
        "            'shrimp', 'lobster', 'fish', 'milk', 'dairy', 'lactose',\n",
        "            'egg', 'wheat', 'gluten', 'soy', 'sesame', 'corn'\n",
        "        ],\n",
        "        'environmental_allergens': [\n",
        "            'pollen', 'dust', 'dust mite', 'mold', 'grass', 'tree pollen',\n",
        "            'ragweed', 'cat', 'dog', 'animal dander', 'pet dander',\n",
        "            'bee sting', 'wasp', 'insect'\n",
        "        ],\n",
        "        'other_allergens': [\n",
        "            'perfume', 'fragrance', 'smoke', 'detergent', 'nickel',\n",
        "            'formaldehyde', 'rubber', 'wool', 'chemical'\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    # Reaction patterns\n",
        "    reaction_patterns = [\n",
        "        'rash', 'hives', 'urticaria', 'swelling', 'angioedema', 'itching',\n",
        "        'pruritus', 'breathing difficulty', 'wheezing', 'anaphylaxis',\n",
        "        'nausea', 'vomiting', 'throat swelling', 'flushing'\n",
        "    ]\n",
        "    \n",
        "    # Status patterns\n",
        "    status_patterns = {\n",
        "        'no_allergies': ['no known allergies', 'no allergies', 'nka', 'nkda', \n",
        "                        'no known drug allergies', 'denies allergies', 'none'],\n",
        "        'severe': ['anaphylaxis', 'anaphylactic', 'severe', 'life-threatening',\n",
        "                  'epipen', 'epinephrine'],\n",
        "        'tested': ['tested', 'skin test', 'patch test', 'ige', 'allergy testing']\n",
        "    }\n",
        "    \n",
        "    allergy_entities = []\n",
        "    \n",
        "    for (df_index, text_original), idx in zip(texts.items(), ids_series):\n",
        "        if text_original:\n",
        "            text = text_original.lower()\n",
        "            \n",
        "            # Extract allergens\n",
        "            for category, allergens in allergy_patterns.items():\n",
        "                for allergen in allergens:\n",
        "                    pattern = r'\\b' + re.escape(allergen) + r'\\b'\n",
        "                    for match in re.finditer(pattern, text):\n",
        "                        allergy_entities.append({\n",
        "                            'text': text_original[match.start():match.end()],\n",
        "                            'label': 'ALLERGEN',\n",
        "                            'category': category,\n",
        "                            'start': match.start(),\n",
        "                            'end': match.end(),\n",
        "                            'original_text': text_original,\n",
        "                            'source': 'custom_allergy_extraction',\n",
        "                            'row_idx': idx\n",
        "                        })\n",
        "            \n",
        "            # Extract reactions\n",
        "            for reaction in reaction_patterns:\n",
        "                pattern = r'\\b' + re.escape(reaction) + r'\\b'\n",
        "                for match in re.finditer(pattern, text):\n",
        "                    allergy_entities.append({\n",
        "                        'text': text_original[match.start():match.end()],\n",
        "                        'label': 'ALLERGIC_REACTION',\n",
        "                        'category': 'reaction',\n",
        "                        'start': match.start(),\n",
        "                        'end': match.end(),\n",
        "                        'original_text': text_original,\n",
        "                        'source': 'custom_allergy_extraction',\n",
        "                        'row_idx': idx\n",
        "                    })\n",
        "            \n",
        "            # Extract allergy status\n",
        "            for status_type, terms in status_patterns.items():\n",
        "                for term in terms:\n",
        "                    if term in text:\n",
        "                        start_idx = text.find(term)\n",
        "                        allergy_entities.append({\n",
        "                            'text': text_original[start_idx:start_idx + len(term)],\n",
        "                            'label': 'ALLERGY_STATUS',\n",
        "                            'category': status_type,\n",
        "                            'start': start_idx,\n",
        "                            'end': start_idx + len(term),\n",
        "                            'original_text': text_original,\n",
        "                            'source': 'custom_allergy_extraction',\n",
        "                            'row_idx': idx\n",
        "                        })\n",
        "    \n",
        "    return pd.DataFrame(allergy_entities)\n",
        "\n",
        "\n",
        "# Process allergies using BC5CDR model (recognizes DISEASE and CHEMICAL)\n",
        "if __name__ == \"__main__\":\n",
        "    # Run extraction for the 'allergies' column\n",
        "    df_allergies_entities, allergies_summary, allergies_rules = run_medical_ner_extraction(\n",
        "        df_medical, \n",
        "        text_column='allergies',\n",
        "        model_name=\"en_ner_bc5cdr_md\",\n",
        "        batch_size=300,\n",
        "        id_column='idx' \n",
        "    )\n",
        "\n",
        "    # Test the generated rules\n",
        "    print(\"\\nTesting BC5CDR-generated labeling functions for allergies...\")\n",
        "    if not df_medical.empty:\n",
        "        sample_row = df_medical.iloc[0]\n",
        "        for rule_name, rule_func in allergies_rules.items():\n",
        "            try:\n",
        "                test_result = rule_func(sample_row)\n",
        "                if test_result != 'ABSTAIN':\n",
        "                    print(f\"{rule_name} applied to row 0: {test_result}\")\n",
        "            except KeyError as e:\n",
        "                print(f\"Error applying rule {rule_name}: {e}. Make sure the column 'allergies' exists in df_medical.\")\n",
        "    else:\n",
        "        print(\"df_medical is empty, cannot test rules.\")\n",
        "\n",
        "    # Check BC5CDR results\n",
        "    print(\"\\n=== BC5CDR Extraction Results ===\")\n",
        "    print(f\"Shape of df_allergies_entities: {df_allergies_entities.shape}\")\n",
        "    if not df_allergies_entities.empty:\n",
        "        print(\"\\nEntity Labels Found:\")\n",
        "        print(df_allergies_entities['label'].value_counts())\n",
        "        print(\"\\nTop Entities:\")\n",
        "        print(df_allergies_entities['text'].value_counts().head(30))\n",
        "\n",
        "    # Extract custom allergy entities\n",
        "    print(\"\\n=== CUSTOM ALLERGY ENTITY EXTRACTION ===\")\n",
        "    df_custom_allergies = extract_allergy_entities_custom(\n",
        "        df_medical,\n",
        "        text_column='allergies',\n",
        "        id_column='idx'\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nCustom extraction found {len(df_custom_allergies)} allergy entities\")\n",
        "    if not df_custom_allergies.empty:\n",
        "        print(\"\\nCustom Entity Distribution:\")\n",
        "        print(df_custom_allergies['label'].value_counts())\n",
        "        print(\"\\nCustom Entity Categories:\")\n",
        "        print(df_custom_allergies['category'].value_counts())\n",
        "\n",
        "    # Create specific labeling functions for allergy data (spanified)\n",
        "    def create_allergy_labeling_functions(entities_df):\n",
        "        \"\"\"Create spanified labeling functions for allergies\"\"\"\n",
        "        COL = 'allergies'\n",
        "\n",
        "        def lf_drug_allergy(row):\n",
        "            \"\"\"Detect drug/medication allergies\"\"\"\n",
        "            text = str(row.get(COL, ''))\n",
        "            drug_patterns = [\n",
        "                'penicillin', 'amoxicillin', 'ampicillin', 'antibiotic',\n",
        "                'sulfa', 'aspirin', 'nsaid', 'ibuprofen', 'morphine',\n",
        "                'codeine', 'contrast', 'iodine', 'latex', 'adhesive'\n",
        "            ]\n",
        "            hit = _first_hit(text, drug_patterns)\n",
        "            return {'label': 'DRUG_ALLERGY', 'column': COL, 'match': hit, 'category': 'drug'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_food_allergy(row):\n",
        "            \"\"\"Detect food allergies\"\"\"\n",
        "            text = str(row.get(COL, ''))\n",
        "            food_patterns = [\n",
        "                'peanut', 'nut', 'shellfish', 'fish', 'milk', 'dairy',\n",
        "                'egg', 'wheat', 'gluten', 'soy', 'sesame', 'food'\n",
        "            ]\n",
        "            hit = _first_hit(text, food_patterns)\n",
        "            return {'label': 'FOOD_ALLERGY', 'column': COL, 'match': hit, 'category': 'food'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_environmental_allergy(row):\n",
        "            \"\"\"Detect environmental allergies\"\"\"\n",
        "            text = str(row.get(COL, ''))\n",
        "            env_patterns = [\n",
        "                'pollen', 'dust', 'mold', 'grass', 'tree', 'ragweed',\n",
        "                'cat', 'dog', 'animal', 'dander', 'environmental'\n",
        "            ]\n",
        "            hit = _first_hit(text, env_patterns)\n",
        "            return {'label': 'ENVIRONMENTAL_ALLERGY', 'column': COL, 'match': hit, 'category': 'environmental'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_no_allergies(row):\n",
        "            \"\"\"Detect absence of allergies\"\"\"\n",
        "            text = str(row.get(COL, ''))\n",
        "            no_allergy_patterns = [\n",
        "                'no known allergies', 'no allergies', 'nka', 'nkda',\n",
        "                'no known drug allergies', 'denies allergies', 'none'\n",
        "            ]\n",
        "            hit = _first_hit(text, no_allergy_patterns)\n",
        "            return {'label': 'NO_ALLERGIES', 'column': COL, 'match': hit, 'category': 'status'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_allergy_severity(row):\n",
        "            \"\"\"Detect severe allergic reactions\"\"\"\n",
        "            text = str(row.get(COL, ''))\n",
        "            severity_patterns = [\n",
        "                'anaphylaxis', 'anaphylactic', 'severe', 'life-threatening',\n",
        "                'epipen', 'epinephrine', 'emergency'\n",
        "            ]\n",
        "            hit = _first_hit(text, severity_patterns)\n",
        "            return {'label': 'SEVERE_ALLERGY', 'column': COL, 'match': hit, 'category': 'severity'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_allergy_reaction_type(row):\n",
        "            \"\"\"Detect specific reaction types\"\"\"\n",
        "            text = str(row.get(COL, ''))\n",
        "            reaction_patterns = [\n",
        "                'rash', 'hives', 'swelling', 'itching', 'breathing',\n",
        "                'wheezing', 'nausea', 'vomiting', 'throat'\n",
        "            ]\n",
        "            hit = _first_hit(text, reaction_patterns)\n",
        "            return {'label': 'ALLERGIC_REACTION_DESCRIBED', 'column': COL, 'match': hit, 'category': 'reaction'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_seasonal_allergy(row):\n",
        "            \"\"\"Detect seasonal allergies\"\"\"\n",
        "            text = str(row.get(COL, ''))\n",
        "            seasonal_terms = ['seasonal', 'spring', 'fall', 'hay fever']\n",
        "            hit = _first_hit(text, seasonal_terms)\n",
        "            return {'label': 'SEASONAL_ALLERGY', 'column': COL, 'match': hit, 'category': 'seasonal'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_chemical_sensitivity(row):\n",
        "            \"\"\"Detect chemical sensitivities\"\"\"\n",
        "            text = str(row.get(COL, ''))\n",
        "            chemical_patterns = [\n",
        "                'chemical', 'perfume', 'fragrance', 'smoke', 'detergent',\n",
        "                'cleaning', 'formaldehyde'\n",
        "            ]\n",
        "            hit = _first_hit(text, chemical_patterns)\n",
        "            return {'label': 'CHEMICAL_SENSITIVITY', 'column': COL, 'match': hit, 'category': 'chemical'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_multiple_allergies(row):\n",
        "            \"\"\"Detect multiple allergies\"\"\"\n",
        "            text = str(row.get(COL, ''))\n",
        "            if (text.count(',') >= 2 or text.count(' and ') >= 2) and 'no known' not in text:\n",
        "                # For multiple allergies, just return the first allergen found\n",
        "                allergens = ['penicillin', 'peanut', 'shellfish', 'dust', 'pollen']\n",
        "                hit = _first_hit(text, allergens)\n",
        "                return {'label': 'MULTIPLE_ALLERGIES', 'column': COL, 'match': hit or 'multiple', 'category': 'multiple'} if hit or text else {'label': 'ABSTAIN'}\n",
        "            return {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_allergy_testing(row):\n",
        "            \"\"\"Detect allergy testing mentions\"\"\"\n",
        "            text = str(row.get(COL, ''))\n",
        "            test_terms = ['tested', 'skin test', 'patch test', 'ige']\n",
        "            hit = _first_hit(text, test_terms)\n",
        "            return {'label': 'ALLERGY_TESTED', 'column': COL, 'match': hit, 'category': 'testing'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        return [\n",
        "            lf_drug_allergy, lf_food_allergy, lf_environmental_allergy,\n",
        "            lf_no_allergies, lf_allergy_severity, lf_allergy_reaction_type,\n",
        "            lf_seasonal_allergy, lf_chemical_sensitivity, lf_multiple_allergies,\n",
        "            lf_allergy_testing\n",
        "        ]\n",
        "\n",
        "    # Apply the allergy-specific labeling functions\n",
        "    allergy_lfs = create_allergy_labeling_functions(df_allergies_entities)\n",
        "    \n",
        "    # Materialize spans from labeling functions\n",
        "    df_allergy_lf_spans = materialize_lf_spans(df_medical, allergy_lfs, id_column='idx')\n",
        "    print(f\"\\n=== LF-Generated Allergy Spans ===\")\n",
        "    print(f\"Total LF-generated spans: {len(df_allergy_lf_spans)}\")\n",
        "    if not df_allergy_lf_spans.empty:\n",
        "        print(\"\\nLF span distribution:\")\n",
        "        print(df_allergy_lf_spans['label'].value_counts())\n",
        "\n",
        "    # Row-level coverage analysis\n",
        "    print(\"\\n=== Row-Level Coverage Analysis ===\")\n",
        "    total_non_na = df_medical['allergies'].notna().sum()\n",
        "    for lf in allergy_lfs:\n",
        "        labeled_count = sum(lf(row).get('label') != 'ABSTAIN' for _, row in df_medical.iterrows()\n",
        "                           if pd.notna(row.get('allergies', '')))\n",
        "        coverage = (labeled_count / total_non_na * 100) if total_non_na > 0 else 0\n",
        "        print(f\"{lf.__name__}: {coverage:.1f}% coverage ({labeled_count}/{total_non_na})\")\n",
        "\n",
        "    # Combine all sources\n",
        "    print(\"\\n=== COMBINING ALL ALLERGY ENTITY SOURCES ===\")\n",
        "    \n",
        "    # Ensure common columns\n",
        "    common_cols = ['text', 'label', 'start', 'end', 'original_text', 'source', 'row_idx', 'category']\n",
        "    for col in common_cols:\n",
        "        if col not in df_allergies_entities.columns:\n",
        "            df_allergies_entities[col] = 'bc5cdr' if col == 'source' else None\n",
        "        if col not in df_custom_allergies.columns:\n",
        "            df_custom_allergies[col] = 'custom_extraction' if col == 'source' else None\n",
        "        if col not in df_allergy_lf_spans.columns:\n",
        "            df_allergy_lf_spans[col] = None\n",
        "    \n",
        "    df_all_allergy_entities = pd.concat([\n",
        "        df_allergies_entities[common_cols],\n",
        "        df_custom_allergies[common_cols],\n",
        "        df_allergy_lf_spans[common_cols]\n",
        "    ], ignore_index=True)\n",
        "    \n",
        "    print(f\"\\nTotal allergy entities: {len(df_all_allergy_entities)}\")\n",
        "    print(f\"  - BC5CDR: {len(df_allergies_entities)}\")\n",
        "    print(f\"  - Custom extraction: {len(df_custom_allergies)}\")\n",
        "    print(f\"  - LF-generated: {len(df_allergy_lf_spans)}\")\n",
        "    \n",
        "    # Analysis\n",
        "    if not df_all_allergy_entities.empty:\n",
        "        print(\"\\nCombined entity distribution by label:\")\n",
        "        print(df_all_allergy_entities['label'].value_counts())\n",
        "        print(\"\\nCombined entity distribution by source:\")\n",
        "        print(df_all_allergy_entities['source'].value_counts())\n",
        "        \n",
        "        # Allergen type analysis\n",
        "        allergen_entities = df_all_allergy_entities[\n",
        "            df_all_allergy_entities['label'].isin(['ALLERGEN', 'DRUG_ALLERGY', 'FOOD_ALLERGY', 'ENVIRONMENTAL_ALLERGY'])\n",
        "        ]\n",
        "        if not allergen_entities.empty:\n",
        "            print(\"\\n=== Top Allergens by Type ===\")\n",
        "            for cat in ['drug_allergens', 'food_allergens', 'environmental_allergens']:\n",
        "                cat_entities = allergen_entities[allergen_entities['category'] == cat]\n",
        "                if not cat_entities.empty:\n",
        "                    print(f\"\\n{cat.upper()}:\")\n",
        "                    print(cat_entities['text'].value_counts().head(10))\n",
        "\n",
        "    # Add row-level allergy phenotypes\n",
        "    print(\"\\n=== Adding Row-Level Allergy Phenotypes ===\")\n",
        "    for lf in allergy_lfs:\n",
        "        phenotype_name = f\"has_{lf.__name__.replace('lf_', '')}\"\n",
        "        df_medical[phenotype_name] = df_medical.apply(\n",
        "            lambda row: lf(row).get('label') != 'ABSTAIN',\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "    # Save results\n",
        "    df_allergies_entities.to_csv('allergies_entities_comprehensive.csv', index=False)\n",
        "    df_custom_allergies.to_csv('allergies_entities_custom.csv', index=False)\n",
        "    df_allergy_lf_spans.to_csv('allergies_lf_generated_spans.csv', index=False)\n",
        "    \n",
        "    print(\"\\n\\nAllergy entity extraction complete!\")\n",
        "    print(\"All results saved to CSV files.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>category</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>source</th>\n",
              "      <th>row_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No known allergies</td>\n",
              "      <td>NO_ALLERGIES</td>\n",
              "      <td>status</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>No known allergies</td>\n",
              "      <td>lf:lf_no_allergies</td>\n",
              "      <td>32488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>No known drug allergies</td>\n",
              "      <td>NO_ALLERGIES</td>\n",
              "      <td>status</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>No known drug allergies</td>\n",
              "      <td>lf:lf_no_allergies</td>\n",
              "      <td>77061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>amoxicillin</td>\n",
              "      <td>DRUG_ALLERGY</td>\n",
              "      <td>drug</td>\n",
              "      <td>11</td>\n",
              "      <td>22</td>\n",
              "      <td>Allergy to amoxicillin</td>\n",
              "      <td>lf:lf_drug_allergy</td>\n",
              "      <td>83662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>contrast</td>\n",
              "      <td>DRUG_ALLERGY</td>\n",
              "      <td>drug</td>\n",
              "      <td>44</td>\n",
              "      <td>52</td>\n",
              "      <td>numerous drugs and diagnostic agents (e.g., co...</td>\n",
              "      <td>lf:lf_drug_allergy</td>\n",
              "      <td>67018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>aspirin</td>\n",
              "      <td>DRUG_ALLERGY</td>\n",
              "      <td>drug</td>\n",
              "      <td>23</td>\n",
              "      <td>30</td>\n",
              "      <td>Unknown if allergic to aspirin</td>\n",
              "      <td>lf:lf_drug_allergy</td>\n",
              "      <td>91449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>547</th>\n",
              "      <td>dust</td>\n",
              "      <td>ENVIRONMENTAL_ALLERGY</td>\n",
              "      <td>environmental</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>Mild dust allergy</td>\n",
              "      <td>lf:lf_environmental_allergy</td>\n",
              "      <td>157940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>548</th>\n",
              "      <td>No known drug allergies</td>\n",
              "      <td>NO_ALLERGIES</td>\n",
              "      <td>status</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>No known drug allergies</td>\n",
              "      <td>lf:lf_no_allergies</td>\n",
              "      <td>135610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>549</th>\n",
              "      <td>Severe</td>\n",
              "      <td>SEVERE_ALLERGY</td>\n",
              "      <td>severity</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>Severe allergic reaction to docetaxel chemothe...</td>\n",
              "      <td>lf:lf_allergy_severity</td>\n",
              "      <td>40349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>550</th>\n",
              "      <td>No known drug allergies</td>\n",
              "      <td>NO_ALLERGIES</td>\n",
              "      <td>status</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>No known drug allergies</td>\n",
              "      <td>lf:lf_no_allergies</td>\n",
              "      <td>135761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>551</th>\n",
              "      <td>penicillin</td>\n",
              "      <td>DRUG_ALLERGY</td>\n",
              "      <td>drug</td>\n",
              "      <td>12</td>\n",
              "      <td>22</td>\n",
              "      <td>Allergic to penicillin</td>\n",
              "      <td>lf:lf_drug_allergy</td>\n",
              "      <td>138116</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>552 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        text                  label       category  start  \\\n",
              "0         No known allergies           NO_ALLERGIES         status      0   \n",
              "1    No known drug allergies           NO_ALLERGIES         status      0   \n",
              "2                amoxicillin           DRUG_ALLERGY           drug     11   \n",
              "3                   contrast           DRUG_ALLERGY           drug     44   \n",
              "4                    aspirin           DRUG_ALLERGY           drug     23   \n",
              "..                       ...                    ...            ...    ...   \n",
              "547                     dust  ENVIRONMENTAL_ALLERGY  environmental      5   \n",
              "548  No known drug allergies           NO_ALLERGIES         status      0   \n",
              "549                   Severe         SEVERE_ALLERGY       severity      0   \n",
              "550  No known drug allergies           NO_ALLERGIES         status      0   \n",
              "551               penicillin           DRUG_ALLERGY           drug     12   \n",
              "\n",
              "     end                                      original_text  \\\n",
              "0     18                                 No known allergies   \n",
              "1     23                            No known drug allergies   \n",
              "2     22                             Allergy to amoxicillin   \n",
              "3     52  numerous drugs and diagnostic agents (e.g., co...   \n",
              "4     30                     Unknown if allergic to aspirin   \n",
              "..   ...                                                ...   \n",
              "547    9                                  Mild dust allergy   \n",
              "548   23                            No known drug allergies   \n",
              "549    6  Severe allergic reaction to docetaxel chemothe...   \n",
              "550   23                            No known drug allergies   \n",
              "551   22                             Allergic to penicillin   \n",
              "\n",
              "                          source  row_idx  \n",
              "0             lf:lf_no_allergies    32488  \n",
              "1             lf:lf_no_allergies    77061  \n",
              "2             lf:lf_drug_allergy    83662  \n",
              "3             lf:lf_drug_allergy    67018  \n",
              "4             lf:lf_drug_allergy    91449  \n",
              "..                           ...      ...  \n",
              "547  lf:lf_environmental_allergy   157940  \n",
              "548           lf:lf_no_allergies   135610  \n",
              "549       lf:lf_allergy_severity    40349  \n",
              "550           lf:lf_no_allergies   135761  \n",
              "551           lf:lf_drug_allergy   138116  \n",
              "\n",
              "[552 rows x 8 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_allergy_lf_spans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>source_column</th>\n",
              "      <th>source</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>allergies</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>No known allergies</td>\n",
              "      <td>32488</td>\n",
              "      <td>allergies</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>drug allergies</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>9</td>\n",
              "      <td>23</td>\n",
              "      <td>No known drug allergies</td>\n",
              "      <td>77061</td>\n",
              "      <td>allergies</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>allergy</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>No sensitivity or allergy to any drug</td>\n",
              "      <td>149806</td>\n",
              "      <td>allergies</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Allergy</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>Allergy to amoxicillin</td>\n",
              "      <td>83662</td>\n",
              "      <td>allergies</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>amoxicillin</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>11</td>\n",
              "      <td>22</td>\n",
              "      <td>Allergy to amoxicillin</td>\n",
              "      <td>83662</td>\n",
              "      <td>allergies</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>929</th>\n",
              "      <td>docetaxel</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>28</td>\n",
              "      <td>37</td>\n",
              "      <td>Severe allergic reaction to docetaxel chemothe...</td>\n",
              "      <td>40349</td>\n",
              "      <td>allergies</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>930</th>\n",
              "      <td>drug allergies</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>9</td>\n",
              "      <td>23</td>\n",
              "      <td>No known drug allergies</td>\n",
              "      <td>135761</td>\n",
              "      <td>allergies</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>931</th>\n",
              "      <td>Allergic</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>Allergic to penicillin</td>\n",
              "      <td>138116</td>\n",
              "      <td>allergies</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>932</th>\n",
              "      <td>penicillin</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>12</td>\n",
              "      <td>22</td>\n",
              "      <td>Allergic to penicillin</td>\n",
              "      <td>138116</td>\n",
              "      <td>allergies</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>933</th>\n",
              "      <td>allergy</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>14</td>\n",
              "      <td>21</td>\n",
              "      <td>No history of allergy</td>\n",
              "      <td>38936</td>\n",
              "      <td>allergies</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>934 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               text     label  start  end  \\\n",
              "0         allergies   DISEASE      9   18   \n",
              "1    drug allergies   DISEASE      9   23   \n",
              "2           allergy   DISEASE     18   25   \n",
              "3           Allergy   DISEASE      0    7   \n",
              "4       amoxicillin  CHEMICAL     11   22   \n",
              "..              ...       ...    ...  ...   \n",
              "929       docetaxel  CHEMICAL     28   37   \n",
              "930  drug allergies   DISEASE      9   23   \n",
              "931        Allergic   DISEASE      0    8   \n",
              "932      penicillin  CHEMICAL     12   22   \n",
              "933         allergy   DISEASE     14   21   \n",
              "\n",
              "                                         original_text  row_idx source_column  \\\n",
              "0                                   No known allergies    32488     allergies   \n",
              "1                              No known drug allergies    77061     allergies   \n",
              "2                No sensitivity or allergy to any drug   149806     allergies   \n",
              "3                               Allergy to amoxicillin    83662     allergies   \n",
              "4                               Allergy to amoxicillin    83662     allergies   \n",
              "..                                                 ...      ...           ...   \n",
              "929  Severe allergic reaction to docetaxel chemothe...    40349     allergies   \n",
              "930                            No known drug allergies   135761     allergies   \n",
              "931                             Allergic to penicillin   138116     allergies   \n",
              "932                             Allergic to penicillin   138116     allergies   \n",
              "933                              No history of allergy    38936     allergies   \n",
              "\n",
              "     source category  \n",
              "0    bc5cdr     None  \n",
              "1    bc5cdr     None  \n",
              "2    bc5cdr     None  \n",
              "3    bc5cdr     None  \n",
              "4    bc5cdr     None  \n",
              "..      ...      ...  \n",
              "929  bc5cdr     None  \n",
              "930  bc5cdr     None  \n",
              "931  bc5cdr     None  \n",
              "932  bc5cdr     None  \n",
              "933  bc5cdr     None  \n",
              "\n",
              "[934 rows x 9 columns]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_allergies_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoOiikgET1_Z"
      },
      "source": [
        "##### Drug Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zy78zi5T1hH",
        "outputId": "27e02f1c-aed5-4694-92f8-868805d99db5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading en_ner_bc5cdr_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 29755 texts in 100 batches...\n",
            "Using model: en_ner_bc5cdr_md for column: drug usage\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   2%|▏         | 2/100 [00:00<00:36,  2.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  12%|█▏        | 12/100 [00:02<00:16,  5.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 3000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  22%|██▏       | 22/100 [00:04<00:13,  5.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 6000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  32%|███▏      | 32/100 [00:06<00:11,  5.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 9000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  42%|████▏     | 42/100 [00:07<00:10,  5.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 12000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  52%|█████▏    | 52/100 [00:09<00:08,  5.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  62%|██████▏   | 62/100 [00:11<00:06,  5.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 18000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  72%|███████▏  | 72/100 [00:12<00:05,  5.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 21000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  82%|████████▏ | 82/100 [00:14<00:03,  5.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 24000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  92%|█████████▏| 92/100 [00:16<00:01,  5.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 27000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 100/100 [00:17<00:00,  5.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 27 entities appearing >= 5 times\n",
            "\n",
            "Testing BC5CDR-generated labeling functions for drug usage...\n",
            "\n",
            "=== BC5CDR Extraction Results ===\n",
            "Shape of df_drug_usage_entities: (715, 7)\n",
            "\n",
            "Entity Labels Found:\n",
            "label\n",
            "CHEMICAL    447\n",
            "DISEASE     268\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Top Entities:\n",
            "text\n",
            "drug abuse                             113\n",
            "cocaine                                 92\n",
            "substance abuse                         47\n",
            "cannabis                                39\n",
            "methamphetamine                         31\n",
            "Cocaine                                 27\n",
            "steroid                                 17\n",
            "alcohol                                 15\n",
            "Heroin                                  14\n",
            "Cannabis                                10\n",
            "steroids                                10\n",
            "ecstasy                                  9\n",
            "methadone                                8\n",
            "benzodiazepines                          7\n",
            "amphetamines                             7\n",
            "caffeine                                 6\n",
            "LSD                                      6\n",
            "Methamphetamine                          6\n",
            "Substance abuse                          6\n",
            "cannabis abuse                           6\n",
            "Denies substance abuse                   5\n",
            "pain                                     5\n",
            "Polysubstance abuse                      5\n",
            "amphetamine                              5\n",
            "ketamine                                 5\n",
            "testosterone                             5\n",
            "fenethylline                             5\n",
            "cocaine abuse                            4\n",
            "accidental or intentional poisoning      4\n",
            "MDMA                                     4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== CUSTOM DRUG USAGE ENTITY EXTRACTION ===\n",
            "\n",
            "Custom extraction found 1691 drug usage entities\n",
            "\n",
            "Custom Entity Distribution:\n",
            "label\n",
            "USAGE_STATUS     1131\n",
            "SUBSTANCE         550\n",
            "USAGE_PATTERN      10\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Custom Entity Categories:\n",
            "category\n",
            "denial             664\n",
            "recovery           355\n",
            "stimulants         196\n",
            "cannabis           162\n",
            "active             112\n",
            "opioids            105\n",
            "tobacco             34\n",
            "alcohol             20\n",
            "benzodiazepines     17\n",
            "hallucinogens       16\n",
            "pattern             10\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== LF-Generated Drug Usage Spans ===\n",
            "Total LF-generated spans: 1798\n",
            "\n",
            "LF span distribution:\n",
            "label\n",
            "NO_DRUG_USE              699\n",
            "PAST_DRUG_USE            353\n",
            "STIMULANT_USE            170\n",
            "CANNABIS_USE             162\n",
            "IV_DRUG_USE              118\n",
            "OPIOID_USE                92\n",
            "CURRENT_DRUG_USE          88\n",
            "POLYSUBSTANCE_USE         51\n",
            "TOBACCO_USE               31\n",
            "ALCOHOL_USE               20\n",
            "DRUG_TREATMENT            10\n",
            "DRUG_SCREEN_MENTIONED      4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Row-Level Coverage Analysis ===\n",
            "lf_no_drug_use: 48.9% coverage (699/1430)\n",
            "lf_alcohol_use: 1.4% coverage (20/1430)\n",
            "lf_tobacco_use: 2.1% coverage (30/1430)\n",
            "lf_cannabis_use: 11.0% coverage (157/1430)\n",
            "lf_opioid_use: 6.0% coverage (86/1430)\n",
            "lf_stimulant_use: 11.4% coverage (163/1430)\n",
            "lf_iv_drug_use: 8.1% coverage (116/1430)\n",
            "lf_prescription_abuse: 0.0% coverage (0/1430)\n",
            "lf_polysubstance_use: 3.6% coverage (52/1430)\n",
            "lf_past_drug_use: 24.8% coverage (354/1430)\n",
            "lf_current_drug_use: 6.1% coverage (87/1430)\n",
            "lf_drug_treatment: 0.7% coverage (10/1430)\n",
            "lf_drug_screen_result: 0.3% coverage (4/1430)\n",
            "\n",
            "=== COMBINING ALL DRUG USAGE ENTITY SOURCES ===\n",
            "\n",
            "Total drug usage entities: 4204\n",
            "  - BC5CDR: 715\n",
            "  - Custom extraction: 1691\n",
            "  - LF-generated: 1798\n",
            "\n",
            "Combined entity distribution by label:\n",
            "label\n",
            "USAGE_STATUS             1131\n",
            "NO_DRUG_USE               699\n",
            "SUBSTANCE                 550\n",
            "CHEMICAL                  447\n",
            "PAST_DRUG_USE             353\n",
            "DISEASE                   268\n",
            "STIMULANT_USE             170\n",
            "CANNABIS_USE              162\n",
            "IV_DRUG_USE               118\n",
            "OPIOID_USE                 92\n",
            "CURRENT_DRUG_USE           88\n",
            "POLYSUBSTANCE_USE          51\n",
            "TOBACCO_USE                31\n",
            "ALCOHOL_USE                20\n",
            "DRUG_TREATMENT             10\n",
            "USAGE_PATTERN              10\n",
            "DRUG_SCREEN_MENTIONED       4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Combined entity distribution by source:\n",
            "source\n",
            "custom_drug_usage_extraction    1691\n",
            "bc5cdr                           715\n",
            "lf:lf_no_drug_use                699\n",
            "lf:lf_past_drug_use              353\n",
            "lf:lf_stimulant_use              170\n",
            "lf:lf_cannabis_use               162\n",
            "lf:lf_iv_drug_use                118\n",
            "lf:lf_opioid_use                  92\n",
            "lf:lf_current_drug_use            88\n",
            "lf:lf_polysubstance_use           51\n",
            "lf:lf_tobacco_use                 31\n",
            "lf:lf_alcohol_use                 20\n",
            "lf:lf_drug_treatment              10\n",
            "lf:lf_drug_screen_result           4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Substances Mentioned ===\n",
            "text\n",
            "cocaine            192\n",
            "marijuana          180\n",
            "heroin             104\n",
            "cannabis            90\n",
            "Cocaine             60\n",
            "methamphetamine     55\n",
            "alcohol             38\n",
            "Heroin              34\n",
            "Cannabis            26\n",
            "Marijuana           26\n",
            "smoking             24\n",
            "tobacco             18\n",
            "methadone           17\n",
            "ecstasy             12\n",
            "Methamphetamine     12\n",
            "amphetamine         11\n",
            "Tobacco              6\n",
            "Opioid               6\n",
            "opiate               6\n",
            "Smoking              6\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Adding Row-Level Drug Usage Phenotypes ===\n",
            "\n",
            "\n",
            "Drug usage entity extraction complete!\n",
            "All results saved to CSV files.\n"
          ]
        }
      ],
      "source": [
        "def extract_drug_usage_entities_custom(df_medical, text_column='drug usage', id_column='idx'):\n",
        "    \"\"\"Extract drug usage-specific entities beyond what BC5CDR captures\"\"\"\n",
        "    \n",
        "    # Build the id series once\n",
        "    if id_column is not None and id_column in df_medical.columns:\n",
        "        ids_series = df_medical[id_column].where(pd.notna(df_medical[id_column]), df_medical.index)\n",
        "    else:\n",
        "        ids_series = df_medical.index\n",
        "    \n",
        "    texts = df_medical[text_column].fillna('').astype(str)\n",
        "    \n",
        "    # Drug/substance patterns\n",
        "    substance_patterns = {\n",
        "        'alcohol': [\n",
        "            'alcohol', 'drinking', 'beer', 'wine', 'liquor', 'spirits', \n",
        "            'ethanol', 'etoh', 'alcoholism', 'alcoholic'\n",
        "        ],\n",
        "        'tobacco': [\n",
        "            'tobacco', 'smoking', 'cigarette', 'cigarettes', 'nicotine', 'pack',\n",
        "            'cigar', 'chewing tobacco', 'vaping', 'e-cigarette', 'vape'\n",
        "        ],\n",
        "        'cannabis': [\n",
        "            'cannabis', 'marijuana', 'thc', 'weed', 'pot', 'hemp',\n",
        "            'mary jane', 'ganja', 'hash', 'cannabinoid', 'cbd'\n",
        "        ],\n",
        "        'opioids': [\n",
        "            'opioid', 'opiate', 'heroin', 'morphine', 'oxycodone', 'hydrocodone',\n",
        "            'fentanyl', 'codeine', 'tramadol', 'methadone', 'percocet', \n",
        "            'vicodin', 'oxycontin', 'dilaudid', 'demerol'\n",
        "        ],\n",
        "        'stimulants': [\n",
        "            'cocaine', 'crack', 'amphetamine', 'methamphetamine', 'meth',\n",
        "            'speed', 'crystal', 'adderall', 'ritalin', 'mdma', 'ecstasy',\n",
        "            'molly', 'crank'\n",
        "        ],\n",
        "        'benzodiazepines': [\n",
        "            'benzodiazepine', 'xanax', 'alprazolam', 'valium', 'diazepam',\n",
        "            'ativan', 'lorazepam', 'klonopin', 'clonazepam'\n",
        "        ],\n",
        "        'hallucinogens': [\n",
        "            'lsd', 'acid', 'mushrooms', 'psilocybin', 'pcp', 'ketamine',\n",
        "            'dmt', 'mescaline', 'peyote'\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    # Usage patterns\n",
        "    usage_patterns = [\n",
        "        r'\\b(\\d+)\\s*(?:pack|packs)\\s*(?:per|/)\\s*(?:day|week|year)',\n",
        "        r'\\b(\\d+)\\s*(?:drink|drinks|beer|beers)\\s*(?:per|/)\\s*(?:day|week)',\n",
        "        r'\\b(\\d+)\\s*years?\\s*(?:of\\s*)?(?:use|usage|history)',\n",
        "        r'(?:daily|weekly|occasional|social|heavy|moderate|light)\\s*(?:use|usage|user)',\n",
        "        r'(?:former|past|current|active|recovering)\\s*(?:user|addict|alcoholic)'\n",
        "    ]\n",
        "    \n",
        "    # Status patterns\n",
        "    status_patterns = {\n",
        "        'denial': ['no drug', 'denies', 'denied', 'no history', 'no illicit',\n",
        "                   'no substance', 'no recreational', 'never used', 'none'],\n",
        "        'recovery': ['rehab', 'recovery', 'aa', 'na', 'sober', 'clean',\n",
        "                     'abstinent', 'in recovery', 'treatment'],\n",
        "        'active': ['current', 'active', 'ongoing', 'continues', 'daily',\n",
        "                   'regular', 'frequent', 'occasional']\n",
        "    }\n",
        "    \n",
        "    drug_usage_entities = []\n",
        "    \n",
        "    for (df_index, text_original), idx in zip(texts.items(), ids_series):\n",
        "        if text_original:\n",
        "            text = text_original.lower()\n",
        "            \n",
        "            # Extract substances\n",
        "            for category, substances in substance_patterns.items():\n",
        "                for substance in substances:\n",
        "                    pattern = r'\\b' + re.escape(substance) + r'\\b'\n",
        "                    for match in re.finditer(pattern, text):\n",
        "                        drug_usage_entities.append({\n",
        "                            'text': text_original[match.start():match.end()],\n",
        "                            'label': 'SUBSTANCE',\n",
        "                            'category': category,\n",
        "                            'start': match.start(),\n",
        "                            'end': match.end(),\n",
        "                            'original_text': text_original,\n",
        "                            'source': 'custom_drug_usage_extraction',\n",
        "                            'row_idx': idx\n",
        "                        })\n",
        "            \n",
        "            # Extract usage patterns\n",
        "            for pattern in usage_patterns:\n",
        "                for match in re.finditer(pattern, text, re.IGNORECASE):\n",
        "                    drug_usage_entities.append({\n",
        "                        'text': text_original[match.start():match.end()],\n",
        "                        'label': 'USAGE_PATTERN',\n",
        "                        'category': 'pattern',\n",
        "                        'start': match.start(),\n",
        "                        'end': match.end(),\n",
        "                        'original_text': text_original,\n",
        "                        'source': 'custom_drug_usage_extraction',\n",
        "                        'row_idx': idx\n",
        "                    })\n",
        "            \n",
        "            # Extract status\n",
        "            for status_type, terms in status_patterns.items():\n",
        "                for term in terms:\n",
        "                    if term in text:\n",
        "                        start_idx = text.find(term)\n",
        "                        drug_usage_entities.append({\n",
        "                            'text': text_original[start_idx:start_idx + len(term)],\n",
        "                            'label': 'USAGE_STATUS',\n",
        "                            'category': status_type,\n",
        "                            'start': start_idx,\n",
        "                            'end': start_idx + len(term),\n",
        "                            'original_text': text_original,\n",
        "                            'source': 'custom_drug_usage_extraction',\n",
        "                            'row_idx': idx\n",
        "                        })\n",
        "    \n",
        "    return pd.DataFrame(drug_usage_entities)\n",
        "\n",
        "\n",
        "# Process drug usage using BC5CDR model (recognizes DISEASE and CHEMICAL)\n",
        "if __name__ == \"__main__\":\n",
        "    # Run extraction for the 'drug usage' column\n",
        "    df_drug_usage_entities, drug_usage_summary, drug_usage_rules = run_medical_ner_extraction(\n",
        "        df_medical,  \n",
        "        text_column='drug usage',\n",
        "        model_name=\"en_ner_bc5cdr_md\",\n",
        "        batch_size=300, \n",
        "        id_column='idx'\n",
        "    )\n",
        "\n",
        "    # Test the generated rules\n",
        "    print(\"\\nTesting BC5CDR-generated labeling functions for drug usage...\")\n",
        "    if not df_medical.empty:\n",
        "        sample_row = df_medical.iloc[0]\n",
        "        for rule_name, rule_func in drug_usage_rules.items():\n",
        "            try:\n",
        "                test_result = rule_func(sample_row)\n",
        "                if test_result != 'ABSTAIN':\n",
        "                    print(f\"{rule_name} applied to row 0: {test_result}\")\n",
        "            except KeyError as e:\n",
        "                print(f\"Error applying rule {rule_name}: {e}. Make sure the column 'drug usage' exists in df_medical.\")\n",
        "    else:\n",
        "        print(\"df_medical is empty, cannot test rules.\")\n",
        "\n",
        "    # Check BC5CDR results\n",
        "    print(\"\\n=== BC5CDR Extraction Results ===\")\n",
        "    print(f\"Shape of df_drug_usage_entities: {df_drug_usage_entities.shape}\")\n",
        "    if not df_drug_usage_entities.empty:\n",
        "        print(\"\\nEntity Labels Found:\")\n",
        "        print(df_drug_usage_entities['label'].value_counts())\n",
        "        print(\"\\nTop Entities:\")\n",
        "        print(df_drug_usage_entities['text'].value_counts().head(30))\n",
        "\n",
        "    # Extract custom drug usage entities\n",
        "    print(\"\\n=== CUSTOM DRUG USAGE ENTITY EXTRACTION ===\")\n",
        "    df_custom_drug_usage = extract_drug_usage_entities_custom(\n",
        "        df_medical,\n",
        "        text_column='drug usage',\n",
        "        id_column='idx'\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nCustom extraction found {len(df_custom_drug_usage)} drug usage entities\")\n",
        "    if not df_custom_drug_usage.empty:\n",
        "        print(\"\\nCustom Entity Distribution:\")\n",
        "        print(df_custom_drug_usage['label'].value_counts())\n",
        "        print(\"\\nCustom Entity Categories:\")\n",
        "        print(df_custom_drug_usage['category'].value_counts())\n",
        "\n",
        "    # Create specific labeling functions for drug usage data\n",
        "    def create_drug_usage_labeling_functions(entities_df: pd.DataFrame):\n",
        "        \"\"\"Spanified drug usage LFs.\"\"\"\n",
        "        COL = 'drug usage'\n",
        "\n",
        "        # Note: _first_hit is now defined globally\n",
        "\n",
        "        def lf_no_drug_use(row):\n",
        "            text = str(row.get(COL, ''))\n",
        "            terms = ['no drug', 'denies', 'denied', 'no history', 'no illicit',\n",
        "                    'no substance', 'no recreational', 'never', 'none',\n",
        "                    'no personal history', 'negative']\n",
        "            hit = _first_hit(text, terms)\n",
        "            return {'label': 'NO_DRUG_USE', 'column': COL, 'match': hit, 'category': 'status'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_alcohol_use(row):\n",
        "            text = str(row.get(COL, ''))\n",
        "            terms = ['alcohol', 'drinking', 'beer', 'wine', 'liquor', 'spirits', 'ethanol', 'etoh', 'drinks per', 'social drinking']\n",
        "            hit = _first_hit(text, terms)\n",
        "            return {'label': 'ALCOHOL_USE', 'column': COL, 'match': hit, 'category': 'alcohol'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_tobacco_use(row):\n",
        "            text = str(row.get(COL, ''))\n",
        "            terms = ['tobacco', 'smoking', 'cigarette', 'nicotine', 'pack', 'cigar', 'chewing tobacco', 'vaping', 'e-cigarette']\n",
        "            hit = _first_hit(text, terms)\n",
        "            return {'label': 'TOBACCO_USE', 'column': COL, 'match': hit, 'category': 'tobacco'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_cannabis_use(row):\n",
        "            text = str(row.get(COL, ''))\n",
        "            terms = ['cannabis', 'marijuana', 'thc', 'weed', 'pot', 'hemp', 'mary jane', 'ganja', 'hash', 'cannabinoid']\n",
        "            hit = _first_hit(text, terms)\n",
        "            return {'label': 'CANNABIS_USE', 'column': COL, 'match': hit, 'category': 'cannabis'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_opioid_use(row):\n",
        "            text = str(row.get(COL, ''))\n",
        "            terms = ['opioid', 'opiate', 'heroin', 'morphine', 'oxycodone', 'hydrocodone', 'fentanyl', 'codeine', 'tramadol', 'methadone',\n",
        "                    'percocet', 'vicodin', 'oxycontin']\n",
        "            hit = _first_hit(text, terms)\n",
        "            return {'label': 'OPIOID_USE', 'column': COL, 'match': hit, 'category': 'opioid'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_stimulant_use(row):\n",
        "            text = str(row.get(COL, ''))\n",
        "            terms = ['cocaine', 'crack', 'amphetamine', 'methamphetamine', 'meth', 'speed', 'crystal', 'adderall', 'ritalin', 'mdma', 'ecstasy']\n",
        "            hit = _first_hit(text, terms)\n",
        "            return {'label': 'STIMULANT_USE', 'column': COL, 'match': hit, 'category': 'stimulant'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_iv_drug_use(row):\n",
        "            text = str(row.get(COL, ''))\n",
        "            terms = ['iv drug', 'intravenous', 'injection', 'needle', 'inject', 'ivdu', 'shooting up']\n",
        "            hit = _first_hit(text, terms)\n",
        "            return {'label': 'IV_DRUG_USE', 'column': COL, 'match': hit, 'category': 'route'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_prescription_abuse(row):\n",
        "            text = str(row.get(COL, ''))\n",
        "            if ('prescription' in text.lower() or 'prescribed' in text.lower()) and \\\n",
        "               any(k in text.lower() for k in ['abuse', 'misuse', 'dependency', 'addiction']):\n",
        "                return {'label': 'PRESCRIPTION_ABUSE', 'column': COL, 'match': 'prescription', 'category': 'abuse'}\n",
        "            return {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_polysubstance_use(row):\n",
        "            text = str(row.get(COL, '')).lower()\n",
        "            subs = ['alcohol', 'tobacco', 'cannabis', 'cocaine', 'heroin', 'meth']\n",
        "            found_subs = [s for s in subs if s in text]\n",
        "            if len(found_subs) >= 2:\n",
        "                return {'label': 'POLYSUBSTANCE_USE', 'column': COL, 'match': found_subs[0], 'category': 'multiple'}\n",
        "            return {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_past_drug_use(row):\n",
        "            text = str(row.get(COL, ''))\n",
        "            past_terms = ['former', 'past', 'history of', 'previously', 'quit', 'stopped', 'used to', 'years ago', 'in recovery', 'sober']\n",
        "            if any(t in text.lower() for t in past_terms) and not any(t in text.lower() for t in ['current', 'active', 'ongoing']):\n",
        "                hit = _first_hit(text, past_terms)\n",
        "                return {'label': 'PAST_DRUG_USE', 'column': COL, 'match': hit, 'category': 'temporal'}\n",
        "            return {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_current_drug_use(row):\n",
        "            text = str(row.get(COL, ''))\n",
        "            terms = ['current', 'active', 'ongoing', 'continues', 'daily', 'regular', 'frequent', 'occasional']\n",
        "            hit = _first_hit(text, terms)\n",
        "            return {'label': 'CURRENT_DRUG_USE', 'column': COL, 'match': hit, 'category': 'temporal'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_drug_treatment(row):\n",
        "            text = str(row.get(COL, ''))\n",
        "            terms = ['rehab', 'treatment', 'recovery', 'aa', 'na', 'methadone clinic', 'suboxone', 'detox', 'counseling', 'therapy']\n",
        "            hit = _first_hit(text, terms)\n",
        "            return {'label': 'DRUG_TREATMENT', 'column': COL, 'match': hit, 'category': 'treatment'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        def lf_drug_screen_result(row):\n",
        "            text = str(row.get(COL, ''))\n",
        "            terms = ['drug screen', 'urine test', 'tested positive', 'tested negative']\n",
        "            hit = _first_hit(text, terms)\n",
        "            return {'label': 'DRUG_SCREEN_MENTIONED', 'column': COL, 'match': hit, 'category': 'testing'} if hit else {'label': 'ABSTAIN'}\n",
        "\n",
        "        return [\n",
        "            lf_no_drug_use, lf_alcohol_use, lf_tobacco_use, lf_cannabis_use, lf_opioid_use,\n",
        "            lf_stimulant_use, lf_iv_drug_use, lf_prescription_abuse, lf_polysubstance_use,\n",
        "            lf_past_drug_use, lf_current_drug_use, lf_drug_treatment, lf_drug_screen_result\n",
        "        ]\n",
        "\n",
        "    # Apply the drug usage-specific labeling functions\n",
        "    drug_usage_lfs = create_drug_usage_labeling_functions(df_drug_usage_entities)\n",
        "    \n",
        "    # Materialize spans from labeling functions\n",
        "    df_drug_usage_lf_spans = materialize_lf_spans(df_medical, drug_usage_lfs, id_column='idx')\n",
        "    print(f\"\\n=== LF-Generated Drug Usage Spans ===\")\n",
        "    print(f\"Total LF-generated spans: {len(df_drug_usage_lf_spans)}\")\n",
        "    if not df_drug_usage_lf_spans.empty:\n",
        "        print(\"\\nLF span distribution:\")\n",
        "        print(df_drug_usage_lf_spans['label'].value_counts())\n",
        "\n",
        "    # Row-level coverage analysis\n",
        "    print(\"\\n=== Row-Level Coverage Analysis ===\")\n",
        "    total_non_na = df_medical['drug usage'].notna().sum() if 'drug usage' in df_medical.columns else 0\n",
        "    if total_non_na > 0:\n",
        "        for lf in drug_usage_lfs:\n",
        "            labeled_count = sum(lf(row).get('label') != 'ABSTAIN' for _, row in df_medical.iterrows()\n",
        "                               if pd.notna(row.get('drug usage', '')))\n",
        "            coverage = (labeled_count / total_non_na * 100)\n",
        "            print(f\"{lf.__name__}: {coverage:.1f}% coverage ({labeled_count}/{total_non_na})\")\n",
        "\n",
        "    # Combine all sources\n",
        "    print(\"\\n=== COMBINING ALL DRUG USAGE ENTITY SOURCES ===\")\n",
        "    \n",
        "    _d_cols = ['text','label','start','end','original_text','source','row_idx','category']\n",
        "    for col in _d_cols:\n",
        "        if col not in df_drug_usage_entities.columns:\n",
        "            df_drug_usage_entities[col] = 'bc5cdr' if col=='source' else None\n",
        "        if col not in df_custom_drug_usage.columns:\n",
        "            df_custom_drug_usage[col] = 'custom_extraction' if col=='source' else None\n",
        "        if col not in df_drug_usage_lf_spans.columns:\n",
        "            df_drug_usage_lf_spans[col] = None\n",
        "\n",
        "    df_all_drug_usage_entities = pd.concat([\n",
        "        df_drug_usage_entities[_d_cols],\n",
        "        df_custom_drug_usage[_d_cols],\n",
        "        df_drug_usage_lf_spans[_d_cols]\n",
        "    ], ignore_index=True)\n",
        "    \n",
        "    print(f\"\\nTotal drug usage entities: {len(df_all_drug_usage_entities)}\")\n",
        "    print(f\"  - BC5CDR: {len(df_drug_usage_entities)}\")\n",
        "    print(f\"  - Custom extraction: {len(df_custom_drug_usage)}\")\n",
        "    print(f\"  - LF-generated: {len(df_drug_usage_lf_spans)}\")\n",
        "    \n",
        "    # Analysis\n",
        "    if not df_all_drug_usage_entities.empty:\n",
        "        print(\"\\nCombined entity distribution by label:\")\n",
        "        print(df_all_drug_usage_entities['label'].value_counts())\n",
        "        print(\"\\nCombined entity distribution by source:\")\n",
        "        print(df_all_drug_usage_entities['source'].value_counts())\n",
        "        \n",
        "        # Substance analysis\n",
        "        substance_entities = df_all_drug_usage_entities[\n",
        "            df_all_drug_usage_entities['label'].isin(['SUBSTANCE', 'ALCOHOL_USE', 'TOBACCO_USE', \n",
        "                                                     'CANNABIS_USE', 'OPIOID_USE', 'STIMULANT_USE'])\n",
        "        ]\n",
        "        if not substance_entities.empty:\n",
        "            print(\"\\n=== Top Substances Mentioned ===\")\n",
        "            print(substance_entities['text'].value_counts().head(20))\n",
        "\n",
        "    # Add row-level drug usage phenotypes\n",
        "    print(\"\\n=== Adding Row-Level Drug Usage Phenotypes ===\")\n",
        "    for lf in drug_usage_lfs:\n",
        "        phenotype_name = f\"has_{lf.__name__.replace('lf_', '')}\"\n",
        "        df_medical[phenotype_name] = df_medical.apply(\n",
        "            lambda row: lf(row).get('label') != 'ABSTAIN',\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "    # Save results\n",
        "    df_drug_usage_lf_spans.to_csv('drug_usage_lf_generated_spans.csv', index=False)\n",
        "    df_all_drug_usage_entities.to_csv('drug_usage_entities_comprehensive.csv', index=False)\n",
        "    df_custom_drug_usage.to_csv('drug_usage_entities_custom.csv', index=False)\n",
        "    \n",
        "    print(\"\\n\\nDrug usage entity extraction complete!\")\n",
        "    print(\"All results saved to CSV files.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>category</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>source</th>\n",
              "      <th>row_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tobacco</td>\n",
              "      <td>TOBACCO_USE</td>\n",
              "      <td>tobacco</td>\n",
              "      <td>22</td>\n",
              "      <td>29</td>\n",
              "      <td>Chewing pan of Indian tobacco for the last 15 ...</td>\n",
              "      <td>lf:lf_tobacco_use</td>\n",
              "      <td>40451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>No history</td>\n",
              "      <td>NO_DRUG_USE</td>\n",
              "      <td>status</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>No history of tobacco or drug intake</td>\n",
              "      <td>lf:lf_no_drug_use</td>\n",
              "      <td>149806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tobacco</td>\n",
              "      <td>TOBACCO_USE</td>\n",
              "      <td>tobacco</td>\n",
              "      <td>14</td>\n",
              "      <td>21</td>\n",
              "      <td>No history of tobacco or drug intake</td>\n",
              "      <td>lf:lf_tobacco_use</td>\n",
              "      <td>149806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>history of</td>\n",
              "      <td>PAST_DRUG_USE</td>\n",
              "      <td>temporal</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>No history of tobacco or drug intake</td>\n",
              "      <td>lf:lf_past_drug_use</td>\n",
              "      <td>149806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>methadone</td>\n",
              "      <td>OPIOID_USE</td>\n",
              "      <td>opioid</td>\n",
              "      <td>13</td>\n",
              "      <td>22</td>\n",
              "      <td>Diazepam and methadone overdose</td>\n",
              "      <td>lf:lf_opioid_use</td>\n",
              "      <td>163624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1793</th>\n",
              "      <td>smoking</td>\n",
              "      <td>TOBACCO_USE</td>\n",
              "      <td>tobacco</td>\n",
              "      <td>13</td>\n",
              "      <td>20</td>\n",
              "      <td>occasionally smoking of marijuana</td>\n",
              "      <td>lf:lf_tobacco_use</td>\n",
              "      <td>100070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1794</th>\n",
              "      <td>marijuana</td>\n",
              "      <td>CANNABIS_USE</td>\n",
              "      <td>cannabis</td>\n",
              "      <td>24</td>\n",
              "      <td>33</td>\n",
              "      <td>occasionally smoking of marijuana</td>\n",
              "      <td>lf:lf_cannabis_use</td>\n",
              "      <td>100070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1795</th>\n",
              "      <td>Denied</td>\n",
              "      <td>NO_DRUG_USE</td>\n",
              "      <td>status</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>Denied any intravenous drug use, urine drug sc...</td>\n",
              "      <td>lf:lf_no_drug_use</td>\n",
              "      <td>97973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1796</th>\n",
              "      <td>intravenous</td>\n",
              "      <td>IV_DRUG_USE</td>\n",
              "      <td>route</td>\n",
              "      <td>11</td>\n",
              "      <td>22</td>\n",
              "      <td>Denied any intravenous drug use, urine drug sc...</td>\n",
              "      <td>lf:lf_iv_drug_use</td>\n",
              "      <td>97973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1797</th>\n",
              "      <td>drug screen</td>\n",
              "      <td>DRUG_SCREEN_MENTIONED</td>\n",
              "      <td>testing</td>\n",
              "      <td>39</td>\n",
              "      <td>50</td>\n",
              "      <td>Denied any intravenous drug use, urine drug sc...</td>\n",
              "      <td>lf:lf_drug_screen_result</td>\n",
              "      <td>97973</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1798 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             text                  label  category  start  end  \\\n",
              "0         tobacco            TOBACCO_USE   tobacco     22   29   \n",
              "1      No history            NO_DRUG_USE    status      0   10   \n",
              "2         tobacco            TOBACCO_USE   tobacco     14   21   \n",
              "3      history of          PAST_DRUG_USE  temporal      3   13   \n",
              "4       methadone             OPIOID_USE    opioid     13   22   \n",
              "...           ...                    ...       ...    ...  ...   \n",
              "1793      smoking            TOBACCO_USE   tobacco     13   20   \n",
              "1794    marijuana           CANNABIS_USE  cannabis     24   33   \n",
              "1795       Denied            NO_DRUG_USE    status      0    6   \n",
              "1796  intravenous            IV_DRUG_USE     route     11   22   \n",
              "1797  drug screen  DRUG_SCREEN_MENTIONED   testing     39   50   \n",
              "\n",
              "                                          original_text  \\\n",
              "0     Chewing pan of Indian tobacco for the last 15 ...   \n",
              "1                  No history of tobacco or drug intake   \n",
              "2                  No history of tobacco or drug intake   \n",
              "3                  No history of tobacco or drug intake   \n",
              "4                       Diazepam and methadone overdose   \n",
              "...                                                 ...   \n",
              "1793                  occasionally smoking of marijuana   \n",
              "1794                  occasionally smoking of marijuana   \n",
              "1795  Denied any intravenous drug use, urine drug sc...   \n",
              "1796  Denied any intravenous drug use, urine drug sc...   \n",
              "1797  Denied any intravenous drug use, urine drug sc...   \n",
              "\n",
              "                        source  row_idx  \n",
              "0            lf:lf_tobacco_use    40451  \n",
              "1            lf:lf_no_drug_use   149806  \n",
              "2            lf:lf_tobacco_use   149806  \n",
              "3          lf:lf_past_drug_use   149806  \n",
              "4             lf:lf_opioid_use   163624  \n",
              "...                        ...      ...  \n",
              "1793         lf:lf_tobacco_use   100070  \n",
              "1794        lf:lf_cannabis_use   100070  \n",
              "1795         lf:lf_no_drug_use    97973  \n",
              "1796         lf:lf_iv_drug_use    97973  \n",
              "1797  lf:lf_drug_screen_result    97973  \n",
              "\n",
              "[1798 rows x 8 columns]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_drug_usage_lf_spans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>source_column</th>\n",
              "      <th>source</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Diazepam</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>Diazepam and methadone overdose</td>\n",
              "      <td>163624</td>\n",
              "      <td>drug usage</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>methadone overdose</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>13</td>\n",
              "      <td>31</td>\n",
              "      <td>Diazepam and methadone overdose</td>\n",
              "      <td>163624</td>\n",
              "      <td>drug usage</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>zolpidem</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>9</td>\n",
              "      <td>17</td>\n",
              "      <td>Abuse of zolpidem</td>\n",
              "      <td>90815</td>\n",
              "      <td>drug usage</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>drug abuse</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>11</td>\n",
              "      <td>21</td>\n",
              "      <td>History of drug abuse</td>\n",
              "      <td>43921</td>\n",
              "      <td>drug usage</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>drug abuse</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>12</td>\n",
              "      <td>22</td>\n",
              "      <td>Intravenous drug abuse</td>\n",
              "      <td>84350</td>\n",
              "      <td>drug usage</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>710</th>\n",
              "      <td>bipolar disorder</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>34</td>\n",
              "      <td>50</td>\n",
              "      <td>Remote history of lithium use for bipolar diso...</td>\n",
              "      <td>113022</td>\n",
              "      <td>drug usage</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>711</th>\n",
              "      <td>cocaine</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>24</td>\n",
              "      <td>31</td>\n",
              "      <td>Occasional recreational cocaine use, most rece...</td>\n",
              "      <td>137819</td>\n",
              "      <td>drug usage</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>712</th>\n",
              "      <td>cannabis</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>93</td>\n",
              "      <td>101</td>\n",
              "      <td>Heavy e-cigarette use for the previous 2 years...</td>\n",
              "      <td>99885</td>\n",
              "      <td>drug usage</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>713</th>\n",
              "      <td>neck pain</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>61</td>\n",
              "      <td>70</td>\n",
              "      <td>Used heroin, street bought oral opiates to sel...</td>\n",
              "      <td>97753</td>\n",
              "      <td>drug usage</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>714</th>\n",
              "      <td>cocaine</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>9</td>\n",
              "      <td>16</td>\n",
              "      <td>Previous cocaine abuse, ceased ten years ago</td>\n",
              "      <td>38570</td>\n",
              "      <td>drug usage</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>715 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   text     label  start  end  \\\n",
              "0              Diazepam  CHEMICAL      0    8   \n",
              "1    methadone overdose  CHEMICAL     13   31   \n",
              "2              zolpidem  CHEMICAL      9   17   \n",
              "3            drug abuse   DISEASE     11   21   \n",
              "4            drug abuse   DISEASE     12   22   \n",
              "..                  ...       ...    ...  ...   \n",
              "710    bipolar disorder   DISEASE     34   50   \n",
              "711             cocaine  CHEMICAL     24   31   \n",
              "712            cannabis  CHEMICAL     93  101   \n",
              "713           neck pain   DISEASE     61   70   \n",
              "714             cocaine  CHEMICAL      9   16   \n",
              "\n",
              "                                         original_text  row_idx source_column  \\\n",
              "0                      Diazepam and methadone overdose   163624    drug usage   \n",
              "1                      Diazepam and methadone overdose   163624    drug usage   \n",
              "2                                    Abuse of zolpidem    90815    drug usage   \n",
              "3                                History of drug abuse    43921    drug usage   \n",
              "4                               Intravenous drug abuse    84350    drug usage   \n",
              "..                                                 ...      ...           ...   \n",
              "710  Remote history of lithium use for bipolar diso...   113022    drug usage   \n",
              "711  Occasional recreational cocaine use, most rece...   137819    drug usage   \n",
              "712  Heavy e-cigarette use for the previous 2 years...    99885    drug usage   \n",
              "713  Used heroin, street bought oral opiates to sel...    97753    drug usage   \n",
              "714       Previous cocaine abuse, ceased ten years ago    38570    drug usage   \n",
              "\n",
              "     source category  \n",
              "0    bc5cdr     None  \n",
              "1    bc5cdr     None  \n",
              "2    bc5cdr     None  \n",
              "3    bc5cdr     None  \n",
              "4    bc5cdr     None  \n",
              "..      ...      ...  \n",
              "710  bc5cdr     None  \n",
              "711  bc5cdr     None  \n",
              "712  bc5cdr     None  \n",
              "713  bc5cdr     None  \n",
              "714  bc5cdr     None  \n",
              "\n",
              "[715 rows x 9 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_drug_usage_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVItZWQ_7Cb-"
      },
      "source": [
        "### Extracting Surgeries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        },
        "id": "h9RTUlzN7HRr",
        "outputId": "9ce66ad4-8450-41c5-ec06-ace74eb10761"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>has_surgery</th>\n",
              "      <th>reason</th>\n",
              "      <th>Type</th>\n",
              "      <th>time</th>\n",
              "      <th>outcome</th>\n",
              "      <th>details</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155216</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>133948</td>\n",
              "      <td>True</td>\n",
              "      <td>Idiopathic osteonecrosis of the femoral head</td>\n",
              "      <td>Total Hip Arthroplasty (THA)</td>\n",
              "      <td>After diagnosis</td>\n",
              "      <td>Discharged in good condition without specific ...</td>\n",
              "      <td>First THA on the left hip</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133948</td>\n",
              "      <td>True</td>\n",
              "      <td>Pain and limited ROM in the contralateral hip ...</td>\n",
              "      <td>Total Hip Arthroplasty (THA)</td>\n",
              "      <td>One year after the first THA</td>\n",
              "      <td>Discharged in good condition without specific ...</td>\n",
              "      <td>Second THA on the contralateral hip</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80176</td>\n",
              "      <td>True</td>\n",
              "      <td>Posttraumatic arthritis</td>\n",
              "      <td>Left elbow arthrodesis</td>\n",
              "      <td>At the age of 18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Elbow was fused at 90 degrees</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>80176</td>\n",
              "      <td>True</td>\n",
              "      <td>Hypertrophic nonunion of ulnar shaft fracture ...</td>\n",
              "      <td>Repair of nonunion and conversion of elbow art...</td>\n",
              "      <td>Three months after the fall and subsequent con...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The stem of the ulnar component would act as a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35859</th>\n",
              "      <td>98004</td>\n",
              "      <td>True</td>\n",
              "      <td>Inferior segment elevation (ST) elevation myoc...</td>\n",
              "      <td>Primary percutaneous coronary intervention (dr...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Successful treatment of right coronary artery ...</td>\n",
              "      <td>Procedure complicated by Ventricular Fibrillat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35860</th>\n",
              "      <td>133320</td>\n",
              "      <td>True</td>\n",
              "      <td>Leiomyosarcoma</td>\n",
              "      <td>Wide tumor resection</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Successful with no adjuvant chemotherapy and r...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35861</th>\n",
              "      <td>133320</td>\n",
              "      <td>True</td>\n",
              "      <td>Lung nodules</td>\n",
              "      <td>Excisional biopsy</td>\n",
              "      <td>One year and 3 months postoperatively</td>\n",
              "      <td>Histopathological diagnosis was consistent wit...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35862</th>\n",
              "      <td>133320</td>\n",
              "      <td>True</td>\n",
              "      <td>Bone metastasis of the right femur</td>\n",
              "      <td>Cryoablation under CT guidance</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ablation needles were inserted into the proxim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35863</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Acute severe aortic insufficiency from endocar...</td>\n",
              "      <td>Emergent mechanical aortic valve replacement s...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Uncomplicated postoperative course</td>\n",
              "      <td>Patient was extubated postoperative day 4, neu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35864 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          idx  has_surgery                                             reason  \\\n",
              "0      155216        False                                                NaN   \n",
              "1      133948         True       Idiopathic osteonecrosis of the femoral head   \n",
              "2      133948         True  Pain and limited ROM in the contralateral hip ...   \n",
              "3       80176         True                            Posttraumatic arthritis   \n",
              "4       80176         True  Hypertrophic nonunion of ulnar shaft fracture ...   \n",
              "...       ...          ...                                                ...   \n",
              "35859   98004         True  Inferior segment elevation (ST) elevation myoc...   \n",
              "35860  133320         True                                     Leiomyosarcoma   \n",
              "35861  133320         True                                       Lung nodules   \n",
              "35862  133320         True                 Bone metastasis of the right femur   \n",
              "35863   97973         True  Acute severe aortic insufficiency from endocar...   \n",
              "\n",
              "                                                    Type  \\\n",
              "0                                                    NaN   \n",
              "1                           Total Hip Arthroplasty (THA)   \n",
              "2                           Total Hip Arthroplasty (THA)   \n",
              "3                                 Left elbow arthrodesis   \n",
              "4      Repair of nonunion and conversion of elbow art...   \n",
              "...                                                  ...   \n",
              "35859  Primary percutaneous coronary intervention (dr...   \n",
              "35860                               Wide tumor resection   \n",
              "35861                                  Excisional biopsy   \n",
              "35862                     Cryoablation under CT guidance   \n",
              "35863  Emergent mechanical aortic valve replacement s...   \n",
              "\n",
              "                                                    time  \\\n",
              "0                                                    NaN   \n",
              "1                                        After diagnosis   \n",
              "2                           One year after the first THA   \n",
              "3                                       At the age of 18   \n",
              "4      Three months after the fall and subsequent con...   \n",
              "...                                                  ...   \n",
              "35859                                                NaN   \n",
              "35860                                                NaN   \n",
              "35861              One year and 3 months postoperatively   \n",
              "35862                                                NaN   \n",
              "35863                                                NaN   \n",
              "\n",
              "                                                 outcome  \\\n",
              "0                                                    NaN   \n",
              "1      Discharged in good condition without specific ...   \n",
              "2      Discharged in good condition without specific ...   \n",
              "3                                                    NaN   \n",
              "4                                                    NaN   \n",
              "...                                                  ...   \n",
              "35859  Successful treatment of right coronary artery ...   \n",
              "35860  Successful with no adjuvant chemotherapy and r...   \n",
              "35861  Histopathological diagnosis was consistent wit...   \n",
              "35862                                                NaN   \n",
              "35863                 Uncomplicated postoperative course   \n",
              "\n",
              "                                                 details  \n",
              "0                                                    NaN  \n",
              "1                              First THA on the left hip  \n",
              "2                    Second THA on the contralateral hip  \n",
              "3                          Elbow was fused at 90 degrees  \n",
              "4      The stem of the ulnar component would act as a...  \n",
              "...                                                  ...  \n",
              "35859  Procedure complicated by Ventricular Fibrillat...  \n",
              "35860                                                NaN  \n",
              "35861                                                NaN  \n",
              "35862  Ablation needles were inserted into the proxim...  \n",
              "35863  Patient was extubated postoperative day 4, neu...  \n",
              "\n",
              "[35864 rows x 7 columns]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_surgery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "kPOQefZw9O04"
      },
      "outputs": [],
      "source": [
        "class TemporalStandardizer:\n",
        "    \"\"\"Extract and standardize temporal expressions from medical text\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Load spaCy model\n",
        "        try:\n",
        "            self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "        except:\n",
        "            self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "        # Conversion mappings - Define this BEFORE adding patterns\n",
        "        self.time_units = {\n",
        "            'day': 1, 'days': 1, 'd': 1,\n",
        "            'week': 7, 'weeks': 7, 'wk': 7, 'wks': 7,\n",
        "            'month': 30, 'months': 30, 'mo': 30, 'mos': 30,\n",
        "            'year': 365, 'years': 365, 'yr': 365, 'yrs': 365,\n",
        "            'hour': 1/24, 'hours': 1/24, 'hr': 1/24, 'hrs': 1/24,\n",
        "            'minute': 1/1440, 'minutes': 1/1440, 'min': 1/1440, 'mins': 1/1440\n",
        "        }\n",
        "\n",
        "        # Initialize matcher for temporal patterns\n",
        "        self.matcher = Matcher(self.nlp.vocab)\n",
        "        # Now call _add_temporal_patterns AFTER time_units is defined\n",
        "        self._add_temporal_patterns()\n",
        "\n",
        "\n",
        "    def _add_temporal_patterns(self):\n",
        "        \"\"\"Add temporal patterns to spaCy matcher\"\"\"\n",
        "\n",
        "        # Pattern: \"X days/weeks/months\"\n",
        "        pattern1 = [\n",
        "            {\"LIKE_NUM\": True},\n",
        "            # Access self.time_units here is now safe\n",
        "            {\"LOWER\": {\"IN\": list(self.time_units.keys())}}\n",
        "        ]\n",
        "        self.matcher.add(\"DURATION\", [pattern1])\n",
        "\n",
        "        # Pattern: \"past X days/weeks\"\n",
        "        pattern2 = [\n",
        "            {\"LOWER\": {\"IN\": [\"past\", \"last\", \"previous\"]}},\n",
        "            {\"LIKE_NUM\": True},\n",
        "            {\"LOWER\": {\"IN\": list(self.time_units.keys())}}\n",
        "        ]\n",
        "        self.matcher.add(\"PAST_DURATION\", [pattern2])\n",
        "\n",
        "        # Pattern: \"X days/weeks ago\"\n",
        "        pattern3 = [\n",
        "            {\"LIKE_NUM\": True},\n",
        "            {\"LOWER\": {\"IN\": list(self.time_units.keys())}},\n",
        "            {\"LOWER\": \"ago\"}\n",
        "        ]\n",
        "        self.matcher.add(\"AGO_DURATION\", [pattern3])\n",
        "\n",
        "    def extract_all_temporal_info(self, text):\n",
        "        \"\"\"Extract all temporal information from text\"\"\"\n",
        "        if pd.isna(text) or text == '':\n",
        "            return {\n",
        "                'duration_days': None,\n",
        "                'is_ongoing': False,\n",
        "                'has_date': False,\n",
        "                'temporal_type': None,\n",
        "                'original_text': text\n",
        "            }\n",
        "\n",
        "        text = str(text)\n",
        "        info = {\n",
        "            'duration_days': None,\n",
        "            'is_ongoing': False,\n",
        "            'has_date': False,\n",
        "            'temporal_type': None,\n",
        "            'original_text': text\n",
        "        }\n",
        "\n",
        "        # Check for ongoing conditions\n",
        "        ongoing_patterns = [\n",
        "            'persisting', 'continuing', 'ongoing', 'current',\n",
        "            'still', 'continues', 'persistent', 'chronic'\n",
        "        ]\n",
        "        info['is_ongoing'] = any(pattern in text.lower() for pattern in ongoing_patterns)\n",
        "\n",
        "        # Try to extract specific dates\n",
        "        dates = self._extract_dates(text)\n",
        "        if dates:\n",
        "            info['has_date'] = True\n",
        "            info['extracted_dates'] = dates\n",
        "\n",
        "        # Extract duration\n",
        "        duration = self._extract_duration(text)\n",
        "        if duration:\n",
        "            info['duration_days'] = duration\n",
        "\n",
        "        # Classify temporal type\n",
        "        info['temporal_type'] = self._classify_temporal_type(text)\n",
        "\n",
        "        return info\n",
        "\n",
        "    def _extract_dates(self, text):\n",
        "        \"\"\"Extract actual dates from text\"\"\"\n",
        "        dates = []\n",
        "\n",
        "        # Common date patterns\n",
        "        date_patterns = [\n",
        "            r'\\b\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}\\b',  # MM/DD/YYYY or MM-DD-YYYY\n",
        "            r'\\b\\d{4}[-/]\\d{1,2}[-/]\\d{1,2}\\b',    # YYYY-MM-DD\n",
        "            r'\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\\s+\\d{1,2},?\\s+\\d{4}\\b',  # Month DD, YYYY\n",
        "            r'\\b\\d{1,2}\\s+(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\\s+\\d{4}\\b',     # DD Month YYYY\n",
        "        ]\n",
        "\n",
        "        for pattern in date_patterns:\n",
        "            matches = re.finditer(pattern, text, re.IGNORECASE)\n",
        "            for match in matches:\n",
        "                try:\n",
        "                    parsed_date = parser.parse(match.group(), fuzzy=False)\n",
        "                    dates.append(parsed_date)\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        return dates\n",
        "\n",
        "    def _extract_duration(self, text):\n",
        "        \"\"\"Extract duration in days from temporal expressions\"\"\"\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        # Use regex to find duration patterns\n",
        "        patterns = [\n",
        "            # \"X days/weeks/months\"\n",
        "            r'(\\d+)\\s*(day|days|week|weeks|month|months|year|years|hour|hours)',\n",
        "            # \"a few days/weeks\"\n",
        "            r'(a few|several|couple of)\\s*(day|days|week|weeks|month|months)',\n",
        "            # Written numbers\n",
        "            r'(one|two|three|four|five|six|seven|eight|nine|ten)\\s*(day|days|week|weeks|month|months|year|years)',\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, text_lower)\n",
        "            if match:\n",
        "                # Extract number\n",
        "                number_text = match.group(1)\n",
        "                unit = match.group(2)\n",
        "\n",
        "                # Convert to number\n",
        "                if number_text.isdigit():\n",
        "                    number = int(number_text)\n",
        "                elif number_text in ['a few', 'several']:\n",
        "                    number = 3  # Approximate\n",
        "                elif number_text == 'couple of':\n",
        "                    number = 2\n",
        "                else:\n",
        "                    # Convert written numbers\n",
        "                    number_map = {\n",
        "                        'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5,\n",
        "                        'six': 6, 'seven': 7, 'eight': 8, 'nine': 9, 'ten': 10\n",
        "                    }\n",
        "                    number = number_map.get(number_text, 1)\n",
        "\n",
        "                # Convert to days\n",
        "                if unit in self.time_units:\n",
        "                    return number * self.time_units[unit]\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _classify_temporal_type(self, text):\n",
        "        \"\"\"Classify the type of temporal expression\"\"\"\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        if any(word in text_lower for word in ['ago', 'before', 'prior', 'previously']):\n",
        "            return 'past_reference'\n",
        "        elif any(word in text_lower for word in ['since', 'from', 'started']):\n",
        "            return 'onset_reference'\n",
        "        elif any(word in text_lower for word in ['for', 'duration', 'lasted']):\n",
        "            return 'duration_reference'\n",
        "        elif any(word in text_lower for word in ['until', 'through', 'to']):\n",
        "            return 'range_reference'\n",
        "        elif any(word in text_lower for word in ['after', 'following', 'post']):\n",
        "            return 'post_event'\n",
        "        elif re.search(r'\\d{4}', text):  # Contains year\n",
        "            return 'absolute_date'\n",
        "        else:\n",
        "            return 'unspecified'\n",
        "\n",
        "    def standardize_temporal_column(self, df, column_name):\n",
        "        \"\"\"Standardize an entire temporal column\"\"\"\n",
        "\n",
        "        print(f\"\\nProcessing temporal column: {column_name}\")\n",
        "\n",
        "        # Apply extraction to all values\n",
        "        temporal_data = df[column_name].apply(self.extract_all_temporal_info)\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        temporal_df = pd.DataFrame(temporal_data.tolist())\n",
        "\n",
        "        # Add prefix to column names\n",
        "        temporal_df.columns = [f\"{column_name}_{col}\" for col in temporal_df.columns]\n",
        "\n",
        "        # Concatenate with original dataframe\n",
        "        result_df = pd.concat([df, temporal_df], axis=1)\n",
        "\n",
        "        # Generate report\n",
        "        report = self._generate_temporal_report(temporal_df, column_name)\n",
        "\n",
        "        return result_df, report\n",
        "\n",
        "    def _generate_temporal_report(self, temporal_df, column_name):\n",
        "        \"\"\"Generate report on temporal extraction\"\"\"\n",
        "\n",
        "        duration_col = f\"{column_name}_duration_days\"\n",
        "        type_col = f\"{column_name}_temporal_type\"\n",
        "\n",
        "        report = {\n",
        "            'column': column_name,\n",
        "            'total_entries': len(temporal_df),\n",
        "            'extracted_durations': temporal_df[duration_col].notna().sum(),\n",
        "            'ongoing_conditions': temporal_df[f\"{column_name}_is_ongoing\"].sum(),\n",
        "            'has_specific_dates': temporal_df[f\"{column_name}_has_date\"].sum(),\n",
        "            'temporal_types': temporal_df[type_col].value_counts().to_dict()\n",
        "        }\n",
        "\n",
        "        # Duration statistics\n",
        "        if temporal_df[duration_col].notna().any():\n",
        "            report['duration_stats'] = {\n",
        "                'min_days': temporal_df[duration_col].min(),\n",
        "                'max_days': temporal_df[duration_col].max(),\n",
        "                'mean_days': temporal_df[duration_col].mean(),\n",
        "                'median_days': temporal_df[duration_col].median()\n",
        "            }\n",
        "\n",
        "        return report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing temporal column: time\n",
            "\n",
            "Temporal extraction results:\n",
            "Successfully extracted duration: 6388\n",
            "Temporal types: {'unspecified': 3554, 'absolute_date': 2836, 'post_event': 2806, 'past_reference': 2754, 'range_reference': 654, 'duration_reference': 261, 'onset_reference': 191}\n",
            "Loading en_ner_bionlp13cg_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 35864 texts in 120 batches...\n",
            "Using model: en_ner_bionlp13cg_md for column: combined_text\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   1%|          | 1/120 [00:02<04:12,  2.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   9%|▉         | 11/120 [00:16<02:41,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 3000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  18%|█▊        | 21/120 [00:30<02:19,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 6000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  26%|██▌       | 31/120 [00:44<02:09,  1.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 9000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  34%|███▍      | 41/120 [00:57<01:53,  1.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 12000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  42%|████▎     | 51/120 [01:11<01:43,  1.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  51%|█████     | 61/120 [01:25<01:28,  1.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 18000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  59%|█████▉    | 71/120 [01:38<01:14,  1.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 21000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  68%|██████▊   | 81/120 [01:52<00:57,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 24000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  76%|███████▌  | 91/120 [02:05<00:43,  1.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 27000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  84%|████████▍ | 101/120 [02:19<00:30,  1.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 30000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  92%|█████████▎| 111/120 [02:32<00:14,  1.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 33000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 120/120 [02:43<00:00,  1.36s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3452 entities appearing >= 5 times\n",
            "\n",
            "=== Entity Types Found ===\n",
            "{'MULTI_TISSUE_STRUCTURE': 32237, 'CANCER': 17003, 'TISSUE': 16665, 'ORGAN': 14854, 'PATHOLOGICAL_FORMATION': 14321, 'ORGANISM_SUBDIVISION': 4084, 'GENE_OR_GENE_PRODUCT': 3097, 'CELL': 2784, 'SIMPLE_CHEMICAL': 2742, 'ORGANISM': 2378, 'IMMATERIAL_ANATOMICAL_ENTITY': 1800, 'CELLULAR_COMPONENT': 1777, 'ORGANISM_SUBSTANCE': 1306, 'AMINO_ACID': 111, 'ANATOMICAL_SYSTEM': 48, 'DEVELOPING_ANATOMICAL_STRUCTURE': 1}\n",
            "\n",
            "Custom extraction found:\n",
            "label\n",
            "PROCEDURE     24770\n",
            "ANATOMY       20351\n",
            "LATERALITY    19618\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== COMBINED Entity Distribution ===\n",
            "label\n",
            "MULTI_TISSUE_STRUCTURE             32237\n",
            "PROCEDURE                          24770\n",
            "ANATOMY                            20351\n",
            "LATERALITY                         19618\n",
            "CANCER                             17003\n",
            "TISSUE                             16665\n",
            "ORGAN                              14854\n",
            "PATHOLOGICAL_FORMATION             14321\n",
            "ORGANISM_SUBDIVISION                4084\n",
            "GENE_OR_GENE_PRODUCT                3097\n",
            "CELL                                2784\n",
            "SIMPLE_CHEMICAL                     2742\n",
            "ORGANISM                            2378\n",
            "IMMATERIAL_ANATOMICAL_ENTITY        1800\n",
            "CELLULAR_COMPONENT                  1777\n",
            "ORGANISM_SUBSTANCE                  1306\n",
            "AMINO_ACID                           111\n",
            "ANATOMICAL_SYSTEM                     48\n",
            "DEVELOPING_ANATOMICAL_STRUCTURE        1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Anatomical Entities ===\n",
            "text\n",
            "artery      3347\n",
            "bone        1868\n",
            "vein        1316\n",
            "nerve       1267\n",
            "liver       1058\n",
            "knee         933\n",
            "muscle       890\n",
            "lung         860\n",
            "hip          827\n",
            "kidney       805\n",
            "joint        700\n",
            "cervical     654\n",
            "vascular     602\n",
            "tendon       563\n",
            "femur        459\n",
            "heart        443\n",
            "ligament     370\n",
            "tibia        276\n",
            "lumbar       261\n",
            "veins        251\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Anatomy by Category ===\n",
            "category\n",
            "vessel    5753\n",
            "organ     3474\n",
            "bone      2799\n",
            "muscle    2167\n",
            "nerve     1505\n",
            "knee      1494\n",
            "spine     1380\n",
            "hip       1015\n",
            "joint      764\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Surgical Procedures ===\n",
            "text\n",
            "resection         5026\n",
            "excision          3459\n",
            "removal           3193\n",
            "repair            1755\n",
            "biopsy            1636\n",
            "graft             1628\n",
            "reconstruction    1309\n",
            "fixation          1250\n",
            "replacement        957\n",
            "implantation       608\n",
            "exploration        577\n",
            "implant            498\n",
            "decompression      407\n",
            "transplant         387\n",
            "arthroplasty       334\n",
            "osteotomy          331\n",
            "fusion             321\n",
            "diagnostic         285\n",
            "implants           183\n",
            "release            176\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Procedures by Category ===\n",
            "category\n",
            "removal          11789\n",
            "repair            4345\n",
            "transplant        2789\n",
            "diagnostic        2502\n",
            "replacement       2010\n",
            "fusion             716\n",
            "decompression      619\n",
            "Name: count, dtype: int64\n",
            "\n",
            "LF-generated surgery spans: 6244\n",
            "label\n",
            "MINIMALLY_INVASIVE     2058\n",
            "BILATERAL_PROCEDURE    1540\n",
            "FRACTURE_SURGERY       1365\n",
            "EMERGENCY_SURGERY       575\n",
            "KNEE_SURGERY            375\n",
            "HIP_SURGERY             331\n",
            "Name: count, dtype: int64\n",
            "Total surgery entities (model+custom+LF): 186191\n"
          ]
        }
      ],
      "source": [
        "def extract_surgical_entities_custom(df_surgery):\n",
        "    \"\"\"\n",
        "    Custom extraction for anatomy and procedures not caught by the model.\n",
        "    Uses 'idx' column for row identity when available; falls back to df.index otherwise.\n",
        "    Adds 'row_idx' to every extracted entity.\n",
        "    Uses regex word-boundary matching; allows simple plurals (e.g., hips, arteries).\n",
        "    \"\"\"\n",
        "\n",
        "    custom_entities = []\n",
        "\n",
        "    # Anatomy vocab by category\n",
        "    anatomy_patterns = {\n",
        "        'hip':        ['hip', 'acetabul', 'femoral head'],\n",
        "        'knee':       ['knee', 'meniscus', 'patella', 'tibia'],\n",
        "        'bone':       ['bone', 'femur', 'humerus', 'radius', 'ulna'],\n",
        "        'joint':      ['joint', 'articulation'],\n",
        "        'spine':      ['spine', 'vertebra', 'disc', 'lumbar', 'cervical'],\n",
        "        'organ':      ['kidney', 'liver', 'heart', 'lung', 'spleen'],\n",
        "        'vessel':     ['artery', 'vein', 'vessel', 'vascular'],\n",
        "        'nerve':      ['nerve', 'neural', 'plexus'],\n",
        "        'muscle':     ['muscle', 'tendon', 'ligament']\n",
        "    }\n",
        "\n",
        "    # Procedure vocab by category\n",
        "    procedure_patterns = {\n",
        "        'replacement':   ['arthroplasty', 'replacement', 'implant'],\n",
        "        'repair':        ['repair', 'reconstruction', 'fixation'],\n",
        "        'removal':       ['removal', 'excision', 'resection', 'ectomy'],\n",
        "        'fusion':        ['fusion', 'arthrodesis', 'osteotomy'],\n",
        "        'diagnostic':    ['biopsy', 'exploration', 'diagnostic'],\n",
        "        'decompression': ['decompression', 'release', 'neurolysis'],\n",
        "        'transplant':    ['transplant', 'graft', 'implantation']\n",
        "    }\n",
        "\n",
        "    laterality_terms = ['left', 'right', 'bilateral', 'unilateral']\n",
        "\n",
        "    for df_idx, row in df_surgery.iterrows():\n",
        "        # ---- choose the correct row id from 'idx' with fallback to the DataFrame index\n",
        "        if 'idx' in row and pd.notna(row['idx']):\n",
        "            row_id = row['idx']\n",
        "        else:\n",
        "            row_id = df_idx\n",
        "\n",
        "        # ---- text (keep original for offsets; search on lowercased copy)\n",
        "        original_text = str(row.get('combined_text', ''))\n",
        "        text = original_text.lower()\n",
        "\n",
        "        # ---- Anatomy extraction (regex with word boundaries; allow simple plural 's')\n",
        "        for category, terms in anatomy_patterns.items():\n",
        "            for term in terms:\n",
        "                # allow plural 's' for basic nouns (skip stems like 'acetabul' where 's' doesn't apply cleanly)\n",
        "                plural_opt = 's?' if term.isalpha() and not term.endswith(('al','el','ul')) else ''\n",
        "                pattern = r'\\b' + re.escape(term.lower()) + plural_opt + r'\\b'\n",
        "                for m in re.finditer(pattern, text):\n",
        "                    custom_entities.append({\n",
        "                        'text': original_text[m.start():m.end()],\n",
        "                        'label': 'ANATOMY',\n",
        "                        'category': category,\n",
        "                        'start': m.start(),\n",
        "                        'end': m.end(),\n",
        "                        'original_text': original_text,\n",
        "                        'source': 'custom_extraction',\n",
        "                        'row_idx': row_id,   # <-- correct ID retained\n",
        "                    })\n",
        "\n",
        "        # ---- Procedure extraction (also boundary-based)\n",
        "        for category, terms in procedure_patterns.items():\n",
        "            for term in terms:\n",
        "                plural_opt = 's?' if term.isalpha() else ''\n",
        "                pattern = r'\\b' + re.escape(term.lower()) + plural_opt + r'\\b'\n",
        "                for m in re.finditer(pattern, text):\n",
        "                    custom_entities.append({\n",
        "                        'text': original_text[m.start():m.end()],\n",
        "                        'label': 'PROCEDURE',\n",
        "                        'category': category,\n",
        "                        'start': m.start(),\n",
        "                        'end': m.end(),\n",
        "                        'original_text': original_text,\n",
        "                        'source': 'custom_extraction',\n",
        "                        'row_idx': row_id,   # <-- correct ID retained\n",
        "                    })\n",
        "\n",
        "        # ---- Laterality extraction\n",
        "        for lat in laterality_terms:\n",
        "            pattern = r'\\b' + re.escape(lat) + r'\\b'\n",
        "            for m in re.finditer(pattern, text):\n",
        "                custom_entities.append({\n",
        "                    'text': original_text[m.start():m.end()],\n",
        "                    'label': 'LATERALITY',\n",
        "                    'category': 'laterality',\n",
        "                    'start': m.start(),\n",
        "                    'end': m.end(),\n",
        "                    'original_text': original_text,\n",
        "                    'source': 'custom_extraction',\n",
        "                    'row_idx': row_id,   # <-- correct ID retained\n",
        "                })\n",
        "\n",
        "    return pd.DataFrame(custom_entities)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Apply temporal standardization\n",
        "    temporal_standardizer = TemporalStandardizer()\n",
        "    df_surgery_processed, temporal_report = temporal_standardizer.standardize_temporal_column(\n",
        "        df_surgery, \n",
        "        'time'\n",
        "    )\n",
        "   \n",
        "    print(f\"\\nTemporal extraction results:\")\n",
        "    print(f\"Successfully extracted duration: {temporal_report['extracted_durations']}\")\n",
        "    print(f\"Temporal types: {temporal_report['temporal_types']}\")\n",
        "\n",
        "    # Combine surgery text columns\n",
        "    # (use str() to be tolerant to NaNs)\n",
        "    df_surgery['combined_text'] = df_surgery.apply(\n",
        "        lambda row: f\"{str(row.get('reason',''))} {str(row.get('Type',''))} {str(row.get('details',''))} {str(row.get('outcome',''))}\",\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Copy combined_text to processed dataframe (keeps alignment with df_surgery by index)\n",
        "    df_surgery_processed['combined_text'] = df_surgery['combined_text']\n",
        "\n",
        "    # Add temporal features to combined text\n",
        "    df_surgery_processed['combined_text_enriched'] = df_surgery_processed.apply(\n",
        "        lambda row: f\"{row['combined_text']} {'lasting ' + str(row.get('time_duration_days', '')) + ' days' if pd.notna(row.get('time_duration_days')) else ''}\",\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # NER over the (non-enriched) combined_text in df_surgery\n",
        "    df_surgery_entities, surgery_summary, surgery_rules = run_medical_ner_extraction(\n",
        "        df_surgery,\n",
        "        text_column='combined_text',\n",
        "        model_name='en_ner_bionlp13cg_md', \n",
        "        batch_size=300,\n",
        "        id_column='idx'\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== Entity Types Found ===\")\n",
        "    print(surgery_summary['entity_types'])\n",
        "\n",
        "\n",
        "    # Extract custom entities\n",
        "    df_custom_entities = extract_surgical_entities_custom(df_surgery)\n",
        "\n",
        "    print(f\"\\nCustom extraction found:\")\n",
        "    if not df_custom_entities.empty and 'label' in df_custom_entities.columns:\n",
        "        print(df_custom_entities['label'].value_counts())\n",
        "    else:\n",
        "        print(\"No custom entities found.\")\n",
        "\n",
        "    # Combine model entities and custom entities\n",
        "    # (keep row_idx/category when present for traceability)\n",
        "    df_all_surgery_entities = pd.concat(\n",
        "        [df_surgery_entities, df_custom_entities],\n",
        "        ignore_index=True,\n",
        "        sort=False\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== COMBINED Entity Distribution ===\")\n",
        "    if not df_all_surgery_entities.empty and 'label' in df_all_surgery_entities.columns:\n",
        "        print(df_all_surgery_entities['label'].value_counts())\n",
        "    else:\n",
        "        print(\"No combined entities to show.\")\n",
        "\n",
        "    # Analyze anatomy entities\n",
        "    anatomy_entities = df_all_surgery_entities[df_all_surgery_entities['label'] == 'ANATOMY'] if not df_all_surgery_entities.empty else pd.DataFrame()\n",
        "    if not anatomy_entities.empty:\n",
        "        print(f\"\\n=== Top Anatomical Entities ===\")\n",
        "        print(anatomy_entities['text'].str.lower().value_counts().head(20))\n",
        "\n",
        "        if 'category' in anatomy_entities.columns:\n",
        "            print(f\"\\n=== Anatomy by Category ===\")\n",
        "            print(anatomy_entities['category'].value_counts())\n",
        "\n",
        "    # Analyze procedure entities\n",
        "    procedure_entities = df_all_surgery_entities[df_all_surgery_entities['label'] == 'PROCEDURE'] if not df_all_surgery_entities.empty else pd.DataFrame()\n",
        "    if not procedure_entities.empty:\n",
        "        print(f\"\\n=== Top Surgical Procedures ===\")\n",
        "        print(procedure_entities['text'].str.lower().value_counts().head(20))\n",
        "\n",
        "        if 'category' in procedure_entities.columns:\n",
        "            print(f\"\\n=== Procedures by Category ===\")\n",
        "            print(procedure_entities['category'].value_counts())\n",
        "\n",
        "    # ========== Labeling functions (unchanged logic) ==========\n",
        "\n",
        "    def create_surgical_labeling_functions():\n",
        "        COL = 'combined_text'   # main free text\n",
        "        REASON = 'reason'       # for emergency logic\n",
        "\n",
        "        def lf_hip_surgery(row):\n",
        "            text = str(row.get(COL,''))\n",
        "            if ('hip' in text.lower() and _first_hit(text, ['arthroplasty','replacement','repair'])):\n",
        "                return {'label':'HIP_SURGERY','column':COL,'match':'hip','category':'joint'}\n",
        "            return {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_knee_surgery(row):\n",
        "            text = str(row.get(COL,''))\n",
        "            if ('knee' in text.lower() and _first_hit(text, ['arthroplasty','replacement','arthroscopy'])):\n",
        "                return {'label':'KNEE_SURGERY','column':COL,'match':'knee','category':'joint'}\n",
        "            return {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_fracture_surgery(row):\n",
        "            text = str(row.get(COL,''))\n",
        "            if ('fracture' in text.lower() and _first_hit(text, ['fixation','repair','reduction'])):\n",
        "                return {'label':'FRACTURE_SURGERY','column':COL,'match':'fracture','category':'bone'}\n",
        "            return {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_bilateral_procedure(row):\n",
        "            text = str(row.get(COL,''))\n",
        "            hit = _first_hit(text, ['bilateral'])\n",
        "            return {'label':'BILATERAL_PROCEDURE','column':COL,'match':hit,'category':'laterality'} if hit else {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_minimally_invasive(row):\n",
        "            text = str(row.get(COL,''))\n",
        "            hit = _first_hit(text, ['arthroscopic','endoscopic','laparoscopic','minimally invasive'])\n",
        "            return {'label':'MINIMALLY_INVASIVE','column':COL,'match':hit,'category':'approach'} if hit else {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_emergency_procedure(row):\n",
        "            reason = str(row.get(REASON,''))\n",
        "            hit = _first_hit(reason, ['emergency','urgent','acute','trauma'])\n",
        "            return {'label':'EMERGENCY_SURGERY','column':REASON,'match':hit,'category':'urgency'} if hit else {'label':'ABSTAIN'}\n",
        "\n",
        "        return [lf_hip_surgery, lf_knee_surgery, lf_fracture_surgery,\n",
        "                lf_bilateral_procedure, lf_minimally_invasive, lf_emergency_procedure]\n",
        "\n",
        "    # --- materialize spans ---\n",
        "    surgical_lfs_span = create_surgical_labeling_functions()\n",
        "    df_surgery_lf_spans = materialize_lf_spans(df_surgery, surgical_lfs_span, id_column='idx')\n",
        "    print(f\"\\nLF-generated surgery spans: {len(df_surgery_lf_spans)}\")\n",
        "    if not df_surgery_lf_spans.empty:\n",
        "        print(df_surgery_lf_spans['label'].value_counts())\n",
        "\n",
        "    # --- combine model + custom + LF spans ---\n",
        "    _cols = ['text','label','start','end','original_text','source','row_idx','category']\n",
        "    for col in _cols:\n",
        "        if col not in df_surgery_entities.columns: df_surgery_entities[col] = 'bionlp13cg' if col=='source' else None\n",
        "        if col not in df_custom_entities.columns: df_custom_entities[col] = 'custom_extraction' if col=='source' else None\n",
        "        if col not in df_surgery_lf_spans.columns: df_surgery_lf_spans[col] = None\n",
        "\n",
        "    df_all_surgery_entities = pd.concat(\n",
        "        [df_surgery_entities[_cols], df_custom_entities[_cols], df_surgery_lf_spans[_cols]],\n",
        "        ignore_index=True\n",
        "    )\n",
        "    print(f\"Total surgery entities (model+custom+LF): {len(df_all_surgery_entities)}\")\n",
        "    df_surgery_lf_spans.to_csv('surgery_lf_generated_spans.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "id": "uniu23sqp0SV",
        "outputId": "a61f1782-077f-4077-8e0b-882c30d3ce70"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>source</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>femoral head</td>\n",
              "      <td>PATHOLOGICAL_FORMATION</td>\n",
              "      <td>32</td>\n",
              "      <td>44</td>\n",
              "      <td>Idiopathic osteonecrosis of the femoral head T...</td>\n",
              "      <td>bionlp13cg</td>\n",
              "      <td>133948</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>left hip</td>\n",
              "      <td>PATHOLOGICAL_FORMATION</td>\n",
              "      <td>91</td>\n",
              "      <td>99</td>\n",
              "      <td>Idiopathic osteonecrosis of the femoral head T...</td>\n",
              "      <td>bionlp13cg</td>\n",
              "      <td>133948</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>joint Total</td>\n",
              "      <td>MULTI_TISSUE_STRUCTURE</td>\n",
              "      <td>46</td>\n",
              "      <td>57</td>\n",
              "      <td>Pain and limited ROM in the contralateral hip ...</td>\n",
              "      <td>bionlp13cg</td>\n",
              "      <td>133948</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Left elbow</td>\n",
              "      <td>TISSUE</td>\n",
              "      <td>24</td>\n",
              "      <td>34</td>\n",
              "      <td>Posttraumatic arthritis Left elbow arthrodesis...</td>\n",
              "      <td>bionlp13cg</td>\n",
              "      <td>80176</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ulnar shaft</td>\n",
              "      <td>MULTI_TISSUE_STRUCTURE</td>\n",
              "      <td>25</td>\n",
              "      <td>36</td>\n",
              "      <td>Hypertrophic nonunion of ulnar shaft fracture ...</td>\n",
              "      <td>bionlp13cg</td>\n",
              "      <td>80176</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186186</th>\n",
              "      <td>bilateral</td>\n",
              "      <td>BILATERAL_PROCEDURE</td>\n",
              "      <td>237</td>\n",
              "      <td>246</td>\n",
              "      <td>Suprasellar, hemorrhagic mass with optic chias...</td>\n",
              "      <td>lf:lf_bilateral_procedure</td>\n",
              "      <td>77772</td>\n",
              "      <td>laterality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186187</th>\n",
              "      <td>Endoscopic</td>\n",
              "      <td>MINIMALLY_INVASIVE</td>\n",
              "      <td>60</td>\n",
              "      <td>70</td>\n",
              "      <td>Suprasellar, hemorrhagic mass with optic chias...</td>\n",
              "      <td>lf:lf_minimally_invasive</td>\n",
              "      <td>77772</td>\n",
              "      <td>approach</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186188</th>\n",
              "      <td>Laparoscopic</td>\n",
              "      <td>MINIMALLY_INVASIVE</td>\n",
              "      <td>20</td>\n",
              "      <td>32</td>\n",
              "      <td>Internal herniation Laparoscopic surgery First...</td>\n",
              "      <td>lf:lf_minimally_invasive</td>\n",
              "      <td>138087</td>\n",
              "      <td>approach</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186189</th>\n",
              "      <td>Minimally invasive</td>\n",
              "      <td>MINIMALLY_INVASIVE</td>\n",
              "      <td>94</td>\n",
              "      <td>112</td>\n",
              "      <td>Incidental mass in the right kidney CT-guided ...</td>\n",
              "      <td>lf:lf_minimally_invasive</td>\n",
              "      <td>157822</td>\n",
              "      <td>approach</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186190</th>\n",
              "      <td>Acute</td>\n",
              "      <td>EMERGENCY_SURGERY</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>Acute severe aortic insufficiency from endocar...</td>\n",
              "      <td>lf:lf_emergency_procedure</td>\n",
              "      <td>97973</td>\n",
              "      <td>urgency</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>186191 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      text                   label  start  end  \\\n",
              "0             femoral head  PATHOLOGICAL_FORMATION     32   44   \n",
              "1                 left hip  PATHOLOGICAL_FORMATION     91   99   \n",
              "2              joint Total  MULTI_TISSUE_STRUCTURE     46   57   \n",
              "3               Left elbow                  TISSUE     24   34   \n",
              "4              ulnar shaft  MULTI_TISSUE_STRUCTURE     25   36   \n",
              "...                    ...                     ...    ...  ...   \n",
              "186186           bilateral     BILATERAL_PROCEDURE    237  246   \n",
              "186187          Endoscopic      MINIMALLY_INVASIVE     60   70   \n",
              "186188        Laparoscopic      MINIMALLY_INVASIVE     20   32   \n",
              "186189  Minimally invasive      MINIMALLY_INVASIVE     94  112   \n",
              "186190               Acute       EMERGENCY_SURGERY      0    5   \n",
              "\n",
              "                                            original_text  \\\n",
              "0       Idiopathic osteonecrosis of the femoral head T...   \n",
              "1       Idiopathic osteonecrosis of the femoral head T...   \n",
              "2       Pain and limited ROM in the contralateral hip ...   \n",
              "3       Posttraumatic arthritis Left elbow arthrodesis...   \n",
              "4       Hypertrophic nonunion of ulnar shaft fracture ...   \n",
              "...                                                   ...   \n",
              "186186  Suprasellar, hemorrhagic mass with optic chias...   \n",
              "186187  Suprasellar, hemorrhagic mass with optic chias...   \n",
              "186188  Internal herniation Laparoscopic surgery First...   \n",
              "186189  Incidental mass in the right kidney CT-guided ...   \n",
              "186190  Acute severe aortic insufficiency from endocar...   \n",
              "\n",
              "                           source  row_idx    category  \n",
              "0                      bionlp13cg   133948        None  \n",
              "1                      bionlp13cg   133948        None  \n",
              "2                      bionlp13cg   133948        None  \n",
              "3                      bionlp13cg    80176        None  \n",
              "4                      bionlp13cg    80176        None  \n",
              "...                           ...      ...         ...  \n",
              "186186  lf:lf_bilateral_procedure    77772  laterality  \n",
              "186187   lf:lf_minimally_invasive    77772    approach  \n",
              "186188   lf:lf_minimally_invasive   138087    approach  \n",
              "186189   lf:lf_minimally_invasive   157822    approach  \n",
              "186190  lf:lf_emergency_procedure    97973     urgency  \n",
              "\n",
              "[186191 rows x 8 columns]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_all_surgery_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting Symptoms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 963
        },
        "id": "gfbXYJpJ7Rqj",
        "outputId": "086917d6-7022-4c5b-a9ae-7c754bbd349a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>has_symptom</th>\n",
              "      <th>name of symptom</th>\n",
              "      <th>intensity of symptom</th>\n",
              "      <th>location</th>\n",
              "      <th>time</th>\n",
              "      <th>temporalisation</th>\n",
              "      <th>behaviours affecting the symptom</th>\n",
              "      <th>details</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155216</td>\n",
              "      <td>True</td>\n",
              "      <td>Discomfort in the neck and lower back, restric...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Neck and lower back</td>\n",
              "      <td>Past four months</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Standing up from a sitting position</td>\n",
              "      <td>Head turned to the right and upwards due to su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>133948</td>\n",
              "      <td>True</td>\n",
              "      <td>Pain</td>\n",
              "      <td>Severe</td>\n",
              "      <td>Left hip joint</td>\n",
              "      <td>Persisting for two months</td>\n",
              "      <td>Increased over the following three weeks</td>\n",
              "      <td>Aggravated by hip joint flexion or rotation</td>\n",
              "      <td>Also complained of pain and limited ROM in the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133948</td>\n",
              "      <td>True</td>\n",
              "      <td>Restricted range of motion</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Left hip joint</td>\n",
              "      <td>Persisting for two months</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>133948</td>\n",
              "      <td>True</td>\n",
              "      <td>Gait disturbance</td>\n",
              "      <td>Severe</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Secondary to hip pain</td>\n",
              "      <td>Continued for two months and increased over th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>133948</td>\n",
              "      <td>True</td>\n",
              "      <td>Moderate moon face</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Face</td>\n",
              "      <td>At the time of the second surgery</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Initially overlooked as weight gain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54939</th>\n",
              "      <td>137017</td>\n",
              "      <td>True</td>\n",
              "      <td>Left-sided weakness</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Left side</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54940</th>\n",
              "      <td>98004</td>\n",
              "      <td>True</td>\n",
              "      <td>Chest pain</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Chest</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Cardiac sounding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54941</th>\n",
              "      <td>133320</td>\n",
              "      <td>True</td>\n",
              "      <td>Mass in right thigh</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Lateral side of the right thigh</td>\n",
              "      <td>Noticed four years prior to presentation</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Diameter of 4 cm, no adhesion with skin and no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54942</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Crushing substernal chest pressure</td>\n",
              "      <td>Acute onset</td>\n",
              "      <td>Substernal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Following 1-week-long febrile illness</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Accompanied by dyspnea and profuse sweating</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54943</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Dyspnea</td>\n",
              "      <td>Rapidly developed</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Patient developed dyspnea, tachypnea, and tach...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>54944 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          idx  has_symptom                                    name of symptom  \\\n",
              "0      155216         True  Discomfort in the neck and lower back, restric...   \n",
              "1      133948         True                                               Pain   \n",
              "2      133948         True                         Restricted range of motion   \n",
              "3      133948         True                                   Gait disturbance   \n",
              "4      133948         True                                 Moderate moon face   \n",
              "...       ...          ...                                                ...   \n",
              "54939  137017         True                                Left-sided weakness   \n",
              "54940   98004         True                                         Chest pain   \n",
              "54941  133320         True                                Mass in right thigh   \n",
              "54942   97973         True                 Crushing substernal chest pressure   \n",
              "54943   97973         True                                            Dyspnea   \n",
              "\n",
              "      intensity of symptom                         location  \\\n",
              "0                      NaN              Neck and lower back   \n",
              "1                   Severe                   Left hip joint   \n",
              "2                      NaN                   Left hip joint   \n",
              "3                   Severe                              NaN   \n",
              "4                 Moderate                             Face   \n",
              "...                    ...                              ...   \n",
              "54939                  NaN                        Left side   \n",
              "54940                  NaN                            Chest   \n",
              "54941                  NaN  Lateral side of the right thigh   \n",
              "54942          Acute onset                       Substernal   \n",
              "54943    Rapidly developed                              NaN   \n",
              "\n",
              "                                           time  \\\n",
              "0                              Past four months   \n",
              "1                     Persisting for two months   \n",
              "2                     Persisting for two months   \n",
              "3                                           NaN   \n",
              "4             At the time of the second surgery   \n",
              "...                                         ...   \n",
              "54939                                       NaN   \n",
              "54940                                       NaN   \n",
              "54941  Noticed four years prior to presentation   \n",
              "54942                                       NaN   \n",
              "54943                                       NaN   \n",
              "\n",
              "                                temporalisation  \\\n",
              "0                                           NaN   \n",
              "1      Increased over the following three weeks   \n",
              "2                                           NaN   \n",
              "3                                           NaN   \n",
              "4                                           NaN   \n",
              "...                                         ...   \n",
              "54939                                       NaN   \n",
              "54940                                       NaN   \n",
              "54941                                       NaN   \n",
              "54942     Following 1-week-long febrile illness   \n",
              "54943                                       NaN   \n",
              "\n",
              "                  behaviours affecting the symptom  \\\n",
              "0              Standing up from a sitting position   \n",
              "1      Aggravated by hip joint flexion or rotation   \n",
              "2                                              NaN   \n",
              "3                            Secondary to hip pain   \n",
              "4                                              NaN   \n",
              "...                                            ...   \n",
              "54939                                          NaN   \n",
              "54940                                          NaN   \n",
              "54941                                          NaN   \n",
              "54942                                          NaN   \n",
              "54943                                          NaN   \n",
              "\n",
              "                                                 details  \n",
              "0      Head turned to the right and upwards due to su...  \n",
              "1      Also complained of pain and limited ROM in the...  \n",
              "2                                                    NaN  \n",
              "3      Continued for two months and increased over th...  \n",
              "4                    Initially overlooked as weight gain  \n",
              "...                                                  ...  \n",
              "54939                                                NaN  \n",
              "54940                                   Cardiac sounding  \n",
              "54941  Diameter of 4 cm, no adhesion with skin and no...  \n",
              "54942        Accompanied by dyspnea and profuse sweating  \n",
              "54943  Patient developed dyspnea, tachypnea, and tach...  \n",
              "\n",
              "[54944 rows x 9 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_symptoms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m5jzEN8EPnX",
        "outputId": "3a06cf64-4e26-4781-93d0-c3c608e923f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing temporal column: time\n",
            "\n",
            "Temporal extraction results:\n",
            "Successfully extracted duration: 18893\n",
            "Temporal types: {'unspecified': 13201, 'post_event': 6146, 'range_reference': 5023, 'past_reference': 4704, 'duration_reference': 4063, 'onset_reference': 2904, 'absolute_date': 1164}\n",
            "Loading en_ner_bc5cdr_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 54944 texts in 184 batches...\n",
            "Using model: en_ner_bc5cdr_md for column: combined_text\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   1%|          | 1/184 [00:01<05:49,  1.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   6%|▌         | 11/184 [00:13<03:32,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 3000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  11%|█▏        | 21/184 [00:25<03:16,  1.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 6000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  17%|█▋        | 31/184 [00:37<02:59,  1.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 9000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  22%|██▏       | 41/184 [00:48<02:51,  1.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 12000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  28%|██▊       | 51/184 [00:59<02:35,  1.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  33%|███▎      | 61/184 [01:11<02:28,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 18000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  39%|███▊      | 71/184 [01:22<02:13,  1.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 21000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  44%|████▍     | 81/184 [01:33<02:02,  1.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 24000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  49%|████▉     | 91/184 [01:45<01:49,  1.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 27000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  55%|█████▍    | 101/184 [01:56<01:40,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 30000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  60%|██████    | 111/184 [02:07<01:28,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 33000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  66%|██████▌   | 121/184 [02:18<01:16,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 36000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  71%|███████   | 131/184 [02:30<01:04,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 39000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  77%|███████▋  | 141/184 [02:41<00:53,  1.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 42000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  82%|████████▏ | 151/184 [02:52<00:40,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 45000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  88%|████████▊ | 161/184 [03:03<00:28,  1.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 48000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  93%|█████████▎| 171/184 [03:15<00:15,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 51000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  98%|█████████▊| 181/184 [03:26<00:03,  1.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 54000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 184/184 [03:28<00:00,  1.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1857 entities appearing >= 5 times\n",
            "\n",
            "=== BC5CDR Entity Types Found ===\n",
            "{'DISEASE': 84179, 'CHEMICAL': 2286}\n",
            "\n",
            "Custom extraction found:\n",
            "label\n",
            "ANATOMY             67817\n",
            "SYMPTOM_TYPE        56789\n",
            "SYMPTOM             53580\n",
            "LATERALITY          31971\n",
            "TEMPORAL_PATTERN    14118\n",
            "SEVERITY             5306\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== COMBINED Entity Distribution ===\n",
            "label\n",
            "DISEASE             84179\n",
            "ANATOMY             67817\n",
            "SYMPTOM_TYPE        56789\n",
            "SYMPTOM             53580\n",
            "LATERALITY          31971\n",
            "TEMPORAL_PATTERN    14118\n",
            "SEVERITY             5306\n",
            "CHEMICAL             2286\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Symptoms ===\n",
            "text\n",
            "pain                    1796\n",
            "abdominal pain          1182\n",
            "swelling                1146\n",
            "fever                    825\n",
            "headache                 722\n",
            "chest pain               576\n",
            "vomiting                 575\n",
            "dyspnea                  519\n",
            "shortness of breath      501\n",
            "weight loss              459\n",
            "nausea                   399\n",
            "dysphagia                313\n",
            "fatigue                  307\n",
            "weakness                 291\n",
            "cough                    284\n",
            "pain and swelling        257\n",
            "back pain                257\n",
            "dizziness                225\n",
            "numbness                 224\n",
            "abdominal distension     207\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Symptom Locations ===\n",
            "text\n",
            "abdomen     4733\n",
            "chest       4489\n",
            "back        3187\n",
            "neck        2776\n",
            "leg         2034\n",
            "knee        1829\n",
            "face        1580\n",
            "hand        1244\n",
            "hip         1213\n",
            "head        1171\n",
            "shoulder    1075\n",
            "arm         1058\n",
            "joint        942\n",
            "thigh        930\n",
            "foot         915\n",
            "legs         828\n",
            "ankle        722\n",
            "throat       694\n",
            "left eye     617\n",
            "elbow        577\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Severity Distribution ===\n",
            "text\n",
            "severe         3508\n",
            "mild           1245\n",
            "significant     306\n",
            "moderate        196\n",
            "extreme          32\n",
            "minimal          19\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Creating Symptom-Specific Labeling Functions ===\n",
            "\n",
            "LF-generated symptom spans: 67817\n",
            "label\n",
            "LOCALIZED_PAIN         30067\n",
            "CHRONIC_SYMPTOM        10722\n",
            "PROGRESSIVE_SYMPTOM     5220\n",
            "SYSTEMIC_SYMPTOM        4914\n",
            "NEUROLOGICAL            4454\n",
            "ACUTE_ONSET             3149\n",
            "SEVERE_PAIN             2925\n",
            "MOBILITY_ISSUE          1785\n",
            "BILATERAL_SYMPTOM       1757\n",
            "BACK_PAIN               1377\n",
            "KNEE_PAIN                873\n",
            "HIP_PAIN                 574\n",
            "Name: count, dtype: int64\n",
            "Total symptom entities (model+custom+LF): 383863\n"
          ]
        }
      ],
      "source": [
        "def extract_symptom_entities_custom(df_symptoms):\n",
        "    \"\"\"\n",
        "    Extract symptom-specific entities not caught by BC5CDR.\n",
        "    Uses 'idx' for row identity when available; falls back to df.index otherwise.\n",
        "    Adds 'row_idx' to every extracted entity.\n",
        "    Regex with word boundaries is used to avoid substring false positives.\n",
        "    \"\"\"\n",
        "    custom_entities = []\n",
        "\n",
        "    # Symptom type patterns\n",
        "    symptom_patterns = {\n",
        "        'pain':         ['pain', 'ache', 'soreness', 'tenderness', 'discomfort'],\n",
        "        'neurological': ['numbness', 'tingling', 'weakness', 'paralysis', 'tremor'],\n",
        "        'mobility':     ['inability to walk', 'gait disturbance', 'limited range of motion', 'stiffness'],\n",
        "        'swelling':     ['swelling', 'edema', 'inflammation', 'mass', 'lump'],\n",
        "        'sensory':      ['vision', 'hearing', 'taste', 'smell', 'sensation'],\n",
        "        'systemic':     ['fever', 'fatigue', 'malaise', 'weight loss', 'night sweats'],\n",
        "        'respiratory':  ['dyspnea', 'cough', 'wheezing', 'shortness of breath'],\n",
        "        'gi':           ['nausea', 'vomiting', 'diarrhea', 'constipation', 'abdominal'],\n",
        "        'skin':         ['rash', 'itching', 'lesion', 'discoloration', 'bruising']\n",
        "    }\n",
        "\n",
        "    # Anatomical location patterns\n",
        "    anatomy_patterns = {\n",
        "        'head_neck':      ['head', 'neck', 'scalp', 'face', 'throat', 'cervical'],\n",
        "        'upper_extremity': ['shoulder', 'arm', 'elbow', 'forearm', 'wrist', 'hand', 'finger'],\n",
        "        'lower_extremity': ['hip', 'thigh', 'knee', 'leg', 'ankle', 'foot', 'toe'],\n",
        "        'trunk':           ['chest', 'back', 'abdomen', 'pelvis', 'spine', 'lumbar'],\n",
        "        'joint':           ['joint', 'articulation'],\n",
        "        'internal':        ['heart', 'lung', 'liver', 'kidney', 'stomach']\n",
        "    }\n",
        "\n",
        "    # Severity/Intensity (column-driven)\n",
        "    severity_values = {'mild', 'moderate', 'severe', 'extreme', 'minimal', 'significant'}\n",
        "\n",
        "    # Temporal patterns\n",
        "    temporal_patterns = {\n",
        "        'acute':        ['acute', 'sudden', 'abrupt', 'rapid'],\n",
        "        'chronic':      ['chronic', 'persistent', 'ongoing', 'continuous'],\n",
        "        'intermittent': ['intermittent', 'episodic', 'recurrent', 'periodic'],\n",
        "        'progressive':  ['progressive', 'worsening', 'increasing', 'deteriorating']\n",
        "    }\n",
        "\n",
        "    laterality_terms = ['left', 'right', 'bilateral', 'both']\n",
        "\n",
        "    for df_index, row in df_symptoms.iterrows():\n",
        "        # ---- choose the correct row id from 'idx' with fallback to the DataFrame index\n",
        "        row_id = row['idx'] if ('idx' in row and pd.notna(row['idx'])) else df_index\n",
        "\n",
        "        original_text = str(row.get('combined_text', ''))\n",
        "        combined = original_text.lower()\n",
        "\n",
        "        # Columns (original + lower)\n",
        "        symptom_name_orig = str(row.get('name of symptom', ''))\n",
        "        symptom_name = symptom_name_orig.lower()\n",
        "        location_orig = str(row.get('location', ''))\n",
        "        location = location_orig.lower()\n",
        "        intensity_orig = str(row.get('intensity of symptom', ''))\n",
        "        intensity = intensity_orig.lower()\n",
        "        temporalisation_orig = str(row.get('temporalisation', ''))\n",
        "        temporalisation = temporalisation_orig.lower()\n",
        "\n",
        "        # ---- Primary SYMPTOM from name column (if present)\n",
        "        if pd.notna(row.get('name of symptom')) and symptom_name.strip() != '' and symptom_name != 'nan':\n",
        "            # try to find position in combined; if not found, set to 0\n",
        "            start = combined.find(symptom_name)\n",
        "            if start < 0:\n",
        "                start = 0\n",
        "            end = start + len(symptom_name_orig)\n",
        "            end = min(end, len(original_text))\n",
        "            custom_entities.append({\n",
        "                'text': symptom_name_orig,\n",
        "                'label': 'SYMPTOM',\n",
        "                'category': 'primary_symptom',\n",
        "                'start': start,\n",
        "                'end': end,\n",
        "                'original_text': original_text,\n",
        "                'source': 'symptom_name_column',\n",
        "                'row_idx': row_id\n",
        "            })\n",
        "\n",
        "        # ---- Symptom types (regex boundary matches)\n",
        "        for category, terms in symptom_patterns.items():\n",
        "            for term in terms:\n",
        "                pattern = r'\\b' + re.escape(term.lower()) + r'\\b'\n",
        "                for m in re.finditer(pattern, combined):\n",
        "                    custom_entities.append({\n",
        "                        'text': original_text[m.start():m.end()],\n",
        "                        'label': 'SYMPTOM_TYPE',\n",
        "                        'category': category,\n",
        "                        'start': m.start(),\n",
        "                        'end': m.end(),\n",
        "                        'original_text': original_text,\n",
        "                        'source': 'pattern_matching',\n",
        "                        'row_idx': row_id\n",
        "                    })\n",
        "\n",
        "        # ---- Anatomical location from location column\n",
        "        if pd.notna(row.get('location')) and location.strip() != '' and location != 'nan':\n",
        "            start = combined.find(location)\n",
        "            if start >= 0:\n",
        "                end = start + len(location)\n",
        "                custom_entities.append({\n",
        "                    'text': location_orig,\n",
        "                    'label': 'ANATOMY',\n",
        "                    'category': 'symptom_location',\n",
        "                    'start': start,\n",
        "                    'end': end,\n",
        "                    'original_text': original_text,\n",
        "                    'source': 'location_column',\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "\n",
        "        # ---- Additional anatomy from patterns\n",
        "        for category, terms in anatomy_patterns.items():\n",
        "            for term in terms:\n",
        "                # allow simple plural 's' for nouns\n",
        "                plural_opt = 's?' if term.isalpha() else ''\n",
        "                pattern = r'\\b' + re.escape(term.lower()) + plural_opt + r'\\b'\n",
        "                for m in re.finditer(pattern, combined):\n",
        "                    custom_entities.append({\n",
        "                        'text': original_text[m.start():m.end()],\n",
        "                        'label': 'ANATOMY',\n",
        "                        'category': category,\n",
        "                        'start': m.start(),\n",
        "                        'end': m.end(),\n",
        "                        'original_text': original_text,\n",
        "                        'source': 'pattern_matching',\n",
        "                        'row_idx': row_id\n",
        "                    })\n",
        "\n",
        "        # ---- Severity from intensity column (exact value match)\n",
        "        if pd.notna(row.get('intensity of symptom')) and intensity in severity_values:\n",
        "            start = combined.find(intensity)\n",
        "            if start >= 0:\n",
        "                custom_entities.append({\n",
        "                    'text': intensity_orig,\n",
        "                    'label': 'SEVERITY',\n",
        "                    'category': 'intensity',\n",
        "                    'start': start,\n",
        "                    'end': start + len(intensity_orig),\n",
        "                    'original_text': original_text,\n",
        "                    'source': 'intensity_column',\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "\n",
        "        # ---- Temporal patterns (look in temporalisation column and combined text)\n",
        "        for category, terms in temporal_patterns.items():\n",
        "            for term in terms:\n",
        "                found = False\n",
        "                # search in combined first (to get offsets)\n",
        "                m = re.search(r'\\b' + re.escape(term) + r'\\b', combined)\n",
        "                if m:\n",
        "                    custom_entities.append({\n",
        "                        'text': original_text[m.start():m.end()],\n",
        "                        'label': 'TEMPORAL_PATTERN',\n",
        "                        'category': category,\n",
        "                        'start': m.start(),\n",
        "                        'end': m.end(),\n",
        "                        'original_text': original_text,\n",
        "                        'source': 'temporal_extraction',\n",
        "                        'row_idx': row_id\n",
        "                    })\n",
        "                    found = True\n",
        "                # if not found in combined but present in temporalisation text, add without exact offset\n",
        "                if not found and term in temporalisation:\n",
        "                    custom_entities.append({\n",
        "                        'text': term,\n",
        "                        'label': 'TEMPORAL_PATTERN',\n",
        "                        'category': category,\n",
        "                        'start': 0,\n",
        "                        'end': len(term),\n",
        "                        'original_text': original_text,\n",
        "                        'source': 'temporal_extraction',\n",
        "                        'row_idx': row_id\n",
        "                    })\n",
        "\n",
        "        # ---- Laterality (location or combined)\n",
        "        for lat in laterality_terms:\n",
        "            pattern = r'\\b' + re.escape(lat) + r'\\b'\n",
        "            for m in re.finditer(pattern, combined):\n",
        "                custom_entities.append({\n",
        "                    'text': original_text[m.start():m.end()],\n",
        "                    'label': 'LATERALITY',\n",
        "                    'category': 'laterality',\n",
        "                    'start': m.start(),\n",
        "                    'end': m.end(),\n",
        "                    'original_text': original_text,\n",
        "                    'source': 'laterality_extraction',\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "\n",
        "    return pd.DataFrame(custom_entities)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Apply temporal standardization\n",
        "    temporal_standardizer = TemporalStandardizer()\n",
        "    df_symptoms_processed, temporal_report = temporal_standardizer.standardize_temporal_column(\n",
        "        df_symptoms, \n",
        "        'time'\n",
        "    )\n",
        "   \n",
        "    print(f\"\\nTemporal extraction results:\")\n",
        "    print(f\"Successfully extracted duration: {temporal_report['extracted_durations']}\")\n",
        "    print(f\"Temporal types: {temporal_report['temporal_types']}\")\n",
        "\n",
        "    # Combine symptom information into comprehensive text (robust to NaNs)\n",
        "    df_symptoms['combined_text'] = df_symptoms.apply(\n",
        "        lambda row: f\"{str(row.get('name of symptom',''))} with {str(row.get('intensity of symptom',''))} \"\n",
        "                    f\"intensity located in {str(row.get('location',''))} lasting {str(row.get('time',''))} \"\n",
        "                    f\"{str(row.get('temporalisation',''))} {str(row.get('details',''))}\",\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Copy combined_text to processed dataframe (corrected to use df_symptoms)\n",
        "    df_symptoms_processed['combined_text'] = df_symptoms['combined_text']\n",
        "\n",
        "    # Add temporal features to combined text (uses time_duration_days if present)\n",
        "    df_symptoms_processed['combined_text_enriched'] = df_symptoms_processed.apply(\n",
        "        lambda row: f\"{row['combined_text']} \"\n",
        "                    f\"{'lasting ' + str(row.get('time_duration_days', '')) + ' days' if pd.notna(row.get('time_duration_days')) else ''}\",\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Run NER extraction with BC5CDR over combined_text\n",
        "    df_symptoms_entities, symptoms_summary, symptoms_rules = run_medical_ner_extraction(\n",
        "        df_symptoms,\n",
        "        text_column='combined_text',\n",
        "        model_name=\"en_ner_bc5cdr_md\",\n",
        "        batch_size=300,\n",
        "        id_column='idx'\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== BC5CDR Entity Types Found ===\")\n",
        "    print(symptoms_summary['entity_types'])\n",
        "\n",
        "\n",
        "    # Extract custom entities\n",
        "    df_custom_symptom_entities = extract_symptom_entities_custom(df_symptoms)\n",
        "\n",
        "    print(f\"\\nCustom extraction found:\")\n",
        "    if not df_custom_symptom_entities.empty and 'label' in df_custom_symptom_entities.columns:\n",
        "        print(df_custom_symptom_entities['label'].value_counts())\n",
        "    else:\n",
        "        print(\"No custom symptom entities found.\")\n",
        "\n",
        "    # Combine all entities (preserve row_idx/category when present)\n",
        "    df_all_symptom_entities = pd.concat(\n",
        "        [df_symptoms_entities, df_custom_symptom_entities],\n",
        "        ignore_index=True,\n",
        "        sort=False\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== COMBINED Entity Distribution ===\")\n",
        "    if not df_all_symptom_entities.empty and 'label' in df_all_symptom_entities.columns:\n",
        "        print(df_all_symptom_entities['label'].value_counts())\n",
        "    else:\n",
        "        print(\"No combined entities to show.\")\n",
        "\n",
        "    # Analyze symptom entities\n",
        "    symptom_entities = df_all_symptom_entities[df_all_symptom_entities['label'] == 'SYMPTOM'] if not df_all_symptom_entities.empty else pd.DataFrame()\n",
        "    if not symptom_entities.empty:\n",
        "        print(f\"\\n=== Top Symptoms ===\")\n",
        "        print(symptom_entities['text'].str.lower().value_counts().head(20))\n",
        "\n",
        "    # Analyze anatomical locations\n",
        "    anatomy_entities = df_all_symptom_entities[df_all_symptom_entities['label'] == 'ANATOMY'] if not df_all_symptom_entities.empty else pd.DataFrame()\n",
        "    if not anatomy_entities.empty:\n",
        "        print(f\"\\n=== Top Symptom Locations ===\")\n",
        "        print(anatomy_entities['text'].str.lower().value_counts().head(20))\n",
        "\n",
        "    # Analyze severity\n",
        "    severity_entities = df_all_symptom_entities[df_all_symptom_entities['label'] == 'SEVERITY'] if not df_all_symptom_entities.empty else pd.DataFrame()\n",
        "    if not severity_entities.empty:\n",
        "        print(f\"\\n=== Severity Distribution ===\")\n",
        "        print(severity_entities['text'].str.lower().value_counts())\n",
        "\n",
        "    # ================= Symptom-specific labeling functions =================\n",
        "    print(\"\\n=== Creating Symptom-Specific Labeling Functions ===\")\n",
        "\n",
        "    def create_symptom_labeling_functions():\n",
        "        COL = 'combined_text'\n",
        "        LOC = 'location'\n",
        "        TEMP = 'temporalisation'\n",
        "\n",
        "        def lf_severe_pain(row):\n",
        "            text = str(row.get(COL,''))\n",
        "            if 'pain' in text.lower() and _first_hit(text, ['severe']):\n",
        "                return {'label':'SEVERE_PAIN','column':COL,'match':'severe','category':'severity'}\n",
        "            return {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_chronic_symptom(row):\n",
        "            t = ' '.join([str(row.get(TEMP,'')), str(row.get('time',''))])\n",
        "            hit = _first_hit(t, ['chronic','persistent','ongoing','months','years'])\n",
        "            return {'label':'CHRONIC_SYMPTOM','column':TEMP if hit and hit in str(row.get(TEMP,'')).lower() else 'time','match':hit,'category':'temporal'} if hit else {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_neurological_symptom(row):\n",
        "            text = str(row.get(COL,''))\n",
        "            hit = _first_hit(text, ['numbness','tingling','weakness','paralysis','sensation','tremor'])\n",
        "            return {'label':'NEUROLOGICAL','column':COL,'match':hit,'category':'neuro'} if hit else {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_bilateral_symptom(row):\n",
        "            loc = str(row.get(LOC,''))\n",
        "            hit = _first_hit(loc, ['bilateral','both','left and right'])\n",
        "            return {'label':'BILATERAL_SYMPTOM','column':LOC,'match':hit,'category':'laterality'} if hit else {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_acute_onset(row):\n",
        "            text = str(row.get(COL,''))\n",
        "            hit = _first_hit(text, ['sudden','acute','abrupt','rapid onset'])\n",
        "            return {'label':'ACUTE_ONSET','column':COL,'match':hit,'category':'temporal'} if hit else {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_progressive_symptom(row):\n",
        "            text = str(row.get(COL,''))\n",
        "            hit = _first_hit(text, ['worsening','progressive','increasing'])\n",
        "            return {'label':'PROGRESSIVE_SYMPTOM','column':COL,'match':hit,'category':'temporal'} if hit else {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_mobility_issue(row):\n",
        "            text = str(row.get(COL,''))\n",
        "            hit = _first_hit(text, ['walk','gait','mobility','movement'])\n",
        "            return {'label':'MOBILITY_ISSUE','column':COL,'match':hit,'category':'function'} if hit else {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_pain_with_location(row):\n",
        "            loc = str(row.get(LOC,''))\n",
        "            if not loc: return {'label':'ABSTAIN'}\n",
        "            for area, lab in [('hip','HIP_PAIN'), ('knee','KNEE_PAIN'), ('back','BACK_PAIN')]:\n",
        "                if area in loc.lower():\n",
        "                    return {'label':lab,'column':LOC,'match':area,'category':'localized'}\n",
        "            if loc.strip().lower() not in ('', 'nan'):\n",
        "                return {'label':'LOCALIZED_PAIN','column':LOC,'match':loc.split()[0].lower(),'category':'localized'}\n",
        "            return {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_systemic_symptom(row):\n",
        "            text = str(row.get(COL,''))\n",
        "            hit = _first_hit(text, ['fever','fatigue','weight loss','malaise'])\n",
        "            return {'label':'SYSTEMIC_SYMPTOM','column':COL,'match':hit,'category':'systemic'} if hit else {'label':'ABSTAIN'}\n",
        "\n",
        "        return [lf_severe_pain, lf_chronic_symptom, lf_neurological_symptom, lf_bilateral_symptom,\n",
        "                lf_acute_onset, lf_progressive_symptom, lf_mobility_issue, lf_pain_with_location,\n",
        "                lf_systemic_symptom]\n",
        "\n",
        "    # --- materialize spans ---\n",
        "    symptom_lfs_span = create_symptom_labeling_functions()\n",
        "    df_symptom_lf_spans = materialize_lf_spans(df_symptoms, symptom_lfs_span, id_column='idx')\n",
        "    print(f\"\\nLF-generated symptom spans: {len(df_symptom_lf_spans)}\")\n",
        "    if not df_symptom_lf_spans.empty:\n",
        "        print(df_symptom_lf_spans['label'].value_counts())\n",
        "\n",
        "    # --- combine model + custom + LF spans ---\n",
        "    _cols = ['text','label','start','end','original_text','source','row_idx','category']\n",
        "    for col in _cols:\n",
        "        if col not in df_symptoms_entities.columns: df_symptoms_entities[col] = 'bc5cdr' if col=='source' else None\n",
        "        if col not in df_custom_symptom_entities.columns: df_custom_symptom_entities[col] = 'custom_extraction' if col=='source' else None\n",
        "        if col not in df_symptom_lf_spans.columns: df_symptom_lf_spans[col] = None\n",
        "\n",
        "    df_all_symptom_entities = pd.concat(\n",
        "        [df_symptoms_entities[_cols], df_custom_symptom_entities[_cols], df_symptom_lf_spans[_cols]],\n",
        "        ignore_index=True\n",
        "    )\n",
        "    print(f\"Total symptom entities (model+custom+LF): {len(df_all_symptom_entities)}\")\n",
        "    df_symptom_lf_spans.to_csv('symptom_lf_generated_spans.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>source</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pain</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Pain with Severe intensity located in Left hip...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>133948</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pain</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>147</td>\n",
              "      <td>151</td>\n",
              "      <td>Pain with Severe intensity located in Left hip...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>133948</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>weight gain</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>129</td>\n",
              "      <td>140</td>\n",
              "      <td>Moderate moon face with Moderate intensity loc...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>133948</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Central obesity</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>Central obesity with nan intensity located in ...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>133948</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Muscle mass reduction</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>Muscle mass reduction with nan intensity locat...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>133948</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383858</th>\n",
              "      <td>Chest</td>\n",
              "      <td>LOCALIZED_PAIN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>Chest</td>\n",
              "      <td>lf:lf_pain_with_location</td>\n",
              "      <td>98004</td>\n",
              "      <td>localized</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383859</th>\n",
              "      <td>years</td>\n",
              "      <td>CHRONIC_SYMPTOM</td>\n",
              "      <td>13</td>\n",
              "      <td>18</td>\n",
              "      <td>Noticed four years prior to presentation</td>\n",
              "      <td>lf:lf_chronic_symptom</td>\n",
              "      <td>133320</td>\n",
              "      <td>temporal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383860</th>\n",
              "      <td>Lateral</td>\n",
              "      <td>LOCALIZED_PAIN</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>Lateral side of the right thigh</td>\n",
              "      <td>lf:lf_pain_with_location</td>\n",
              "      <td>133320</td>\n",
              "      <td>localized</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383861</th>\n",
              "      <td>Acute</td>\n",
              "      <td>ACUTE_ONSET</td>\n",
              "      <td>40</td>\n",
              "      <td>45</td>\n",
              "      <td>Crushing substernal chest pressure with Acute ...</td>\n",
              "      <td>lf:lf_acute_onset</td>\n",
              "      <td>97973</td>\n",
              "      <td>temporal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383862</th>\n",
              "      <td>Substernal</td>\n",
              "      <td>LOCALIZED_PAIN</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>Substernal</td>\n",
              "      <td>lf:lf_pain_with_location</td>\n",
              "      <td>97973</td>\n",
              "      <td>localized</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>383863 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         text            label  start  end  \\\n",
              "0                        Pain          DISEASE      0    4   \n",
              "1                        pain          DISEASE    147  151   \n",
              "2                 weight gain          DISEASE    129  140   \n",
              "3             Central obesity          DISEASE      0   15   \n",
              "4       Muscle mass reduction          DISEASE      0   21   \n",
              "...                       ...              ...    ...  ...   \n",
              "383858                  Chest   LOCALIZED_PAIN      0    5   \n",
              "383859                  years  CHRONIC_SYMPTOM     13   18   \n",
              "383860                Lateral   LOCALIZED_PAIN      0    7   \n",
              "383861                  Acute      ACUTE_ONSET     40   45   \n",
              "383862             Substernal   LOCALIZED_PAIN      0   10   \n",
              "\n",
              "                                            original_text  \\\n",
              "0       Pain with Severe intensity located in Left hip...   \n",
              "1       Pain with Severe intensity located in Left hip...   \n",
              "2       Moderate moon face with Moderate intensity loc...   \n",
              "3       Central obesity with nan intensity located in ...   \n",
              "4       Muscle mass reduction with nan intensity locat...   \n",
              "...                                                   ...   \n",
              "383858                                              Chest   \n",
              "383859           Noticed four years prior to presentation   \n",
              "383860                    Lateral side of the right thigh   \n",
              "383861  Crushing substernal chest pressure with Acute ...   \n",
              "383862                                         Substernal   \n",
              "\n",
              "                          source  row_idx   category  \n",
              "0                         bc5cdr   133948       None  \n",
              "1                         bc5cdr   133948       None  \n",
              "2                         bc5cdr   133948       None  \n",
              "3                         bc5cdr   133948       None  \n",
              "4                         bc5cdr   133948       None  \n",
              "...                          ...      ...        ...  \n",
              "383858  lf:lf_pain_with_location    98004  localized  \n",
              "383859     lf:lf_chronic_symptom   133320   temporal  \n",
              "383860  lf:lf_pain_with_location   133320  localized  \n",
              "383861         lf:lf_acute_onset    97973   temporal  \n",
              "383862  lf:lf_pain_with_location    97973  localized  \n",
              "\n",
              "[383863 rows x 8 columns]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_all_symptom_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting Diagnosis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "id": "xK0iHDeMoHg6",
        "outputId": "0d334c5a-89db-43b8-be57-92d556df35e6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>has_diagnosis</th>\n",
              "      <th>test</th>\n",
              "      <th>severity</th>\n",
              "      <th>result</th>\n",
              "      <th>condition</th>\n",
              "      <th>time</th>\n",
              "      <th>details</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155216</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>133948</td>\n",
              "      <td>True</td>\n",
              "      <td>Magnetic resonance imaging (MRI) scan</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Increased amount of joint fluid and bone marro...</td>\n",
              "      <td>Idiopathic osteonecrosis of the femoral head</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Patient did not complain of any pain on the co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133948</td>\n",
              "      <td>True</td>\n",
              "      <td>Repeat MRI</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Similar findings to those noted previously in ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>One year after the initial surgery and symptom...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80176</td>\n",
              "      <td>True</td>\n",
              "      <td>Radiographs</td>\n",
              "      <td>Minimally displaced</td>\n",
              "      <td>Proximal ulnar shaft fracture</td>\n",
              "      <td>Proximal ulnar shaft fracture, hypertrophic no...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Elbow arthrodesis at 90 degrees with retained ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72232</td>\n",
              "      <td>True</td>\n",
              "      <td>MRI</td>\n",
              "      <td>Moderate-sized</td>\n",
              "      <td>Focal area of marrow edema/contusion involving...</td>\n",
              "      <td>Bone marrow edema</td>\n",
              "      <td>September 2016, three months later, April 2017...</td>\n",
              "      <td>Involvement of medial femoral condyle in mid a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61350</th>\n",
              "      <td>133320</td>\n",
              "      <td>True</td>\n",
              "      <td>Histopathological examination</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Consistent with lung metastasis of leiomyosarcoma</td>\n",
              "      <td>Lung metastasis of leiomyosarcoma</td>\n",
              "      <td>One year and 3 months postoperatively</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61351</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Electrocardiogram (ECG)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Diffuse ST depressions in all precordial leads</td>\n",
              "      <td>Consistent with an acute coronary syndrome</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61352</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Transthoracic echocardiogram</td>\n",
              "      <td>Ejection fraction (EF) of 45% with severe aort...</td>\n",
              "      <td>Torn right coronary cusp</td>\n",
              "      <td>Severe aortic insufficiency</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Emergent transthoracic echocardiogram performed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61353</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Blood cultures</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Positive for S.\\nlugdunensis in both bottles</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61354</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Transesophageal echocardiogram</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Large vegetation prolapsing into the left vent...</td>\n",
              "      <td>Acute severe aortic insufficiency from endocar...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Performed while patient was intubated</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>61355 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          idx  has_diagnosis                                   test  \\\n",
              "0      155216          False                                    NaN   \n",
              "1      133948           True  Magnetic resonance imaging (MRI) scan   \n",
              "2      133948           True                             Repeat MRI   \n",
              "3       80176           True                            Radiographs   \n",
              "4       72232           True                                    MRI   \n",
              "...       ...            ...                                    ...   \n",
              "61350  133320           True          Histopathological examination   \n",
              "61351   97973           True                Electrocardiogram (ECG)   \n",
              "61352   97973           True           Transthoracic echocardiogram   \n",
              "61353   97973           True                         Blood cultures   \n",
              "61354   97973           True         Transesophageal echocardiogram   \n",
              "\n",
              "                                                severity  \\\n",
              "0                                                    NaN   \n",
              "1                                                    NaN   \n",
              "2                                                    NaN   \n",
              "3                                    Minimally displaced   \n",
              "4                                         Moderate-sized   \n",
              "...                                                  ...   \n",
              "61350                                                NaN   \n",
              "61351                                                NaN   \n",
              "61352  Ejection fraction (EF) of 45% with severe aort...   \n",
              "61353                                                NaN   \n",
              "61354                                                NaN   \n",
              "\n",
              "                                                  result  \\\n",
              "0                                                    NaN   \n",
              "1      Increased amount of joint fluid and bone marro...   \n",
              "2      Similar findings to those noted previously in ...   \n",
              "3                          Proximal ulnar shaft fracture   \n",
              "4      Focal area of marrow edema/contusion involving...   \n",
              "...                                                  ...   \n",
              "61350  Consistent with lung metastasis of leiomyosarcoma   \n",
              "61351     Diffuse ST depressions in all precordial leads   \n",
              "61352                           Torn right coronary cusp   \n",
              "61353       Positive for S.\\nlugdunensis in both bottles   \n",
              "61354  Large vegetation prolapsing into the left vent...   \n",
              "\n",
              "                                               condition  \\\n",
              "0                                                    NaN   \n",
              "1           Idiopathic osteonecrosis of the femoral head   \n",
              "2                                                    NaN   \n",
              "3      Proximal ulnar shaft fracture, hypertrophic no...   \n",
              "4                                      Bone marrow edema   \n",
              "...                                                  ...   \n",
              "61350                  Lung metastasis of leiomyosarcoma   \n",
              "61351         Consistent with an acute coronary syndrome   \n",
              "61352                        Severe aortic insufficiency   \n",
              "61353                                                NaN   \n",
              "61354  Acute severe aortic insufficiency from endocar...   \n",
              "\n",
              "                                                    time  \\\n",
              "0                                                    NaN   \n",
              "1                                                    NaN   \n",
              "2      One year after the initial surgery and symptom...   \n",
              "3                                                    NaN   \n",
              "4      September 2016, three months later, April 2017...   \n",
              "...                                                  ...   \n",
              "61350              One year and 3 months postoperatively   \n",
              "61351                                                NaN   \n",
              "61352                                                NaN   \n",
              "61353                                                NaN   \n",
              "61354                                                NaN   \n",
              "\n",
              "                                                 details  \n",
              "0                                                    NaN  \n",
              "1      Patient did not complain of any pain on the co...  \n",
              "2                                                    NaN  \n",
              "3      Elbow arthrodesis at 90 degrees with retained ...  \n",
              "4      Involvement of medial femoral condyle in mid a...  \n",
              "...                                                  ...  \n",
              "61350                                                NaN  \n",
              "61351                                                NaN  \n",
              "61352    Emergent transthoracic echocardiogram performed  \n",
              "61353                                                NaN  \n",
              "61354              Performed while patient was intubated  \n",
              "\n",
              "[61355 rows x 8 columns]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_diagnosis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing temporal column: time\n",
            "\n",
            "Temporal extraction results:\n",
            "Successfully extracted duration: 3879\n",
            "Temporal types: {'unspecified': 4734, 'post_event': 3354, 'absolute_date': 1766, 'past_reference': 1280, 'range_reference': 1258, 'duration_reference': 299, 'onset_reference': 155}\n",
            "Loading en_ner_bc5cdr_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 61355 texts in 205 batches...\n",
            "Using model: en_ner_bc5cdr_md for column: combined_text\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   0%|          | 1/205 [00:02<06:59,  2.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   5%|▌         | 11/205 [00:16<04:39,  1.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 3000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  10%|█         | 21/205 [00:30<04:37,  1.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 6000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  15%|█▌        | 31/205 [00:44<04:16,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 9000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  20%|██        | 41/205 [00:58<03:54,  1.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 12000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  25%|██▍       | 51/205 [01:12<03:37,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  30%|██▉       | 61/205 [01:26<03:27,  1.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 18000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  35%|███▍      | 71/205 [01:40<03:16,  1.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 21000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  40%|███▉      | 81/205 [01:54<02:58,  1.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 24000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  44%|████▍     | 91/205 [02:08<02:48,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 27000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  49%|████▉     | 101/205 [02:22<02:34,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 30000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  54%|█████▍    | 111/205 [02:36<02:18,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 33000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  59%|█████▉    | 121/205 [02:50<02:04,  1.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 36000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  64%|██████▍   | 131/205 [03:05<01:52,  1.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 39000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  69%|██████▉   | 141/205 [03:19<01:37,  1.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 42000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  74%|███████▎  | 151/205 [03:33<01:22,  1.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 45000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  79%|███████▊  | 161/205 [03:47<01:06,  1.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 48000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  83%|████████▎ | 171/205 [04:01<00:52,  1.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 51000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  88%|████████▊ | 181/205 [04:15<00:36,  1.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 54000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  93%|█████████▎| 191/205 [04:29<00:21,  1.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 57000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  98%|█████████▊| 201/205 [04:44<00:06,  1.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 60000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 205/205 [04:48<00:00,  1.41s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2745 entities appearing >= 5 times\n",
            "\n",
            "=== BC5CDR Entity Types Found ===\n",
            "{'DISEASE': 77150, 'CHEMICAL': 8577}\n",
            "\n",
            "Custom extraction found:\n",
            "label\n",
            "TEST           56150\n",
            "TEST_TYPE      51197\n",
            "FINDING        40916\n",
            "CONDITION      36529\n",
            "ANATOMY        27435\n",
            "LATERALITY     25373\n",
            "MEASUREMENT    10044\n",
            "SEVERITY        1054\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== COMBINED Entity Distribution ===\n",
            "label\n",
            "DISEASE        77150\n",
            "TEST           56150\n",
            "TEST_TYPE      51197\n",
            "FINDING        40916\n",
            "CONDITION      36529\n",
            "ANATOMY        27435\n",
            "LATERALITY     25373\n",
            "MEASUREMENT    10044\n",
            "CHEMICAL        8577\n",
            "SEVERITY        1054\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Diagnostic Tests ===\n",
            "text\n",
            "mri                                 1005\n",
            "ct scan                              786\n",
            "biopsy                               663\n",
            "magnetic resonance imaging (mri)     655\n",
            "histopathological examination        577\n",
            "chest x-ray                          537\n",
            "computed tomography (ct) scan        402\n",
            "laboratory tests                     397\n",
            "computed tomography (ct)             394\n",
            "radiographs                          318\n",
            "blood tests                          315\n",
            "histological examination             304\n",
            "ultrasound                           249\n",
            "colonoscopy                          239\n",
            "histopathology                       234\n",
            "brain mri                            233\n",
            "blood cultures                       232\n",
            "electrocardiogram                    224\n",
            "echocardiography                     218\n",
            "incisional biopsy                    217\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Diagnostic Findings ===\n",
            "text\n",
            "mass            7083\n",
            "lesion          5276\n",
            "tumor           4980\n",
            "carcinoma       2818\n",
            "fracture        2737\n",
            "cyst            1519\n",
            "aneurysm        1444\n",
            "stenosis        1440\n",
            "metastasis      1155\n",
            "malignant       1139\n",
            "hemorrhage       934\n",
            "occlusion        807\n",
            "effusion         752\n",
            "edema            702\n",
            "necrosis         701\n",
            "benign           642\n",
            "inflammation     611\n",
            "thrombosis       610\n",
            "infarction       560\n",
            "nodule           560\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Diagnosed Conditions ===\n",
            "text\n",
            "infection                  179\n",
            "squamous cell carcinoma    124\n",
            "anemia                     112\n",
            "coronary artery disease    110\n",
            "adenocarcinoma              86\n",
            "tuberculosis                74\n",
            "metastatic disease          73\n",
            "stroke                      71\n",
            "malignant melanoma          67\n",
            "pseudoaneurysm              63\n",
            "metastatic melanoma         57\n",
            "osteosarcoma                57\n",
            "covid-19                    55\n",
            "pregnancy                   52\n",
            "tumor                       50\n",
            "pulmonary embolism          50\n",
            "hiv                         48\n",
            "breast cancer               45\n",
            "fracture                    44\n",
            "prostate cancer             42\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Creating Diagnosis-Specific Labeling Functions ===\n",
            "\n",
            "LF-generated diagnosis spans: 66386\n",
            "label\n",
            "IMAGING_TEST            19906\n",
            "NEOPLASTIC_FINDING      16827\n",
            "NORMAL_FINDING           9866\n",
            "VASCULAR_FINDING         7941\n",
            "BONE_PATHOLOGY           3857\n",
            "INFLAMMATORY_FINDING     3288\n",
            "BILATERAL_FINDING        1977\n",
            "FRACTURE_PRESENT         1748\n",
            "CRITICAL_FINDING          670\n",
            "FOLLOWUP_NEEDED           287\n",
            "NO_FRACTURE                19\n",
            "Name: count, dtype: int64\n",
            "Total diagnosis entities (model+custom+LF): 400811\n"
          ]
        }
      ],
      "source": [
        "def extract_diagnosis_entities_custom(df_diagnosis):\n",
        "        \"\"\"\n",
        "        Extract diagnosis-specific entities not (fully) caught by BC5CDR.\n",
        "        Uses 'idx' for row identity when available; falls back to df.index otherwise.\n",
        "        Adds 'row_idx' and character offsets for all extracted entities.\n",
        "        Regex with word boundaries is used to avoid substring false positives.\n",
        "        \"\"\"\n",
        "        custom_entities = []\n",
        "\n",
        "        # Test/Procedure patterns\n",
        "        test_patterns = {\n",
        "            'imaging': [\n",
        "                'mri', 'magnetic resonance', 'ct', 'computed tomography',\n",
        "                'x-ray', 'radiograph', 'ultrasound', 'sonography', 'scan',\n",
        "                'pet', 'spect', 'angiography', 'mammography'\n",
        "            ],\n",
        "            'laboratory': [\n",
        "                'blood test', 'serum', 'plasma', 'biochemical', 'hematology',\n",
        "                'urinalysis', 'culture', 'biopsy', 'cytology', 'pathology'\n",
        "            ],\n",
        "            'functional': [\n",
        "                'ecg', 'ekg', 'electrocardiogram', 'eeg', 'electroencephalogram',\n",
        "                'emg', 'electromyography', 'spirometry', 'pulmonary function'\n",
        "            ],\n",
        "            'endoscopy': [\n",
        "                'endoscopy', 'colonoscopy', 'gastroscopy', 'bronchoscopy',\n",
        "                'cystoscopy', 'arthroscopy', 'laparoscopy'\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        # Finding/Result patterns\n",
        "        finding_patterns = {\n",
        "            'structural': [\n",
        "                'fracture', 'lesion', 'mass', 'tumor', 'cyst', 'nodule',\n",
        "                'stenosis', 'occlusion', 'herniation', 'displacement'\n",
        "            ],\n",
        "            'inflammatory': [\n",
        "                'inflammation', 'edema', 'swelling', 'effusion', 'congestion',\n",
        "                'infiltration', 'consolidation'\n",
        "            ],\n",
        "            'degenerative': [\n",
        "                'degeneration', 'atrophy', 'necrosis', 'fibrosis', 'sclerosis',\n",
        "                'osteoarthritis', 'spondylosis'\n",
        "            ],\n",
        "            'vascular': [\n",
        "                'ischemia', 'infarction', 'hemorrhage', 'aneurysm', 'thrombosis',\n",
        "                'embolism', 'vasculitis'\n",
        "            ],\n",
        "            'neoplastic': [\n",
        "                'malignant', 'benign', 'metastasis', 'carcinoma', 'sarcoma',\n",
        "                'lymphoma', 'adenoma'\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        # Anatomical patterns specific to diagnosis\n",
        "        anatomy_patterns = {\n",
        "            'bone':   ['femur', 'tibia', 'fibula', 'humerus', 'radius', 'ulna', 'vertebra'],\n",
        "            'joint':  ['hip', 'knee', 'shoulder', 'elbow', 'ankle', 'wrist'],\n",
        "            'organ':  ['liver', 'kidney', 'heart', 'lung', 'brain', 'pancreas', 'spleen'],\n",
        "            'vessel': ['artery', 'vein', 'aorta', 'carotid', 'coronary'],\n",
        "            'region': ['parietal', 'temporal', 'frontal', 'occipital', 'cervical', 'lumbar']\n",
        "        }\n",
        "\n",
        "        # Severity/Grade patterns (from column)\n",
        "        severity_patterns = {\n",
        "            'mild':     ['mild', 'minimal', 'slight', 'minor'],\n",
        "            'moderate': ['moderate', 'medium', 'intermediate'],\n",
        "            'severe':   ['severe', 'significant', 'marked', 'extensive'],\n",
        "            'critical': ['critical', 'life-threatening', 'emergency']\n",
        "        }\n",
        "\n",
        "        # Laterality\n",
        "        laterality_terms = ['left', 'right', 'bilateral']\n",
        "\n",
        "        for df_index, row in df_diagnosis.iterrows():\n",
        "            # ---- choose the correct row id from 'idx' with fallback to the DataFrame index\n",
        "            row_id = row['idx'] if ('idx' in row and pd.notna(row['idx'])) else df_index\n",
        "\n",
        "            original_text = str(row.get('combined_text', ''))\n",
        "            combined = original_text.lower()\n",
        "\n",
        "            test_text_orig = str(row.get('test', ''))\n",
        "            test_text = test_text_orig.lower()\n",
        "            result_text = str(row.get('result', '')).lower()\n",
        "            condition_text_orig = str(row.get('condition', ''))\n",
        "            condition_text = condition_text_orig.lower()\n",
        "            severity_text_orig = str(row.get('severity', ''))\n",
        "            severity_text = severity_text_orig.lower()\n",
        "\n",
        "            # ---- TEST from test column (place in the combined text if possible)\n",
        "            if test_text and test_text != 'nan':\n",
        "                start = combined.find(test_text)\n",
        "                if start < 0:\n",
        "                    start = 0\n",
        "                end = min(start + len(test_text_orig), len(original_text))\n",
        "                custom_entities.append({\n",
        "                    'text': test_text_orig,\n",
        "                    'label': 'TEST',\n",
        "                    'category': 'diagnostic_test',\n",
        "                    'start': start,\n",
        "                    'end': end,\n",
        "                    'original_text': original_text,\n",
        "                    'source': 'test_column',\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "                # TEST_TYPE via patterns (regex boundaries)\n",
        "                for category, terms in test_patterns.items():\n",
        "                    for term in terms:\n",
        "                        pattern = r'\\b' + re.escape(term.lower()) + r'\\b'\n",
        "                        for m in re.finditer(pattern, combined):\n",
        "                            custom_entities.append({\n",
        "                                'text': original_text[m.start():m.end()],\n",
        "                                'label': 'TEST_TYPE',\n",
        "                                'category': category,\n",
        "                                'start': m.start(),\n",
        "                                'end': m.end(),\n",
        "                                'original_text': original_text,\n",
        "                                'source': 'pattern_matching',\n",
        "                                'row_idx': row_id\n",
        "                            })\n",
        "\n",
        "            # ---- FINDINGS from result (search in combined for offsets)\n",
        "            if result_text and result_text != 'nan':\n",
        "                for category, terms in finding_patterns.items():\n",
        "                    for term in terms:\n",
        "                        pattern = r'\\b' + re.escape(term.lower()) + r'\\b'\n",
        "                        for m in re.finditer(pattern, combined):\n",
        "                            custom_entities.append({\n",
        "                                'text': original_text[m.start():m.end()],\n",
        "                                'label': 'FINDING',\n",
        "                                'category': category,\n",
        "                                'start': m.start(),\n",
        "                                'end': m.end(),\n",
        "                                'original_text': original_text,\n",
        "                                'source': 'result_extraction',\n",
        "                                'row_idx': row_id\n",
        "                            })\n",
        "\n",
        "            # ---- CONDITION from condition column\n",
        "            if condition_text and condition_text != 'nan':\n",
        "                start = combined.find(condition_text)\n",
        "                if start < 0:\n",
        "                    start = 0\n",
        "                end = min(start + len(condition_text_orig), len(original_text))\n",
        "                custom_entities.append({\n",
        "                    'text': condition_text_orig,\n",
        "                    'label': 'CONDITION',\n",
        "                    'category': 'diagnosis',\n",
        "                    'start': start,\n",
        "                    'end': end,\n",
        "                    'original_text': original_text,\n",
        "                    'source': 'condition_column',\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "\n",
        "            # ---- ANATOMY patterns (allow simple plural 's')\n",
        "            for category, terms in anatomy_patterns.items():\n",
        "                for term in terms:\n",
        "                    plural_opt = 's?' if term.isalpha() else ''\n",
        "                    pattern = r'\\b' + re.escape(term.lower()) + plural_opt + r'\\b'\n",
        "                    for m in re.finditer(pattern, combined):\n",
        "                        custom_entities.append({\n",
        "                            'text': original_text[m.start():m.end()],\n",
        "                            'label': 'ANATOMY',\n",
        "                            'category': category,\n",
        "                            'start': m.start(),\n",
        "                            'end': m.end(),\n",
        "                            'original_text': original_text,\n",
        "                            'source': 'anatomy_extraction',\n",
        "                            'row_idx': row_id\n",
        "                        })\n",
        "\n",
        "            # ---- SEVERITY from severity column\n",
        "            if severity_text and severity_text != 'nan':\n",
        "                for category, terms in severity_patterns.items():\n",
        "                    if severity_text in terms:\n",
        "                        start = combined.find(severity_text)\n",
        "                        if start < 0:\n",
        "                            start = 0\n",
        "                        end = min(start + len(severity_text_orig), len(original_text))\n",
        "                        custom_entities.append({\n",
        "                            'text': severity_text_orig,\n",
        "                            'label': 'SEVERITY',\n",
        "                            'category': category,\n",
        "                            'start': start,\n",
        "                            'end': end,\n",
        "                            'original_text': original_text,\n",
        "                            'source': 'severity_column',\n",
        "                            'row_idx': row_id\n",
        "                        })\n",
        "                        break\n",
        "\n",
        "            # ---- LATERALITY\n",
        "            for lat in laterality_terms:\n",
        "                pattern = r'\\b' + re.escape(lat) + r'\\b'\n",
        "                for m in re.finditer(pattern, combined):\n",
        "                    custom_entities.append({\n",
        "                        'text': original_text[m.start():m.end()],\n",
        "                        'label': 'LATERALITY',\n",
        "                        'category': 'laterality',\n",
        "                        'start': m.start(),\n",
        "                        'end': m.end(),\n",
        "                        'original_text': original_text,\n",
        "                        'source': 'laterality_extraction',\n",
        "                        'row_idx': row_id\n",
        "                    })\n",
        "\n",
        "            # ---- MEASUREMENTS (capture full token with units)\n",
        "            # e.g., \"12 mm\", \"3.5 cm\", \"45%\", \"10 mg\", \"30 ml\"\n",
        "            measurement_pattern = r'\\b\\d+(?:\\.\\d+)?\\s*(?:mm|cm|ml|mg|%)\\b'\n",
        "            for m in re.finditer(measurement_pattern, combined):\n",
        "                custom_entities.append({\n",
        "                    'text': original_text[m.start():m.end()],\n",
        "                    'label': 'MEASUREMENT',\n",
        "                    'category': 'quantitative',\n",
        "                    'start': m.start(),\n",
        "                    'end': m.end(),\n",
        "                    'original_text': original_text,\n",
        "                    'source': 'measurement_extraction',\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "\n",
        "        return pd.DataFrame(custom_entities)\n",
        "if __name__ == \"__main__\":\n",
        "    # Apply temporal standardization\n",
        "    temporal_standardizer = TemporalStandardizer()\n",
        "    df_diagnosis_processed, temporal_report = temporal_standardizer.standardize_temporal_column(\n",
        "        df_diagnosis, \n",
        "        'time'\n",
        "    )\n",
        "   \n",
        "    print(f\"\\nTemporal extraction results:\")\n",
        "    print(f\"Successfully extracted duration: {temporal_report['extracted_durations']}\")\n",
        "    print(f\"Temporal types: {temporal_report['temporal_types']}\")\n",
        "\n",
        "    # Combine diagnosis text columns (robust to NaNs)\n",
        "    df_diagnosis['combined_text'] = df_diagnosis.apply(\n",
        "        lambda row: f\"{str(row.get('test',''))} performed with {str(row.get('severity',''))} severity \"\n",
        "                    f\"showed {str(row.get('result',''))} indicating {str(row.get('condition',''))} \"\n",
        "                    f\"{str(row.get('details',''))} at {str(row.get('time',''))}\",\n",
        "        axis=1        \n",
        "    )\n",
        "\n",
        "    # Copy combined_text to processed dataframe\n",
        "    df_diagnosis_processed['combined_text'] = df_diagnosis['combined_text']\n",
        "\n",
        "    # Add temporal features to combined text\n",
        "    df_diagnosis_processed['combined_text_enriched'] = df_diagnosis_processed.apply(\n",
        "        lambda row: f\"{row['combined_text']} \"\n",
        "                    f\"{'lasting ' + str(row.get('time_duration_days', '')) + ' days' if pd.notna(row.get('time_duration_days')) else ''}\",\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Run NER extraction with BC5CDR\n",
        "    df_diagnosis_entities, diagnosis_summary, diagnosis_rules = run_medical_ner_extraction(\n",
        "        df_diagnosis,\n",
        "        text_column='combined_text',\n",
        "        model_name=\"en_ner_bc5cdr_md\",\n",
        "        batch_size=300, \n",
        "        id_column='idx'\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== BC5CDR Entity Types Found ===\")\n",
        "    print(diagnosis_summary['entity_types'])\n",
        "    \n",
        "\n",
        "    # Extract custom entities\n",
        "    df_custom_diagnosis_entities = extract_diagnosis_entities_custom(df_diagnosis)\n",
        "\n",
        "    print(f\"\\nCustom extraction found:\")\n",
        "    if not df_custom_diagnosis_entities.empty and 'label' in df_custom_diagnosis_entities.columns:\n",
        "        print(df_custom_diagnosis_entities['label'].value_counts())\n",
        "    else:\n",
        "        print(\"No custom diagnosis entities found.\")\n",
        "\n",
        "    # Combine all entities (preserve row_idx/category when present)\n",
        "    df_all_diagnosis_entities = pd.concat(\n",
        "        [df_diagnosis_entities, df_custom_diagnosis_entities],\n",
        "        ignore_index=True,\n",
        "        sort=False\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== COMBINED Entity Distribution ===\")\n",
        "    if not df_all_diagnosis_entities.empty and 'label' in df_all_diagnosis_entities.columns:\n",
        "        print(df_all_diagnosis_entities['label'].value_counts())\n",
        "    else:\n",
        "        print(\"No combined entities to show.\")\n",
        "\n",
        "    # Analyze test entities\n",
        "    test_entities = df_all_diagnosis_entities[df_all_diagnosis_entities['label'] == 'TEST'] if not df_all_diagnosis_entities.empty else pd.DataFrame()\n",
        "    if not test_entities.empty:\n",
        "        print(f\"\\n=== Top Diagnostic Tests ===\")\n",
        "        print(test_entities['text'].str.lower().value_counts().head(20))\n",
        "\n",
        "    # Analyze findings\n",
        "    finding_entities = df_all_diagnosis_entities[df_all_diagnosis_entities['label'] == 'FINDING'] if not df_all_diagnosis_entities.empty else pd.DataFrame()\n",
        "    if not finding_entities.empty:\n",
        "        print(f\"\\n=== Top Diagnostic Findings ===\")\n",
        "        print(finding_entities['text'].str.lower().value_counts().head(20))\n",
        "\n",
        "    # Analyze conditions\n",
        "    condition_entities = df_all_diagnosis_entities[df_all_diagnosis_entities['label'] == 'CONDITION'] if not df_all_diagnosis_entities.empty else pd.DataFrame()\n",
        "    if not condition_entities.empty:\n",
        "        print(f\"\\n=== Top Diagnosed Conditions ===\")\n",
        "        print(condition_entities['text'].str.lower().value_counts().head(20))\n",
        "\n",
        "    # ================= Diagnosis-specific labeling functions =================\n",
        "    print(\"\\n=== Creating Diagnosis-Specific Labeling Functions ===\")\n",
        "\n",
        "    def create_diagnosis_labeling_functions():\n",
        "        COL = 'combined_text'\n",
        "\n",
        "        def lf_imaging_test(row):\n",
        "            test = str(row.get('test',''))\n",
        "            hit = _first_hit(test, ['mri','ct','x-ray','radiograph','ultrasound','scan'])\n",
        "            return {'label':'IMAGING_TEST','column':'test','match':hit,'category':'test'} if hit else {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_fracture_diagnosis(row):\n",
        "            res = str(row.get('result',''))\n",
        "            cond = str(row.get('condition',''))\n",
        "            if 'no fracture' in res.lower() or 'no fracture' in cond.lower():\n",
        "                col = 'result' if 'no fracture' in res.lower() else 'condition'\n",
        "                return {'label':'NO_FRACTURE','column':col,'match':'no fracture','category':'finding'}\n",
        "            if 'fracture' in res.lower() or 'fracture' in cond.lower():\n",
        "                col = 'result' if 'fracture' in res.lower() else 'condition'\n",
        "                return {'label':'FRACTURE_PRESENT','column':col,'match':'fracture','category':'finding'}\n",
        "            return {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_neoplastic_finding(row):\n",
        "            text = str(row.get(COL,''))\n",
        "            hit = _first_hit(text, ['tumor','mass','lesion','malignant','benign','metastasis'])\n",
        "            return {'label':'NEOPLASTIC_FINDING','column':COL,'match':hit,'category':'neoplastic'} if hit else {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_normal_finding(row):\n",
        "            res = str(row.get('result',''))\n",
        "            hit = _first_hit(res, ['normal','negative','no abnormality','unremarkable'])\n",
        "            return {'label':'NORMAL_FINDING','column':'result','match':hit,'category':'normal'} if hit else {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_critical_finding(row):\n",
        "            sev = str(row.get('severity',''))\n",
        "            det = str(row.get('details',''))\n",
        "            for col, txt in [('severity', sev), ('details', det), (COL, str(row.get(COL,'')))]:\n",
        "                hit = _first_hit(txt, ['critical','emergency','urgent','life-threatening'])\n",
        "                if hit:\n",
        "                    return {'label':'CRITICAL_FINDING','column':col,'match':hit,'category':'critical'}\n",
        "            return {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_bone_pathology(row):\n",
        "            text = str(row.get(COL,''))\n",
        "            if any(b in text.lower() for b in ['bone','osseous','fracture','osteo','marrow']):\n",
        "                hit = _first_hit(text, ['lesion','edema','necrosis','fracture'])\n",
        "                if hit:\n",
        "                    return {'label':'BONE_PATHOLOGY','column':COL,'match':hit,'category':'bone'}\n",
        "            return {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_vascular_finding(row):\n",
        "            text = str(row.get(COL,''))\n",
        "            hit = _first_hit(text, ['vascular','artery','vein','aneurysm','stenosis','occlusion'])\n",
        "            return {'label':'VASCULAR_FINDING','column':COL,'match':hit,'category':'vascular'} if hit else {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_inflammatory_finding(row):\n",
        "            text = str(row.get(COL,''))\n",
        "            hit = _first_hit(text, ['inflammation','inflammatory','edema','effusion','swelling'])\n",
        "            return {'label':'INFLAMMATORY_FINDING','column':COL,'match':hit,'category':'inflammatory'} if hit else {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_bilateral_finding(row):\n",
        "            text = str(row.get(COL,''))\n",
        "            hit = _first_hit(text, ['bilateral'])\n",
        "            return {'label':'BILATERAL_FINDING','column':COL,'match':hit,'category':'laterality'} if hit else {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_followup_needed(row):\n",
        "            det = str(row.get('details',''))\n",
        "            hit = _first_hit(det, ['follow-up','followup','repeat','monitor','reassess'])\n",
        "            return {'label':'FOLLOWUP_NEEDED','column':'details','match':hit,'category':'plan'} if hit else {'label':'ABSTAIN'}\n",
        "\n",
        "        return [lf_imaging_test, lf_fracture_diagnosis, lf_neoplastic_finding, lf_normal_finding,\n",
        "                lf_critical_finding, lf_bone_pathology, lf_vascular_finding,\n",
        "                lf_inflammatory_finding, lf_bilateral_finding, lf_followup_needed]\n",
        "\n",
        "    # --- materialize spans ---\n",
        "    diagnosis_lfs_span = create_diagnosis_labeling_functions()\n",
        "    df_diagnosis_lf_spans = materialize_lf_spans(df_diagnosis, diagnosis_lfs_span, id_column='idx')\n",
        "    print(f\"\\nLF-generated diagnosis spans: {len(df_diagnosis_lf_spans)}\")\n",
        "    if not df_diagnosis_lf_spans.empty:\n",
        "        print(df_diagnosis_lf_spans['label'].value_counts())\n",
        "\n",
        "    # --- combine model + custom + LF spans ---\n",
        "    _cols = ['text','label','start','end','original_text','source','row_idx','category']\n",
        "    for col in _cols:\n",
        "        if col not in df_diagnosis_entities.columns: df_diagnosis_entities[col] = 'bc5cdr' if col=='source' else None\n",
        "        if col not in df_custom_diagnosis_entities.columns: df_custom_diagnosis_entities[col] = 'custom_extraction' if col=='source' else None\n",
        "        if col not in df_diagnosis_lf_spans.columns: df_diagnosis_lf_spans[col] = None\n",
        "\n",
        "    df_all_diagnosis_entities = pd.concat(\n",
        "        [df_diagnosis_entities[_cols], df_custom_diagnosis_entities[_cols], df_diagnosis_lf_spans[_cols]],\n",
        "        ignore_index=True\n",
        "    )\n",
        "    print(f\"Total diagnosis entities (model+custom+LF): {len(df_all_diagnosis_entities)}\")\n",
        "    df_diagnosis_lf_spans.to_csv('diagnosis_lf_generated_spans.csv', index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>source</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bone marrow edema</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>109</td>\n",
              "      <td>126</td>\n",
              "      <td>Magnetic resonance imaging (MRI) scan performe...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>133948</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>femoral head necrosis</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>148</td>\n",
              "      <td>169</td>\n",
              "      <td>Magnetic resonance imaging (MRI) scan performe...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>133948</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Idiopathic osteonecrosis of the femoral head P...</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>207</td>\n",
              "      <td>263</td>\n",
              "      <td>Magnetic resonance imaging (MRI) scan performe...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>133948</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pain</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>284</td>\n",
              "      <td>288</td>\n",
              "      <td>Magnetic resonance imaging (MRI) scan performe...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>133948</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fracture</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>84</td>\n",
              "      <td>92</td>\n",
              "      <td>Radiographs performed with Minimally displaced...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>80176</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400806</th>\n",
              "      <td>CT</td>\n",
              "      <td>IMAGING_TEST</td>\n",
              "      <td>39</td>\n",
              "      <td>41</td>\n",
              "      <td>Low-dose thoracic computed tomography (CT)</td>\n",
              "      <td>lf:lf_imaging_test</td>\n",
              "      <td>137017</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400807</th>\n",
              "      <td>lesion</td>\n",
              "      <td>NEOPLASTIC_FINDING</td>\n",
              "      <td>86</td>\n",
              "      <td>92</td>\n",
              "      <td>Coronary angiography performed with nan severi...</td>\n",
              "      <td>lf:lf_neoplastic_finding</td>\n",
              "      <td>98004</td>\n",
              "      <td>neoplastic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400808</th>\n",
              "      <td>artery</td>\n",
              "      <td>VASCULAR_FINDING</td>\n",
              "      <td>71</td>\n",
              "      <td>77</td>\n",
              "      <td>Coronary angiography performed with nan severi...</td>\n",
              "      <td>lf:lf_vascular_finding</td>\n",
              "      <td>98004</td>\n",
              "      <td>vascular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400809</th>\n",
              "      <td>metastasis</td>\n",
              "      <td>NEOPLASTIC_FINDING</td>\n",
              "      <td>86</td>\n",
              "      <td>96</td>\n",
              "      <td>Histopathological examination performed with n...</td>\n",
              "      <td>lf:lf_neoplastic_finding</td>\n",
              "      <td>133320</td>\n",
              "      <td>neoplastic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400810</th>\n",
              "      <td>metastasis</td>\n",
              "      <td>NEOPLASTIC_FINDING</td>\n",
              "      <td>131</td>\n",
              "      <td>141</td>\n",
              "      <td>Histopathological examination performed with n...</td>\n",
              "      <td>lf:lf_neoplastic_finding</td>\n",
              "      <td>133320</td>\n",
              "      <td>neoplastic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400811 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text               label  \\\n",
              "0                                       bone marrow edema             DISEASE   \n",
              "1                                   femoral head necrosis             DISEASE   \n",
              "2       Idiopathic osteonecrosis of the femoral head P...             DISEASE   \n",
              "3                                                    pain             DISEASE   \n",
              "4                                                fracture             DISEASE   \n",
              "...                                                   ...                 ...   \n",
              "400806                                                 CT        IMAGING_TEST   \n",
              "400807                                             lesion  NEOPLASTIC_FINDING   \n",
              "400808                                             artery    VASCULAR_FINDING   \n",
              "400809                                         metastasis  NEOPLASTIC_FINDING   \n",
              "400810                                         metastasis  NEOPLASTIC_FINDING   \n",
              "\n",
              "        start  end                                      original_text  \\\n",
              "0         109  126  Magnetic resonance imaging (MRI) scan performe...   \n",
              "1         148  169  Magnetic resonance imaging (MRI) scan performe...   \n",
              "2         207  263  Magnetic resonance imaging (MRI) scan performe...   \n",
              "3         284  288  Magnetic resonance imaging (MRI) scan performe...   \n",
              "4          84   92  Radiographs performed with Minimally displaced...   \n",
              "...       ...  ...                                                ...   \n",
              "400806     39   41         Low-dose thoracic computed tomography (CT)   \n",
              "400807     86   92  Coronary angiography performed with nan severi...   \n",
              "400808     71   77  Coronary angiography performed with nan severi...   \n",
              "400809     86   96  Histopathological examination performed with n...   \n",
              "400810    131  141  Histopathological examination performed with n...   \n",
              "\n",
              "                          source  row_idx    category  \n",
              "0                         bc5cdr   133948        None  \n",
              "1                         bc5cdr   133948        None  \n",
              "2                         bc5cdr   133948        None  \n",
              "3                         bc5cdr   133948        None  \n",
              "4                         bc5cdr    80176        None  \n",
              "...                          ...      ...         ...  \n",
              "400806        lf:lf_imaging_test   137017        test  \n",
              "400807  lf:lf_neoplastic_finding    98004  neoplastic  \n",
              "400808    lf:lf_vascular_finding    98004    vascular  \n",
              "400809  lf:lf_neoplastic_finding   133320  neoplastic  \n",
              "400810  lf:lf_neoplastic_finding   133320  neoplastic  \n",
              "\n",
              "[400811 rows x 8 columns]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_all_diagnosis_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting Treatments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>has_treatments</th>\n",
              "      <th>name</th>\n",
              "      <th>related condition</th>\n",
              "      <th>dosage</th>\n",
              "      <th>time</th>\n",
              "      <th>frequency</th>\n",
              "      <th>duration</th>\n",
              "      <th>reason for taking</th>\n",
              "      <th>reaction to treatment</th>\n",
              "      <th>details</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155216</td>\n",
              "      <td>True</td>\n",
              "      <td>Olanzapine tablets</td>\n",
              "      <td>Bipolar affective disorder</td>\n",
              "      <td>5 mg per day</td>\n",
              "      <td>Past four months</td>\n",
              "      <td>Daily</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Control of exacerbated mental illness</td>\n",
              "      <td>Pain and discomfort in neck, sustained and abn...</td>\n",
              "      <td>Previously managed with olanzapine tablets in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>155216</td>\n",
              "      <td>True</td>\n",
              "      <td>Trihexyphenidyl</td>\n",
              "      <td>Rigidity in upper limbs</td>\n",
              "      <td>4 mg per day</td>\n",
              "      <td>Brief period of around three weeks</td>\n",
              "      <td>Daily</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Rigidity in upper limbs</td>\n",
              "      <td>Good response</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133948</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80176</td>\n",
              "      <td>True</td>\n",
              "      <td>Closed treatment in a cast</td>\n",
              "      <td>Proximal ulnar shaft fracture</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Initially after the fall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>To treat the ulnar shaft fracture</td>\n",
              "      <td>Developed a hypertrophic nonunion</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>80176</td>\n",
              "      <td>True</td>\n",
              "      <td>Conservative treatment</td>\n",
              "      <td>Ulna nonunion</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Three months after the fall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>An additional three months</td>\n",
              "      <td>To treat the ulna nonunion</td>\n",
              "      <td>Worsening motion through the nonunion site</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50421</th>\n",
              "      <td>98004</td>\n",
              "      <td>True</td>\n",
              "      <td>Hypovolaemic shock treatment</td>\n",
              "      <td>Haemodynamic instability and hypovolaemic shock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>To maintain blood pressure and treat shock</td>\n",
              "      <td>Required large doses of vasopressor and blood ...</td>\n",
              "      <td>Treatment given after becoming haemodynamicall...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50422</th>\n",
              "      <td>133320</td>\n",
              "      <td>True</td>\n",
              "      <td>Systemic chemotherapy</td>\n",
              "      <td>Lung and bone metastases</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>To treat lung and bone metastases</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Using doxorubicin and ifosfamide</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50423</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Rapid sequence intubation</td>\n",
              "      <td>Cardiogenic shock and flash pulmonary edema</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>To manage suspected cardiogenic shock and flas...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50424</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Advanced cardiac life support (ACLS) protocol</td>\n",
              "      <td>Cardiac arrest</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13 min</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>To restore return of spontaneous circulation a...</td>\n",
              "      <td>Return of spontaneous circulation was restored</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50425</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Intravenous nafcillin</td>\n",
              "      <td>Endocarditis</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Postoperative</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>To treat S.\\nlugdunensis infection</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Patient was discharged home on intravenous naf...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50426 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          idx  has_treatments                                           name  \\\n",
              "0      155216            True                             Olanzapine tablets   \n",
              "1      155216            True                                Trihexyphenidyl   \n",
              "2      133948           False                                            NaN   \n",
              "3       80176            True                     Closed treatment in a cast   \n",
              "4       80176            True                         Conservative treatment   \n",
              "...       ...             ...                                            ...   \n",
              "50421   98004            True                   Hypovolaemic shock treatment   \n",
              "50422  133320            True                          Systemic chemotherapy   \n",
              "50423   97973            True                      Rapid sequence intubation   \n",
              "50424   97973            True  Advanced cardiac life support (ACLS) protocol   \n",
              "50425   97973            True                          Intravenous nafcillin   \n",
              "\n",
              "                                     related condition        dosage  \\\n",
              "0                           Bipolar affective disorder  5 mg per day   \n",
              "1                              Rigidity in upper limbs  4 mg per day   \n",
              "2                                                  NaN           NaN   \n",
              "3                        Proximal ulnar shaft fracture           NaN   \n",
              "4                                        Ulna nonunion           NaN   \n",
              "...                                                ...           ...   \n",
              "50421  Haemodynamic instability and hypovolaemic shock           NaN   \n",
              "50422                         Lung and bone metastases           NaN   \n",
              "50423      Cardiogenic shock and flash pulmonary edema           NaN   \n",
              "50424                                   Cardiac arrest           NaN   \n",
              "50425                                     Endocarditis           NaN   \n",
              "\n",
              "                                     time frequency  \\\n",
              "0                        Past four months     Daily   \n",
              "1      Brief period of around three weeks     Daily   \n",
              "2                                     NaN       NaN   \n",
              "3                Initially after the fall       NaN   \n",
              "4             Three months after the fall       NaN   \n",
              "...                                   ...       ...   \n",
              "50421                                 NaN       NaN   \n",
              "50422                                 NaN       NaN   \n",
              "50423                                 NaN       NaN   \n",
              "50424                              13 min       NaN   \n",
              "50425                       Postoperative       NaN   \n",
              "\n",
              "                         duration  \\\n",
              "0                             NaN   \n",
              "1                             NaN   \n",
              "2                             NaN   \n",
              "3                             NaN   \n",
              "4      An additional three months   \n",
              "...                           ...   \n",
              "50421                         NaN   \n",
              "50422                         NaN   \n",
              "50423                         NaN   \n",
              "50424                         NaN   \n",
              "50425                         NaN   \n",
              "\n",
              "                                       reason for taking  \\\n",
              "0                  Control of exacerbated mental illness   \n",
              "1                                Rigidity in upper limbs   \n",
              "2                                                    NaN   \n",
              "3                      To treat the ulnar shaft fracture   \n",
              "4                             To treat the ulna nonunion   \n",
              "...                                                  ...   \n",
              "50421         To maintain blood pressure and treat shock   \n",
              "50422                  To treat lung and bone metastases   \n",
              "50423  To manage suspected cardiogenic shock and flas...   \n",
              "50424  To restore return of spontaneous circulation a...   \n",
              "50425                 To treat S.\\nlugdunensis infection   \n",
              "\n",
              "                                   reaction to treatment  \\\n",
              "0      Pain and discomfort in neck, sustained and abn...   \n",
              "1                                          Good response   \n",
              "2                                                    NaN   \n",
              "3                      Developed a hypertrophic nonunion   \n",
              "4             Worsening motion through the nonunion site   \n",
              "...                                                  ...   \n",
              "50421  Required large doses of vasopressor and blood ...   \n",
              "50422                                                NaN   \n",
              "50423                                                NaN   \n",
              "50424     Return of spontaneous circulation was restored   \n",
              "50425                                                NaN   \n",
              "\n",
              "                                                 details  \n",
              "0      Previously managed with olanzapine tablets in ...  \n",
              "1                                                    NaN  \n",
              "2                                                    NaN  \n",
              "3                                                    NaN  \n",
              "4                                                    NaN  \n",
              "...                                                  ...  \n",
              "50421  Treatment given after becoming haemodynamicall...  \n",
              "50422                   Using doxorubicin and ifosfamide  \n",
              "50423                                                NaN  \n",
              "50424                                                NaN  \n",
              "50425  Patient was discharged home on intravenous naf...  \n",
              "\n",
              "[50426 rows x 11 columns]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_treatments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_treatment_text(row):\n",
        "    \"\"\"Create comprehensive text from treatment row\"\"\"\n",
        "    parts = []\n",
        "    \n",
        "    if pd.notna(row.get('name')) and str(row['name']) != 'NaN':\n",
        "        parts.append(f\"Treatment: {row['name']}\")\n",
        "    \n",
        "    if pd.notna(row.get('related condition')) and str(row['related condition']) != 'NaN':\n",
        "        parts.append(f\"for {row['related condition']}\")\n",
        "    \n",
        "    if pd.notna(row.get('dosage')) and str(row['dosage']) != 'NaN':\n",
        "        parts.append(f\"dosage {row['dosage']}\")\n",
        "    \n",
        "    if pd.notna(row.get('frequency')) and str(row['frequency']) != 'NaN':\n",
        "        parts.append(f\"frequency {row['frequency']}\")\n",
        "    \n",
        "    if pd.notna(row.get('time')) and str(row['time']) != 'NaN':\n",
        "        parts.append(f\"time {row['time']}\")\n",
        "    \n",
        "    if pd.notna(row.get('duration')) and str(row['duration']) != 'NaN':\n",
        "        parts.append(f\"duration {row['duration']}\")\n",
        "    \n",
        "    if pd.notna(row.get('reason for taking')) and str(row['reason for taking']) != 'NaN':\n",
        "        parts.append(f\"reason: {row['reason for taking']}\")\n",
        "    \n",
        "    if pd.notna(row.get('reaction to treatment')) and str(row['reaction to treatment']) != 'NaN':\n",
        "        parts.append(f\"reaction: {row['reaction to treatment']}\")\n",
        "    \n",
        "    if pd.notna(row.get('details')) and str(row['details']) != 'NaN':\n",
        "        parts.append(f\"details: {row['details']}\")\n",
        "    \n",
        "    return \" \".join(parts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing temporal column: time\n",
            "\n",
            "Processing temporal column: duration\n",
            "\n",
            "Temporal extraction results:\n",
            "Duration extracted from 'time' column: 5037 rows\n",
            "Temporal types: {'unspecified': 6645, 'post_event': 5777, 'range_reference': 2315, 'past_reference': 2193, 'onset_reference': 2007, 'absolute_date': 1267, 'duration_reference': 914}\n",
            "Loading en_ner_bc5cdr_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 50426 texts in 169 batches...\n",
            "Using model: en_ner_bc5cdr_md for column: combined_text\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   1%|          | 1/169 [00:02<05:54,  2.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   7%|▋         | 11/169 [00:15<03:36,  1.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 3000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  12%|█▏        | 21/169 [00:28<03:23,  1.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 6000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  18%|█▊        | 31/169 [00:42<03:11,  1.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 9000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  24%|██▍       | 41/169 [00:55<02:55,  1.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 12000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  30%|███       | 51/169 [01:08<02:41,  1.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  36%|███▌      | 61/169 [01:21<02:31,  1.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 18000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  42%|████▏     | 71/169 [01:34<02:18,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 21000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  48%|████▊     | 81/169 [01:47<02:02,  1.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 24000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  54%|█████▍    | 91/169 [02:00<01:50,  1.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 27000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  60%|█████▉    | 101/169 [02:14<01:38,  1.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 30000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  66%|██████▌   | 111/169 [02:27<01:23,  1.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 33000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  72%|███████▏  | 121/169 [02:40<01:09,  1.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 36000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  78%|███████▊  | 131/169 [02:54<00:59,  1.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 39000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  83%|████████▎ | 141/169 [03:08<00:42,  1.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 42000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  89%|████████▉ | 151/169 [03:22<00:28,  1.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 45000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  95%|█████████▌| 161/169 [03:35<00:12,  1.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 48000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 169/169 [03:44<00:00,  1.33s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3696 entities appearing >= 5 times\n",
            "\n",
            "=== BC5CDR Entity Types Found ===\n",
            "{'DISEASE': 80940, 'CHEMICAL': 37907}\n",
            "\n",
            "=== CUSTOM TREATMENT ENTITY EXTRACTION ===\n",
            "\n",
            "=== COMBINED Entity Distribution ===\n",
            "label\n",
            "DISEASE               80940\n",
            "TREATMENT             44086\n",
            "CONDITION             43157\n",
            "CHEMICAL              37907\n",
            "TREATMENT_TYPE        33978\n",
            "TREATMENT_REASON      16765\n",
            "CONDITION_TYPE        14634\n",
            "TREATMENT_RESPONSE    13219\n",
            "TEMPORAL_PATTERN      12523\n",
            "DOSAGE                12305\n",
            "ROUTE                  8352\n",
            "FREQUENCY              6813\n",
            "MEDICATION             3117\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Treatments ===\n",
            "text\n",
            "chemotherapy               522\n",
            "antibiotics                520\n",
            "surgery                    285\n",
            "conservative treatment     282\n",
            "aspirin                    280\n",
            "surgical excision          265\n",
            "blood transfusion          255\n",
            "conservative management    250\n",
            "prednisone                 220\n",
            "intravenous antibiotics    170\n",
            "surgical resection         170\n",
            "radiotherapy               168\n",
            "adjuvant chemotherapy      158\n",
            "dexamethasone              155\n",
            "prednisolone               153\n",
            "warfarin                   142\n",
            "radiation therapy          139\n",
            "surgical treatment         137\n",
            "surgical intervention      134\n",
            "intubation                 125\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Medications ===\n",
            "text\n",
            "vancomycin         592\n",
            "ceftriaxone        408\n",
            "amoxicillin        325\n",
            "fentanyl           214\n",
            "morphine           197\n",
            "acetaminophen      176\n",
            "olanzapine         173\n",
            "ibuprofen          167\n",
            "risperidone        161\n",
            "penicillin         137\n",
            "haloperidol        114\n",
            "quetiapine          94\n",
            "oxycodone           69\n",
            "baclofen            61\n",
            "clozapine           59\n",
            "vasopressor         57\n",
            "beta blocker        37\n",
            "ace inhibitor       22\n",
            "trihexyphenidyl     19\n",
            "hypovolaemic         9\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Conditions Treated ===\n",
            "text\n",
            "hypertension            451\n",
            "seizures                118\n",
            "hypotension             118\n",
            "breast cancer           116\n",
            "infection               116\n",
            "pain management         116\n",
            "epilepsy                114\n",
            "respiratory distress    109\n",
            "schizophrenia           105\n",
            "cardiac arrest          105\n",
            "postoperative care      100\n",
            "atrial fibrillation      96\n",
            "suspected infection      88\n",
            "anemia                   86\n",
            "hypothyroidism           80\n",
            "septic shock             78\n",
            "abdominal pain           77\n",
            "metastatic melanoma      75\n",
            "pneumonia                73\n",
            "headache                 69\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Dosage Distribution ===\n",
            "text\n",
            "daily      1088\n",
            "/day        937\n",
            "10 mg       530\n",
            "500 mg      506\n",
            "100 mg      505\n",
            "50 mg       466\n",
            "5 mg        435\n",
            "20 mg       393\n",
            "40 mg       339\n",
            "per day     333\n",
            "1 mg        286\n",
            "200 mg      275\n",
            "400 mg      266\n",
            "60 mg       230\n",
            "300 mg      219\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Treatment Response Distribution ===\n",
            "category\n",
            "positive    5956\n",
            "neutral     4096\n",
            "negative    2773\n",
            "partial      394\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Treatment Type Distribution ===\n",
            "category\n",
            "procedure       20062\n",
            "supportive       3687\n",
            "medication       3613\n",
            "chemotherapy     2427\n",
            "emergency        2052\n",
            "conservative     1293\n",
            "diagnostic        844\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Creating Treatment-Specific Labeling Functions ===\n",
            "\n",
            "LF-generated treatment spans: 88766\n",
            "label\n",
            "HAS_TREATMENT                   44083\n",
            "MEDICATION_TREATMENT            10173\n",
            "TREATMENT_DURATION_MENTIONED     8076\n",
            "CANCER_TREATMENT                 4503\n",
            "SURGICAL_TREATMENT               4433\n",
            "CHRONIC_TREATMENT                3968\n",
            "DAILY_MEDICATION                 3636\n",
            "INFECTION_TREATMENT              3143\n",
            "POSITIVE_RESPONSE                2812\n",
            "EMERGENCY_TREATMENT              1360\n",
            "CARDIOVASCULAR_TREATMENT         1131\n",
            "CONSERVATIVE_TREATMENT            735\n",
            "PSYCHIATRIC_TREATMENT             713\n",
            "Name: count, dtype: int64\n",
            "Total treatment entities (model+custom+LF): 416562\n"
          ]
        }
      ],
      "source": [
        "def extract_treatment_entities_custom(df_treatments):\n",
        "    \"\"\"Extract treatment-specific entities not caught by BC5CDR.\n",
        "        Uses 'idx' for row identity when available; falls back to df.index otherwise.\n",
        "        Adds 'row_idx' to every extracted entity.\n",
        "    \"\"\"\n",
        "    custom_entities = []\n",
        "    \n",
        "    # Treatment type patterns\n",
        "    treatment_type_patterns = {\n",
        "        'medication': ['tablet', 'tablets', 'pill', 'pills', 'capsule', 'injection', 'infusion', 'medication', 'drug'],\n",
        "        'procedure': ['surgery', 'surgical', 'operation', 'procedure', 'therapy', 'intubation', 'resection', 'removal', 'repair'],\n",
        "        'supportive': ['support', 'life support', 'ventilation', 'oxygen', 'fluid', 'nutrition', 'acls', 'protocol'],\n",
        "        'chemotherapy': ['chemotherapy', 'chemo', 'cytotoxic', 'antineoplastic', 'systemic chemotherapy'],\n",
        "        'conservative': ['conservative', 'non-operative', 'non-surgical', 'observation', 'closed treatment'],\n",
        "        'emergency': ['emergency', 'urgent', 'rapid', 'resuscitation', 'life-saving'],\n",
        "        'diagnostic': ['biopsy', 'exploration', 'diagnostic', 'assessment']\n",
        "    }\n",
        "    \n",
        "    # Drug/medication patterns\n",
        "    medication_patterns = {\n",
        "        'antipsychotic': ['olanzapine', 'risperidone', 'quetiapine', 'haloperidol', 'clozapine'],\n",
        "        'muscle_relaxant': ['trihexyphenidyl', 'baclofen', 'tizanidine', 'cyclobenzaprine'],\n",
        "        'antibiotic': ['nafcillin', 'vancomycin', 'ceftriaxone', 'penicillin', 'amoxicillin'],\n",
        "        'cardiovascular': ['vasopressor', 'inotrope', 'beta blocker', 'ace inhibitor', 'hypovolaemic'],\n",
        "        'analgesic': ['morphine', 'fentanyl', 'oxycodone', 'acetaminophen', 'ibuprofen']\n",
        "    }\n",
        "    \n",
        "    # Condition patterns (treated conditions)\n",
        "    condition_patterns = {\n",
        "        'psychiatric': ['bipolar', 'affective disorder', 'psychosis', 'mania', 'depression', 'mental illness'],\n",
        "        'orthopedic': ['fracture', 'joint', 'bone', 'hip', 'knee', 'spine', 'ulnar shaft'],\n",
        "        'cardiovascular': ['cardiac', 'heart', 'arrhythmia', 'shock', 'arrest', 'hypovolaemic', 'endocarditis'],\n",
        "        'oncological': ['cancer', 'metastases', 'tumor', 'malignancy', 'carcinoma'],\n",
        "        'neurological': ['rigidity', 'tremor', 'paralysis', 'nerve', 'neurological'],\n",
        "        'infectious': ['infection', 'sepsis', 'endocarditis', 'abscess', 'pneumonia']\n",
        "    }\n",
        "    \n",
        "    # Dosage unit patterns\n",
        "    dosage_patterns = {\n",
        "        'mg': r'\\b(\\d+\\.?\\d*)\\s*mg\\b',\n",
        "        'mcg': r'\\b(\\d+\\.?\\d*)\\s*mcg\\b',\n",
        "        'units': r'\\b(\\d+\\.?\\d*)\\s*units?\\b',\n",
        "        'ml': r'\\b(\\d+\\.?\\d*)\\s*ml\\b',\n",
        "        'per_day': r'\\b(?:per\\s*day|/day|daily)\\b',\n",
        "        'min': r'\\b(\\d+\\.?\\d*)\\s*min(?:utes?)?\\b'\n",
        "    }\n",
        "    \n",
        "    # Frequency patterns\n",
        "    frequency_terms = ['daily', 'twice daily', 'three times', 'qid', 'bid', 'tid', 'prn', \n",
        "                        'as needed', 'every', 'once', 'continuous', 'intermittent']\n",
        "    \n",
        "    # Route of administration patterns\n",
        "    route_terms = ['oral', 'intravenous', 'iv', 'im', 'intramuscular', 'subcutaneous', \n",
        "                    'topical', 'inhaled', 'nasal', 'rectal']\n",
        "    \n",
        "    # Treatment response/outcome patterns\n",
        "    response_patterns = {\n",
        "        'positive': ['good response', 'improved', 'resolved', 'successful', 'effective', \n",
        "                        'restored', 'return of', 'recovered'],\n",
        "        'negative': ['worsening', 'failed', 'no response', 'adverse', 'side effect', \n",
        "                        'complication', 'deterioration'],\n",
        "        'neutral': ['no change', 'stable', 'maintained', 'sustained', 'continued'],\n",
        "        'partial': ['partial response', 'some improvement', 'limited response']\n",
        "    }\n",
        "    \n",
        "    # Temporal patterns specific to treatments\n",
        "    temporal_patterns = {\n",
        "        'acute': ['acute', 'sudden', 'rapid', 'emergency', 'immediate'],\n",
        "        'chronic': ['chronic', 'long-term', 'maintenance', 'ongoing', 'continuous'],\n",
        "        'perioperative': ['preoperative', 'postoperative', 'intraoperative', 'perioperative'],\n",
        "        'duration': ['months', 'weeks', 'days', 'hours', 'years']\n",
        "    }\n",
        "    \n",
        "    for df_index, row in df_treatments.iterrows():\n",
        "        # ---- choose the correct row id from 'idx' with fallback to the DataFrame index\n",
        "        row_id = row['idx'] if ('idx' in row and pd.notna(row['idx'])) else df_index\n",
        "\n",
        "        # Get relevant text fields with safe string conversion\n",
        "        name_orig = str(row.get('name', ''))\n",
        "        name = name_orig.lower() if pd.notna(row.get('name')) else ''\n",
        "        condition_orig = str(row.get('related condition', ''))\n",
        "        condition = condition_orig.lower() if pd.notna(row.get('related condition')) else ''\n",
        "        dosage_orig = str(row.get('dosage', ''))\n",
        "        dosage = dosage_orig.lower() if pd.notna(row.get('dosage')) else ''\n",
        "        frequency_orig = str(row.get('frequency', ''))\n",
        "        frequency = frequency_orig.lower() if pd.notna(row.get('frequency')) else ''\n",
        "        time_orig = str(row.get('time', ''))\n",
        "        time_l = time_orig.lower() if pd.notna(row.get('time')) else ''\n",
        "        duration_orig = str(row.get('duration', ''))\n",
        "        duration_l = duration_orig.lower() if pd.notna(row.get('duration')) else ''\n",
        "        reason_orig = str(row.get('reason for taking', ''))\n",
        "        reason = reason_orig.lower() if pd.notna(row.get('reason for taking')) else ''\n",
        "        reaction_orig = str(row.get('reaction to treatment', ''))\n",
        "        reaction = reaction_orig.lower() if pd.notna(row.get('reaction to treatment')) else ''\n",
        "        details_orig = str(row.get('details', ''))\n",
        "        details = details_orig.lower() if pd.notna(row.get('details')) else ''\n",
        "        combined_orig = str(row.get('combined_text', ''))\n",
        "        combined = combined_orig.lower()\n",
        "\n",
        "        # Primary TREATMENT from name column (position in combined if possible)\n",
        "        if name and name != 'nan':\n",
        "            start = combined.find(name)\n",
        "            if start < 0:\n",
        "                start = 0\n",
        "            end = min(start + len(name_orig), len(combined_orig))\n",
        "            custom_entities.append({\n",
        "                'text': name_orig,\n",
        "                'label': 'TREATMENT',\n",
        "                'category': 'primary_treatment',\n",
        "                'start': start,\n",
        "                'end': end,\n",
        "                'original_text': combined_orig if combined_orig else name_orig,\n",
        "                'source': 'name_column',\n",
        "                'row_idx': row_id\n",
        "            })\n",
        "        \n",
        "        # CONDITION (indication)\n",
        "        if condition and condition != 'nan':\n",
        "            start = combined.find(condition)\n",
        "            if start < 0:\n",
        "                start = 0\n",
        "            end = min(start + len(condition_orig), len(combined_orig))\n",
        "            custom_entities.append({\n",
        "                'text': condition_orig,\n",
        "                'label': 'CONDITION',\n",
        "                'category': 'treatment_indication',\n",
        "                'start': start,\n",
        "                'end': end,\n",
        "                'original_text': combined_orig if combined_orig else condition_orig,\n",
        "                'source': 'condition_column',\n",
        "                'row_idx': row_id\n",
        "            })\n",
        "        \n",
        "        # TREATMENT_TYPE (search in combined)\n",
        "        for category, terms in treatment_type_patterns.items():\n",
        "            for term in terms:\n",
        "                pattern = r'\\b' + re.escape(term) + r'\\b'\n",
        "                for m in re.finditer(pattern, combined):\n",
        "                    custom_entities.append({\n",
        "                        'text': combined_orig[m.start():m.end()],\n",
        "                        'label': 'TREATMENT_TYPE',\n",
        "                        'category': category,\n",
        "                        'start': m.start(),\n",
        "                        'end': m.end(),\n",
        "                        'original_text': combined_orig,\n",
        "                        'source': 'pattern_matching',\n",
        "                        'row_idx': row_id\n",
        "                    })\n",
        "        \n",
        "        # MEDICATION names/classes (search in combined)\n",
        "        for drug_class, drugs in medication_patterns.items():\n",
        "            for drug in drugs:\n",
        "                pattern = r'\\b' + re.escape(drug) + r'\\b'\n",
        "                for m in re.finditer(pattern, combined):\n",
        "                    custom_entities.append({\n",
        "                        'text': combined_orig[m.start():m.end()],\n",
        "                        'label': 'MEDICATION',\n",
        "                        'category': drug_class,\n",
        "                        'start': m.start(),\n",
        "                        'end': m.end(),\n",
        "                        'original_text': combined_orig,\n",
        "                        'source': 'medication_pattern',\n",
        "                        'row_idx': row_id\n",
        "                    })\n",
        "        \n",
        "        # DOSAGE (from dosage column)\n",
        "        if dosage and dosage != 'nan':\n",
        "            for unit, pattern in dosage_patterns.items():\n",
        "                for match in re.finditer(pattern, dosage, re.IGNORECASE):\n",
        "                    custom_entities.append({\n",
        "                        'text': match.group(0),\n",
        "                        'label': 'DOSAGE',\n",
        "                        'category': unit,\n",
        "                        'start': match.start(),\n",
        "                        'end': match.end(),\n",
        "                        'original_text': dosage_orig,\n",
        "                        'source': 'dosage_column',\n",
        "                        'row_idx': row_id\n",
        "                    })\n",
        "        \n",
        "        # FREQUENCY (from frequency column)\n",
        "        if frequency and frequency != 'nan':\n",
        "            for freq_term in frequency_terms:\n",
        "                pattern = r'\\b' + re.escape(freq_term) + r'\\b'\n",
        "                for m in re.finditer(pattern, frequency):\n",
        "                    custom_entities.append({\n",
        "                        'text': frequency_orig[m.start():m.end()],\n",
        "                        'label': 'FREQUENCY',\n",
        "                        'category': 'dosing_frequency',\n",
        "                        'start': m.start(),\n",
        "                        'end': m.end(),\n",
        "                        'original_text': frequency_orig,\n",
        "                        'source': 'frequency_column',\n",
        "                        'row_idx': row_id\n",
        "                    })\n",
        "        \n",
        "        # ROUTE (search across combined context)\n",
        "        for route in route_terms:\n",
        "            pattern = r'\\b' + re.escape(route) + r'\\b'\n",
        "            for m in re.finditer(pattern, combined):\n",
        "                custom_entities.append({\n",
        "                    'text': combined_orig[m.start():m.end()],\n",
        "                    'label': 'ROUTE',\n",
        "                    'category': 'administration_route',\n",
        "                    'start': m.start(),\n",
        "                    'end': m.end(),\n",
        "                    'original_text': combined_orig,\n",
        "                    'source': 'route_extraction',\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "        \n",
        "        # TREATMENT_RESPONSE (reaction + details + combined)\n",
        "        response_text_orig = ' '.join([reaction_orig, details_orig, combined_orig])\n",
        "        response_text = response_text_orig.lower()\n",
        "        for response_type, patterns in response_patterns.items():\n",
        "            for phrase in patterns:\n",
        "                pattern = r'\\b' + re.escape(phrase) + r'\\b'\n",
        "                for m in re.finditer(pattern, response_text):\n",
        "                    custom_entities.append({\n",
        "                        'text': response_text_orig[m.start():m.end()],\n",
        "                        'label': 'TREATMENT_RESPONSE',\n",
        "                        'category': response_type,\n",
        "                        'start': m.start(),\n",
        "                        'end': m.end(),\n",
        "                        'original_text': response_text_orig,\n",
        "                        'source': 'response_extraction',\n",
        "                        'row_idx': row_id\n",
        "                    })\n",
        "        \n",
        "        # CONDITION_TYPE categories (condition or reason)\n",
        "        for condition_type, condition_terms in condition_patterns.items():\n",
        "            for term in condition_terms:\n",
        "                pattern = r'\\b' + re.escape(term) + r'\\b'\n",
        "                # search in condition text first, then reason, else combined\n",
        "                found = False\n",
        "                for text_orig, text_l, source in [\n",
        "                    (condition_orig, condition, 'condition_pattern'),\n",
        "                    (reason_orig, reason, 'reason_pattern'),\n",
        "                    (combined_orig, combined, 'combined_pattern'),\n",
        "                ]:\n",
        "                    m = re.search(pattern, text_l)\n",
        "                    if m:\n",
        "                        custom_entities.append({\n",
        "                            'text': text_orig[m.start():m.end()],\n",
        "                            'label': 'CONDITION_TYPE',\n",
        "                            'category': condition_type,\n",
        "                            'start': m.start(),\n",
        "                            'end': m.end(),\n",
        "                            'original_text': text_orig,\n",
        "                            'source': source,\n",
        "                            'row_idx': row_id\n",
        "                        })\n",
        "                        found = True\n",
        "                        break\n",
        "        \n",
        "        # TEMPORAL_PATTERN\n",
        "        temporal_text_orig = ' '.join([time_orig, duration_orig, details_orig])\n",
        "        temporal_text = temporal_text_orig.lower()\n",
        "        for temp_category, temp_terms in temporal_patterns.items():\n",
        "            for term in temp_terms:\n",
        "                pattern = r'\\b' + re.escape(term) + r'\\b'\n",
        "                for m in re.finditer(pattern, temporal_text):\n",
        "                    custom_entities.append({\n",
        "                        'text': temporal_text_orig[m.start():m.end()],\n",
        "                        'label': 'TEMPORAL_PATTERN',\n",
        "                        'category': temp_category,\n",
        "                        'start': m.start(),\n",
        "                        'end': m.end(),\n",
        "                        'original_text': temporal_text_orig,\n",
        "                        'source': 'temporal_extraction',\n",
        "                        'row_idx': row_id\n",
        "                    })\n",
        "        \n",
        "        # TREATMENT_REASON (from reason column specific patterns)\n",
        "        if reason and reason != 'nan':\n",
        "            reason_patterns = [\n",
        "                (r'to\\s+treat\\s+(\\w+(?:\\s+\\w+)*)', 'treatment_goal'),\n",
        "                (r'to\\s+manage\\s+(\\w+(?:\\s+\\w+)*)', 'management_goal'),\n",
        "                (r'control\\s+of\\s+(\\w+(?:\\s+\\w+)*)', 'control_goal'),\n",
        "                (r'for\\s+(\\w+(?:\\s+\\w+)*)', 'indication')\n",
        "            ]\n",
        "            for pattern, category in reason_patterns:\n",
        "                for match in re.finditer(pattern, reason, re.IGNORECASE):\n",
        "                    custom_entities.append({\n",
        "                        'text': match.group(0),\n",
        "                        'label': 'TREATMENT_REASON',\n",
        "                        'category': category,\n",
        "                        'start': match.start(),\n",
        "                        'end': match.end(),\n",
        "                        'original_text': reason_orig,\n",
        "                        'source': 'reason_column',\n",
        "                        'row_idx': row_id\n",
        "                    })\n",
        "    \n",
        "    return pd.DataFrame(custom_entities)\n",
        "if __name__ == \"__main__\":\n",
        "    # Use the global TemporalStandardizer class \n",
        "    temporal_standardizer = TemporalStandardizer()\n",
        "\n",
        "    # Process temporal information using the standardize_temporal_column method\n",
        "    df_treatments_processed, temporal_report = temporal_standardizer.standardize_temporal_column(\n",
        "        df_treatments, \n",
        "        'time'\n",
        "    )\n",
        "    \n",
        "    # Process duration column as well\n",
        "    df_treatments_processed, duration_report = temporal_standardizer.standardize_temporal_column(\n",
        "        df_treatments_processed, \n",
        "        'duration'\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTemporal extraction results:\")\n",
        "    print(f\"Duration extracted from 'time' column: {temporal_report['extracted_durations']} rows\")\n",
        "    print(f\"Temporal types: {temporal_report['temporal_types']}\")\n",
        "\n",
        "    # Combine treatments information into comprehensive text\n",
        "    df_treatments_processed['combined_text'] = df_treatments_processed.apply(\n",
        "        lambda row: create_treatment_text(row),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Run NER extraction with BC5CDR\n",
        "    df_treatments_entities, treatments_summary, treatments_rules = run_medical_ner_extraction(\n",
        "        df_treatments_processed,\n",
        "        text_column='combined_text',\n",
        "        model_name=\"en_ner_bc5cdr_md\",\n",
        "        batch_size=300,\n",
        "        id_column='idx'\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== BC5CDR Entity Types Found ===\")\n",
        "    print(treatments_summary['entity_types'])\n",
        "\n",
        "    # Custom entity extraction for treatment-specific entities (keeps correct row_idx)\n",
        "    print(\"\\n=== CUSTOM TREATMENT ENTITY EXTRACTION ===\")\n",
        "\n",
        "\n",
        "    # Extract custom entities\n",
        "    df_custom_treatments_entities = extract_treatment_entities_custom(df_treatments_processed)\n",
        "\n",
        "    # Combine all entities (preserve row_idx/category when present)\n",
        "    df_all_treatments_entities = pd.concat(\n",
        "        [df_treatments_entities, df_custom_treatments_entities],\n",
        "        ignore_index=True,\n",
        "        sort=False\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== COMBINED Entity Distribution ===\")\n",
        "    if not df_all_treatments_entities.empty and 'label' in df_all_treatments_entities.columns:\n",
        "        print(df_all_treatments_entities['label'].value_counts())\n",
        "    else:\n",
        "        print(\"No combined entities to show.\")\n",
        "\n",
        "    # Analyze treatment entities\n",
        "    treatment_entities = df_all_treatments_entities[df_all_treatments_entities['label'] == 'TREATMENT'] if not df_all_treatments_entities.empty else pd.DataFrame()\n",
        "    if not treatment_entities.empty:\n",
        "        print(f\"\\n=== Top Treatments ===\")\n",
        "        print(treatment_entities['text'].str.lower().value_counts().head(20))\n",
        "\n",
        "    # Analyze medications\n",
        "    medication_entities = df_all_treatments_entities[df_all_treatments_entities['label'] == 'MEDICATION'] if not df_all_treatments_entities.empty else pd.DataFrame()\n",
        "    if not medication_entities.empty:\n",
        "        print(f\"\\n=== Top Medications ===\")\n",
        "        print(medication_entities['text'].str.lower().value_counts().head(20))\n",
        "\n",
        "    # Analyze conditions being treated\n",
        "    condition_entities = df_all_treatments_entities[df_all_treatments_entities['label'] == 'CONDITION'] if not df_all_treatments_entities.empty else pd.DataFrame()\n",
        "    if not condition_entities.empty:\n",
        "        print(f\"\\n=== Top Conditions Treated ===\")\n",
        "        print(condition_entities['text'].str.lower().value_counts().head(20))\n",
        "\n",
        "    # Analyze dosages\n",
        "    dosage_entities = df_all_treatments_entities[df_all_treatments_entities['label'] == 'DOSAGE'] if not df_all_treatments_entities.empty else pd.DataFrame()\n",
        "    if not dosage_entities.empty:\n",
        "        print(f\"\\n=== Dosage Distribution ===\")\n",
        "        print(dosage_entities['text'].str.lower().value_counts().head(15))\n",
        "\n",
        "    # Analyze treatment responses\n",
        "    response_entities = df_all_treatments_entities[df_all_treatments_entities['label'] == 'TREATMENT_RESPONSE'] if not df_all_treatments_entities.empty else pd.DataFrame()\n",
        "    if not response_entities.empty:\n",
        "        print(f\"\\n=== Treatment Response Distribution ===\")\n",
        "        print(response_entities['category'].value_counts())\n",
        "\n",
        "    # Analyze treatment types\n",
        "    treatment_type_entities = df_all_treatments_entities[df_all_treatments_entities['label'] == 'TREATMENT_TYPE'] if not df_all_treatments_entities.empty else pd.DataFrame()\n",
        "    if not treatment_type_entities.empty:\n",
        "        print(f\"\\n=== Treatment Type Distribution ===\")\n",
        "        print(treatment_type_entities['category'].value_counts())\n",
        "\n",
        "    # Create treatment-specific labeling functions (unchanged logic)\n",
        "    print(\"\\n=== Creating Treatment-Specific Labeling Functions ===\")\n",
        "\n",
        "    def create_treatment_labeling_functions():\n",
        "        COL = 'combined_text'\n",
        "\n",
        "        def lf_has_treatment(row):\n",
        "            if row.get('has_treatments') is True:\n",
        "                # anchor on treatment name if present\n",
        "                nm = str(row.get('name',''))\n",
        "                if nm:\n",
        "                    return {'label':'HAS_TREATMENT','column':'name','match':nm.split()[0].lower(),'category':'presence'}\n",
        "            elif row.get('has_treatments') is False:\n",
        "                hit = _first_hit(str(row.get(COL,'')), ['no treatment','none'])\n",
        "                if hit:\n",
        "                    return {'label':'NO_TREATMENT','column':COL,'match':hit,'category':'absence'}\n",
        "            return {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_medication_treatment(row):\n",
        "            name = str(row.get('name','')); dose = str(row.get('dosage','')); text = ' '.join([name,dose,str(row.get(COL,''))])\n",
        "            hit = _first_hit(text, ['tablet','tablets','pill','mg','mcg','capsule','injection','infusion'])\n",
        "            if hit:\n",
        "                # choose best column for offsets\n",
        "                col = 'name' if hit in name.lower() else ('dosage' if hit in dose.lower() else COL)\n",
        "                return {'label':'MEDICATION_TREATMENT','column':col,'match':hit,'category':'medication'}\n",
        "            return {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_surgical_treatment(row):\n",
        "            name = str(row.get('name','')); det = str(row.get('details',''))\n",
        "            text = name + ' ' + det\n",
        "            hit = _first_hit(text, ['surgery','surgical','operation','resection','removal','repair','intubation'])\n",
        "            if hit:\n",
        "                col = 'name' if hit in name.lower() else 'details'\n",
        "                return {'label':'SURGICAL_TREATMENT','column':col,'match':hit,'category':'procedure'}\n",
        "            return {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_emergency_treatment(row):\n",
        "            text = ' '.join([str(row.get('name','')), str(row.get('related condition','')), str(row.get('details',''))])\n",
        "            hit = _first_hit(text, ['emergency','urgent','cardiac arrest','shock','life support','acls','resuscitation','rapid sequence'])\n",
        "            if hit:\n",
        "                # pick the column containing the hit\n",
        "                for col in ['name','related condition','details']:\n",
        "                    if hit in str(row.get(col,'')).lower():\n",
        "                        return {'label':'EMERGENCY_TREATMENT','column':col,'match':hit,'category':'urgency'}\n",
        "            return {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_cancer_treatment(row):\n",
        "            text = ' '.join([str(row.get('name','')), str(row.get('related condition','')), str(row.get('reason for taking',''))])\n",
        "            hit = _first_hit(text, ['chemotherapy','cancer','metastases','tumor','oncology','malignant','carcinoma'])\n",
        "            if hit:\n",
        "                for col in ['name','related condition','reason for taking']:\n",
        "                    if hit in str(row.get(col,'')).lower():\n",
        "                        return {'label':'CANCER_TREATMENT','column':col,'match':hit,'category':'oncology'}\n",
        "            return {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_psychiatric_treatment(row):\n",
        "            name = str(row.get('name','')); cond = str(row.get('related condition',''))\n",
        "            drug_hit = _first_hit(name, ['olanzapine','risperidone','haloperidol','quetiapine','trihexyphenidyl'])\n",
        "            cond_hit = _first_hit(cond, ['bipolar','psychosis','mania','depression','anxiety','affective disorder'])\n",
        "            if drug_hit:\n",
        "                return {'label':'PSYCHIATRIC_TREATMENT','column':'name','match':drug_hit,'category':'psychiatry'}\n",
        "            if cond_hit:\n",
        "                return {'label':'PSYCHIATRIC_TREATMENT','column':'related condition','match':cond_hit,'category':'psychiatry'}\n",
        "            return {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_chronic_treatment(row):\n",
        "            t = str(row.get('time','')); d = str(row.get('duration',''))\n",
        "            hit = _first_hit(t + ' ' + d, ['months','years','chronic','long-term','maintenance'])\n",
        "            if hit:\n",
        "                col = 'duration' if hit in d.lower() else 'time'\n",
        "                return {'label':'CHRONIC_TREATMENT','column':col,'match':hit,'category':'temporal'}\n",
        "            return {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_daily_medication(row):\n",
        "            freq = str(row.get('frequency',''))\n",
        "            hit = _first_hit(freq, ['daily','every day','per day'])\n",
        "            return {'label':'DAILY_MEDICATION','column':'frequency','match':hit,'category':'frequency'} if hit else {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_positive_response(row):\n",
        "            rxn = str(row.get('reaction to treatment','')); det = str(row.get('details',''))\n",
        "            for col, txt in [('reaction to treatment', rxn), ('details', det)]:\n",
        "                hit = _first_hit(txt, ['good response','improved','resolved','successful','effective','restored','return of','recovered'])\n",
        "                if hit:\n",
        "                    return {'label':'POSITIVE_RESPONSE','column':col,'match':hit,'category':'response'}\n",
        "            return {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_conservative_treatment(row):\n",
        "            name = str(row.get('name',''))\n",
        "            hit = _first_hit(name, ['conservative','non-operative','closed treatment'])\n",
        "            return {'label':'CONSERVATIVE_TREATMENT','column':'name','match':hit,'category':'conservative'} if hit else {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_infection_treatment(row):\n",
        "            text = ' '.join([str(row.get('name','')), str(row.get('related condition','')), str(row.get('reason for taking',''))])\n",
        "            hit = _first_hit(text, ['antibiotic','infection','endocarditis','sepsis','nafcillin','antimicrobial'])\n",
        "            if hit:\n",
        "                for col in ['name','related condition','reason for taking']:\n",
        "                    if hit in str(row.get(col,'')).lower():\n",
        "                        return {'label':'INFECTION_TREATMENT','column':col,'match':hit,'category':'infectious'}\n",
        "            return {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_cardiovascular_treatment(row):\n",
        "            text = ' '.join([str(row.get('name','')), str(row.get('related condition',''))])\n",
        "            hit = _first_hit(text, ['cardiac','heart','hypovolaemic','shock','arrest','vasopressor','arrhythmia'])\n",
        "            if hit:\n",
        "                for col in ['name','related condition']:\n",
        "                    if hit in str(row.get(col,'')).lower():\n",
        "                        return {'label':'CARDIOVASCULAR_TREATMENT','column':col,'match':hit,'category':'cardio'}\n",
        "            return {'label':'ABSTAIN'}\n",
        "\n",
        "        def lf_treatment_duration(row):\n",
        "            # anchor on explicit duration tokens if present\n",
        "            dur = str(row.get('duration','')); time = str(row.get('time',''))\n",
        "            hit = _first_hit(dur + ' ' + time, ['days','weeks','months','years','hours'])\n",
        "            if hit:\n",
        "                col = 'duration' if hit in dur.lower() else 'time'\n",
        "                return {'label':'TREATMENT_DURATION_MENTIONED','column':col,'match':hit,'category':'duration'}\n",
        "            return {'label':'ABSTAIN'}\n",
        "\n",
        "        return [lf_has_treatment, lf_medication_treatment, lf_surgical_treatment, lf_emergency_treatment,\n",
        "                lf_cancer_treatment, lf_psychiatric_treatment, lf_chronic_treatment, lf_daily_medication,\n",
        "                lf_positive_response, lf_conservative_treatment, lf_infection_treatment, lf_cardiovascular_treatment,\n",
        "                lf_treatment_duration]\n",
        "\n",
        "    # --- materialize spans (use the processed DF which holds combined_text) ---\n",
        "    treatment_lfs_span = create_treatment_labeling_functions()\n",
        "    df_treatments_lf_spans = materialize_lf_spans(df_treatments_processed, treatment_lfs_span, id_column='idx')\n",
        "    print(f\"\\nLF-generated treatment spans: {len(df_treatments_lf_spans)}\")\n",
        "    if not df_treatments_lf_spans.empty:\n",
        "        print(df_treatments_lf_spans['label'].value_counts())\n",
        "\n",
        "    # --- combine model + custom + LF spans ---\n",
        "    _cols = ['text','label','start','end','original_text','source','row_idx','category']\n",
        "    for col in _cols:\n",
        "        if col not in df_treatments_entities.columns: df_treatments_entities[col] = 'bc5cdr' if col=='source' else None\n",
        "        if col not in df_custom_treatments_entities.columns: df_custom_treatments_entities[col] = 'custom_extraction' if col=='source' else None\n",
        "        if col not in df_treatments_lf_spans.columns: df_treatments_lf_spans[col] = None\n",
        "\n",
        "    df_all_treatments_entities = pd.concat(\n",
        "        [df_treatments_entities[_cols], df_custom_treatments_entities[_cols], df_treatments_lf_spans[_cols]],\n",
        "        ignore_index=True\n",
        "    )\n",
        "    print(f\"Total treatment entities (model+custom+LF): {len(df_all_treatments_entities)}\")\n",
        "    df_treatments_lf_spans.to_csv('treatments_lf_generated_spans.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>source</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Olanzapine</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>11</td>\n",
              "      <td>21</td>\n",
              "      <td>Treatment: Olanzapine tablets for Bipolar affe...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>155216</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bipolar affective disorder</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>34</td>\n",
              "      <td>60</td>\n",
              "      <td>Treatment: Olanzapine tablets for Bipolar affe...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>155216</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mental illness reaction</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>150</td>\n",
              "      <td>173</td>\n",
              "      <td>Treatment: Olanzapine tablets for Bipolar affe...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>155216</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pain</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>175</td>\n",
              "      <td>179</td>\n",
              "      <td>Treatment: Olanzapine tablets for Bipolar affe...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>155216</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>olanzapine</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>326</td>\n",
              "      <td>336</td>\n",
              "      <td>Treatment: Olanzapine tablets for Bipolar affe...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>155216</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416557</th>\n",
              "      <td>Cardiac arrest</td>\n",
              "      <td>EMERGENCY_TREATMENT</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>Cardiac arrest</td>\n",
              "      <td>lf:lf_emergency_treatment</td>\n",
              "      <td>97973</td>\n",
              "      <td>urgency</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416558</th>\n",
              "      <td>restored</td>\n",
              "      <td>POSITIVE_RESPONSE</td>\n",
              "      <td>38</td>\n",
              "      <td>46</td>\n",
              "      <td>Return of spontaneous circulation was restored</td>\n",
              "      <td>lf:lf_positive_response</td>\n",
              "      <td>97973</td>\n",
              "      <td>response</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416559</th>\n",
              "      <td>cardiac</td>\n",
              "      <td>CARDIOVASCULAR_TREATMENT</td>\n",
              "      <td>9</td>\n",
              "      <td>16</td>\n",
              "      <td>Advanced cardiac life support (ACLS) protocol</td>\n",
              "      <td>lf:lf_cardiovascular_treatment</td>\n",
              "      <td>97973</td>\n",
              "      <td>cardio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416560</th>\n",
              "      <td>Intravenous</td>\n",
              "      <td>HAS_TREATMENT</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>Intravenous nafcillin</td>\n",
              "      <td>lf:lf_has_treatment</td>\n",
              "      <td>97973</td>\n",
              "      <td>presence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416561</th>\n",
              "      <td>infection</td>\n",
              "      <td>INFECTION_TREATMENT</td>\n",
              "      <td>24</td>\n",
              "      <td>33</td>\n",
              "      <td>To treat S.\\nlugdunensis infection</td>\n",
              "      <td>lf:lf_infection_treatment</td>\n",
              "      <td>97973</td>\n",
              "      <td>infectious</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>416562 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                              text                     label  start  end  \\\n",
              "0                       Olanzapine                  CHEMICAL     11   21   \n",
              "1       Bipolar affective disorder                   DISEASE     34   60   \n",
              "2          mental illness reaction                   DISEASE    150  173   \n",
              "3                             Pain                   DISEASE    175  179   \n",
              "4                       olanzapine                  CHEMICAL    326  336   \n",
              "...                            ...                       ...    ...  ...   \n",
              "416557              Cardiac arrest       EMERGENCY_TREATMENT      0   14   \n",
              "416558                    restored         POSITIVE_RESPONSE     38   46   \n",
              "416559                     cardiac  CARDIOVASCULAR_TREATMENT      9   16   \n",
              "416560                 Intravenous             HAS_TREATMENT      0   11   \n",
              "416561                   infection       INFECTION_TREATMENT     24   33   \n",
              "\n",
              "                                            original_text  \\\n",
              "0       Treatment: Olanzapine tablets for Bipolar affe...   \n",
              "1       Treatment: Olanzapine tablets for Bipolar affe...   \n",
              "2       Treatment: Olanzapine tablets for Bipolar affe...   \n",
              "3       Treatment: Olanzapine tablets for Bipolar affe...   \n",
              "4       Treatment: Olanzapine tablets for Bipolar affe...   \n",
              "...                                                   ...   \n",
              "416557                                     Cardiac arrest   \n",
              "416558     Return of spontaneous circulation was restored   \n",
              "416559      Advanced cardiac life support (ACLS) protocol   \n",
              "416560                              Intravenous nafcillin   \n",
              "416561                 To treat S.\\nlugdunensis infection   \n",
              "\n",
              "                                source  row_idx    category  \n",
              "0                               bc5cdr   155216        None  \n",
              "1                               bc5cdr   155216        None  \n",
              "2                               bc5cdr   155216        None  \n",
              "3                               bc5cdr   155216        None  \n",
              "4                               bc5cdr   155216        None  \n",
              "...                                ...      ...         ...  \n",
              "416557       lf:lf_emergency_treatment    97973     urgency  \n",
              "416558         lf:lf_positive_response    97973    response  \n",
              "416559  lf:lf_cardiovascular_treatment    97973      cardio  \n",
              "416560             lf:lf_has_treatment    97973    presence  \n",
              "416561       lf:lf_infection_treatment    97973  infectious  \n",
              "\n",
              "[416562 rows x 8 columns]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_all_treatments_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155216</td>\n",
              "      <td>Sixteen years old</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133948</td>\n",
              "      <td>36 years old</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80176</td>\n",
              "      <td>49</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72232</td>\n",
              "      <td>47</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>31864</td>\n",
              "      <td>24 years</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>39279</td>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>137017</td>\n",
              "      <td>82</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>98004</td>\n",
              "      <td>54</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>133320</td>\n",
              "      <td>49</td>\n",
              "      <td>Woman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>97973</td>\n",
              "      <td>31</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29755 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          idx                age     sex\n",
              "0      155216  Sixteen years old  Female\n",
              "2      133948       36 years old  Female\n",
              "3       80176                 49    male\n",
              "4       72232                 47    Male\n",
              "5       31864           24 years  Female\n",
              "...       ...                ...     ...\n",
              "29995   39279                 28    male\n",
              "29996  137017                 82    Male\n",
              "29997   98004                 54    Male\n",
              "29998  133320                 49   Woman\n",
              "29999   97973                 31    male\n",
              "\n",
              "[29755 rows x 3 columns]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sex\n",
              "Female                                                             10077\n",
              "Male                                                                9974\n",
              "male                                                                4588\n",
              "Woman                                                               2486\n",
              "female                                                               993\n",
              "man                                                                  497\n",
              "woman                                                                391\n",
              "boy                                                                  190\n",
              "Boy                                                                   78\n",
              "Girl                                                                  77\n",
              "girl                                                                  72\n",
              "Man                                                                   68\n",
              "Gentleman                                                              7\n",
              "Trans man                                                              6\n",
              "gentleman                                                              6\n",
              "Trans woman                                                            5\n",
              "Neutered male                                                          4\n",
              "lady                                                                   3\n",
              "Entire male                                                            2\n",
              "Female neutered                                                        2\n",
              "Male for the first patient, Female for the second patient              2\n",
              "Male for both patients                                                 2\n",
              "Castrated male                                                         2\n",
              "Female phenotype                                                       1\n",
              "Twin A (sex not specified)                                             1\n",
              "Male and Female                                                        1\n",
              "Transgender woman                                                      1\n",
              "Not specified                                                          1\n",
              "Phenotypical male                                                      1\n",
              "Male (after legal gender change)                                       1\n",
              "Male (transgender)                                                     1\n",
              "Female (social gender)                                                 1\n",
              "Female (46,XX)                                                         1\n",
              "Lady                                                                   1\n",
              "Female, spayed                                                         1\n",
              "neutered male                                                          1\n",
              "Male for the second and third cases, Female for the fourth case        1\n",
              "Female spayed                                                          1\n",
              "Neutered female                                                        1\n",
              "Sex not specified                                                      1\n",
              "Two men and one woman                                                  1\n",
              "Female; Male; Male                                                     1\n",
              "Assigned female at birth, raised as male                               1\n",
              "Male; Female                                                           1\n",
              "Female / Male                                                          1\n",
              "One female and one male                                                1\n",
              "Female and Male                                                        1\n",
              "Cisgender woman                                                        1\n",
              "Brother (male) and sister (female)                                     1\n",
              "man, woman, woman                                                      1\n",
              "female spayed                                                          1\n",
              "Biological male                                                        1\n",
              "Male (Geminus A)                                                       1\n",
              "Male neutered                                                          1\n",
              "Female for Patient Case 1, Male for Patient Case 2                     1\n",
              "Assigned female at birth                                               1\n",
              "Designated female at birth, transitioned to male                       1\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_info['sex'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Standardized Sex Distribution:\n",
            "sex_standardized\n",
            "Male                15429\n",
            "Female              14129\n",
            "Multiple_Records        5\n",
            "Other                   3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Age Distribution:\n",
            "age_category\n",
            "Adult         19376\n",
            "Elderly        6153\n",
            "Child          2566\n",
            "Adolescent     1489\n",
            "Infant           89\n",
            "Unknown          82\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Special Cases:\n",
            "Veterinary cases: 13\n",
            "Multiple patient records: 5\n",
            "Complex age descriptions: 120\n"
          ]
        }
      ],
      "source": [
        "def standardize_sex(sex_str):\n",
        "    \"\"\"\n",
        "    Standardize sex/gender values based on the variations in your data.\n",
        "    \n",
        "    Special cases handled:\n",
        "    - Veterinary cases (neutered/castrated)\n",
        "    - Multiple patients in one record\n",
        "    - Trans individuals\n",
        "    - Various capitalizations and terms\n",
        "    \"\"\"\n",
        "    if pd.isna(sex_str):\n",
        "        return None\n",
        "    \n",
        "    sex_str = str(sex_str).strip().lower()\n",
        "    \n",
        "    # Handle multiple patients first\n",
        "    if 'both' in sex_str or 'second patient' in sex_str or 'patient case' in sex_str:\n",
        "        return 'Multiple_Patients'\n",
        "    \n",
        "    # Map variations to standard values\n",
        "    female_terms = ['female', 'woman', 'girl', 'lady']\n",
        "    male_terms = ['male', 'man', 'boy', 'gentleman']\n",
        "    \n",
        "    # Check for trans individuals\n",
        "    if 'trans' in sex_str:\n",
        "        if 'trans man' in sex_str or 'transitioned to male' in sex_str:\n",
        "            return 'Trans_Male'\n",
        "        elif 'trans woman' in sex_str:\n",
        "            return 'Trans_Female'\n",
        "    \n",
        "    # Check for assigned at birth\n",
        "    if 'assigned female at birth' in sex_str:\n",
        "        return 'AFAB'\n",
        "    \n",
        "    # Check for phenotype mentions\n",
        "    if 'phenotype' in sex_str:\n",
        "        if 'female' in sex_str:\n",
        "            return 'Female_Phenotype'\n",
        "    \n",
        "    # Check for veterinary cases (neutered/castrated)\n",
        "    if 'neutered' in sex_str or 'castrated' in sex_str or 'entire' in sex_str:\n",
        "        if any(term in sex_str for term in female_terms):\n",
        "            if 'neutered' in sex_str:\n",
        "                return 'Female_Neutered'\n",
        "            else:\n",
        "                return 'Female_Intact'\n",
        "        elif any(term in sex_str for term in male_terms):\n",
        "            if 'neutered' in sex_str or 'castrated' in sex_str:\n",
        "                return 'Male_Neutered'\n",
        "            else:\n",
        "                return 'Male_Intact'\n",
        "    \n",
        "    # Standard cases\n",
        "    for term in female_terms:\n",
        "        if term == sex_str:\n",
        "            return 'Female'\n",
        "    \n",
        "    for term in male_terms:\n",
        "        if term == sex_str:\n",
        "            return 'Male'\n",
        "    \n",
        "    # If we can't classify, return as unclassified\n",
        "    return 'Unclassified'\n",
        "\n",
        "\n",
        "def standardize_sex_simple(sex_str):\n",
        "    \"\"\"\n",
        "    Simplified version that maps to just Male/Female/Other categories\n",
        "    \"\"\"\n",
        "    if pd.isna(sex_str):\n",
        "        return None\n",
        "    \n",
        "    sex_str = str(sex_str).strip().lower()\n",
        "    \n",
        "    # Handle multiple patients\n",
        "    if 'both' in sex_str or 'second patient' in sex_str or 'patient case' in sex_str:\n",
        "        return 'Multiple_Records'\n",
        "    \n",
        "    # Simple mapping\n",
        "    female_terms = ['female', 'woman', 'girl', 'lady', 'trans woman', 'female phenotype']\n",
        "    male_terms = ['male', 'man', 'boy', 'gentleman', 'trans man']\n",
        "    \n",
        "    # Check for main terms\n",
        "    for term in female_terms:\n",
        "        if term in sex_str:\n",
        "            return 'Female'\n",
        "    \n",
        "    for term in male_terms:\n",
        "        if term in sex_str:\n",
        "            return 'Male'\n",
        "    \n",
        "    return 'Other'\n",
        "\n",
        "\n",
        "def extract_age_from_text(age_str):\n",
        "    \"\"\"\n",
        "    Extract numeric age from various text formats in your data.\n",
        "    \n",
        "    Handles cases like:\n",
        "    - Simple numbers: \"62\", \"35\"\n",
        "    - Years old format: \"18 yr old\", \"37-years old\"\n",
        "    - Written numbers: \"Sixteen years old\", \"Almost three-year old\"\n",
        "    - Complex cases: \"Initially 21 years old, 33 years old at last mention\"\n",
        "    - Age ranges: \"29 at first admission, 55 at the time of the last mentioned clinical examination\"\n",
        "    \"\"\"\n",
        "    if pd.isna(age_str):\n",
        "        return None\n",
        "    \n",
        "    age_str = str(age_str).strip()\n",
        "    \n",
        "    # First check if it's already a simple number\n",
        "    if age_str.isdigit():\n",
        "        return int(age_str)\n",
        "    \n",
        "    # Convert written numbers to digits\n",
        "    written_numbers = {\n",
        "        'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5,\n",
        "        'six': 6, 'seven': 7, 'eight': 8, 'nine': 9, 'ten': 10,\n",
        "        'eleven': 11, 'twelve': 12, 'thirteen': 13, 'fourteen': 14,\n",
        "        'fifteen': 15, 'sixteen': 16, 'seventeen': 17, 'eighteen': 18,\n",
        "        'nineteen': 19, 'twenty': 20, 'thirty': 30, 'forty': 40,\n",
        "        'fifty': 50, 'sixty': 60, 'seventy': 70, 'eighty': 80,\n",
        "        'ninety': 90\n",
        "    }\n",
        "    \n",
        "    # Replace written numbers with digits\n",
        "    age_str_lower = age_str.lower()\n",
        "    for word, num in written_numbers.items():\n",
        "        age_str_lower = age_str_lower.replace(word, str(num))\n",
        "    \n",
        "    # Handle compound written numbers (e.g., \"twenty-one\")\n",
        "    age_str_lower = re.sub(r'(\\d+)\\s*-\\s*(\\d+)', lambda m: str(int(m.group(1)) + int(m.group(2))), age_str_lower)\n",
        "    \n",
        "    # Extract all numbers from the text\n",
        "    numbers = re.findall(r'\\d+', age_str_lower)\n",
        "    \n",
        "    if not numbers:\n",
        "        return None\n",
        "    \n",
        "    # For multiple ages (patient history), typically want the first mentioned age\n",
        "    # You might want to change this logic based on your needs\n",
        "    if 'initially' in age_str_lower or 'first' in age_str_lower:\n",
        "        # Return the first number\n",
        "        return int(numbers[0])\n",
        "    elif 'last' in age_str_lower or 'current' in age_str_lower:\n",
        "        # Return the last number\n",
        "        return int(numbers[-1])\n",
        "    else:\n",
        "        # Default to first number found\n",
        "        return int(numbers[0])\n",
        "\n",
        "\n",
        "def get_age_category(age):\n",
        "    \"\"\"\n",
        "    Categorize age into standard medical categories\n",
        "    \"\"\"\n",
        "    if pd.isna(age):\n",
        "        return 'Unknown'\n",
        "    \n",
        "    if age < 2:\n",
        "        return 'Infant'\n",
        "    elif age < 13:\n",
        "        return 'Child'\n",
        "    elif age < 18:\n",
        "        return 'Adolescent'\n",
        "    elif age < 65:\n",
        "        return 'Adult'\n",
        "    else:\n",
        "        return 'Elderly'\n",
        "\n",
        "\n",
        "def standardize_demographics(df):\n",
        "    \"\"\"\n",
        "    Apply all standardization to the dataframe\n",
        "    \"\"\"\n",
        "    # Create a copy to avoid modifying original\n",
        "    df_clean = df.copy()\n",
        "    \n",
        "    # Standardize sex - both detailed and simple versions\n",
        "    df_clean['sex_detailed'] = df_clean['sex'].apply(standardize_sex)\n",
        "    df_clean['sex_standardized'] = df_clean['sex'].apply(standardize_sex_simple)\n",
        "    \n",
        "    # Extract numeric age\n",
        "    df_clean['age_numeric'] = df_clean['age'].apply(extract_age_from_text)\n",
        "    \n",
        "    # Add age category\n",
        "    df_clean['age_category'] = df_clean['age_numeric'].apply(get_age_category)\n",
        "    \n",
        "    # Create flags for special cases\n",
        "    df_clean['is_veterinary'] = df_clean['sex_detailed'].str.contains('Neutered|Intact', na=False)\n",
        "    df_clean['is_multiple_patients'] = df_clean['sex_detailed'] == 'Multiple_Patients'\n",
        "    df_clean['has_complex_age'] = df_clean['age'].str.contains('initially|first|last|mention', case=False, na=False)\n",
        "    \n",
        "    return df_clean\n",
        "\n",
        "\n",
        "    \n",
        "# Apply to your dataframe:\n",
        "df_info_clean = standardize_demographics(df_info)\n",
        "\n",
        "# View results:\n",
        "print(\"\\nStandardized Sex Distribution:\")\n",
        "print(df_info_clean['sex_standardized'].value_counts())\n",
        "print(\"\\nAge Distribution:\")\n",
        "print(df_info_clean['age_category'].value_counts())\n",
        "print(\"\\nSpecial Cases:\")\n",
        "print(f\"Veterinary cases: {df_info_clean['is_veterinary'].sum()}\")\n",
        "print(f\"Multiple patient records: {df_info_clean['is_multiple_patients'].sum()}\")\n",
        "print(f\"Complex age descriptions: {df_info_clean['has_complex_age'].sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>sex_detailed</th>\n",
              "      <th>sex_standardized</th>\n",
              "      <th>age_numeric</th>\n",
              "      <th>age_category</th>\n",
              "      <th>is_veterinary</th>\n",
              "      <th>is_multiple_patients</th>\n",
              "      <th>has_complex_age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155216</td>\n",
              "      <td>Sixteen years old</td>\n",
              "      <td>Female</td>\n",
              "      <td>Female</td>\n",
              "      <td>Female</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Child</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133948</td>\n",
              "      <td>36 years old</td>\n",
              "      <td>Female</td>\n",
              "      <td>Female</td>\n",
              "      <td>Female</td>\n",
              "      <td>36.0</td>\n",
              "      <td>Adult</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80176</td>\n",
              "      <td>49</td>\n",
              "      <td>male</td>\n",
              "      <td>Male</td>\n",
              "      <td>Male</td>\n",
              "      <td>49.0</td>\n",
              "      <td>Adult</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72232</td>\n",
              "      <td>47</td>\n",
              "      <td>Male</td>\n",
              "      <td>Male</td>\n",
              "      <td>Male</td>\n",
              "      <td>47.0</td>\n",
              "      <td>Adult</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>31864</td>\n",
              "      <td>24 years</td>\n",
              "      <td>Female</td>\n",
              "      <td>Female</td>\n",
              "      <td>Female</td>\n",
              "      <td>24.0</td>\n",
              "      <td>Adult</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>39279</td>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>Male</td>\n",
              "      <td>Male</td>\n",
              "      <td>28.0</td>\n",
              "      <td>Adult</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>137017</td>\n",
              "      <td>82</td>\n",
              "      <td>Male</td>\n",
              "      <td>Male</td>\n",
              "      <td>Male</td>\n",
              "      <td>82.0</td>\n",
              "      <td>Elderly</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>98004</td>\n",
              "      <td>54</td>\n",
              "      <td>Male</td>\n",
              "      <td>Male</td>\n",
              "      <td>Male</td>\n",
              "      <td>54.0</td>\n",
              "      <td>Adult</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>133320</td>\n",
              "      <td>49</td>\n",
              "      <td>Woman</td>\n",
              "      <td>Female</td>\n",
              "      <td>Female</td>\n",
              "      <td>49.0</td>\n",
              "      <td>Adult</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>97973</td>\n",
              "      <td>31</td>\n",
              "      <td>male</td>\n",
              "      <td>Male</td>\n",
              "      <td>Male</td>\n",
              "      <td>31.0</td>\n",
              "      <td>Adult</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29755 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          idx                age     sex sex_detailed sex_standardized  \\\n",
              "0      155216  Sixteen years old  Female       Female           Female   \n",
              "2      133948       36 years old  Female       Female           Female   \n",
              "3       80176                 49    male         Male             Male   \n",
              "4       72232                 47    Male         Male             Male   \n",
              "5       31864           24 years  Female       Female           Female   \n",
              "...       ...                ...     ...          ...              ...   \n",
              "29995   39279                 28    male         Male             Male   \n",
              "29996  137017                 82    Male         Male             Male   \n",
              "29997   98004                 54    Male         Male             Male   \n",
              "29998  133320                 49   Woman       Female           Female   \n",
              "29999   97973                 31    male         Male             Male   \n",
              "\n",
              "       age_numeric age_category  is_veterinary  is_multiple_patients  \\\n",
              "0              6.0        Child          False                 False   \n",
              "2             36.0        Adult          False                 False   \n",
              "3             49.0        Adult          False                 False   \n",
              "4             47.0        Adult          False                 False   \n",
              "5             24.0        Adult          False                 False   \n",
              "...            ...          ...            ...                   ...   \n",
              "29995         28.0        Adult          False                 False   \n",
              "29996         82.0      Elderly          False                 False   \n",
              "29997         54.0        Adult          False                 False   \n",
              "29998         49.0        Adult          False                 False   \n",
              "29999         31.0        Adult          False                 False   \n",
              "\n",
              "       has_complex_age  \n",
              "0                False  \n",
              "2                False  \n",
              "3                False  \n",
              "4                False  \n",
              "5                False  \n",
              "...                ...  \n",
              "29995            False  \n",
              "29996            False  \n",
              "29997            False  \n",
              "29998            False  \n",
              "29999            False  \n",
              "\n",
              "[29755 rows x 10 columns]"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_info_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1029121, 4) label\n",
            "AgeSex    707568\n",
            "Age       203321\n",
            "Sex       118232\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# df_info_clean has: idx, age, sex, sex_detailed, sex_standardized, age_numeric, ...\n",
        "\n",
        "info = df_info_clean.rename(columns={\"idx\":\"row_idx\"}).copy()\n",
        "\n",
        "def age_variants(n: int):\n",
        "    n = int(n)\n",
        "    return [\n",
        "        f\"{n} years old\", f\"{n} year old\",\n",
        "        f\"{n}-year-old\", f\"{n} yo\", f\"{n} y/o\", f\"aged {n}\"\n",
        "    ]\n",
        "\n",
        "SEX_SYNONYMS = {\n",
        "    \"female\": [\"female\", \"woman\", \"female patient\", \"women\"],\n",
        "    \"male\":   [\"male\", \"man\", \"male patient\", \"men\"],\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for r in info.itertuples(index=False):\n",
        "    rid = r.row_idx\n",
        "\n",
        "    # 1) Use the raw age text if present\n",
        "    if isinstance(r.age, str) and r.age.strip():\n",
        "        rows.append({\"row_idx\": rid, \"text\": r.age.strip(), \"label\": \"Age\", \"table\": \"info\"})\n",
        "\n",
        "    # 2) Generate common age variants from numeric\n",
        "    if pd.notna(r.age_numeric):\n",
        "        for t in age_variants(r.age_numeric):\n",
        "            rows.append({\"row_idx\": rid, \"text\": t, \"label\": \"Age\", \"table\": \"info\"})\n",
        "\n",
        "    # 3) Sex synonyms (driven by standardized sex if available)\n",
        "    sex_std = None\n",
        "    for s in (getattr(r, \"sex_standardized\", None), getattr(r, \"sex_detailed\", None), getattr(r, \"sex\", None)):\n",
        "        if isinstance(s, str) and s.strip():\n",
        "            sex_std = s.strip().lower()\n",
        "            break\n",
        "    if sex_std in SEX_SYNONYMS:\n",
        "        for t in SEX_SYNONYMS[sex_std]:\n",
        "            rows.append({\"row_idx\": rid, \"text\": t, \"label\": \"Sex\", \"table\": \"info\"})\n",
        "\n",
        "        # 4) Age+sex combos (very common in narratives, e.g., \"36-year-old female\")\n",
        "        if pd.notna(r.age_numeric):\n",
        "            for av in age_variants(r.age_numeric):\n",
        "                for sx in SEX_SYNONYMS[sex_std]:\n",
        "                    rows.append({\"row_idx\": rid, \"text\": f\"{av} {sx}\", \"label\": \"AgeSex\", \"table\": \"info\"})\n",
        "\n",
        "df_info_entities = pd.DataFrame(rows).drop_duplicates([\"row_idx\",\"text\",\"label\"])\n",
        "print(df_info_entities.shape, df_info_entities.label.value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total entities across all tables: 2,473,487\n",
            "\n",
            "Entity distribution by table:\n",
            "table\n",
            "info             1029121\n",
            "treatments        416562\n",
            "diagnosis         400811\n",
            "symptoms          383863\n",
            "surgery           186191\n",
            "physiological      51759\n",
            "psychological       3402\n",
            "allergies            934\n",
            "drug_usage           715\n",
            "vaccination          129\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Entity types found:\n",
            "label\n",
            "AgeSex                                   707568\n",
            "DISEASE                                  281269\n",
            "Age                                      203321\n",
            "ANATOMY                                  125649\n",
            "Sex                                      118232\n",
            "                                          ...  \n",
            "AMINO_ACID                                  111\n",
            "ANATOMY_WITH_LATERALITY_AND_DIRECTION        52\n",
            "ANATOMICAL_SYSTEM                            48\n",
            "NO_FRACTURE                                  19\n",
            "DEVELOPING_ANATOMICAL_STRUCTURE               1\n",
            "Name: count, Length: 91, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "all_entities = pd.concat([\n",
        "    df_all_physiological_entities.assign(table='physiological'),\n",
        "    df_psychological_entities.assign(table='psychological'),\n",
        "    df_vaccination_entities.assign(table='vaccination'),\n",
        "    df_allergies_entities.assign(table='allergies'),\n",
        "    df_drug_usage_entities.assign(table='drug_usage'),\n",
        "    df_all_surgery_entities.assign(table='surgery'),\n",
        "    df_all_symptom_entities.assign(table='symptoms'),\n",
        "    df_all_diagnosis_entities.assign(table='diagnosis'),\n",
        "    df_all_treatments_entities.assign(table='treatments'),\n",
        "    df_info_entities.assign(table='info')\n",
        "], ignore_index=True)\n",
        "\n",
        "print(f\"Total entities across all tables: {len(all_entities):,}\")\n",
        "print(\"\\nEntity distribution by table:\")\n",
        "print(all_entities['table'].value_counts())\n",
        "print(\"\\nEntity types found:\")\n",
        "print(all_entities['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['DISEASE', 'CHEMICAL', 'ANATOMY_WITH_LATERALITY', 'ANATOMY',\n",
              "       'ANATOMY_WITH_DIRECTION', 'ANATOMY_WITH_LATERALITY_AND_DIRECTION',\n",
              "       'MUSCULOSKELETAL', 'BILATERAL_CONDITION', 'CARDIAC_ANATOMY',\n",
              "       'NEUROLOGICAL_ANATOMY', 'PATHOLOGICAL_FORMATION',\n",
              "       'MULTI_TISSUE_STRUCTURE', 'TISSUE', 'ORGANISM_SUBDIVISION', 'CELL',\n",
              "       'ORGAN', 'CANCER', 'ORGANISM_SUBSTANCE', 'ORGANISM',\n",
              "       'IMMATERIAL_ANATOMICAL_ENTITY', 'GENE_OR_GENE_PRODUCT',\n",
              "       'SIMPLE_CHEMICAL', 'CELLULAR_COMPONENT', 'AMINO_ACID',\n",
              "       'ANATOMICAL_SYSTEM', 'DEVELOPING_ANATOMICAL_STRUCTURE',\n",
              "       'PROCEDURE', 'LATERALITY', 'HIP_SURGERY', 'FRACTURE_SURGERY',\n",
              "       'MINIMALLY_INVASIVE', 'KNEE_SURGERY', 'BILATERAL_PROCEDURE',\n",
              "       'EMERGENCY_SURGERY', 'SYMPTOM', 'SYMPTOM_TYPE', 'SEVERITY',\n",
              "       'TEMPORAL_PATTERN', 'CHRONIC_SYMPTOM', 'BACK_PAIN', 'SEVERE_PAIN',\n",
              "       'HIP_PAIN', 'MOBILITY_ISSUE', 'LOCALIZED_PAIN',\n",
              "       'BILATERAL_SYMPTOM', 'KNEE_PAIN', 'NEUROLOGICAL',\n",
              "       'PROGRESSIVE_SYMPTOM', 'SYSTEMIC_SYMPTOM', 'ACUTE_ONSET', 'TEST',\n",
              "       'TEST_TYPE', 'FINDING', 'CONDITION', 'MEASUREMENT', 'IMAGING_TEST',\n",
              "       'BONE_PATHOLOGY', 'INFLAMMATORY_FINDING', 'FRACTURE_PRESENT',\n",
              "       'NORMAL_FINDING', 'BILATERAL_FINDING', 'NEOPLASTIC_FINDING',\n",
              "       'VASCULAR_FINDING', 'FOLLOWUP_NEEDED', 'CRITICAL_FINDING',\n",
              "       'NO_FRACTURE', 'TREATMENT', 'TREATMENT_TYPE', 'MEDICATION',\n",
              "       'DOSAGE', 'FREQUENCY', 'TREATMENT_RESPONSE', 'CONDITION_TYPE',\n",
              "       'TREATMENT_REASON', 'ROUTE', 'HAS_TREATMENT',\n",
              "       'MEDICATION_TREATMENT', 'PSYCHIATRIC_TREATMENT',\n",
              "       'CHRONIC_TREATMENT', 'DAILY_MEDICATION',\n",
              "       'TREATMENT_DURATION_MENTIONED', 'POSITIVE_RESPONSE',\n",
              "       'CONSERVATIVE_TREATMENT', 'SURGICAL_TREATMENT', 'CANCER_TREATMENT',\n",
              "       'CARDIOVASCULAR_TREATMENT', 'INFECTION_TREATMENT',\n",
              "       'EMERGENCY_TREATMENT', 'Age', 'Sex', 'AgeSex'], dtype=object)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_entities['label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "ROOT = Path.cwd().parent\n",
        "all_entities_filepath = ROOT/\"data\"/ \"clean\"/'all_entities.csv'\n",
        "all_entities.to_csv(all_entities_filepath, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>source</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>category</th>\n",
              "      <th>table</th>\n",
              "      <th>source_column</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>posttraumatic arthritis</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>48.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>History of left elbow arthrodesis performed fo...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>80176</td>\n",
              "      <td>None</td>\n",
              "      <td>physiological</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pain</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>116.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>Inability to walk since babyhood, did not walk...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>31864</td>\n",
              "      <td>None</td>\n",
              "      <td>physiological</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fracture</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>151.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>Inability to walk since babyhood, did not walk...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>31864</td>\n",
              "      <td>None</td>\n",
              "      <td>physiological</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Coxa vara deformity</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>Coxa vara deformity of bilateral hips, bilater...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>149866</td>\n",
              "      <td>None</td>\n",
              "      <td>physiological</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fracture</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>75.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>Coxa vara deformity of bilateral hips, bilater...</td>\n",
              "      <td>bc5cdr</td>\n",
              "      <td>149866</td>\n",
              "      <td>None</td>\n",
              "      <td>physiological</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      text    label  start    end  \\\n",
              "0  posttraumatic arthritis  DISEASE   48.0   71.0   \n",
              "1                     pain  DISEASE  116.0  120.0   \n",
              "2                 fracture  DISEASE  151.0  159.0   \n",
              "3      Coxa vara deformity  DISEASE    0.0   19.0   \n",
              "4                 fracture  DISEASE   75.0   83.0   \n",
              "\n",
              "                                       original_text  source  row_idx  \\\n",
              "0  History of left elbow arthrodesis performed fo...  bc5cdr    80176   \n",
              "1  Inability to walk since babyhood, did not walk...  bc5cdr    31864   \n",
              "2  Inability to walk since babyhood, did not walk...  bc5cdr    31864   \n",
              "3  Coxa vara deformity of bilateral hips, bilater...  bc5cdr   149866   \n",
              "4  Coxa vara deformity of bilateral hips, bilater...  bc5cdr   149866   \n",
              "\n",
              "  category          table source_column  \n",
              "0     None  physiological           NaN  \n",
              "1     None  physiological           NaN  \n",
              "2     None  physiological           NaN  \n",
              "3     None  physiological           NaN  \n",
              "4     None  physiological           NaN  "
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_entities.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### NER Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Stage 1: Configuration for Data Ingestion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TEXT_COL = \"note\"        # main note column\n",
        "MODEL_NAME = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "MAX_LEN = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_lean_file = ROOT / \"data\" / \"clean\" / \"augmented_notes_30K.csv\"\n",
        "df_lean = pd.read_csv(df_lean_file).reset_index(drop=True)\n",
        "df_lean.head()\n",
        "df_lean = df_lean[[\"idx\", TEXT_COL]].dropna(subset=[TEXT_COL]).copy()\n",
        "df_lean[TEXT_COL] = df_lean[TEXT_COL].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_entities = all_entities.rename(columns={\"row_idx\": \"idx\"})\n",
        "all_entities = all_entities[[\"idx\",\"text\", \"label\", \"start\",\"end\", \"table\", \"original_text\"]].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Label Mapping for Silver Spanning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "LABEL_MAP = {\n",
        "    # Problems\n",
        "    \"DISEASE\":\"Problem\",\"SYMPTOM\":\"Problem\",\"CONDITION\":\"Problem\",\"CONDITION_TYPE\":\"Problem\",\"CANCER\":\"Problem\",\"FINDING\":\"Problem\",\n",
        "    # Anatomy\n",
        "    \"ANATOMY\":\"Anatomy\",\"ANATOMY_WITH_LATERALITY\":\"Anatomy\",\"TISSUE\":\"Anatomy\",\"MULTI_TISSUE_STRUCTURE\":\"Anatomy\",\"ORGAN\":\"Anatomy\",\n",
        "    \"ANATOMICAL_SYSTEM\":\"Anatomy\",\"ORGANISM_SUBDIVISION\":\"Anatomy\",\"DEVELOPING_ANATOMICAL_STRUCTURE\":\"Anatomy\",\"IMMATERIAL_ANATOMICAL_ENTITY\":\"Anatomy\",\n",
        "    \"CELL\":\"Anatomy\",\"CELLULAR_COMPONENT\":\"Anatomy\",\n",
        "    # Meds / substances\n",
        "    \"CHEMICAL\":\"Medication\",\"SIMPLE_CHEMICAL\":\"Medication\",\"MEDICATION\":\"Medication\",\n",
        "    \"GENE_OR_GENE_PRODUCT\":\"Substance\",\"AMINO_ACID\":\"Substance\",\"ORGANISM\":\"Substance\",\"ORGANISM_SUBSTANCE\":\"Substance\",\n",
        "    # Procedures/tests\n",
        "    \"PROCEDURE\":\"Procedure\",\"TEST\":\"TestName\",\"TEST_TYPE\":\"TestType\",\n",
        "    # Modifiers\n",
        "    \"LATERALITY\":\"Laterality\",\"SEVERITY\":\"Severity\",\"TEMPORAL_PATTERN\":\"TemporalPattern\",\"MEASUREMENT\":\"Measurement\",\n",
        "    # Treatment related\n",
        "    \"TREATMENT\":\"TreatmentName\",\"TREATMENT_TYPE\":\"TreatmentType\",\"TREATMENT_RESPONSE\":\"TreatmentResponse\",\"TREATMENT_REASON\":\"TreatmentReason\",\n",
        "    # Dosing\n",
        "    \"DOSAGE\":\"Dosage\",\"FREQUENCY\":\"Frequency\",\"ROUTE\":\"Route\",\n",
        "    # Symptom subtype\n",
        "    \"SYMPTOM_TYPE\":\"Problem\",\n",
        "    # Info\n",
        "    \"AGE\":\"Age\",\"SEX\":\"Sex\",\"AGESEX\":\"AgeSex\",\"AGE_SEX\":\"AgeSex\",\n",
        "}\n",
        "ALLOWED_LABELS = {\n",
        "    \"Problem\",\"Anatomy\",\"Medication\",\"Procedure\",\"TestName\",\"TestType\",\"Laterality\",\"Severity\",\"TemporalPattern\",\n",
        "    \"Measurement\",\"Dosage\",\"Frequency\",\"Route\",\"TreatmentName\",\"TreatmentType\",\"TreatmentResponse\",\"TreatmentReason\",\"Age\",\"Sex\",\"AgeSex\"\n",
        "}\n",
        "\n",
        "def normalize_label(lbl: str) -> str:\n",
        "    if not isinstance(lbl, str):\n",
        "        return \"\"\n",
        "    base = lbl.strip().upper()\n",
        "    base = LABEL_MAP.get(base, base)\n",
        "    # normalize exact cases for final schema\n",
        "    if base in {\"AGE\",\"SEX\",\"AGESEX\"}:\n",
        "        return {\"AGE\":\"Age\",\"SEX\":\"Sex\",\"AGESEX\":\"AgeSex\"}[base]\n",
        "    return base\n",
        "\n",
        "def normalize_phrase(s: str) -> str:\n",
        "    return re.sub(r\"\\s+\", \" \", str(s).strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Stage 2: Labeling Functions & Probes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PROBE] Surgery combined_text probes: rows=35864\n",
            "  - contains /\\bhip\\b/ : 506\n",
            "    examples:\n",
            "     · idiopathic osteonecrosis of the femoral head total hip arthroplasty (tha) first tha on the left hip discharged in good c …\n",
            "     · pain and limited rom in the contralateral hip joint total hip arthroplasty (tha) second tha on the contralateral hip dis …\n",
            "     · femoral neck fracture with dislocation of the femoral head into the pelvis hip surgery with lateral approach and anterio …\n",
            "     · fistula injury of the ipsilateral ureter urological evaluation and surgery moore prosthesis extracted, hip debrided and  …\n",
            "     · severe osteoarthritis pain total left hip arthroplasty nan nan …\n",
            "     · extensive femoral bone loss with displacement of the femoral component, femoral pseudo-tumor revision total hip arthropl …\n",
            "     · severe osteoarthritis pain that hindered baseline activities total left hip arthroplasty nan nan …\n",
            "     · extensive femoral bone loss with displacement of the femoral component, femoral pseudo-tumor revision total hip arthropl …\n",
            "  - contains /\\barthroplasty\\b/ : 291\n",
            "  - contains /\\breplacement\\b/ : 757\n",
            "  - contains /\\bfracture\\b/ : 1316\n",
            "  - contains /\\bfixation\\b/ : 980\n",
            "  - contains /\\brepair\\b/ : 1412\n",
            "  - contains /\\bbilateral\\b/ : 1272\n",
            "[PROBE] Symptoms combined_text probes: rows=54944\n",
            "  - contains /\\bpain\\b/ : 12875\n",
            "    examples:\n",
            "     · pain with severe intensity located in left hip joint lasting persisting for two months increased over the following thre …\n",
            "     · pain with nan intensity located in left proximal forearm lasting after a fall nan patient was tender at the proximal uln …\n",
            "     · pain with severe intensity located in medial aspect of the left knee, lateral aspect of the left knee, medial side of th …\n",
            "     · inability to walk with severe intensity located in legs lasting last 4 years chronic and worsening associated with sever …\n",
            "     · inability to walk with nan intensity located in both lower limbs lasting last 3 months initially able to walk with a lim …\n",
            "     · pain with severe intensity located in right temporomandibular joint (tmj) region, right ear lasting nan nan mouth openin …\n",
            "     · abdominal pain with acute intensity located in abdomen lasting sudden onset nan no abdominal symptoms at the time of sur …\n",
            "     · pain with nan intensity located in thigh lasting 3 months into the postoperative period nan patient reported to emergenc …\n",
            "  - contains /\\bsevere\\b/ : 4777\n",
            "  - contains /\\bchronic\\b/ : 642\n",
            "  - contains /\\bacute\\b/ : 1301\n",
            "  - contains /\\bbilateral\\b/ : 1472\n",
            "  - contains /\\bhip\\b/ : 712\n",
            "  - contains /\\bknee\\b/ : 1082\n",
            "  - contains /\\bback\\b/ : 1959\n",
            "[PROBE] Diagnosis combined_text probes: rows=61355\n",
            "  - contains /\\bmri\\b/ : 5376\n",
            "    examples:\n",
            "     · magnetic resonance imaging (mri) scan performed with nan severity showed increased amount of joint fluid and bone marrow …\n",
            "     · repeat mri performed with nan severity showed similar findings to those noted previously in the left hip indicating nan  …\n",
            "     · mri performed with moderate-sized severity showed focal area of marrow edema/contusion involving the medial femoral cond …\n",
            "     · cerebral magnetic resonance imaging (mri) performed with nan severity showed nan indicating simple skin lesion performed …\n",
            "     · mri scan performed with nan severity showed no evidence of spinal cord pathology indicating initially suspected acute di …\n",
            "     · mri performed with nan severity showed mesenchymal component in an encapsulated mass indicating possibility of a liposar …\n",
            "     · mri examination performed with nan severity showed nan indicating nan the mri examination result is not provided in the  …\n",
            "     · mri of head and neck performed with nan severity showed identified the limits of the malformation and the key vessel ind …\n",
            "  - contains /\\bct\\b/ : 9987\n",
            "  - contains /\\bx-ray\\b/ : 1534\n",
            "  - contains /\\bradiograph\\b/ : 940\n",
            "  - contains /\\bfracture\\b/ : 1547\n",
            "  - contains /\\btumor\\b/ : 3668\n",
            "  - contains /\\bnormal\\b/ : 7021\n",
            "  - contains /\\bcritical\\b/ : 38\n",
            "[PROBE] Treatments combined_text probes: rows=50426\n",
            "  - contains /\\bemergency\\b/ : 877\n",
            "    examples:\n",
            "     · treatment: intravenous morphine for chest pain reason: to alleviate chest pain in the emergency room reaction: chest pai …\n",
            "     · treatment: diltiazem infusion for atrial fibrillation with rapid ventricular rate time in the emergency department reaso …\n",
            "     · treatment: monitoring for possible emergency intervention with an endobronchial stent for complete collapse of the left  …\n",
            "     · treatment: intubation and sedation for airway protection due to low glasgow coma scale dosage dosage not specified time  …\n",
            "     · treatment: open reduction and internal fixation for fibula and talus dislocation time same day as presentation to the em …\n",
            "     · treatment: intravenous antihypertensive medications for pre-eclampsia with severe features reason: to manage severe bloo …\n",
            "     · treatment: emergency consultation, rapid hemodynamic stabilization for poor general condition, severe maxillofacial trau …\n",
            "     · treatment: tiquizium bromide for initially suspected gastrointestinal tract spasm time after first visiting another hosp …\n",
            "  - contains /\\bshock\\b/ : 485\n",
            "  - contains /\\bchemotherapy\\b/ : 1802\n",
            "  - contains /\\bantibiotic\\b/ : 1070\n",
            "  - contains /\\bmorphine\\b/ : 154\n",
            "  - contains /\\bsurgery\\b/ : 4546\n",
            "[Stage 2] Signals index: (29755, 44)\n",
            "Any surgery.* flags? True\n",
            "Any symptoms.* flags? True\n",
            "Any diagnosis.* flags? True\n",
            "Any treatments.* flags? True\n",
            "[Stage 2] Examples with provenance (first 10):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>surgery.BILATERAL_PROCEDURE</th>\n",
              "      <th>surgery.EMERGENCY_SURGERY</th>\n",
              "      <th>surgery.FRACTURE_SURGERY</th>\n",
              "      <th>surgery.HIP_SURGERY</th>\n",
              "      <th>surgery.KNEE_SURGERY</th>\n",
              "      <th>surgery.MINIMALLY_INVASIVE</th>\n",
              "      <th>symptoms.ACUTE_ONSET</th>\n",
              "      <th>symptoms.BACK_PAIN</th>\n",
              "      <th>symptoms.BILATERAL_SYMPTOM</th>\n",
              "      <th>...</th>\n",
              "      <th>treatments.DAILY_MEDICATION</th>\n",
              "      <th>treatments.EMERGENCY_TREATMENT</th>\n",
              "      <th>treatments.HAS_TREATMENT</th>\n",
              "      <th>treatments.INFECTION_TREATMENT</th>\n",
              "      <th>treatments.MEDICATION_TREATMENT</th>\n",
              "      <th>treatments.POSITIVE_RESPONSE</th>\n",
              "      <th>treatments.PSYCHIATRIC_TREATMENT</th>\n",
              "      <th>treatments.SURGICAL_TREATMENT</th>\n",
              "      <th>treatments.TREATMENT_DURATION_MENTIONED</th>\n",
              "      <th>lf_provenance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[lf_pain_with_location=&gt;LOCALIZED_PAIN, lf_ima...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[lf_chronic_symptom=&gt;CHRONIC_SYMPTOM, lf_acute...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[lf_bilateral_symptom=&gt;BILATERAL_SYMPTOM, lf_m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[lf_neurological_symptom=&gt;NEUROLOGICAL, lf_neu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>91</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[lf_has_treatment=&gt;HAS_TREATMENT, lf_cardiovas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>94</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[lf_bilateral_procedure=&gt;BILATERAL_PROCEDURE, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>104</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[lf_has_treatment=&gt;HAS_TREATMENT, lf_medicatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>156</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[lf_chronic_symptom=&gt;CHRONIC_SYMPTOM, lf_has_t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>169</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[lf_pain_with_location=&gt;LOCALIZED_PAIN, lf_pai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>171</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[lf_pain_with_location=&gt;LOCALIZED_PAIN, lf_neu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 44 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   idx  surgery.BILATERAL_PROCEDURE  surgery.EMERGENCY_SURGERY  \\\n",
              "0   14                            0                          0   \n",
              "1   21                            0                          0   \n",
              "2   41                            0                          0   \n",
              "3   48                            0                          0   \n",
              "4   91                            0                          0   \n",
              "5   94                            1                          0   \n",
              "6  104                            0                          0   \n",
              "7  156                            0                          0   \n",
              "8  169                            0                          0   \n",
              "9  171                            0                          0   \n",
              "\n",
              "   surgery.FRACTURE_SURGERY  surgery.HIP_SURGERY  surgery.KNEE_SURGERY  \\\n",
              "0                         0                    0                     0   \n",
              "1                         0                    0                     0   \n",
              "2                         0                    0                     0   \n",
              "3                         0                    0                     0   \n",
              "4                         0                    0                     0   \n",
              "5                         0                    0                     0   \n",
              "6                         0                    0                     0   \n",
              "7                         0                    0                     0   \n",
              "8                         0                    0                     0   \n",
              "9                         0                    0                     0   \n",
              "\n",
              "   surgery.MINIMALLY_INVASIVE  symptoms.ACUTE_ONSET  symptoms.BACK_PAIN  \\\n",
              "0                           0                     0                   0   \n",
              "1                           0                     1                   0   \n",
              "2                           0                     0                   0   \n",
              "3                           0                     0                   0   \n",
              "4                           0                     0                   0   \n",
              "5                           0                     0                   0   \n",
              "6                           0                     0                   0   \n",
              "7                           0                     0                   0   \n",
              "8                           0                     0                   0   \n",
              "9                           0                     0                   0   \n",
              "\n",
              "   symptoms.BILATERAL_SYMPTOM  ...  treatments.DAILY_MEDICATION  \\\n",
              "0                           0  ...                            0   \n",
              "1                           0  ...                            0   \n",
              "2                           1  ...                            0   \n",
              "3                           1  ...                            0   \n",
              "4                           0  ...                            0   \n",
              "5                           0  ...                            0   \n",
              "6                           0  ...                            0   \n",
              "7                           0  ...                            1   \n",
              "8                           0  ...                            0   \n",
              "9                           0  ...                            0   \n",
              "\n",
              "   treatments.EMERGENCY_TREATMENT  treatments.HAS_TREATMENT  \\\n",
              "0                               0                         1   \n",
              "1                               0                         1   \n",
              "2                               0                         1   \n",
              "3                               0                         1   \n",
              "4                               0                         1   \n",
              "5                               0                         1   \n",
              "6                               0                         1   \n",
              "7                               0                         1   \n",
              "8                               0                         1   \n",
              "9                               0                         1   \n",
              "\n",
              "   treatments.INFECTION_TREATMENT  treatments.MEDICATION_TREATMENT  \\\n",
              "0                               0                                0   \n",
              "1                               0                                0   \n",
              "2                               0                                0   \n",
              "3                               0                                0   \n",
              "4                               0                                0   \n",
              "5                               0                                0   \n",
              "6                               0                                1   \n",
              "7                               0                                1   \n",
              "8                               0                                0   \n",
              "9                               0                                0   \n",
              "\n",
              "   treatments.POSITIVE_RESPONSE  treatments.PSYCHIATRIC_TREATMENT  \\\n",
              "0                             0                                 0   \n",
              "1                             0                                 0   \n",
              "2                             0                                 0   \n",
              "3                             0                                 0   \n",
              "4                             0                                 0   \n",
              "5                             0                                 0   \n",
              "6                             0                                 0   \n",
              "7                             0                                 0   \n",
              "8                             0                                 0   \n",
              "9                             1                                 0   \n",
              "\n",
              "   treatments.SURGICAL_TREATMENT  treatments.TREATMENT_DURATION_MENTIONED  \\\n",
              "0                              0                                        0   \n",
              "1                              0                                        1   \n",
              "2                              0                                        1   \n",
              "3                              0                                        0   \n",
              "4                              0                                        0   \n",
              "5                              0                                        0   \n",
              "6                              1                                        0   \n",
              "7                              0                                        0   \n",
              "8                              0                                        0   \n",
              "9                              0                                        0   \n",
              "\n",
              "                                       lf_provenance  \n",
              "0  [lf_pain_with_location=>LOCALIZED_PAIN, lf_ima...  \n",
              "1  [lf_chronic_symptom=>CHRONIC_SYMPTOM, lf_acute...  \n",
              "2  [lf_bilateral_symptom=>BILATERAL_SYMPTOM, lf_m...  \n",
              "3  [lf_neurological_symptom=>NEUROLOGICAL, lf_neu...  \n",
              "4  [lf_has_treatment=>HAS_TREATMENT, lf_cardiovas...  \n",
              "5  [lf_bilateral_procedure=>BILATERAL_PROCEDURE, ...  \n",
              "6  [lf_has_treatment=>HAS_TREATMENT, lf_medicatio...  \n",
              "7  [lf_chronic_symptom=>CHRONIC_SYMPTOM, lf_has_t...  \n",
              "8  [lf_pain_with_location=>LOCALIZED_PAIN, lf_pai...  \n",
              "9  [lf_pain_with_location=>LOCALIZED_PAIN, lf_neu...  \n",
              "\n",
              "[10 rows x 44 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coverage (sampled):\n",
            "  Surgery  : {'lf_hip_surgery': '34/2000 = 1.7%', 'lf_knee_surgery': '29/2000 = 1.4%', 'lf_fracture_surgery': '86/2000 = 4.3%', 'lf_bilateral_procedure': '71/2000 = 3.5%', 'lf_minimally_invasive': '98/2000 = 4.9%', 'lf_emergency_procedure': '35/2000 = 1.8%'}\n",
            "  Symptoms : {'lf_severe_pain': '127/2000 = 6.3%', 'lf_chronic_symptom': '440/2000 = 22.0%', 'lf_neurological_symptom': '158/2000 = 7.9%', 'lf_bilateral_symptom': '57/2000 = 2.9%', 'lf_acute_onset': '103/2000 = 5.2%', 'lf_progressive_symptom': '189/2000 = 9.4%', 'lf_mobility_issue': '54/2000 = 2.7%', 'lf_pain_with_location': '1399/2000 = 70.0%', 'lf_systemic_symptom': '112/2000 = 5.6%'}\n",
            "  Diagnosis: {'lf_imaging_test': '638/2000 = 31.9%', 'lf_fracture_diagnosis': '91/2000 = 4.5%', 'lf_neoplastic_finding': '440/2000 = 22.0%', 'lf_normal_finding': '232/2000 = 11.6%', 'lf_critical_finding': '28/2000 = 1.4%', 'lf_bone_pathology': '132/2000 = 6.6%', 'lf_vascular_finding': '242/2000 = 12.1%', 'lf_inflammatory_finding': '78/2000 = 3.9%', 'lf_bilateral_finding': '40/2000 = 2.0%', 'lf_followup_needed': '11/2000 = 0.6%'}\n",
            "  Treatment: {'lf_has_treatment': '1744/2000 = 87.2%', 'lf_medication_treatment': '219/2000 = 10.9%', 'lf_surgical_treatment': '227/2000 = 11.3%', 'lf_emergency_treatment': '38/2000 = 1.9%', 'lf_cancer_treatment': '201/2000 = 10.1%', 'lf_psychiatric_treatment': '16/2000 = 0.8%', 'lf_chronic_treatment': '136/2000 = 6.8%', 'lf_daily_medication': '78/2000 = 3.9%', 'lf_positive_response': '115/2000 = 5.8%', 'lf_conservative_treatment': '56/2000 = 2.8%', 'lf_infection_treatment': '101/2000 = 5.0%', 'lf_cardiovascular_treatment': '22/2000 = 1.1%', 'lf_treatment_duration': '286/2000 = 14.3%'}\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# Stage 2 — robust LF signals + probes\n",
        "# =========================\n",
        "\n",
        "ABSTAIN = \"ABSTAIN\"\n",
        "USE_PREFILTER = False  \n",
        "\n",
        "def _is_abstain(x):\n",
        "    if isinstance(x, dict):\n",
        "        return x.get('label', 'ABSTAIN').upper() == 'ABSTAIN'\n",
        "    return (not isinstance(x, str)) or (x.strip() == \"\") or (x.strip().upper() == \"ABSTAIN\")\n",
        "\n",
        "def _norm_bool(s):\n",
        "    \"\"\"Treat True/1/yes/'true' as True; works if the column is string or bool.\"\"\"\n",
        "    return s.astype(str).str.lower().isin([\"true\",\"1\",\"yes\",\"y\"])\n",
        "\n",
        "def _probe_keywords(df, col, patterns, title, n_show=8):\n",
        "    if col not in df.columns:\n",
        "        print(f\"[PROBE] {title}: '{col}' missing\")\n",
        "        return\n",
        "    s = df[col].astype(str).str.lower()\n",
        "    print(f\"[PROBE] {title}: rows={len(df)}\")\n",
        "    found_any = False\n",
        "    for p in patterns:\n",
        "        m = s.str.contains(p, na=False, regex=True)\n",
        "        cnt = int(m.sum())\n",
        "        print(f\"  - contains /{p}/ : {cnt}\")\n",
        "        if cnt and not found_any:\n",
        "            # show a few examples\n",
        "            print(\"    examples:\")\n",
        "            for t in s[m].head(n_show):\n",
        "                print(\"     ·\", t[:120], \"…\")\n",
        "            found_any = True\n",
        "    if not found_any:\n",
        "        print(\"  (no examples matched any probe pattern)\")\n",
        "\n",
        "def build_signals_table_dynamic(df, lfs, namespace: str, id_col='idx'):\n",
        "    \"\"\"\n",
        "    Iterate full df, collect fired labels dynamically, and materialize a wide signals table.\n",
        "    Adds 'lf_provenance' list per idx (lf_name=>label).\n",
        "    \"\"\"\n",
        "    import math\n",
        "    from collections import defaultdict\n",
        "    if df is None or len(df) == 0:\n",
        "        return pd.DataFrame({id_col: []}), []\n",
        "\n",
        "    assert id_col in df.columns, f\"{namespace} df must contain '{id_col}'\"\n",
        "\n",
        "    idx2cols   = defaultdict(set)\n",
        "    idx2prov   = defaultdict(list)\n",
        "    all_cols   = set()\n",
        "\n",
        "    # Iterate rows (no sampling)\n",
        "    for _, row in df.iterrows():\n",
        "        idx = row[id_col]\n",
        "        for lf in lfs:\n",
        "            try:\n",
        "                out = lf(row)\n",
        "            except Exception:\n",
        "                continue\n",
        "            \n",
        "            # Extract label from dict if needed\n",
        "            if isinstance(out, dict):\n",
        "                label = out.get('label', 'ABSTAIN')\n",
        "            else:\n",
        "                label = out\n",
        "                \n",
        "            if not _is_abstain(label):\n",
        "                col = f\"{namespace}.{label}\"\n",
        "                all_cols.add(col)\n",
        "                idx2cols[idx].add(col)\n",
        "                idx2prov[idx].append(f\"{lf.__name__}=>{label}\")\n",
        "\n",
        "    sig = pd.DataFrame({id_col: df[id_col].drop_duplicates().values})\n",
        "    for col in sorted(all_cols):\n",
        "        sig[col] = sig[id_col].map(lambda i: 1 if col in idx2cols.get(i, set()) else 0).astype(int)\n",
        "    sig[\"lf_provenance\"] = sig[id_col].map(lambda i: idx2prov.get(i, []))\n",
        "    labels = sorted({c.split(\".\", 1)[1] for c in all_cols})\n",
        "    return sig, labels\n",
        "\n",
        "def unify_signals_safe(*signals, id_col='idx'):\n",
        "    frames = [s for s in signals if s is not None and len(s) > 0]\n",
        "    if not frames:\n",
        "        return pd.DataFrame({id_col: []})\n",
        "\n",
        "    prov_parts, numeric_frames = [], []\n",
        "    for s in frames:\n",
        "        s = s.copy()\n",
        "        if 'lf_provenance' in s.columns:\n",
        "            prov_parts.append(s[[id_col, 'lf_provenance']])\n",
        "            s = s.drop(columns=['lf_provenance'])\n",
        "        numeric_frames.append(s)\n",
        "\n",
        "    base = numeric_frames[0]\n",
        "    for s in numeric_frames[1:]:\n",
        "        base = base.merge(s, on=id_col, how='outer')\n",
        "\n",
        "    for c in base.columns:\n",
        "        if c != id_col and pd.api.types.is_numeric_dtype(base[c]):\n",
        "            base[c] = base[c].fillna(0).astype(int)\n",
        "\n",
        "    if prov_parts:\n",
        "        prov = pd.concat(prov_parts, ignore_index=True)\n",
        "        prov = prov.groupby(id_col, as_index=False)['lf_provenance'] \\\n",
        "                   .agg(lambda L: sum((v if isinstance(v, list) else [] for v in L), []))\n",
        "        base = base.merge(prov, on=id_col, how='left')\n",
        "        base['lf_provenance'] = base['lf_provenance'].apply(lambda v: v if isinstance(v, list) else [])\n",
        "    return base\n",
        "\n",
        "def _debug_cov(df, lfs, name, n=2000):\n",
        "    cov = {}\n",
        "    sample = df.head(n) if len(df) > n else df\n",
        "    for lf in lfs:\n",
        "        hits = 0\n",
        "        for _, r in sample.iterrows():\n",
        "            try:\n",
        "                out = lf(r)\n",
        "            except Exception:\n",
        "                out = ABSTAIN\n",
        "            if not _is_abstain(out):\n",
        "                hits += 1\n",
        "        cov[lf.__name__] = f\"{hits}/{len(sample)} = {100*hits/max(1,len(sample)):.1f}%\"\n",
        "    return {name: cov}\n",
        "\n",
        "surg_lfs  = create_surgical_labeling_functions()\n",
        "symp_lfs  = create_symptom_labeling_functions()\n",
        "diag_lfs  = create_diagnosis_labeling_functions()\n",
        "treat_lfs = create_treatment_labeling_functions()\n",
        "\n",
        "signals = []\n",
        "coverage_report = {}\n",
        "\n",
        "# ----- SURGERY -----\n",
        "dfS = df_surgery.copy()\n",
        "if USE_PREFILTER and 'has_surgery' in dfS.columns:\n",
        "    mask = _norm_bool(dfS['has_surgery'])\n",
        "    dfS = dfS[mask]\n",
        "# ensure combined_text exists\n",
        "if 'combined_text' not in dfS.columns:\n",
        "    dfS['combined_text'] = dfS.apply(\n",
        "        lambda r: f\"{str(r.get('reason',''))} {str(r.get('Type',''))} {str(r.get('details',''))} {str(r.get('outcome',''))}\",\n",
        "        axis=1\n",
        "    )\n",
        "# Probes for what the surgery LFs look for\n",
        "_probe_keywords(\n",
        "    dfS, \"combined_text\",\n",
        "    patterns=[r\"\\bhip\\b\", r\"\\barthroplasty\\b\", r\"\\breplacement\\b\", r\"\\bfracture\\b\", r\"\\bfixation\\b\", r\"\\brepair\\b\", r\"\\bbilateral\\b\"],\n",
        "    title=\"Surgery combined_text probes\"\n",
        ")\n",
        "sig_surg, labs_surg = build_signals_table_dynamic(dfS, surg_lfs, \"surgery\", id_col='idx')\n",
        "signals.append(sig_surg)\n",
        "coverage_report.update(_debug_cov(dfS, surg_lfs, \"Surgery\"))\n",
        "\n",
        "# ----- SYMPTOMS -----\n",
        "dfY = df_symptoms.copy()\n",
        "if USE_PREFILTER and 'has_symptom' in dfY.columns:\n",
        "    dfY = dfY[_norm_bool(dfY['has_symptom'])]\n",
        "if 'combined_text' not in dfY.columns:\n",
        "    dfY['combined_text'] = dfY.apply(\n",
        "        lambda r: f\"{str(r.get('name of symptom',''))} with {str(r.get('intensity of symptom',''))} \"\n",
        "                  f\"located in {str(r.get('location',''))} lasting {str(r.get('time',''))} \"\n",
        "                  f\"{str(r.get('temporalisation',''))} {str(r.get('details',''))}\",\n",
        "        axis=1\n",
        "    )\n",
        "_probe_keywords(\n",
        "    dfY, \"combined_text\",\n",
        "    patterns=[r\"\\bpain\\b\", r\"\\bsevere\\b\", r\"\\bchronic\\b\", r\"\\bacute\\b\", r\"\\bbilateral\\b\", r\"\\bhip\\b\", r\"\\bknee\\b\", r\"\\bback\\b\"],\n",
        "    title=\"Symptoms combined_text probes\"\n",
        ")\n",
        "sig_symp, labs_symp = build_signals_table_dynamic(dfY, symp_lfs, \"symptoms\", id_col='idx')\n",
        "signals.append(sig_symp)\n",
        "coverage_report.update(_debug_cov(dfY, symp_lfs, \"Symptoms\"))\n",
        "\n",
        "# ----- DIAGNOSIS -----\n",
        "dfD = df_diagnosis.copy()\n",
        "if USE_PREFILTER and 'has_diagnosis' in dfD.columns:\n",
        "    dfD = dfD[_norm_bool(dfD['has_diagnosis'])]\n",
        "if 'combined_text' not in dfD.columns:\n",
        "    dfD['combined_text'] = dfD.apply(\n",
        "        lambda r: f\"{str(r.get('test',''))} {str(r.get('result',''))} {str(r.get('condition',''))} \"\n",
        "                  f\"{str(r.get('details',''))} {str(r.get('time',''))}\",\n",
        "        axis=1\n",
        "    )\n",
        "_probe_keywords(\n",
        "    dfD, \"combined_text\",\n",
        "    patterns=[r\"\\bmri\\b\", r\"\\bct\\b\", r\"\\bx-ray\\b\", r\"\\bradiograph\\b\", r\"\\bfracture\\b\", r\"\\btumor\\b\", r\"\\bnormal\\b\", r\"\\bcritical\\b\"],\n",
        "    title=\"Diagnosis combined_text probes\"\n",
        ")\n",
        "sig_diag, labs_diag = build_signals_table_dynamic(dfD, diag_lfs, \"diagnosis\", id_col='idx')\n",
        "signals.append(sig_diag)\n",
        "coverage_report.update(_debug_cov(dfD, diag_lfs, \"Diagnosis\"))\n",
        "\n",
        "# ----- TREATMENTS -----\n",
        "dfT = df_treatments_processed.copy()\n",
        "if USE_PREFILTER and 'has_treatments' in dfT.columns:\n",
        "    dfT = dfT[_norm_bool(dfT['has_treatments'])]\n",
        "if 'combined_text' not in dfT.columns:\n",
        "    dfT['combined_text'] = dfT.apply(\n",
        "        lambda r: \" \".join(\n",
        "            str(x) for x in [\n",
        "                r.get('name',''), r.get('related condition',''),\n",
        "                r.get('dosage',''), r.get('frequency',''),\n",
        "                r.get('route',''), r.get('time',''),\n",
        "                r.get('duration',''), r.get('reason for taking',''),\n",
        "                r.get('reaction to treatment',''), r.get('details','')\n",
        "            ]\n",
        "        ),\n",
        "        axis=1\n",
        "    )\n",
        "_probe_keywords(\n",
        "    dfT, \"combined_text\",\n",
        "    patterns=[r\"\\bemergency\\b\", r\"\\bshock\\b\", r\"\\bchemotherapy\\b\", r\"\\bantibiotic\\b\", r\"\\bmorphine\\b\", r\"\\bsurgery\\b\"],\n",
        "    title=\"Treatments combined_text probes\"\n",
        ")\n",
        "sig_treat, labs_treat = build_signals_table_dynamic(dfT, treat_lfs, \"treatments\", id_col='idx')\n",
        "signals.append(sig_treat)\n",
        "coverage_report.update(_debug_cov(dfT, treat_lfs, \"Treatment\"))\n",
        "\n",
        "# ----- unify & show -----\n",
        "signals_idx = unify_signals_safe(sig_surg, sig_symp, sig_diag, sig_treat)\n",
        "signals_idx.to_parquet(\"lf_signals_index.parquet\", index=False)\n",
        "\n",
        "print(f\"[Stage 2] Signals index: {signals_idx.shape}\")\n",
        "print(\"Any surgery.* flags?\", any(c.startswith(\"surgery.\") for c in signals_idx.columns))\n",
        "print(\"Any symptoms.* flags?\", any(c.startswith(\"symptoms.\") for c in signals_idx.columns))\n",
        "print(\"Any diagnosis.* flags?\", any(c.startswith(\"diagnosis.\") for c in signals_idx.columns))\n",
        "print(\"Any treatments.* flags?\", any(c.startswith(\"treatments.\") for c in signals_idx.columns))\n",
        "\n",
        "# show a few rows that actually fired\n",
        "if 'lf_provenance' in signals_idx.columns:\n",
        "    demo = signals_idx[signals_idx['lf_provenance'].str.len() > 0].head(10)\n",
        "    print(\"[Stage 2] Examples with provenance (first 10):\")\n",
        "    display(demo)\n",
        "\n",
        "print(\"Coverage (sampled):\")\n",
        "for k, v in coverage_report.items():\n",
        "    print(f\"  {k:<9}: {v}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Stage 3: Create Silver Spans for NER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Stage 3] Candidate phrases: (1876570, 3)\n",
            "[Stage 3] Notes with ≥1 span: 29755/30000 = 99.2%\n",
            "[Stage 3] Silver spans saved. Notes with ≥1 span: 29755\n"
          ]
        }
      ],
      "source": [
        "# STAGE 3 — Silver spans for NER \n",
        "# ------------------------------------------------------\n",
        "ae = all_entities.dropna(subset=[\"text\",\"label\"]).copy()\n",
        "ae[\"text\"]  = ae[\"text\"].astype(str).map(normalize_phrase)\n",
        "ae[\"label\"] = ae[\"label\"].astype(str).map(normalize_label)\n",
        "ae = ae[(ae[\"text\"].str.len() >= 2) & (ae[\"label\"].isin(ALLOWED_LABELS))]\n",
        "ae = ae[[\"idx\",\"text\",\"label\"]].drop_duplicates()\n",
        "\n",
        "print(\"[Stage 3] Candidate phrases:\", ae.shape)\n",
        "\n",
        "# Pre-group for speed: idx -> [{'text','label'}, ...]\n",
        "ents_by_idx = {k: g[[\"text\",\"label\"]].to_dict(\"records\") for k,g in ae.groupby(\"idx\")}\n",
        "\n",
        "def find_all(text: str, phrase: str):\n",
        "    return [(m.start(), m.end()) for m in re.finditer(re.escape(phrase), text, flags=re.IGNORECASE)]\n",
        "\n",
        "def dedupe_overlaps(spans):\n",
        "    spans = sorted(spans, key=lambda x: (x[\"label\"], x[\"start\"], -(x[\"end\"]-x[\"start\"])))\n",
        "    kept = []\n",
        "    for sp in spans:\n",
        "        conflict = False\n",
        "        for kp in kept:\n",
        "            if sp[\"label\"] == kp[\"label\"] and not (sp[\"end\"] <= kp[\"start\"] or sp[\"start\"] >= kp[\"end\"]):\n",
        "                conflict = True\n",
        "                if (sp[\"end\"]-sp[\"start\"]) > (kp[\"end\"]-kp[\"start\"]):\n",
        "                    kp.update(sp)\n",
        "                break\n",
        "        if not conflict:\n",
        "            kept.append(sp)\n",
        "    return kept\n",
        "\n",
        "silver_rows, matched_notes = [], 0\n",
        "for r in df_lean.itertuples(index=False):\n",
        "    note_id = r.idx\n",
        "    text    = getattr(r, TEXT_COL)\n",
        "    spans = []\n",
        "    for ent in ents_by_idx.get(note_id, []):\n",
        "        for (s,e) in find_all(text, ent[\"text\"]):\n",
        "            spans.append({\"start\": s, \"end\": e, \"label\": ent[\"label\"], \"text\": text[s:e]})\n",
        "    spans = dedupe_overlaps(spans)\n",
        "    matched_notes += int(len(spans) > 0)\n",
        "    silver_rows.append({\"idx\": note_id, \"text\": text, \"silver_spans\": spans})\n",
        "\n",
        "silver_df = pd.DataFrame(silver_rows)\n",
        "silver_df[\"n_spans\"] = silver_df[\"silver_spans\"].str.len()\n",
        "print(f\"[Stage 3] Notes with ≥1 span: {matched_notes}/{len(silver_df)} = {matched_notes/len(silver_df):.1%}\")\n",
        "\n",
        "# Light confidence filter \n",
        "rows = []\n",
        "for r in silver_df.itertuples(index=False):\n",
        "    for sp in r.silver_spans:\n",
        "        rows.append({\"idx\": r.idx, \"note_text\": r.text, **sp})\n",
        "cand = pd.DataFrame(rows)\n",
        "\n",
        "if len(cand):\n",
        "    freq = (cand.groupby([\"label\",\"text\"]).size()/len(silver_df)).to_dict()\n",
        "    def conf_score(row):\n",
        "        s = 0.0\n",
        "        s += 0.45 * freq.get((row[\"label\"], row[\"text\"]), 0)\n",
        "        s += 0.25 * (1.0 if row[\"note_text\"][row[\"start\"]:row[\"end\"]] == row[\"text\"] else 0.0)\n",
        "        local = row[\"note_text\"][max(0,row[\"start\"]-40):min(len(row[\"note_text\"]),row[\"end\"]+40)]\n",
        "        s += 0.30 * (fuzz.partial_ratio(row[\"text\"].lower(), local.lower())/100.0)\n",
        "        return min(s,1.0)\n",
        "    cand[\"conf\"] = cand.apply(conf_score, axis=1)\n",
        "    cand = cand[cand[\"conf\"] >= 0.35]\n",
        "\n",
        "    def rebuild(group):\n",
        "        spans = group[[\"start\",\"end\",\"label\",\"text\"]].to_dict(\"records\")\n",
        "        return pd.Series({\"text\": group[\"note_text\"].iloc[0], \"silver_spans\": spans})\n",
        "\n",
        "    silver_df = cand.groupby(\"idx\").apply(rebuild).reset_index()\n",
        "    silver_df[\"n_spans\"] = silver_df[\"silver_spans\"].str.len()\n",
        "\n",
        "silver_df.to_parquet(\"silver_spans_filtered.parquet\", index=False)\n",
        "print(f\"[Stage 3] Silver spans saved. Notes with ≥1 span: {(silver_df['n_spans']>0).sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Stage 4: Train NER Model on Silver Spans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Tokenize + BIO: 100%|██████████| 29755/29755 [01:07<00:00, 437.79 examples/s]\n",
            "Saving the dataset (1/1 shards): 100%|██████████| 25291/25291 [00:00<00:00, 127857.67 examples/s]\n",
            "Saving the dataset (1/1 shards): 100%|██████████| 4464/4464 [00:00<00:00, 121410.06 examples/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Stage 4] Saved HF dataset + label space\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4743' max='4743' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4743/4743 5:10:58, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.306600</td>\n",
              "      <td>0.284814</td>\n",
              "      <td>0.547895</td>\n",
              "      <td>0.676287</td>\n",
              "      <td>0.605358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.270100</td>\n",
              "      <td>0.261943</td>\n",
              "      <td>0.574710</td>\n",
              "      <td>0.704480</td>\n",
              "      <td>0.633013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.243200</td>\n",
              "      <td>0.259012</td>\n",
              "      <td>0.592299</td>\n",
              "      <td>0.711481</td>\n",
              "      <td>0.646443</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='279' max='279' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [279/279 04:29]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Stage 4] NER eval: {'eval_loss': 0.25901228189468384, 'eval_precision': 0.5922989807474519, 'eval_recall': 0.7114811774363785, 'eval_f1': 0.6464426898528488, 'eval_runtime': 277.987, 'eval_samples_per_second': 16.058, 'eval_steps_per_second': 1.004, 'epoch': 3.0}\n",
            "[Stage 4] Saved model_ner_best\n"
          ]
        }
      ],
      "source": [
        "# ======================================================\n",
        "# Stage 4 — Build HF dataset & train NER on Silver (fixed)\n",
        "# ======================================================\n",
        "\n",
        "from seqeval.metrics import precision_score, recall_score, f1_score\n",
        "import gc, numpy as np\n",
        "\n",
        "# label space for BIO tags\n",
        "entity_labels = sorted({sp[\"label\"] for L in silver_df[\"silver_spans\"] for sp in L}) if len(silver_df) else []\n",
        "id2label_list = [\"O\"] + sum(([f\"B-{l}\", f\"I-{l}\"] for l in entity_labels), [])\n",
        "label2id = {l:i for i,l in enumerate(id2label_list)}\n",
        "id2label = {i:l for i,l in enumerate(id2label_list)}\n",
        "\n",
        "MODEL_NAME = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "MAX_LEN = 256\n",
        "tok = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "def to_bio(example):\n",
        "    text, spans = example[\"text\"], example[\"silver_spans\"]\n",
        "    enc = tok(text, truncation=True, max_length=MAX_LEN, return_offsets_mapping=True)\n",
        "    # start with -100 for all tokens (ignored by loss/metrics)\n",
        "    labels = [-100] * len(enc[\"offset_mapping\"])\n",
        "\n",
        "    # mark non-special tokens as \"O\"\n",
        "    for i, (a, b) in enumerate(enc[\"offset_mapping\"]):\n",
        "        if a != b:  # real token span\n",
        "            labels[i] = label2id[\"O\"]\n",
        "\n",
        "    # paint spans\n",
        "    for sp in spans:\n",
        "        s, e, lab = sp[\"start\"], sp[\"end\"], sp[\"label\"]\n",
        "        began = False\n",
        "        for i, (a, b) in enumerate(enc[\"offset_mapping\"]):\n",
        "            if a == b: \n",
        "                continue\n",
        "            if a >= s and b <= e:\n",
        "                labels[i] = label2id[f\"I-{lab}\" if began else f\"B-{lab}\"]\n",
        "                began = True\n",
        "\n",
        "    enc[\"labels\"] = labels\n",
        "    enc.pop(\"offset_mapping\", None)\n",
        "    enc[\"idx\"] = example[\"idx\"]\n",
        "    return enc\n",
        "\n",
        "# ---- Dataset build ----\n",
        "if len(silver_df):\n",
        "    hf = ds.Dataset.from_pandas(silver_df[[\"idx\",\"text\",\"silver_spans\"]], preserve_index=False)\n",
        "    hf = hf.map(to_bio, remove_columns=[\"text\",\"silver_spans\"], desc=\"Tokenize + BIO\")\n",
        "    splits = hf.train_test_split(test_size=0.15, seed=42)\n",
        "    splits.save_to_disk(\"ds_ner_silver_with_idx\")\n",
        "    with open(\"ner_label_space.json\",\"w\") as f:\n",
        "        json.dump({\"id2label\": id2label_list, \"label2id\": label2id}, f, indent=2)\n",
        "    print(\"[Stage 4] Saved HF dataset + label space\")\n",
        "else:\n",
        "    print(\"[Stage 4] Skipped (no silver spans)\")\n",
        "\n",
        "# ---- Training ----\n",
        "if len(silver_df):\n",
        "    tokenizer = tok\n",
        "    model = AutoModelForTokenClassification.from_pretrained(\n",
        "        MODEL_NAME, num_labels=len(id2label), id2label=id2label, label2id=label2id\n",
        "    )\n",
        "    data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
        "\n",
        "    TA_FIELDS = set(TrainingArguments.__dataclass_fields__.keys())\n",
        "    ta = dict(\n",
        "        output_dir=\"ckpt/ner\",\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=16,\n",
        "        learning_rate=2e-5,\n",
        "        num_train_epochs=3,\n",
        "        weight_decay=0.01,\n",
        "        logging_steps=50,\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "    if \"warmup_ratio\" in TA_FIELDS: ta[\"warmup_ratio\"] = 0.1\n",
        "    if \"fp16\" in TA_FIELDS: ta[\"fp16\"] = torch.cuda.is_available()\n",
        "\n",
        "    # ---- Robust save/eval strategy handling (fixes your error) ----\n",
        "    eval_key = \"eval_strategy\" if \"eval_strategy\" in TA_FIELDS else (\"evaluation_strategy\" if \"evaluation_strategy\" in TA_FIELDS else None)\n",
        "    if eval_key:\n",
        "        ta[eval_key] = \"epoch\"\n",
        "    if \"save_strategy\" in TA_FIELDS:\n",
        "        ta[\"save_strategy\"] = \"epoch\"\n",
        "\n",
        "    # remove step-based settings so they can't force 'steps'\n",
        "    for k in (\"save_steps\", \"eval_steps\"):\n",
        "        if k in ta:\n",
        "            ta.pop(k)\n",
        "\n",
        "    if \"load_best_model_at_end\" in TA_FIELDS:\n",
        "        ta[\"load_best_model_at_end\"] = True\n",
        "        if \"metric_for_best_model\" in TA_FIELDS: ta[\"metric_for_best_model\"] = \"eval_f1\"\n",
        "        if \"greater_is_better\" in TA_FIELDS:    ta[\"greater_is_better\"] = True\n",
        "\n",
        "    args = TrainingArguments(**ta)\n",
        "\n",
        "    def align_and_decode(preds, labels):\n",
        "        pred_labels, true_labels = [], []\n",
        "        for p, t in zip(preds, labels):\n",
        "            p = np.array(p); t = np.array(t)\n",
        "            mask = t != -100\n",
        "            p = p[mask]; t = t[mask]\n",
        "            pred_labels.append([id2label[i] for i in p])\n",
        "            true_labels.append([id2label[i] for i in t])\n",
        "        return pred_labels, true_labels\n",
        "\n",
        "    def compute_metrics(p):\n",
        "        logits, labels = p.predictions, p.label_ids\n",
        "        preds = np.argmax(logits, axis=-1)\n",
        "        pred_tags, true_tags = align_and_decode(preds, labels)\n",
        "        return {\n",
        "            \"precision\": precision_score(true_tags, pred_tags),\n",
        "            \"recall\":    recall_score(true_tags, pred_tags),\n",
        "            \"f1\":        f1_score(true_tags, pred_tags),\n",
        "        }\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model, args=args,\n",
        "        train_dataset=splits[\"train\"],\n",
        "        eval_dataset=splits.get(\"validation\", splits.get(\"test\")),\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        "    )\n",
        "    trainer.train()\n",
        "    eval_output = trainer.evaluate()\n",
        "    print(\"[Stage 4] NER eval:\", eval_output)\n",
        "\n",
        "    trainer.save_model(\"model_ner_best\")\n",
        "    tokenizer.save_pretrained(\"model_ner_best\")\n",
        "    print(\"[Stage 4] Saved model_ner_best\")\n",
        "\n",
        "    del trainer, model; gc.collect()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Stage 5: Weak-Supervised Row Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Stage 5] POS signals present: ['surgery.EMERGENCY_SURGERY', 'treatments.EMERGENCY_TREATMENT', 'diagnosis.CRITICAL_FINDING']\n",
            "[Stage 5] Row classifier saved → row_classifier_emergency.joblib\n",
            "[Stage 5] Weakly-supervised in-sample report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0      0.999     0.935     0.966     27637\n",
            "           1      0.540     0.992     0.699      2118\n",
            "\n",
            "    accuracy                          0.939     29755\n",
            "   macro avg      0.769     0.964     0.833     29755\n",
            "weighted avg      0.967     0.939     0.947     29755\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ------------------------------------------------------\n",
        "# STAGE 5 — Weak→supervised row classifier\n",
        "# ------------------------------------------------------\n",
        "def make_target_from_signals(signals_idx: pd.DataFrame, positive_any: list, negative_any: list = None):\n",
        "    df = signals_idx.copy()\n",
        "    for col in positive_any:\n",
        "        if col not in df.columns: df[col] = 0\n",
        "    pos = np.zeros(len(df), dtype=int)\n",
        "    for col in positive_any:\n",
        "        pos |= df[col].astype(int).values\n",
        "    if negative_any:\n",
        "        for col in negative_any:\n",
        "            if col not in df.columns: df[col] = 0\n",
        "        neg = np.zeros(len(df), dtype=int)\n",
        "        for col in negative_any:\n",
        "            neg |= df[col].astype(int).values\n",
        "        y = np.where((pos == 1) & (neg == 0), 1, 0)\n",
        "    else:\n",
        "        y = pos\n",
        "    return df[[\"idx\"]].assign(y=y)\n",
        "\n",
        "POSITIVE_SIGNALS = [\n",
        "    \"surgery.EMERGENCY_SURGERY\",\n",
        "    \"treatments.EMERGENCY_TREATMENT\",\n",
        "    \"diagnosis.CRITICAL_FINDING\",\n",
        "]\n",
        "NEGATIVE_SIGNALS = []\n",
        "\n",
        "def train_row_classifier(df_notes, signals_idx, positive_cols, negative_cols=None, text_col=TEXT_COL):\n",
        "    present = [c for c in positive_cols if c in signals_idx.columns and signals_idx[c].sum() > 0]\n",
        "    missing = [c for c in positive_cols if c not in signals_idx.columns]\n",
        "    print(f\"[Stage 5] POS signals present: {present if present else 'None'}\")\n",
        "    if missing:\n",
        "        print(\"[Stage 5] POS signals missing (not in signals_idx):\", missing)\n",
        "\n",
        "    if not present:\n",
        "        print(\"[Stage 5] No positive signal columns found. Skipping classifier training.\")\n",
        "        return None\n",
        "\n",
        "    y_df = make_target_from_signals(signals_idx, positive_cols, negative_cols)\n",
        "    train_df = df_notes.merge(y_df, on=\"idx\", how=\"inner\")\n",
        "\n",
        "    cls_counts = train_df[\"y\"].value_counts().to_dict()\n",
        "    if len(cls_counts) < 2:\n",
        "        print(f\"[Stage 5] Only one class present {cls_counts}. Skipping classifier.\")\n",
        "        return None\n",
        "\n",
        "    clf_pipe = Pipeline([\n",
        "        (\"tfidf\", TfidfVectorizer(max_features=50000, ngram_range=(1,2))),\n",
        "        (\"clf\",   LogisticRegression(max_iter=1000, class_weight=\"balanced\", n_jobs=None))\n",
        "    ])\n",
        "    clf_pipe.fit(train_df[text_col], train_df[\"y\"])\n",
        "    joblib.dump(clf_pipe, \"row_classifier_emergency.joblib\")\n",
        "    print(\"[Stage 5] Row classifier saved → row_classifier_emergency.joblib\")\n",
        "\n",
        "    pred = clf_pipe.predict(train_df[text_col])\n",
        "    print(\"[Stage 5] Weakly-supervised in-sample report:\\n\", skl_report(train_df[\"y\"], pred, digits=3))\n",
        "    return clf_pipe\n",
        "\n",
        "row_clf = train_row_classifier(df_lean, signals_idx, POSITIVE_SIGNALS, NEGATIVE_SIGNALS, text_col=TEXT_COL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Stage 6 & 7: Information Retrieval & Classifier Use Cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Stage 6] Emergency surgery notes (signal-only): 565\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Stage 7] Notes after LF+gate: 555\n",
            "[Stage 7] Saved ner_predictions_prefiltered.parquet\n",
            "\n",
            "[Stage 7 - Extended] Running NER on full dataset...\n",
            "[Stage 7 - Extended] Saved full predictions for 30000 notes\n",
            "\n",
            "Sample predictions:\n",
            "\n",
            "Note 155216 entities:\n",
            "  - discomfort [Problem] (conf: 0.99)\n",
            "  - neck [Anatomy] (conf: 0.56)\n",
            "  - lower back [Problem] (conf: 0.46)\n",
            "  - right [Laterality] (conf: 0.81)\n",
            "  - sustained [TemporalPattern] (conf: 0.54)\n",
            "  - neck [Anatomy] (conf: 0.93)\n",
            "  - back [Anatomy] (conf: 0.88)\n",
            "  - lumbar [Anatomy] (conf: 0.86)\n",
            "  - back [Anatomy] (conf: 0.78)\n",
            "  - neck [Anatomy] (conf: 0.94)\n",
            "  - neck [Anatomy] (conf: 0.94)\n",
            "  - lumbar [Anatomy] (conf: 0.87)\n",
            "  - daily [Frequency] (conf: 0.77)\n",
            "  - months [TemporalPattern] (conf: 0.56)\n",
            "  - olanzapine [TreatmentName] (conf: 0.84)\n",
            "  - tablets [TreatmentType] (conf: 0.90)\n",
            "  - mental illness [Problem] (conf: 0.59)\n",
            "  - years [TemporalPattern] (conf: 0.55)\n",
            "  - bipolar affective disorder [Problem] (conf: 0.97)\n",
            "  - affective disorder [Problem] (conf: 0.77)\n",
            "  - mania [Problem] (conf: 0.94)\n",
            "  - olanzapine [TreatmentName] (conf: 0.82)\n",
            "  - tablets [TreatmentType] (conf: 0.90)\n",
            "  - 10 mg [Dosage] (conf: 0.96)\n",
            "  - per day [Dosage] (conf: 0.92)\n",
            "  - pain and discomfort [Problem] (conf: 0.79)\n",
            "  - neck [Anatomy] (conf: 0.85)\n",
            "  - tablet [TreatmentType] (conf: 0.73)\n",
            "  - olanzapine [TreatmentName] (conf: 0.82)\n",
            "  - 5 mg [Dosage] (conf: 0.97)\n",
            "  - per day [Dosage] (conf: 0.97)\n",
            "  - sustained [TemporalPattern] (conf: 0.74)\n",
            "  - neck [Anatomy] (conf: 0.70)\n",
            "  - head [Anatomy] (conf: 0.60)\n",
            "  - right [Laterality] (conf: 0.88)\n",
            "  - years [TemporalPattern] (conf: 0.59)\n",
            "  - olanzapine [TreatmentName] (conf: 0.61)\n",
            "  - weeks [TemporalPattern] (conf: 0.68)\n",
            "  - tablet [TreatmentType] (conf: 0.80)\n",
            "  - trihexyphenidyl [TreatmentName] (conf: 0.83)\n",
            "  - 4 mg [Dosage] (conf: 0.98)\n",
            "  - per day [Dosage] (conf: 0.96)\n",
            "  - rigidity [Problem] (conf: 0.92)\n",
            "  - medication [TreatmentType] (conf: 0.75)\n",
            "  - rigidity [Problem] (conf: 0.93)\n",
            "  - medication [TreatmentType] (conf: 0.69)\n",
            "\n",
            "Note 77465 entities:\n",
            "  - 56 - year - old [AgeSex] (conf: 1.00)\n",
            "  - man [Sex] (conf: 1.00)\n",
            "  - dump pain [Problem] (conf: 0.90)\n",
            "  - right [Laterality] (conf: 0.94)\n",
            "  - back [Anatomy] (conf: 0.57)\n",
            "  - swelling [Problem] (conf: 0.95)\n",
            "  - right [Laterality] (conf: 0.78)\n",
            "  - thoracic [Problem] (conf: 0.52)\n",
            "  - right [Laterality] (conf: 0.97)\n",
            "  - right [Laterality] (conf: 0.99)\n",
            "  - ct [TestType] (conf: 0.65)\n",
            "  - tumor [Problem] (conf: 0.98)\n",
            "  - thoraci [Anatomy] (conf: 0.39)\n",
            "  - ##c wall [Problem] (conf: 0.43)\n",
            "  - right [Laterality] (conf: 0.95)\n",
            "  - 4 cm [Measurement] (conf: 0.57)\n",
            "  - tumor [Problem] (conf: 0.98)\n",
            "  - lung [Anatomy] (conf: 0.70)\n",
            "  - lung [Anatomy] (conf: 0.72)\n",
            "  - ##t [TestType] (conf: 0.52)\n",
            "  - lungs [Anatomy] (conf: 0.67)\n",
            "  - right [Laterality] (conf: 0.99)\n",
            "  - lung [Anatomy] (conf: 0.89)\n",
            "  - malignant tumor of the thoracic wall [Problem] (conf: 0.81)\n",
            "  - lungs [Anatomy] (conf: 0.69)\n",
            "  - biopsy [TestType] (conf: 0.47)\n",
            "  - tumor [Problem] (conf: 0.97)\n",
            "  - biopsy [TestType] (conf: 0.54)\n",
            "  - right [Laterality] (conf: 0.92)\n",
            "  - lung [Anatomy] (conf: 0.83)\n",
            "  - ##cision [Procedure] (conf: 0.61)\n",
            "  - biopsy [TestType] (conf: 0.40)\n",
            "  - tumor [Problem] (conf: 0.97)\n",
            "  - thoracic wall [Anatomy] (conf: 0.57)\n",
            "  - right [Laterality] (conf: 0.99)\n",
            "  - lung [Anatomy] (conf: 0.88)\n",
            "  - tumor [Problem] (conf: 0.98)\n",
            "  - malignant [Problem] (conf: 0.68)\n",
            "  - biopsy [TestType] (conf: 0.64)\n",
            "  - resection [TreatmentType] (conf: 0.51)\n",
            "  - tumor [Problem] (conf: 0.97)\n",
            "  - thoraci [Anatomy] (conf: 0.54)\n",
            "  - ##c [Problem] (conf: 0.40)\n",
            "  - wall [Anatomy] (conf: 0.46)\n",
            "\n",
            "Note 133948 entities:\n",
            "  - 36 [Age] (conf: 0.92)\n",
            "  - female patient [Sex] (conf: 1.00)\n",
            "  - pain and restricted range of motion [Problem] (conf: 0.74)\n",
            "  - rom [Problem] (conf: 0.58)\n",
            "  - left [Laterality] (conf: 0.93)\n",
            "  - hip [Problem] (conf: 0.45)\n",
            "  - joint [Problem] (conf: 0.46)\n",
            "  - severe [Severity] (conf: 0.68)\n",
            "  - gait disturbance [Problem] (conf: 0.86)\n",
            "  - hip pain [Problem] (conf: 0.68)\n",
            "  - hip [Problem] (conf: 0.60)\n",
            "  - joint [Problem] (conf: 0.49)\n",
            "  - femoral head [Anatomy] (conf: 0.66)\n",
            "  - left [Laterality] (conf: 0.93)\n",
            "  - hip [Problem] (conf: 0.46)\n",
            "  - sclerosis [Problem] (conf: 0.62)\n",
            "  - femoral head [Anatomy] (conf: 0.70)\n",
            "  - dysplasia [Problem] (conf: 0.65)\n",
            "  - hip [Anatomy] (conf: 0.62)\n",
            "  - magnetic resonance [TestType] (conf: 0.53)\n",
            "  - mri [TestType] (conf: 0.89)\n",
            "  - scan [TestType] (conf: 0.74)\n",
            "  - joint [Anatomy] (conf: 0.49)\n",
            "  - bone [Problem] (conf: 0.54)\n",
            "  - left [Laterality] (conf: 0.98)\n",
            "  - hip [Problem] (conf: 0.51)\n",
            "  - femoral [Anatomy] (conf: 0.67)\n",
            "  - head [Problem] (conf: 0.49)\n",
            "  - necrosis [Problem] (conf: 0.79)\n",
            "  - pain [Problem] (conf: 0.97)\n",
            "  - idiopathic osteonecrosis of the [Problem] (conf: 0.86)\n",
            "  - femoral [Anatomy] (conf: 0.54)\n",
            "  - head [Problem] (conf: 0.72)\n",
            "  - surgery [TreatmentType] (conf: 0.53)\n",
            "  - pain [Problem] (conf: 1.00)\n",
            "  - limited rom [Problem] (conf: 0.73)\n",
            "  - ##tralateral [Anatomy] (conf: 0.70)\n",
            "  - hip [Problem] (conf: 0.53)\n",
            "  - joint [Problem] (conf: 0.50)\n",
            "  - gait disturbance [Problem] (conf: 0.93)\n",
            "  - surgery [TreatmentType] (conf: 0.56)\n",
            "  - mri [TestType] (conf: 0.90)\n",
            "  - left [Laterality] (conf: 0.99)\n",
            "  - hip [Problem] (conf: 0.62)\n",
            "  - left [Laterality] (conf: 0.98)\n",
            "  - hip [Problem] (conf: 0.61)\n",
            "  - surgery [TreatmentType] (conf: 0.57)\n",
            "  - surgery [TreatmentType] (conf: 0.52)\n",
            "  - weight gain [Problem] (conf: 0.71)\n",
            "  - helplessness [Problem] (conf: 0.81)\n",
            "  - central obesity [Problem] (conf: 0.67)\n",
            "  - mass [Problem] (conf: 0.43)\n",
            "  - surgery [TreatmentType] (conf: 0.56)\n",
            "  - surgery [TreatmentType] (conf: 0.59)\n",
            "  - progressive [TemporalPattern] (conf: 0.79)\n",
            "  - ##ning [TemporalPattern] (conf: 0.57)\n"
          ]
        }
      ],
      "source": [
        "# ------------------------------------------------------\n",
        "# STAGE 6 — IR / Filters (signals & classifier)\n",
        "# ------------------------------------------------------\n",
        "def filter_by_signals(df_notes, signals_idx, require: dict, id_col=\"idx\"):\n",
        "    joined = df_notes.merge(signals_idx, on=id_col, how=\"left\").fillna(0)\n",
        "    mask = np.ones(len(joined), dtype=bool)\n",
        "    for col, val in require.items():\n",
        "        if col not in joined.columns:\n",
        "            mask &= False\n",
        "        else:\n",
        "            mask &= (joined[col].astype(int) == int(bool(val)))\n",
        "    return joined.loc[mask, [id_col, TEXT_COL]].copy()\n",
        "\n",
        "def search_within(df, text_query=None, text_col=TEXT_COL, top_k=50):\n",
        "    if not text_query:\n",
        "        return df.head(top_k)\n",
        "    q = str(text_query).lower()\n",
        "    pri = df[text_col].str.lower().str.contains(q, na=False).astype(int)\n",
        "    V = TfidfVectorizer(max_features=20000)\n",
        "    X = V.fit_transform(df[text_col].fillna(\"\"))\n",
        "    qv = V.transform([text_query])\n",
        "    sim = (X @ qv.T).toarray().ravel()\n",
        "    scored = df.assign(_pri=pri, _sim=sim).sort_values([\"_pri\",\"_sim\"], ascending=[False,False])\n",
        "    return scored.head(top_k).drop(columns=[\"_pri\",\"_sim\"])\n",
        "\n",
        "# Example: signal-only filter\n",
        "if len(signals_idx):\n",
        "    emer_only = filter_by_signals(df_lean[[\"idx\", TEXT_COL]], signals_idx, {\"surgery.EMERGENCY_SURGERY\": 1})\n",
        "    print(\"[Stage 6] Emergency surgery notes (signal-only):\", len(emer_only))\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# STAGE 7 — Runtime: prefilter → classifier gate → NER\n",
        "# ------------------------------------------------------\n",
        "# Load NER \n",
        "ner_pipe = None\n",
        "if Path(\"model_ner_best\").exists():\n",
        "    device = 0 if torch.cuda.is_available() else -1\n",
        "    tok_infer = AutoTokenizer.from_pretrained(\"model_ner_best\")\n",
        "    model_infer = AutoModelForTokenClassification.from_pretrained(\"model_ner_best\")\n",
        "    ner_pipe = pipeline(\"token-classification\", model=model_infer, tokenizer=tok_infer,\n",
        "                        aggregation_strategy=\"simple\", device=device)\n",
        "\n",
        "def merge_overlaps(ents):\n",
        "    ents = sorted(ents, key=lambda e: (e[\"start\"], e[\"end\"]))\n",
        "    merged = []\n",
        "    for e in ents:\n",
        "        if merged and e[\"start\"] <= merged[-1][\"end\"] and e[\"entity_group\"] == merged[-1][\"entity_group\"]:\n",
        "            merged[-1][\"end\"]   = max(merged[-1][\"end\"], e[\"end\"])\n",
        "            merged[-1][\"score\"] = max(merged[-1][\"score\"], e[\"score\"])\n",
        "        else:\n",
        "            merged.append(e)\n",
        "    return merged\n",
        "\n",
        "def ner_with_windows(text, tok, pipe, max_length=512, stride=128):\n",
        "    enc = tok(text, return_offsets_mapping=True, return_overflowing_tokens=True,\n",
        "              truncation=True, max_length=max_length, stride=stride)\n",
        "    all_ents = []\n",
        "    for offsets in enc[\"offset_mapping\"]:\n",
        "        valid = [(a, b) for (a, b) in offsets if b > a]\n",
        "        if not valid: \n",
        "            continue\n",
        "        start_char = valid[0][0]; end_char = valid[-1][1]\n",
        "        chunk = text[start_char:end_char]\n",
        "        ents = pipe(chunk)\n",
        "        for e in ents:\n",
        "            e[\"start\"] += start_char\n",
        "            e[\"end\"]   += start_char\n",
        "        all_ents.extend(ents)\n",
        "    return merge_overlaps(all_ents)\n",
        "\n",
        "def run_ner(df_notes, text_col, strategy=\"auto\", max_length=512, stride=128):\n",
        "    if ner_pipe is None:\n",
        "        raise RuntimeError(\"NER pipeline not loaded. Train or place model_ner_best first.\")\n",
        "    rows = []\n",
        "    for r in df_notes.itertuples(index=False):\n",
        "        text = getattr(r, text_col) or \"\"\n",
        "        if strategy == \"truncate\":\n",
        "            ents = ner_pipe(text)\n",
        "        elif strategy == \"window\":\n",
        "            ents = ner_with_windows(text, tok_infer, ner_pipe, max_length=max_length, stride=stride)\n",
        "        else:\n",
        "            approx_len = len(tok_infer(text, add_special_tokens=False)[\"input_ids\"])\n",
        "            if approx_len > max_length - 8:\n",
        "                ents = ner_with_windows(text, tok_infer, ner_pipe, max_length=max_length, stride=stride)\n",
        "            else:\n",
        "                ents = ner_pipe(text)\n",
        "        rows.append({\"idx\": r.idx, \"text\": text, \"pred_entities\": ents})\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# Example runtime flow:\n",
        "# 1) LF prefilter (e.g., emergency across domains)\n",
        "prefilter = filter_by_signals(\n",
        "    df_notes=df_lean[[\"idx\", TEXT_COL]],\n",
        "    signals_idx=signals_idx,\n",
        "    require={\"surgery.EMERGENCY_SURGERY\": 1}\n",
        ") if len(signals_idx) else df_lean[[\"idx\", TEXT_COL]]\n",
        "\n",
        "# 2) Optional classifier gate (boost precision if the classifier exists)\n",
        "if Path(\"row_classifier_emergency.joblib\").exists() and len(prefilter):\n",
        "    gate = joblib.load(\"row_classifier_emergency.joblib\")\n",
        "    mask = gate.predict(prefilter[TEXT_COL]) == 1\n",
        "    gated = prefilter.loc[mask]\n",
        "else:\n",
        "    gated = prefilter\n",
        "print(f\"[Stage 7] Notes after LF+gate: {len(gated)}\")\n",
        "\n",
        "# 3) NER over filtered set\n",
        "if len(gated) and ner_pipe is not None:\n",
        "    pred_df = run_ner(gated, TEXT_COL, strategy=\"auto\") \n",
        "    pred_df.to_parquet(\"ner_predictions_prefiltered.parquet\", index=False)\n",
        "    print(\"[Stage 7] Saved ner_predictions_prefiltered.parquet\")\n",
        "else:\n",
        "    print(\"[Stage 7] Skipped NER inference (no gated set or no NER model)\")\n",
        "\n",
        "# ===== Extended NER runs =====\n",
        "# Run the full pipeline on your dataset\n",
        "print(\"\\n[Stage 7 - Extended] Running NER on full dataset...\")\n",
        "if ner_pipe is not None and len(df_lean) > 0:\n",
        "    # Option 1: Run on all data\n",
        "    full_predictions = run_ner(df_lean[[\"idx\", TEXT_COL]], TEXT_COL, strategy=\"auto\")\n",
        "    full_predictions.to_parquet(\"ner_predictions_full.parquet\", index=False)\n",
        "    print(f\"[Stage 7 - Extended] Saved full predictions for {len(full_predictions)} notes\")\n",
        "    \n",
        "    # Show sample results\n",
        "    print(\"\\nSample predictions:\")\n",
        "    for _, row in full_predictions.head(3).iterrows():\n",
        "        if row['pred_entities']:\n",
        "            print(f\"\\nNote {row['idx']} entities:\")\n",
        "            for ent in row['pred_entities']:\n",
        "                print(f\"  - {ent['word']} [{ent['entity_group']}] (conf: {ent['score']:.2f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If you still have the trainer and test set available:\n",
        "if 'trainer' in locals() and 'splits' in locals() and \"test\" in splits:\n",
        "    pred = trainer.predict(splits[\"test\"])\n",
        "    pred_ids = pred.predictions.argmax(-1)\n",
        "    \n",
        "    def align(ids, gold):\n",
        "        p_tags, t_tags = [], []\n",
        "        for p, t in zip(ids, gold):\n",
        "            mask = (t != -100)\n",
        "            p = p[mask]; t = t[mask]\n",
        "            p_tags.append([id2label[i] for i in p])\n",
        "            t_tags.append([id2label[i] for i in t])\n",
        "        return p_tags, t_tags\n",
        "    \n",
        "    p_tags, t_tags = align(pred_ids, pred.label_ids)\n",
        "    \n",
        "    # Use seqeval for proper NER evaluation\n",
        "    from seqeval.metrics import classification_report\n",
        "    print(\"\\nDetailed NER Evaluation Report:\")\n",
        "    print(classification_report(t_tags, p_tags, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Analyze Entity Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Entity Label Distribution:\n",
            "label\n",
            "Problem              419506\n",
            "Anatomy              230550\n",
            "Laterality           109845\n",
            "TestType              78293\n",
            "TreatmentName         58265\n",
            "TestName              53893\n",
            "TreatmentType         40949\n",
            "TemporalPattern       40344\n",
            "Sex                   33242\n",
            "Medication            32112\n",
            "Procedure             25353\n",
            "AgeSex                17917\n",
            "Dosage                13665\n",
            "Age                   12233\n",
            "Measurement           10795\n",
            "Severity               9450\n",
            "Route                  8557\n",
            "Frequency              7385\n",
            "TreatmentResponse      5605\n",
            "TreatmentReason         427\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Top entities by label:\n",
            "\n",
            "Problem:\n",
            "entity\n",
            "mass              20826\n",
            "pain              15555\n",
            "tumor             15028\n",
            "lesion            10824\n",
            "swelling           7498\n",
            "abdominal          5023\n",
            "fracture           4913\n",
            "hypertension       3941\n",
            "fever              3495\n",
            "abdominal pain     3200\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Anatomy:\n",
            "entity\n",
            "artery      5631\n",
            "eye         5068\n",
            "liver       4613\n",
            "lung        3800\n",
            "neck        3017\n",
            "kidney      3005\n",
            "abdomen     2907\n",
            "chest       2451\n",
            "leg         2429\n",
            "cervical    2312\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Laterality:\n",
            "entity\n",
            "left         49761\n",
            "right        49659\n",
            "bilateral     7077\n",
            "both          3342\n",
            "##teral          4\n",
            "either           2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "TemporalPattern:\n",
            "entity\n",
            "months           5611\n",
            "weeks            4326\n",
            "days             4238\n",
            "years            3655\n",
            "acute            2772\n",
            "progressive      2563\n",
            "intermittent     2139\n",
            "postoperative    1799\n",
            "worsening        1749\n",
            "sudden           1715\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Frequency:\n",
            "entity\n",
            "daily          3614\n",
            "every          1373\n",
            "twice           758\n",
            "once            747\n",
            "three           180\n",
            "times           160\n",
            "bid             141\n",
            "three times     120\n",
            "as               45\n",
            "four             44\n",
            "Name: count, dtype: int64\n",
            "\n",
            "TreatmentName:\n",
            "entity\n",
            "antibiotics     745\n",
            "aspirin         395\n",
            "radio           343\n",
            "warfarin        330\n",
            "treatment       317\n",
            "prednisone      313\n",
            "radiation       312\n",
            "in              294\n",
            "prednisolone    255\n",
            "heparin         228\n",
            "Name: count, dtype: int64\n",
            "\n",
            "TreatmentType:\n",
            "entity\n",
            "surgery         7123\n",
            "therapy         6641\n",
            "surgical        3238\n",
            "chemotherapy    2763\n",
            "conservative    1585\n",
            "injection       1331\n",
            "emergency       1322\n",
            "oxygen          1254\n",
            "procedure       1240\n",
            "fluid           1222\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Dosage:\n",
            "entity\n",
            "/ day      904\n",
            "10 mg      630\n",
            "50 mg      586\n",
            "100 mg     573\n",
            "500 mg     564\n",
            "5 mg       549\n",
            "20 mg      463\n",
            "per day    389\n",
            "40 mg      380\n",
            "1 mg       341\n",
            "Name: count, dtype: int64\n",
            "\n",
            "AgeSex:\n",
            "entity\n",
            "60 - year - old    362\n",
            "65 - year - old    353\n",
            "62 - year - old    339\n",
            "70 - year - old    334\n",
            "50 - year - old    332\n",
            "56 - year - old    320\n",
            "55 - year - old    318\n",
            "67 - year - old    315\n",
            "57 - year - old    303\n",
            "42 - year - old    303\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sex:\n",
            "entity\n",
            "man               8520\n",
            "male              6424\n",
            "woman             6213\n",
            "female            5291\n",
            "male patient      2163\n",
            "##n               1824\n",
            "female patient    1661\n",
            "men                851\n",
            "##man              151\n",
            "women               55\n",
            "Name: count, dtype: int64\n",
            "\n",
            "TestType:\n",
            "entity\n",
            "ct                     16336\n",
            "scan                    9431\n",
            "mri                     8996\n",
            "biopsy                  6953\n",
            "computed tomography     4023\n",
            "##ct                    3769\n",
            "angiography             2898\n",
            "serum                   2443\n",
            "ultrasound              2222\n",
            "magnetic resonance      2132\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Measurement:\n",
            "entity\n",
            "mm       613\n",
            "cm       515\n",
            "mg       268\n",
            ".        265\n",
            "3 cm     182\n",
            "4 cm     148\n",
            "2 cm     142\n",
            "5 cm     133\n",
            "10 cm    120\n",
            "6 cm     114\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Procedure:\n",
            "entity\n",
            "resection         3874\n",
            "excision          3040\n",
            "graft             2778\n",
            "removal           1425\n",
            "fixation          1413\n",
            "reconstruction    1376\n",
            "implant           1199\n",
            "transplant        1080\n",
            "replacement        992\n",
            "repair             953\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Age:\n",
            "entity\n",
            "13 - year - old    172\n",
            "55 - year - old    164\n",
            "35 - year - old    162\n",
            "14 - year - old    157\n",
            "40 - year - old    153\n",
            "12 - year - old    152\n",
            "10 - year - old    146\n",
            "30 - year - old    144\n",
            "50 - year - old    143\n",
            "38 - year - old    142\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Severity:\n",
            "entity\n",
            "severe         6706\n",
            "mild           2066\n",
            "significant     497\n",
            "moderate        176\n",
            "extreme           4\n",
            "profound          1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "TestName:\n",
            "entity\n",
            ")                                3268\n",
            "(                                2901\n",
            "brain                            1210\n",
            "chest                             991\n",
            "abdominal                         784\n",
            "histopathological examination     482\n",
            "imaging                           438\n",
            "head                              427\n",
            "imaging (                         416\n",
            "contrast - enhanced               411\n",
            "Name: count, dtype: int64\n",
            "\n",
            "TreatmentResponse:\n",
            "entity\n",
            "continued     1461\n",
            "improved      1057\n",
            "stable         599\n",
            "resolved       568\n",
            "failed         408\n",
            "worse          239\n",
            "recovered      215\n",
            "maintained     177\n",
            "worsening      114\n",
            "successful     110\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Medication:\n",
            "entity\n",
            "creatinine    892\n",
            "calcium       501\n",
            "glucose       491\n",
            "lad           372\n",
            "la            367\n",
            "cisplatin     354\n",
            "bilirubin     300\n",
            "c             297\n",
            "fdg           270\n",
            "mca           269\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Route:\n",
            "entity\n",
            "oral            2201\n",
            "nasal           1289\n",
            "iv               839\n",
            "intravenous      836\n",
            "subcutaneous     535\n",
            "##al             480\n",
            "re               259\n",
            "in               226\n",
            "##v              196\n",
            "##travenous      189\n",
            "Name: count, dtype: int64\n",
            "\n",
            "TreatmentReason:\n",
            "entity\n",
            "o               16\n",
            "a               11\n",
            "possible         9\n",
            "r                8\n",
            "for              7\n",
            "suspected        7\n",
            "inflammatory     7\n",
            "s                7\n",
            "##ne             6\n",
            "u                6\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Analyze what entities were found\n",
        "def analyze_predictions(pred_df):\n",
        "    all_entities = []\n",
        "    for _, row in pred_df.iterrows():\n",
        "        for ent in row['pred_entities']:\n",
        "            all_entities.append({\n",
        "                'entity': ent['word'],\n",
        "                'label': ent['entity_group'],\n",
        "                'score': ent['score']\n",
        "            })\n",
        "    \n",
        "    entity_df = pd.DataFrame(all_entities)\n",
        "    \n",
        "    print(\"\\nEntity Label Distribution:\")\n",
        "    print(entity_df['label'].value_counts())\n",
        "    \n",
        "    print(\"\\nTop entities by label:\")\n",
        "    for label in entity_df['label'].unique():\n",
        "        print(f\"\\n{label}:\")\n",
        "        top_ents = entity_df[entity_df['label']==label]['entity'].value_counts().head(10)\n",
        "        print(top_ents)\n",
        "    \n",
        "    return entity_df\n",
        "\n",
        "if 'full_predictions' in locals():\n",
        "    entity_analysis = analyze_predictions(full_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Quality Checks and Post-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter by confidence threshold\n",
        "def filter_by_confidence(pred_df, min_score=0.8):\n",
        "    filtered_rows = []\n",
        "    for _, row in pred_df.iterrows():\n",
        "        filtered_ents = [e for e in row['pred_entities'] if e['score'] >= min_score]\n",
        "        filtered_rows.append({\n",
        "            'idx': row['idx'],\n",
        "            'text': row['text'],\n",
        "            'pred_entities': filtered_ents\n",
        "        })\n",
        "    return pd.DataFrame(filtered_rows)\n",
        "\n",
        "high_conf_predictions = filter_by_confidence(full_predictions, min_score=0.85)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Final Entities for Downstream Tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create final entity extraction for downstream use\n",
        "def create_final_entities(pred_df):\n",
        "    rows = []\n",
        "    for _, row in pred_df.iterrows():\n",
        "        for ent in row['pred_entities']:\n",
        "            rows.append({\n",
        "                'idx': row['idx'],\n",
        "                'entity_text': ent['word'],\n",
        "                'entity_label': ent['entity_group'],\n",
        "                'start': ent['start'],\n",
        "                'end': ent['end'],\n",
        "                'confidence': ent['score']\n",
        "            })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "final_entities = create_final_entities(full_predictions)\n",
        "final_entities.to_parquet(\"final_extracted_entities.parquet\", index=False)\n",
        "\n",
        "# Merge with original data if needed\n",
        "enriched_df = df_lean.merge(\n",
        "    final_entities.groupby('idx').agg(\n",
        "        entities=('entity_text', list),\n",
        "        labels=('entity_label', list),\n",
        "        n_entities=('entity_text', 'count')\n",
        "    ).reset_index(),\n",
        "    on='idx',\n",
        "    how='left'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>note</th>\n",
              "      <th>entities</th>\n",
              "      <th>labels</th>\n",
              "      <th>n_entities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155216</td>\n",
              "      <td>A a sixteen year-old girl, presented to our Ou...</td>\n",
              "      <td>[discomfort, neck, lower back, right, sustaine...</td>\n",
              "      <td>[Problem, Anatomy, Problem, Laterality, Tempor...</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>77465</td>\n",
              "      <td>This is the case of a 56-year-old man that was...</td>\n",
              "      <td>[56 - year - old, man, dump pain, right, back,...</td>\n",
              "      <td>[AgeSex, Sex, Problem, Laterality, Anatomy, Pr...</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133948</td>\n",
              "      <td>A 36-year old female patient visited our hospi...</td>\n",
              "      <td>[36, female patient, pain and restricted range...</td>\n",
              "      <td>[Age, Sex, Problem, Problem, Laterality, Probl...</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80176</td>\n",
              "      <td>A 49-year-old male presented with a complaint ...</td>\n",
              "      <td>[49 - year - old, male, pain, left, proximal f...</td>\n",
              "      <td>[AgeSex, Sex, Problem, Laterality, Anatomy, La...</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72232</td>\n",
              "      <td>A 47-year-old male patient was referred to the...</td>\n",
              "      <td>[47 - year - old, male patient, recurrent, pai...</td>\n",
              "      <td>[AgeSex, Sex, TemporalPattern, Problem, Latera...</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>39279</td>\n",
              "      <td>A 28-year-old male was admitted to the emergen...</td>\n",
              "      <td>[28 - year - old, male, left, nipple, left, ch...</td>\n",
              "      <td>[AgeSex, Sex, Laterality, Anatomy, Laterality,...</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>137017</td>\n",
              "      <td>An 82-year-old man (64.5 kg, 175 cm) diagnosed...</td>\n",
              "      <td>[82 - year - old, man, falcine, men, ##ingioma...</td>\n",
              "      <td>[AgeSex, Sex, Problem, Sex, Problem, Problem, ...</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>98004</td>\n",
              "      <td>A 54 year-old man with no past medical history...</td>\n",
              "      <td>[54, man, cardiac, chest pain, coronary, myoca...</td>\n",
              "      <td>[Age, Sex, Problem, Problem, Anatomy, Problem,...</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>133320</td>\n",
              "      <td>A 49-year-old woman visited the clinic due to ...</td>\n",
              "      <td>[49 - year - old, woman, mass, right, thigh, m...</td>\n",
              "      <td>[AgeSex, Sex, Problem, Laterality, Anatomy, Pr...</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>97973</td>\n",
              "      <td>A 31-year-old male with no significant past me...</td>\n",
              "      <td>[31 - year - old, male, acute, substernal, che...</td>\n",
              "      <td>[AgeSex, Sex, TemporalPattern, Anatomy, Proble...</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          idx                                               note  \\\n",
              "0      155216  A a sixteen year-old girl, presented to our Ou...   \n",
              "1       77465  This is the case of a 56-year-old man that was...   \n",
              "2      133948  A 36-year old female patient visited our hospi...   \n",
              "3       80176  A 49-year-old male presented with a complaint ...   \n",
              "4       72232  A 47-year-old male patient was referred to the...   \n",
              "...       ...                                                ...   \n",
              "29995   39279  A 28-year-old male was admitted to the emergen...   \n",
              "29996  137017  An 82-year-old man (64.5 kg, 175 cm) diagnosed...   \n",
              "29997   98004  A 54 year-old man with no past medical history...   \n",
              "29998  133320  A 49-year-old woman visited the clinic due to ...   \n",
              "29999   97973  A 31-year-old male with no significant past me...   \n",
              "\n",
              "                                                entities  \\\n",
              "0      [discomfort, neck, lower back, right, sustaine...   \n",
              "1      [56 - year - old, man, dump pain, right, back,...   \n",
              "2      [36, female patient, pain and restricted range...   \n",
              "3      [49 - year - old, male, pain, left, proximal f...   \n",
              "4      [47 - year - old, male patient, recurrent, pai...   \n",
              "...                                                  ...   \n",
              "29995  [28 - year - old, male, left, nipple, left, ch...   \n",
              "29996  [82 - year - old, man, falcine, men, ##ingioma...   \n",
              "29997  [54, man, cardiac, chest pain, coronary, myoca...   \n",
              "29998  [49 - year - old, woman, mass, right, thigh, m...   \n",
              "29999  [31 - year - old, male, acute, substernal, che...   \n",
              "\n",
              "                                                  labels  n_entities  \n",
              "0      [Problem, Anatomy, Problem, Laterality, Tempor...          46  \n",
              "1      [AgeSex, Sex, Problem, Laterality, Anatomy, Pr...          44  \n",
              "2      [Age, Sex, Problem, Problem, Laterality, Probl...          56  \n",
              "3      [AgeSex, Sex, Problem, Laterality, Anatomy, La...          49  \n",
              "4      [AgeSex, Sex, TemporalPattern, Problem, Latera...          71  \n",
              "...                                                  ...         ...  \n",
              "29995  [AgeSex, Sex, Laterality, Anatomy, Laterality,...          35  \n",
              "29996  [AgeSex, Sex, Problem, Sex, Problem, Problem, ...          49  \n",
              "29997  [Age, Sex, Problem, Problem, Anatomy, Problem,...          36  \n",
              "29998  [AgeSex, Sex, Problem, Laterality, Anatomy, Pr...          54  \n",
              "29999  [AgeSex, Sex, TemporalPattern, Anatomy, Proble...          53  \n",
              "\n",
              "[30000 rows x 5 columns]"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "enriched_df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp_clinical",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
