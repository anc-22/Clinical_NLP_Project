{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "viVUeCs_w87G"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sys\n",
        "import gc\n",
        "import os\n",
        "import spacy\n",
        "import scispacy\n",
        "from dateutil import parser\n",
        "from spacy.matcher import Matcher\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.4.4\n",
            "0.5.1\n",
            "3.4.0\n",
            "/opt/anaconda3/envs/nlp_clinical/bin/python\n"
          ]
        }
      ],
      "source": [
        "print(spacy.__version__)\n",
        "print(scispacy.__version__)\n",
        "import en_core_web_sm\n",
        "print(en_core_web_sm.__version__)\n",
        "import sys\n",
        "print(sys.executable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_data_path(filename):\n",
        "    \"\"\"\n",
        "    Returns the path to a file in the data/clean directory.\n",
        "    \n",
        "    Args:\n",
        "        filename (str): Name of the file (including extension)\n",
        "    \n",
        "    Returns:\n",
        "        str: Full path to the file\n",
        "    \"\"\"\n",
        "    cwd = os.getcwd()\n",
        "    parent_dir = os.path.dirname(cwd)\n",
        "    file_path = os.path.join(parent_dir, 'data', 'clean', filename)\n",
        "    return file_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MW9AtVsMxHf2"
      },
      "outputs": [],
      "source": [
        "df_medical_expanded = get_data_path('df_medical_expanded.csv')\n",
        "df_medical = pd.read_csv(df_medical_expanded, index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "e83tzaAQyjT0"
      },
      "outputs": [],
      "source": [
        "df_diagnosis_expanded = get_data_path('df_diagnosis_expanded.csv')\n",
        "df_diagnosis = pd.read_csv(df_diagnosis_expanded, index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "o_wuhPP_ynrx"
      },
      "outputs": [],
      "source": [
        "df_surgery_expanded = get_data_path('df_surgery_expanded.csv')\n",
        "df_surgery = pd.read_csv(df_surgery_expanded, index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OA923I2boKGO"
      },
      "outputs": [],
      "source": [
        "df_symptoms_expanded = get_data_path('df_symptoms_expanded.csv')\n",
        "df_symptoms = pd.read_csv(df_symptoms_expanded, index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_treatments_expanded = get_data_path('df_treatments_expanded.csv')\n",
        "df_treatments = pd.read_csv(df_treatments_expanded, index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_info_expanded = get_data_path('df_info_expanded.csv')\n",
        "df_info = pd.read_csv(df_info_expanded, index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV6EH4ZwyfA2"
      },
      "source": [
        "### Medical Entity Extractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MedicalEntityExtractor:\n",
        "    def __init__(self, model_name=\"en_core_sci_sm\", batch_size=500):\n",
        "        \"\"\"\n",
        "        Initialize the medical entity extractor.\n",
        "\n",
        "        Args:\n",
        "            model_name: ScispaCy model to use. Options:\n",
        "                       - \"en_core_sci_sm\" (smaller, faster, generic entities)\n",
        "                       - \"en_core_sci_md\" (medium)\n",
        "                       - \"en_ner_bc5cdr_md\" (disease/chemical focused - BEST FOR MEDICAL)\n",
        "                       - \"en_ner_bionlp13cg_md\" (multiple bio entity types)\n",
        "            batch_size: Number of texts to process at once\n",
        "        \"\"\"\n",
        "        self.batch_size = batch_size\n",
        "        self.model_name = model_name\n",
        "        self.nlp = None\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"Load the SpaCy model with optimizations for memory efficiency.\"\"\"\n",
        "        print(f\"Loading {self.model_name}...\")\n",
        "        try:\n",
        "            self.nlp = spacy.load(self.model_name)\n",
        "        except:\n",
        "            print(f\"Model {self.model_name} not found. Installing...\")\n",
        "            import os\n",
        "            # Install the appropriate model\n",
        "            if self.model_name == \"en_ner_bc5cdr_md\":\n",
        "                os.system(\"pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bc5cdr_md-0.5.1.tar.gz\")\n",
        "            elif self.model_name == \"en_ner_bionlp13cg_md\":\n",
        "                os.system(\"pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bionlp13cg_md-0.5.1.tar.gz\")\n",
        "            else:\n",
        "                os.system(f\"pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/{self.model_name}-0.5.1.tar.gz\")\n",
        "            self.nlp = spacy.load(self.model_name)\n",
        "\n",
        "        # Disable unnecessary pipeline components to save memory\n",
        "        pipes_to_disable = [\"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"]\n",
        "        for pipe in pipes_to_disable:\n",
        "            if pipe in self.nlp.pipe_names:\n",
        "                self.nlp.disable_pipe(pipe)\n",
        "\n",
        "        print(f\"Model loaded. Active pipes: {self.nlp.pipe_names}\")\n",
        "\n",
        "    def process_batch(self, texts, ids):  # renamed 'indices' -> 'ids' for clarity\n",
        "        batch_results = []\n",
        "        docs = list(self.nlp.pipe(texts, batch_size=50))\n",
        "        for doc, original_text, rid in zip(docs, texts, ids):\n",
        "            for ent in doc.ents:\n",
        "                batch_results.append({\n",
        "                    'text': ent.text,\n",
        "                    'label': ent.label_,\n",
        "                    'start': ent.start_char,\n",
        "                    'end': ent.end_char,\n",
        "                    'original_text': original_text,\n",
        "                    'row_idx': rid,   # <- comes from the provided id column\n",
        "                })\n",
        "        del docs\n",
        "        gc.collect()\n",
        "        return batch_results\n",
        "\n",
        "    def extract_entities_from_df(\n",
        "        self, df, text_column, *,\n",
        "        save_checkpoints=True, checkpoint_dir='./ner_checkpoints',\n",
        "        id_column='idx'                    \n",
        "    ):\n",
        "        if self.nlp is None:\n",
        "            self.load_model()\n",
        "\n",
        "        texts = df[text_column].fillna('').astype(str).tolist()\n",
        "\n",
        "        # --- NEW: choose row IDs from the given column; fallback to df.index ---\n",
        "        if id_column is not None and id_column in df.columns:\n",
        "            ids_series = df[id_column]\n",
        "            # if there are NaNs in idx, fall back to positional index for those rows\n",
        "            ids_series = ids_series.where(pd.notna(ids_series), df.index)\n",
        "            ids = ids_series.tolist()\n",
        "            print(f\"Stamping row identifier from column: '{id_column}'\")\n",
        "        else:\n",
        "            ids = df.index.tolist()\n",
        "            print(\"Stamping row identifier from DataFrame index\")\n",
        "\n",
        "        total_batches = (len(texts) + self.batch_size - 1) // self.batch_size\n",
        "        all_results = []\n",
        "\n",
        "        if save_checkpoints:\n",
        "            import os\n",
        "            os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "        print(f\"Processing {len(texts)} texts in {total_batches} batches...\")\n",
        "        print(f\"Using model: {self.model_name} for column: {text_column}\")\n",
        "\n",
        "        for batch_start in tqdm(range(0, len(texts), self.batch_size), desc=\"Processing batches\"):\n",
        "            batch_end   = batch_start + self.batch_size\n",
        "            batch_texts = texts[batch_start:batch_end]\n",
        "            batch_ids   = ids[batch_start:batch_end]\n",
        "\n",
        "            try:\n",
        "                batch_results = self.process_batch(batch_texts, batch_ids)\n",
        "                all_results.extend(batch_results)\n",
        "\n",
        "                if save_checkpoints and ((batch_start // self.batch_size) % 10 == 0):\n",
        "                    checkpoint_df = pd.DataFrame(all_results)\n",
        "                    safe_column_name = text_column.replace(' ', '_').replace('/', '_')\n",
        "                    checkpoint_df.to_csv(\n",
        "                        f\"{checkpoint_dir}/checkpoint_{safe_column_name}_{batch_start}.csv\",\n",
        "                        index=False\n",
        "                    )\n",
        "                    print(f\"\\nCheckpoint saved at batch {batch_start}\")\n",
        "            except Exception as e:\n",
        "                print(f\"\\nError processing batch {batch_start}: {e}\")\n",
        "                continue\n",
        "\n",
        "            if (batch_start // self.batch_size) % 5 == 0:\n",
        "                gc.collect()\n",
        "\n",
        "        results_df = pd.DataFrame(all_results)\n",
        "        results_df['source_column'] = text_column\n",
        "        return results_df\n",
        "\n",
        "    def get_entity_summary(self, entities_df):\n",
        "        \"\"\"Generate summary statistics of extracted entities.\"\"\"\n",
        "        summary = {\n",
        "            'total_entities': len(entities_df),\n",
        "            'unique_entities': entities_df['text'].nunique(),\n",
        "            'entity_types': entities_df['label'].value_counts().to_dict(),\n",
        "            'top_entities': entities_df['text'].value_counts().head(20).to_dict()\n",
        "        }\n",
        "        return summary\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "FMIFtI9oxaEr"
      },
      "outputs": [],
      "source": [
        "# Helper functions for analysis\n",
        "def analyze_medical_entities(entities_df, min_frequency=5):\n",
        "    \"\"\"Analyze extracted entities and create labeling functions.\"\"\"\n",
        "    \n",
        "    # Find frequent medical conditions\n",
        "    frequent_entities = entities_df['text'].value_counts()\n",
        "    frequent_entities = frequent_entities[frequent_entities >= min_frequency]\n",
        "    \n",
        "    print(f\"Found {len(frequent_entities)} entities appearing >= {min_frequency} times\")\n",
        "    \n",
        "    # Group by entity type\n",
        "    entity_groups = {}\n",
        "    for label in entities_df['label'].unique():\n",
        "        label_entities = entities_df[entities_df['label'] == label]['text'].value_counts()\n",
        "        entity_groups[label] = label_entities.head(10).to_dict()\n",
        "    \n",
        "    return frequent_entities, entity_groups\n",
        "\n",
        "def create_entity_based_rules(entities_df, target_labels=['DISEASE', 'CHEMICAL'], source_column=None):\n",
        "    \"\"\"Create labeling functions based on extracted entities.\"\"\"\n",
        "    \n",
        "    # Get the source column from the entities_df if not provided\n",
        "    if source_column is None:\n",
        "        if 'source_column' in entities_df.columns:\n",
        "            source_column = entities_df['source_column'].iloc[0]\n",
        "        else:\n",
        "            raise ValueError(\"source_column must be provided or available in entities_df\")\n",
        "    \n",
        "    # Get top entities for each label type\n",
        "    rules = {}\n",
        "    \n",
        "    for label in target_labels:\n",
        "        if label in entities_df['label'].unique():\n",
        "            top_entities = entities_df[entities_df['label'] == label]['text'].value_counts().head(20)\n",
        "            \n",
        "            # Create a labeling function for this entity type\n",
        "            def make_labeling_function(entity_list, label_name, column_name):\n",
        "                def lf(row):\n",
        "                    # Handle column names with spaces\n",
        "                    if column_name in row:\n",
        "                        text = str(row[column_name]).lower()\n",
        "                    else:\n",
        "                        # Try alternative column names\n",
        "                        alt_column = column_name.replace('_', ' ')\n",
        "                        if alt_column in row:\n",
        "                            text = str(row[alt_column]).lower()\n",
        "                        else:\n",
        "                            return 'ABSTAIN'\n",
        "                    \n",
        "                    for entity in entity_list:\n",
        "                        if entity.lower() in text:\n",
        "                            return label_name\n",
        "                    return 'ABSTAIN'\n",
        "                \n",
        "                # Create safe function name\n",
        "                safe_column_name = column_name.replace(' ', '_').replace('/', '_')\n",
        "                lf.__name__ = f\"lf_{label_name.lower()}_{safe_column_name}\"\n",
        "                return lf\n",
        "            \n",
        "            rules[f'lf_{label.lower()}_{source_column.replace(\" \", \"_\")}'] = make_labeling_function(\n",
        "                top_entities.index.tolist(),\n",
        "                label,\n",
        "                source_column\n",
        "            )\n",
        "    \n",
        "    return rules\n",
        "\n",
        "# Main execution function for single column\n",
        "def run_medical_ner_extraction(df, text_column,\n",
        "                               model_name=\"en_ner_bc5cdr_md\", batch_size=500,id_column='idx'):\n",
        "    \"\"\"\n",
        "    Complete pipeline to extract medical entities from dataframe.\n",
        "    \n",
        "    Args:\n",
        "        df: dataframe with medical text\n",
        "        text_column: Column containing the text (NOW REQUIRED, NO DEFAULT)\n",
        "        model_name: Which ScispaCy model to use\n",
        "        batch_size: Batch size for processing\n",
        "    \n",
        "    Returns:\n",
        "        entities_df: DataFrame with all extracted entities\n",
        "        summary: Summary statistics\n",
        "        rules: Generated labeling functions\n",
        "    \"\"\"\n",
        "    if text_column not in df.columns:\n",
        "        raise ValueError(f\"Column '{text_column}' not found in dataframe.\")\n",
        "\n",
        "    extractor = MedicalEntityExtractor(model_name=model_name, batch_size=batch_size)\n",
        "    entities_df = extractor.extract_entities_from_df(\n",
        "        df, text_column, id_column=id_column\n",
        "    )\n",
        "    summary = extractor.get_entity_summary(entities_df)\n",
        "    frequent_entities, entity_groups = analyze_medical_entities(entities_df)\n",
        "    rules = create_entity_based_rules(entities_df, source_column=text_column)\n",
        "    return entities_df, summary, rules\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXFksOxYy3nJ"
      },
      "source": [
        "#### Extracting Entities From Patient Medical Record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        },
        "id": "AGXyAGvVGsRo",
        "outputId": "c2c61f27-c2c1-4b3f-bdfe-d1c19d76075e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>has_medical_history</th>\n",
              "      <th>physiological context</th>\n",
              "      <th>psychological context</th>\n",
              "      <th>vaccination history</th>\n",
              "      <th>allergies</th>\n",
              "      <th>exercise frequency</th>\n",
              "      <th>nutrition</th>\n",
              "      <th>sexual history</th>\n",
              "      <th>alcohol consumption</th>\n",
              "      <th>drug usage</th>\n",
              "      <th>smoking status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155216</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Diagnosed with bipolar affective disorder at t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133948</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Intensifying feelings of helplessness</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80176</td>\n",
              "      <td>True</td>\n",
              "      <td>History of left elbow arthrodesis performed fo...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72232</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>31864</td>\n",
              "      <td>True</td>\n",
              "      <td>Inability to walk since babyhood, did not walk...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Got married at the age of 15 and became pregna...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>26809</td>\n",
              "      <td>True</td>\n",
              "      <td>Normal Apgar score, no resuscitation required ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>149866</td>\n",
              "      <td>True</td>\n",
              "      <td>Coxa vara deformity of bilateral hips, bilater...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>87064</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Patient could not realize that his symptoms mi...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>123006</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>119317</td>\n",
              "      <td>True</td>\n",
              "      <td>Born at full term by spontaneous vaginal deliv...</td>\n",
              "      <td>Mentally healthy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>92167</td>\n",
              "      <td>True</td>\n",
              "      <td>Colorectal carcinoma treated by rectum and ile...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>42234</td>\n",
              "      <td>True</td>\n",
              "      <td>Healthy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>92105</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>89665</td>\n",
              "      <td>True</td>\n",
              "      <td>Hypertension, Hyperlipidaemia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>149815</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>91779</td>\n",
              "      <td>True</td>\n",
              "      <td>Nondiabetic and nonhypertensive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>146172</td>\n",
              "      <td>True</td>\n",
              "      <td>Otherwise healthy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>89642</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>90928</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Parental distress</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>43555</td>\n",
              "      <td>True</td>\n",
              "      <td>Past medical history significant for RCC, init...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>129465</td>\n",
              "      <td>True</td>\n",
              "      <td>Hypertension, type 2 diabetes, invasive ductal...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>80892</td>\n",
              "      <td>True</td>\n",
              "      <td>Diagnosed with a type of muscular dystrophy at...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>80727</td>\n",
              "      <td>True</td>\n",
              "      <td>Complete heart block, had dual chamber pacemak...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>49286</td>\n",
              "      <td>True</td>\n",
              "      <td>Hypertension, dyslipidemia, traumatic lumbar f...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>159059</td>\n",
              "      <td>True</td>\n",
              "      <td>Born at full term with normal delivery, normal...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>18630</td>\n",
              "      <td>True</td>\n",
              "      <td>gravidity 3, parity 2, no medical problems dur...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>168381</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>45433</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Known to local mental health services for 20 y...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>76225</td>\n",
              "      <td>True</td>\n",
              "      <td>Diagnosed with a left ICA occlusion at an oute...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>88707</td>\n",
              "      <td>True</td>\n",
              "      <td>Three separate left breast biopsies in the pas...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       idx  has_medical_history  \\\n",
              "0   155216                 True   \n",
              "2   133948                 True   \n",
              "3    80176                 True   \n",
              "4    72232                 True   \n",
              "5    31864                 True   \n",
              "6    26809                 True   \n",
              "7   149866                 True   \n",
              "8    87064                 True   \n",
              "9   123006                 True   \n",
              "10  119317                 True   \n",
              "11   92167                 True   \n",
              "12   42234                 True   \n",
              "13   92105                 True   \n",
              "14   89665                 True   \n",
              "15  149815                 True   \n",
              "16   91779                 True   \n",
              "17  146172                 True   \n",
              "18   89642                 True   \n",
              "19   90928                 True   \n",
              "20   43555                 True   \n",
              "21  129465                 True   \n",
              "22   80892                 True   \n",
              "23   80727                 True   \n",
              "24   49286                 True   \n",
              "25  159059                 True   \n",
              "26   18630                 True   \n",
              "27  168381                 True   \n",
              "28   45433                 True   \n",
              "29   76225                 True   \n",
              "30   88707                 True   \n",
              "\n",
              "                                physiological context  \\\n",
              "0                                                 NaN   \n",
              "2                                                 NaN   \n",
              "3   History of left elbow arthrodesis performed fo...   \n",
              "4                                                 NaN   \n",
              "5   Inability to walk since babyhood, did not walk...   \n",
              "6   Normal Apgar score, no resuscitation required ...   \n",
              "7   Coxa vara deformity of bilateral hips, bilater...   \n",
              "8                                                 NaN   \n",
              "9                                                 NaN   \n",
              "10  Born at full term by spontaneous vaginal deliv...   \n",
              "11  Colorectal carcinoma treated by rectum and ile...   \n",
              "12                                            Healthy   \n",
              "13                                                NaN   \n",
              "14                      Hypertension, Hyperlipidaemia   \n",
              "15                                                NaN   \n",
              "16                    Nondiabetic and nonhypertensive   \n",
              "17                                  Otherwise healthy   \n",
              "18                                                NaN   \n",
              "19                                                NaN   \n",
              "20  Past medical history significant for RCC, init...   \n",
              "21  Hypertension, type 2 diabetes, invasive ductal...   \n",
              "22  Diagnosed with a type of muscular dystrophy at...   \n",
              "23  Complete heart block, had dual chamber pacemak...   \n",
              "24  Hypertension, dyslipidemia, traumatic lumbar f...   \n",
              "25  Born at full term with normal delivery, normal...   \n",
              "26  gravidity 3, parity 2, no medical problems dur...   \n",
              "27                                                NaN   \n",
              "28                                                NaN   \n",
              "29  Diagnosed with a left ICA occlusion at an oute...   \n",
              "30  Three separate left breast biopsies in the pas...   \n",
              "\n",
              "                                psychological context vaccination history  \\\n",
              "0   Diagnosed with bipolar affective disorder at t...                 NaN   \n",
              "2               Intensifying feelings of helplessness                 NaN   \n",
              "3                                                 NaN                 NaN   \n",
              "4                                                 NaN                 NaN   \n",
              "5                                                 NaN                 NaN   \n",
              "6                                                 NaN                 NaN   \n",
              "7                                                 NaN                 NaN   \n",
              "8   Patient could not realize that his symptoms mi...                 NaN   \n",
              "9                                                 NaN                 NaN   \n",
              "10                                   Mentally healthy                 NaN   \n",
              "11                                                NaN                 NaN   \n",
              "12                                                NaN                 NaN   \n",
              "13                                                NaN                 NaN   \n",
              "14                                                NaN                 NaN   \n",
              "15                                                NaN                 NaN   \n",
              "16                                                NaN                 NaN   \n",
              "17                                                NaN                 NaN   \n",
              "18                                                NaN                 NaN   \n",
              "19                                  Parental distress                 NaN   \n",
              "20                                                NaN                 NaN   \n",
              "21                                                NaN                 NaN   \n",
              "22                                                NaN                 NaN   \n",
              "23                                                NaN                 NaN   \n",
              "24                                                NaN                 NaN   \n",
              "25                                                NaN                 NaN   \n",
              "26                                                NaN                 NaN   \n",
              "27                                                NaN                 NaN   \n",
              "28  Known to local mental health services for 20 y...                 NaN   \n",
              "29                                                NaN                 NaN   \n",
              "30                                                NaN                 NaN   \n",
              "\n",
              "   allergies exercise frequency nutrition  \\\n",
              "0        NaN                NaN       NaN   \n",
              "2        NaN                NaN       NaN   \n",
              "3        NaN                NaN       NaN   \n",
              "4        NaN                NaN       NaN   \n",
              "5        NaN                NaN       NaN   \n",
              "6        NaN                NaN       NaN   \n",
              "7        NaN                NaN       NaN   \n",
              "8        NaN                NaN       NaN   \n",
              "9        NaN                NaN       NaN   \n",
              "10       NaN                NaN       NaN   \n",
              "11       NaN                NaN       NaN   \n",
              "12       NaN                NaN       NaN   \n",
              "13       NaN                NaN       NaN   \n",
              "14       NaN                NaN       NaN   \n",
              "15       NaN                NaN       NaN   \n",
              "16       NaN                NaN       NaN   \n",
              "17       NaN                NaN       NaN   \n",
              "18       NaN                NaN       NaN   \n",
              "19       NaN                NaN       NaN   \n",
              "20       NaN                NaN       NaN   \n",
              "21       NaN                NaN       NaN   \n",
              "22       NaN                NaN       NaN   \n",
              "23       NaN                NaN       NaN   \n",
              "24       NaN                NaN       NaN   \n",
              "25       NaN                NaN       NaN   \n",
              "26       NaN                NaN       NaN   \n",
              "27       NaN                NaN       NaN   \n",
              "28       NaN                NaN       NaN   \n",
              "29       NaN                NaN       NaN   \n",
              "30       NaN                NaN       NaN   \n",
              "\n",
              "                                       sexual history alcohol consumption  \\\n",
              "0                                                 NaN                 NaN   \n",
              "2                                                 NaN                 NaN   \n",
              "3                                                 NaN                 NaN   \n",
              "4                                                 NaN                 NaN   \n",
              "5   Got married at the age of 15 and became pregna...                 NaN   \n",
              "6                                                 NaN                 NaN   \n",
              "7                                                 NaN                 NaN   \n",
              "8                                                 NaN                 NaN   \n",
              "9                                                 NaN                 NaN   \n",
              "10                                                NaN                 NaN   \n",
              "11                                                NaN                 NaN   \n",
              "12                                                NaN                 NaN   \n",
              "13                                                NaN                 NaN   \n",
              "14                                                NaN                 NaN   \n",
              "15                                                NaN                 NaN   \n",
              "16                                                NaN                 NaN   \n",
              "17                                                NaN                 NaN   \n",
              "18                                                NaN                 NaN   \n",
              "19                                                NaN                 NaN   \n",
              "20                                                NaN                 NaN   \n",
              "21                                                NaN                 NaN   \n",
              "22                                                NaN                 NaN   \n",
              "23                                                NaN                 NaN   \n",
              "24                                                NaN                 NaN   \n",
              "25                                                NaN                 NaN   \n",
              "26                                                NaN                 NaN   \n",
              "27                                                NaN                 NaN   \n",
              "28                                                NaN                 NaN   \n",
              "29                                                NaN                 NaN   \n",
              "30                                                NaN                 NaN   \n",
              "\n",
              "   drug usage smoking status  \n",
              "0         NaN            NaN  \n",
              "2         NaN            NaN  \n",
              "3         NaN            NaN  \n",
              "4         NaN            NaN  \n",
              "5         NaN            NaN  \n",
              "6         NaN            NaN  \n",
              "7         NaN            NaN  \n",
              "8         NaN            NaN  \n",
              "9         NaN            NaN  \n",
              "10        NaN            NaN  \n",
              "11        NaN            NaN  \n",
              "12        NaN            NaN  \n",
              "13        NaN            NaN  \n",
              "14        NaN            NaN  \n",
              "15        NaN            NaN  \n",
              "16        NaN            NaN  \n",
              "17        NaN            NaN  \n",
              "18        NaN            NaN  \n",
              "19        NaN            NaN  \n",
              "20        NaN            NaN  \n",
              "21        NaN            NaN  \n",
              "22        NaN            NaN  \n",
              "23        NaN            NaN  \n",
              "24        NaN            NaN  \n",
              "25        NaN            NaN  \n",
              "26        NaN            NaN  \n",
              "27        NaN            NaN  \n",
              "28        NaN            NaN  \n",
              "29        NaN            NaN  \n",
              "30        NaN            NaN  "
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_medical.head(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "psychological context\n",
              "Depression                                                               85\n",
              "Bipolar disorder                                                         30\n",
              "Schizophrenia                                                            29\n",
              "Anxiety                                                                  27\n",
              "No significant psychosocial history                                      14\n",
              "                                                                         ..\n",
              "Paranoid schizophrenia and bipolar disorder                               1\n",
              "Mentally retarded with aggressive behavior                                1\n",
              "Mental retardation grade 2, intelligence quotient of 23                   1\n",
              "mild phantom limb pain and very frequent nonpainful phantom sensation     1\n",
              "Exhibiting a tortured expression                                          1\n",
              "Name: count, Length: 2231, dtype: int64"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_medical['psychological context'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lrp60uMUy-bz"
      },
      "source": [
        "##### Physiological Contexts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoCanH92yzl_",
        "outputId": "dc25f9e7-9e35-423e-a81b-159aeba11064"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading en_ner_bc5cdr_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 29755 texts in 60 batches...\n",
            "Using model: en_ner_bc5cdr_md for column: physiological context\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   2%|▏         | 1/60 [00:01<01:42,  1.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  18%|█▊        | 11/60 [00:16<01:05,  1.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 5000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  35%|███▌      | 21/60 [00:29<00:51,  1.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 10000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  52%|█████▏    | 31/60 [00:41<00:37,  1.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  68%|██████▊   | 41/60 [00:54<00:25,  1.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 20000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  85%|████████▌ | 51/60 [01:06<00:11,  1.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 25000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 60/60 [01:17<00:00,  1.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1249 entities appearing >= 5 times\n",
            "\n",
            "Testing generated labeling functions on df_medical...\n",
            "lf_disease_physiological_context applied to row 0: ABSTAIN\n",
            "lf_chemical_physiological_context applied to row 0: ABSTAIN\n",
            "\n",
            "=== DEBUG: Check extracted entities dataframe ===\n",
            "Shape of df_physiological_entities: (36272, 7)\n",
            "\n",
            "Column names: ['text', 'label', 'start', 'end', 'original_text', 'row_idx', 'source_column']\n",
            "\n",
            "First few rows:\n",
            "                      text    label  start  end  \\\n",
            "0  posttraumatic arthritis  DISEASE     48   71   \n",
            "1                     pain  DISEASE    116  120   \n",
            "2                 fracture  DISEASE    151  159   \n",
            "3      Coxa vara deformity  DISEASE      0   19   \n",
            "4                 fracture  DISEASE     75   83   \n",
            "\n",
            "                                       original_text  row_idx  \\\n",
            "0  History of left elbow arthrodesis performed fo...    80176   \n",
            "1  Inability to walk since babyhood, did not walk...    31864   \n",
            "2  Inability to walk since babyhood, did not walk...    31864   \n",
            "3  Coxa vara deformity of bilateral hips, bilater...   149866   \n",
            "4  Coxa vara deformity of bilateral hips, bilater...   149866   \n",
            "\n",
            "           source_column  \n",
            "0  physiological context  \n",
            "1  physiological context  \n",
            "2  physiological context  \n",
            "3  physiological context  \n",
            "4  physiological context  \n",
            "\n",
            "=== ACTUAL Entity Labels Found in df_physiological_entities ===\n",
            "label\n",
            "DISEASE     34647\n",
            "CHEMICAL     1625\n",
            "Name: count, dtype: int64\n",
            "\n",
            "============================================================\n",
            "CUSTOM ANATOMY EXTRACTION FOR PHYSIOLOGICAL CONTEXT\n",
            "============================================================\n",
            "\n",
            "Extracting anatomy entities...\n",
            "\n",
            "Custom anatomy extraction found 11110 anatomy mentions\n",
            "\n",
            "=== Anatomy Entity Distribution ===\n",
            "label\n",
            "ANATOMY                    10217\n",
            "ANATOMY_WITH_LATERALITY      893\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Anatomy Terms ===\n",
            "text\n",
            "coronary      763\n",
            "artery        747\n",
            "pulmonary     687\n",
            "heart         609\n",
            "back          584\n",
            "kidney        544\n",
            "liver         400\n",
            "valve         357\n",
            "lung          335\n",
            "knee          304\n",
            "neck          245\n",
            "hip           244\n",
            "cerebral      207\n",
            "cardiac       200\n",
            "thyroid       194\n",
            "bone          193\n",
            "skin          186\n",
            "vein          176\n",
            "bladder       173\n",
            "prostate      165\n",
            "chest         145\n",
            "colon         143\n",
            "limb          136\n",
            "joint         118\n",
            "muscle        107\n",
            "lobe          106\n",
            "extremity     103\n",
            "brain         100\n",
            "lymph node     98\n",
            "femur          97\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Anatomy by Category ===\n",
            "category\n",
            "cardiovascular    3293\n",
            "organs            3075\n",
            "joints            2220\n",
            "bones              811\n",
            "regions            591\n",
            "tissues            481\n",
            "neurological       428\n",
            "muscles            211\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Examples of Anatomy with Laterality ===\n",
            "              text laterality    anatomy\n",
            "1       left elbow       left      elbow\n",
            "4   bilateral hips  bilateral       hips\n",
            "19        left hip       left        hip\n",
            "28  right coronary      right   coronary\n",
            "30        left hip       left        hip\n",
            "32        left hip       left        hip\n",
            "37       left knee       left       knee\n",
            "39        left hip       left        hip\n",
            "44        left hip       left        hip\n",
            "51  left ventricle       left  ventricle\n",
            "\n",
            "=== COMBINING BC5CDR AND CUSTOM ENTITIES ===\n",
            "\n",
            "Total combined entities: 47382\n",
            "\n",
            "Combined entity distribution:\n",
            "label\n",
            "DISEASE                    34647\n",
            "ANATOMY                    10217\n",
            "CHEMICAL                    1625\n",
            "ANATOMY_WITH_LATERALITY      893\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Creating Anatomy-Specific Labeling Functions ===\n",
            "\n",
            "Testing anatomy labeling functions:\n",
            "\n",
            "\n",
            "Entity extraction complete! Saved:\n",
            "- physiological_entities_with_anatomy.csv (combined BC5CDR + anatomy)\n",
            "- anatomy_entities_detailed.csv (detailed anatomy with categories)\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Run extraction for the 'physiological context' column\n",
        "    df_physiological_entities, disease_summary, rules = run_medical_ner_extraction(\n",
        "        df_medical,\n",
        "        text_column='physiological context',\n",
        "        model_name=\"en_ner_bc5cdr_md\",\n",
        "        batch_size=500,\n",
        "        id_column='idx')\n",
        "    \n",
        "    # Test the generated rules\n",
        "    print(\"\\nTesting generated labeling functions on df_medical...\")\n",
        "    \n",
        "    # Select a sample row from the original df_medical to test the rules\n",
        "    # Ensure df_medical is not empty before accessing iloc[0]\n",
        "    if not df_medical.empty:\n",
        "        sample_row = df_medical.iloc[0]\n",
        "        \n",
        "        for rule_name, rule_func in rules.items():\n",
        "            # Apply the rule function to a row from the original df_medical\n",
        "            try:\n",
        "                test_result = rule_func(sample_row)\n",
        "                print(f\"{rule_name} applied to row 0: {test_result}\")\n",
        "            except KeyError as e:\n",
        "                print(f\"Error applying rule {rule_name}: {e}. Make sure the column '{e}' exists in df_medical.\")\n",
        "    else:\n",
        "        print(\"df_medical is empty, cannot test rules.\")\n",
        "    \n",
        "    print(\"\\n=== DEBUG: Check extracted entities dataframe ===\")\n",
        "    print(f\"Shape of df_physiological_entities: {df_physiological_entities.shape}\")\n",
        "    print(f\"\\nColumn names: {df_physiological_entities.columns.tolist()}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(df_physiological_entities.head())\n",
        "    \n",
        "    # Check what labels ScispaCy actually found in the entities dataframe\n",
        "    print(\"\\n=== ACTUAL Entity Labels Found in df_physiological_entities ===\")\n",
        "    if not df_physiological_entities.empty:\n",
        "        print(df_physiological_entities['label'].value_counts())\n",
        "        \n",
        "        # Check for 'ENTITY' label if present\n",
        "        if 'ENTITY' in df_physiological_entities['label'].values:\n",
        "            print(\"\\n=== Top ENTITY type examples from df_physiological_entities ===\")\n",
        "            physiological_entity_examples = df_physiological_entities[df_physiological_entities['label'] == 'ENTITY']['text'].value_counts().head(20)\n",
        "            print(physiological_entity_examples)\n",
        "    else:\n",
        "        print(\"df_physiological_entities is empty.\")\n",
        "    \n",
        "    # ============= CUSTOM ANATOMY EXTRACTION =============\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"CUSTOM ANATOMY EXTRACTION FOR PHYSIOLOGICAL CONTEXT\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    def extract_anatomy_from_physiological_context(df_medical, text_column, id_column='idx'):\n",
        "        \"\"\"Extract anatomy entities from physiological context that BC5CDR might miss\"\"\"\n",
        "        \n",
        "        anatomy_entities = []\n",
        "         # build the id series once\n",
        "        if id_column is not None and id_column in df_medical.columns:\n",
        "            ids_series = df_medical[id_column].where(pd.notna(df_medical[id_column]), df_medical.index)\n",
        "        else:\n",
        "            ids_series = df_medical.index\n",
        "\n",
        "        texts = df_medical[text_column].fillna('').astype(str)\n",
        "        \n",
        "        # Comprehensive anatomy patterns\n",
        "        anatomy_patterns = {\n",
        "            'organs': [\n",
        "                'heart', 'lung', 'lungs', 'liver', 'kidney', 'kidneys', 'brain', \n",
        "                'pancreas', 'spleen', 'stomach', 'intestine', 'colon', 'bladder',\n",
        "                'gallbladder', 'thyroid', 'prostate', 'uterus', 'ovary', 'ovaries'\n",
        "            ],\n",
        "            'bones': [\n",
        "                'bone', 'femur', 'tibia', 'fibula', 'humerus', 'radius', 'ulna',\n",
        "                'skull', 'spine', 'vertebra', 'vertebrae', 'rib', 'ribs', 'pelvis',\n",
        "                'clavicle', 'scapula', 'sternum', 'patella'\n",
        "            ],\n",
        "            'joints': [\n",
        "                'joint', 'hip', 'knee', 'shoulder', 'elbow', 'wrist', 'ankle',\n",
        "                'knuckle', 'finger', 'toe', 'neck', 'back'\n",
        "            ],\n",
        "            'cardiovascular': [\n",
        "                'artery', 'arteries', 'vein', 'veins', 'vessel', 'vessels',\n",
        "                'aorta', 'carotid', 'coronary', 'pulmonary', 'cardiac',\n",
        "                'ventricle', 'atrium', 'valve'\n",
        "            ],\n",
        "            'neurological': [\n",
        "                'nerve', 'nerves', 'neural', 'spinal cord', 'brainstem',\n",
        "                'cerebral', 'cerebellum', 'cortex', 'lobe', 'ganglion'\n",
        "            ],\n",
        "            'muscles': [\n",
        "                'muscle', 'muscles', 'tendon', 'ligament', 'fascia',\n",
        "                'biceps', 'triceps', 'quadriceps', 'hamstring'\n",
        "            ],\n",
        "            'regions': [\n",
        "                'chest', 'abdomen', 'pelvis', 'thorax', 'cranium',\n",
        "                'extremity', 'limb', 'upper extremity', 'lower extremity'\n",
        "            ],\n",
        "            'tissues': [\n",
        "                'skin', 'tissue', 'membrane', 'mucosa', 'epithelium',\n",
        "                'cartilage', 'marrow', 'lymph node', 'gland'\n",
        "            ]\n",
        "        }\n",
        "        \n",
        "        # Laterality terms\n",
        "        laterality_terms = ['left', 'right', 'bilateral', 'unilateral']\n",
        "        \n",
        "        # Process each row\n",
        "        for (df_index, text_original), idx in zip(texts.items(), ids_series):\n",
        "            if text_original:\n",
        "                text = text_original.lower()\n",
        "                \n",
        "                # Extract anatomy terms\n",
        "                for category, terms in anatomy_patterns.items():\n",
        "                    for term in terms:\n",
        "                        if term in text:\n",
        "                            # Find all occurrences\n",
        "                            import re\n",
        "                            for match in re.finditer(r'\\b' + re.escape(term) + r'\\b', text):\n",
        "                                anatomy_entities.append({\n",
        "                                    'text': term,\n",
        "                                    'label': 'ANATOMY',\n",
        "                                    'category': category,\n",
        "                                    'start': match.start(),\n",
        "                                    'end': match.end(),\n",
        "                                    'original_text': df_medical.at[df_index, text_column],\n",
        "                                    'source': 'custom_anatomy_extraction',\n",
        "                                    'row_idx': idx\n",
        "                                })\n",
        "                \n",
        "                # Extract laterality + anatomy combinations\n",
        "                for lat_term in laterality_terms:\n",
        "                    # Pattern: \"left hip\", \"bilateral knees\", etc.\n",
        "                    pattern = rf'\\b{lat_term}\\s+(\\w+)\\b'\n",
        "                    matches = re.finditer(pattern, text)\n",
        "                    for match in matches:\n",
        "                        full_term = match.group(0)\n",
        "                        anatomy_part = match.group(1)\n",
        "                        \n",
        "                        # Check if the anatomy part is in our patterns\n",
        "                        for category, terms in anatomy_patterns.items():\n",
        "                            if any(anatomy_part.startswith(term) for term in terms):\n",
        "                                anatomy_entities.append({\n",
        "                                    'text': full_term,\n",
        "                                    'label': 'ANATOMY_WITH_LATERALITY',\n",
        "                                    'category': category,\n",
        "                                    'laterality': lat_term,\n",
        "                                    'anatomy': anatomy_part,\n",
        "                                    'start': match.start(),\n",
        "                                    'end': match.end(),\n",
        "                                    'original_text': df_medical.at[df_index, text_column],\n",
        "                                    'source': 'custom_anatomy_extraction',\n",
        "                                    'row_idx': idx\n",
        "                                })\n",
        "                                break\n",
        "        \n",
        "        return pd.DataFrame(anatomy_entities)\n",
        "    \n",
        "    # Extract custom anatomy entities\n",
        "    print(\"\\nExtracting anatomy entities...\")\n",
        "    df_anatomy_custom = extract_anatomy_from_physiological_context(df_medical, text_column='physiological context', id_column='idx')\n",
        "    \n",
        "    print(f\"\\nCustom anatomy extraction found {len(df_anatomy_custom)} anatomy mentions\")\n",
        "    \n",
        "    if not df_anatomy_custom.empty:\n",
        "        print(\"\\n=== Anatomy Entity Distribution ===\")\n",
        "        print(df_anatomy_custom['label'].value_counts())\n",
        "        \n",
        "        print(\"\\n=== Top Anatomy Terms ===\")\n",
        "        print(df_anatomy_custom['text'].value_counts().head(30))\n",
        "        \n",
        "        print(\"\\n=== Anatomy by Category ===\")\n",
        "        print(df_anatomy_custom['category'].value_counts())\n",
        "        \n",
        "        # Show examples of laterality\n",
        "        laterality_examples = df_anatomy_custom[df_anatomy_custom['label'] == 'ANATOMY_WITH_LATERALITY']\n",
        "        if not laterality_examples.empty:\n",
        "            print(\"\\n=== Examples of Anatomy with Laterality ===\")\n",
        "            print(laterality_examples[['text', 'laterality', 'anatomy']].head(10))\n",
        "    \n",
        "    # Combine BC5CDR entities with custom anatomy entities\n",
        "    print(\"\\n=== COMBINING BC5CDR AND CUSTOM ENTITIES ===\")\n",
        "    df_all_physiological_entities = pd.concat([\n",
        "        df_physiological_entities,\n",
        "        df_anatomy_custom[['text', 'label', 'start', 'end', 'original_text']]\n",
        "    ], ignore_index=True)\n",
        "    \n",
        "    print(f\"\\nTotal combined entities: {len(df_all_physiological_entities)}\")\n",
        "    print(\"\\nCombined entity distribution:\")\n",
        "    print(df_all_physiological_entities['label'].value_counts())\n",
        "    \n",
        "    # Create anatomy-specific labeling functions\n",
        "    print(\"\\n=== Creating Anatomy-Specific Labeling Functions ===\")\n",
        "    \n",
        "    def create_anatomy_labeling_functions():\n",
        "        \"\"\"Create labeling functions for anatomy patterns\"\"\"\n",
        "        \n",
        "        def lf_cardiac_anatomy(row):\n",
        "            text = str(row.get('physiological context', '')).lower()\n",
        "            cardiac_terms = ['heart', 'cardiac', 'coronary', 'ventricle', 'atrium', 'valve']\n",
        "            if any(term in text for term in cardiac_terms):\n",
        "                return 'CARDIAC_ANATOMY'\n",
        "            return 'ABSTAIN'\n",
        "        \n",
        "        def lf_musculoskeletal(row):\n",
        "            text = str(row.get('physiological context', '')).lower()\n",
        "            msk_terms = ['bone', 'joint', 'muscle', 'tendon', 'ligament', 'cartilage']\n",
        "            if any(term in text for term in msk_terms):\n",
        "                return 'MUSCULOSKELETAL'\n",
        "            return 'ABSTAIN'\n",
        "        \n",
        "        def lf_bilateral_anatomy(row):\n",
        "            text = str(row.get('physiological context', '')).lower()\n",
        "            if 'bilateral' in text:\n",
        "                return 'BILATERAL_CONDITION'\n",
        "            return 'ABSTAIN'\n",
        "        \n",
        "        def lf_neurological_anatomy(row):\n",
        "            text = str(row.get('physiological context', '')).lower()\n",
        "            neuro_terms = ['brain', 'nerve', 'neural', 'spinal', 'cerebral']\n",
        "            if any(term in text for term in neuro_terms):\n",
        "                return 'NEUROLOGICAL_ANATOMY'\n",
        "            return 'ABSTAIN'\n",
        "        \n",
        "        return [lf_cardiac_anatomy, lf_musculoskeletal, lf_bilateral_anatomy, lf_neurological_anatomy]\n",
        "    \n",
        "    # Test anatomy labeling functions\n",
        "    anatomy_lfs = create_anatomy_labeling_functions()\n",
        "    \n",
        "    print(\"\\nTesting anatomy labeling functions:\")\n",
        "    if not df_medical.empty:\n",
        "        for lf in anatomy_lfs:\n",
        "            result = lf(df_medical.iloc[0])\n",
        "            if result != 'ABSTAIN':\n",
        "                print(f\"  {lf.__name__}: {result}\")\n",
        "    keep_cols = ['text','label','start','end','original_text','row_idx','category']\n",
        "    df_all_physiological_entities = pd.concat(\n",
        "    [df_physiological_entities, df_anatomy_custom[keep_cols]],\n",
        "    ignore_index=True\n",
        ")\n",
        "    \n",
        "    # Save combined results\n",
        "    df_all_physiological_entities.to_csv('physiological_entities_comprehensive.csv', index=False)\n",
        "    df_anatomy_custom.to_csv('anatomy_entities_detailed.csv', index=False)\n",
        "    \n",
        "    print(\"\\n\\nEntity extraction complete! Saved:\")\n",
        "    print(\"- physiological_entities_with_anatomy.csv (combined BC5CDR + anatomy)\")\n",
        "    print(\"- anatomy_entities_detailed.csv (detailed anatomy with categories)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>source_column</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>posttraumatic arthritis</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>48</td>\n",
              "      <td>71</td>\n",
              "      <td>History of left elbow arthrodesis performed fo...</td>\n",
              "      <td>80176</td>\n",
              "      <td>physiological context</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pain</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>116</td>\n",
              "      <td>120</td>\n",
              "      <td>Inability to walk since babyhood, did not walk...</td>\n",
              "      <td>31864</td>\n",
              "      <td>physiological context</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fracture</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>151</td>\n",
              "      <td>159</td>\n",
              "      <td>Inability to walk since babyhood, did not walk...</td>\n",
              "      <td>31864</td>\n",
              "      <td>physiological context</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Coxa vara deformity</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>Coxa vara deformity of bilateral hips, bilater...</td>\n",
              "      <td>149866</td>\n",
              "      <td>physiological context</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fracture</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>75</td>\n",
              "      <td>83</td>\n",
              "      <td>Coxa vara deformity of bilateral hips, bilater...</td>\n",
              "      <td>149866</td>\n",
              "      <td>physiological context</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47377</th>\n",
              "      <td>colon</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>61</td>\n",
              "      <td>66</td>\n",
              "      <td>Coronary arteriosclerosis, spinal canal stenos...</td>\n",
              "      <td>86992</td>\n",
              "      <td>NaN</td>\n",
              "      <td>organs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47378</th>\n",
              "      <td>coronary</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>Coronary arteriosclerosis, spinal canal stenos...</td>\n",
              "      <td>86992</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cardiovascular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47379</th>\n",
              "      <td>kidney</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>Kidney stone lithotripsy, hypertension treated...</td>\n",
              "      <td>157822</td>\n",
              "      <td>NaN</td>\n",
              "      <td>organs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47380</th>\n",
              "      <td>pulmonary</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>20</td>\n",
              "      <td>29</td>\n",
              "      <td>Chronic obstructive pulmonary disease, high bl...</td>\n",
              "      <td>77450</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cardiovascular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47381</th>\n",
              "      <td>prostate</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>51</td>\n",
              "      <td>59</td>\n",
              "      <td>Atrial fibrillation, Parkinson's disease, prev...</td>\n",
              "      <td>137017</td>\n",
              "      <td>NaN</td>\n",
              "      <td>organs</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47382 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                          text    label  start  end  \\\n",
              "0      posttraumatic arthritis  DISEASE     48   71   \n",
              "1                         pain  DISEASE    116  120   \n",
              "2                     fracture  DISEASE    151  159   \n",
              "3          Coxa vara deformity  DISEASE      0   19   \n",
              "4                     fracture  DISEASE     75   83   \n",
              "...                        ...      ...    ...  ...   \n",
              "47377                    colon  ANATOMY     61   66   \n",
              "47378                 coronary  ANATOMY      0    8   \n",
              "47379                   kidney  ANATOMY      0    6   \n",
              "47380                pulmonary  ANATOMY     20   29   \n",
              "47381                 prostate  ANATOMY     51   59   \n",
              "\n",
              "                                           original_text  row_idx  \\\n",
              "0      History of left elbow arthrodesis performed fo...    80176   \n",
              "1      Inability to walk since babyhood, did not walk...    31864   \n",
              "2      Inability to walk since babyhood, did not walk...    31864   \n",
              "3      Coxa vara deformity of bilateral hips, bilater...   149866   \n",
              "4      Coxa vara deformity of bilateral hips, bilater...   149866   \n",
              "...                                                  ...      ...   \n",
              "47377  Coronary arteriosclerosis, spinal canal stenos...    86992   \n",
              "47378  Coronary arteriosclerosis, spinal canal stenos...    86992   \n",
              "47379  Kidney stone lithotripsy, hypertension treated...   157822   \n",
              "47380  Chronic obstructive pulmonary disease, high bl...    77450   \n",
              "47381  Atrial fibrillation, Parkinson's disease, prev...   137017   \n",
              "\n",
              "               source_column        category  \n",
              "0      physiological context             NaN  \n",
              "1      physiological context             NaN  \n",
              "2      physiological context             NaN  \n",
              "3      physiological context             NaN  \n",
              "4      physiological context             NaN  \n",
              "...                      ...             ...  \n",
              "47377                    NaN          organs  \n",
              "47378                    NaN  cardiovascular  \n",
              "47379                    NaN          organs  \n",
              "47380                    NaN  cardiovascular  \n",
              "47381                    NaN          organs  \n",
              "\n",
              "[47382 rows x 8 columns]"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_all_physiological_entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>category</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>source</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>laterality</th>\n",
              "      <th>anatomy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>elbow</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>joints</td>\n",
              "      <td>16</td>\n",
              "      <td>21</td>\n",
              "      <td>History of left elbow arthrodesis performed fo...</td>\n",
              "      <td>custom_anatomy_extraction</td>\n",
              "      <td>80176</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>left elbow</td>\n",
              "      <td>ANATOMY_WITH_LATERALITY</td>\n",
              "      <td>joints</td>\n",
              "      <td>11</td>\n",
              "      <td>21</td>\n",
              "      <td>History of left elbow arthrodesis performed fo...</td>\n",
              "      <td>custom_anatomy_extraction</td>\n",
              "      <td>80176</td>\n",
              "      <td>left</td>\n",
              "      <td>elbow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>femur</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>bones</td>\n",
              "      <td>87</td>\n",
              "      <td>92</td>\n",
              "      <td>Coxa vara deformity of bilateral hips, bilater...</td>\n",
              "      <td>custom_anatomy_extraction</td>\n",
              "      <td>149866</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neck</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>joints</td>\n",
              "      <td>93</td>\n",
              "      <td>97</td>\n",
              "      <td>Coxa vara deformity of bilateral hips, bilater...</td>\n",
              "      <td>custom_anatomy_extraction</td>\n",
              "      <td>149866</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bilateral hips</td>\n",
              "      <td>ANATOMY_WITH_LATERALITY</td>\n",
              "      <td>joints</td>\n",
              "      <td>23</td>\n",
              "      <td>37</td>\n",
              "      <td>Coxa vara deformity of bilateral hips, bilater...</td>\n",
              "      <td>custom_anatomy_extraction</td>\n",
              "      <td>149866</td>\n",
              "      <td>bilateral</td>\n",
              "      <td>hips</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11105</th>\n",
              "      <td>colon</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>organs</td>\n",
              "      <td>61</td>\n",
              "      <td>66</td>\n",
              "      <td>Coronary arteriosclerosis, spinal canal stenos...</td>\n",
              "      <td>custom_anatomy_extraction</td>\n",
              "      <td>86992</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11106</th>\n",
              "      <td>coronary</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>cardiovascular</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>Coronary arteriosclerosis, spinal canal stenos...</td>\n",
              "      <td>custom_anatomy_extraction</td>\n",
              "      <td>86992</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11107</th>\n",
              "      <td>kidney</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>organs</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>Kidney stone lithotripsy, hypertension treated...</td>\n",
              "      <td>custom_anatomy_extraction</td>\n",
              "      <td>157822</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11108</th>\n",
              "      <td>pulmonary</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>cardiovascular</td>\n",
              "      <td>20</td>\n",
              "      <td>29</td>\n",
              "      <td>Chronic obstructive pulmonary disease, high bl...</td>\n",
              "      <td>custom_anatomy_extraction</td>\n",
              "      <td>77450</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11109</th>\n",
              "      <td>prostate</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>organs</td>\n",
              "      <td>51</td>\n",
              "      <td>59</td>\n",
              "      <td>Atrial fibrillation, Parkinson's disease, prev...</td>\n",
              "      <td>custom_anatomy_extraction</td>\n",
              "      <td>137017</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11110 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 text                    label        category  start  end  \\\n",
              "0               elbow                  ANATOMY          joints     16   21   \n",
              "1          left elbow  ANATOMY_WITH_LATERALITY          joints     11   21   \n",
              "2               femur                  ANATOMY           bones     87   92   \n",
              "3                neck                  ANATOMY          joints     93   97   \n",
              "4      bilateral hips  ANATOMY_WITH_LATERALITY          joints     23   37   \n",
              "...               ...                      ...             ...    ...  ...   \n",
              "11105           colon                  ANATOMY          organs     61   66   \n",
              "11106        coronary                  ANATOMY  cardiovascular      0    8   \n",
              "11107          kidney                  ANATOMY          organs      0    6   \n",
              "11108       pulmonary                  ANATOMY  cardiovascular     20   29   \n",
              "11109        prostate                  ANATOMY          organs     51   59   \n",
              "\n",
              "                                           original_text  \\\n",
              "0      History of left elbow arthrodesis performed fo...   \n",
              "1      History of left elbow arthrodesis performed fo...   \n",
              "2      Coxa vara deformity of bilateral hips, bilater...   \n",
              "3      Coxa vara deformity of bilateral hips, bilater...   \n",
              "4      Coxa vara deformity of bilateral hips, bilater...   \n",
              "...                                                  ...   \n",
              "11105  Coronary arteriosclerosis, spinal canal stenos...   \n",
              "11106  Coronary arteriosclerosis, spinal canal stenos...   \n",
              "11107  Kidney stone lithotripsy, hypertension treated...   \n",
              "11108  Chronic obstructive pulmonary disease, high bl...   \n",
              "11109  Atrial fibrillation, Parkinson's disease, prev...   \n",
              "\n",
              "                          source  row_idx laterality anatomy  \n",
              "0      custom_anatomy_extraction    80176        NaN     NaN  \n",
              "1      custom_anatomy_extraction    80176       left   elbow  \n",
              "2      custom_anatomy_extraction   149866        NaN     NaN  \n",
              "3      custom_anatomy_extraction   149866        NaN     NaN  \n",
              "4      custom_anatomy_extraction   149866  bilateral    hips  \n",
              "...                          ...      ...        ...     ...  \n",
              "11105  custom_anatomy_extraction    86992        NaN     NaN  \n",
              "11106  custom_anatomy_extraction    86992        NaN     NaN  \n",
              "11107  custom_anatomy_extraction   157822        NaN     NaN  \n",
              "11108  custom_anatomy_extraction    77450        NaN     NaN  \n",
              "11109  custom_anatomy_extraction   137017        NaN     NaN  \n",
              "\n",
              "[11110 rows x 10 columns]"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_anatomy_custom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Irq6-yqQD4Qr"
      },
      "source": [
        "##### Psychological Contexts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUt-GotMD7uV",
        "outputId": "56510d74-ad34-4de2-a826-51d307e0e632"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading en_ner_bc5cdr_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 29755 texts in 60 batches...\n",
            "Using model: en_ner_bc5cdr_md for column: psychological context\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   2%|▏         | 1/60 [00:01<01:09,  1.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  18%|█▊        | 11/60 [00:03<00:14,  3.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 5000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  35%|███▌      | 21/60 [00:06<00:10,  3.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 10000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  52%|█████▏    | 31/60 [00:08<00:07,  3.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  68%|██████▊   | 41/60 [00:11<00:05,  3.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 20000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  85%|████████▌ | 51/60 [00:14<00:02,  3.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 25000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 60/60 [00:16<00:00,  3.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 136 entities appearing >= 5 times\n",
            "\n",
            "Testing generated labeling functions on df_medical...\n",
            "lf_disease_psychological_context applied to row 0: ABSTAIN\n",
            "lf_chemical_psychological_context applied to row 0: ABSTAIN\n",
            "\n",
            "=== DEBUG: Check extracted entities dataframe ===\n",
            "Shape of df_medical_entities: (3402, 7)\n",
            "\n",
            "Column names: ['text', 'label', 'start', 'end', 'original_text', 'row_idx', 'source_column']\n",
            "\n",
            "First few rows:\n",
            "                         text    label  start  end  \\\n",
            "0  bipolar affective disorder  DISEASE     15   41   \n",
            "1                       mania  DISEASE     90   95   \n",
            "2           Parental distress  DISEASE      0   17   \n",
            "3                  depression  DISEASE     68   78   \n",
            "4                     anxiety  DISEASE     83   90   \n",
            "\n",
            "                                       original_text  row_idx  \\\n",
            "0  Diagnosed with bipolar affective disorder at t...   155216   \n",
            "1  Diagnosed with bipolar affective disorder at t...   155216   \n",
            "2                                  Parental distress    90928   \n",
            "3  Known to local mental health services for 20 y...    45433   \n",
            "4  Known to local mental health services for 20 y...    45433   \n",
            "\n",
            "           source_column  \n",
            "0  psychological context  \n",
            "1  psychological context  \n",
            "2  psychological context  \n",
            "3  psychological context  \n",
            "4  psychological context  \n",
            "\n",
            "=== ACTUAL Entity Labels Found in df_physiological_entities ===\n",
            "label\n",
            "DISEASE     3240\n",
            "CHEMICAL     162\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Run extraction for the 'psychological context' column\n",
        "    df_psychological_entities, disease_summary, rules = run_medical_ner_extraction(\n",
        "        df_medical,\n",
        "        text_column='psychological context',\n",
        "        model_name=\"en_ner_bc5cdr_md\",\n",
        "        batch_size=500,\n",
        "        id_column='idx')\n",
        "\n",
        "    # Test the generated rules\n",
        "    print(\"\\nTesting generated labeling functions on df_medical...\")\n",
        "\n",
        "    # Select a sample row from the original df_medical to test the rules\n",
        "    # Ensure df_medical is not empty before accessing iloc[0]\n",
        "    if not df_medical.empty:\n",
        "        sample_row = df_medical.iloc[0]\n",
        "\n",
        "        for rule_name, rule_func in rules.items():\n",
        "            # Apply the rule function to a row from the original df_medical\n",
        "            try:\n",
        "                test_result = rule_func(sample_row)\n",
        "                print(f\"{rule_name} applied to row 0: {test_result}\")\n",
        "            except KeyError as e:\n",
        "                print(f\"Error applying rule {rule_name}: {e}. Make sure the column '{e}' exists in df_medical.\")\n",
        "    else:\n",
        "        print(\"df_medical is empty, cannot test rules.\")\n",
        "\n",
        "\n",
        "print(\"\\n=== DEBUG: Check extracted entities dataframe ===\")\n",
        "print(f\"Shape of df_medical_entities: {df_psychological_entities.shape}\")\n",
        "print(f\"\\nColumn names: {df_psychological_entities.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(df_psychological_entities.head())\n",
        "\n",
        "# Check what labels ScispaCy actually found in the entities dataframe\n",
        "print(\"\\n=== ACTUAL Entity Labels Found in df_physiological_entities ===\")\n",
        "if not df_psychological_entities.empty:\n",
        "    print(df_psychological_entities['label'].value_counts())\n",
        "\n",
        "    # Check for 'ENTITY' label if present\n",
        "    if 'ENTITY' in df_psychological_entities['label'].values:\n",
        "        print(\"\\n=== Top ENTITY type examples from df_medical_entities ===\")\n",
        "        psychological_entity_examples = df_psychological_entities[df_psychological_entities['label'] == 'ENTITY']['text'].value_counts().head(20)\n",
        "        print(psychological_entity_examples)\n",
        "else:\n",
        "    print(\"df_psychological_entities is empty.\")\n",
        "\n",
        "    \n",
        "df_psychological_entities.to_csv('psychological_entities_comprehensive.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>source_column</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bipolar affective disorder</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>15</td>\n",
              "      <td>41</td>\n",
              "      <td>Diagnosed with bipolar affective disorder at t...</td>\n",
              "      <td>155216</td>\n",
              "      <td>psychological context</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mania</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>90</td>\n",
              "      <td>95</td>\n",
              "      <td>Diagnosed with bipolar affective disorder at t...</td>\n",
              "      <td>155216</td>\n",
              "      <td>psychological context</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Parental distress</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>Parental distress</td>\n",
              "      <td>90928</td>\n",
              "      <td>psychological context</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>depression</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>68</td>\n",
              "      <td>78</td>\n",
              "      <td>Known to local mental health services for 20 y...</td>\n",
              "      <td>45433</td>\n",
              "      <td>psychological context</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>anxiety</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>83</td>\n",
              "      <td>90</td>\n",
              "      <td>Known to local mental health services for 20 y...</td>\n",
              "      <td>45433</td>\n",
              "      <td>psychological context</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3397</th>\n",
              "      <td>Bipolar disorder</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>Bipolar disorder</td>\n",
              "      <td>87937</td>\n",
              "      <td>psychological context</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3398</th>\n",
              "      <td>Bipolar disorder</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>Bipolar disorder</td>\n",
              "      <td>113022</td>\n",
              "      <td>psychological context</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3399</th>\n",
              "      <td>psychiatric</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>No psychiatric symptoms or previous psychiatri...</td>\n",
              "      <td>160392</td>\n",
              "      <td>psychological context</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3400</th>\n",
              "      <td>psychiatric illness</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>36</td>\n",
              "      <td>55</td>\n",
              "      <td>No psychiatric symptoms or previous psychiatri...</td>\n",
              "      <td>160392</td>\n",
              "      <td>psychological context</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3401</th>\n",
              "      <td>Anxiety</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>60912</td>\n",
              "      <td>psychological context</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3402 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            text    label  start  end  \\\n",
              "0     bipolar affective disorder  DISEASE     15   41   \n",
              "1                          mania  DISEASE     90   95   \n",
              "2              Parental distress  DISEASE      0   17   \n",
              "3                     depression  DISEASE     68   78   \n",
              "4                        anxiety  DISEASE     83   90   \n",
              "...                          ...      ...    ...  ...   \n",
              "3397            Bipolar disorder  DISEASE      0   16   \n",
              "3398            Bipolar disorder  DISEASE      0   16   \n",
              "3399                 psychiatric  DISEASE      3   14   \n",
              "3400         psychiatric illness  DISEASE     36   55   \n",
              "3401                     Anxiety  DISEASE      0    7   \n",
              "\n",
              "                                          original_text  row_idx  \\\n",
              "0     Diagnosed with bipolar affective disorder at t...   155216   \n",
              "1     Diagnosed with bipolar affective disorder at t...   155216   \n",
              "2                                     Parental distress    90928   \n",
              "3     Known to local mental health services for 20 y...    45433   \n",
              "4     Known to local mental health services for 20 y...    45433   \n",
              "...                                                 ...      ...   \n",
              "3397                                   Bipolar disorder    87937   \n",
              "3398                                   Bipolar disorder   113022   \n",
              "3399  No psychiatric symptoms or previous psychiatri...   160392   \n",
              "3400  No psychiatric symptoms or previous psychiatri...   160392   \n",
              "3401                                            Anxiety    60912   \n",
              "\n",
              "              source_column  \n",
              "0     psychological context  \n",
              "1     psychological context  \n",
              "2     psychological context  \n",
              "3     psychological context  \n",
              "4     psychological context  \n",
              "...                     ...  \n",
              "3397  psychological context  \n",
              "3398  psychological context  \n",
              "3399  psychological context  \n",
              "3400  psychological context  \n",
              "3401  psychological context  \n",
              "\n",
              "[3402 rows x 7 columns]"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_psychological_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8eao_3OH9R4"
      },
      "source": [
        "##### Vaccination History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnTnQ8AQH84G",
        "outputId": "e66fbf8e-04a7-456a-e842-9ecd21f1b753"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading en_ner_bc5cdr_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 29755 texts in 100 batches...\n",
            "Using model: en_ner_bc5cdr_md for column: vaccination history\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   2%|▏         | 2/100 [00:01<00:44,  2.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  12%|█▏        | 12/100 [00:02<00:15,  5.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 3000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  22%|██▏       | 22/100 [00:04<00:13,  5.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 6000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  32%|███▏      | 32/100 [00:06<00:12,  5.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 9000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  41%|████      | 41/100 [00:07<00:11,  5.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 12000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  52%|█████▏    | 52/100 [00:09<00:08,  5.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  62%|██████▏   | 62/100 [00:11<00:06,  5.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 18000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  72%|███████▏  | 72/100 [00:12<00:04,  5.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 21000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  82%|████████▏ | 82/100 [00:14<00:03,  5.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 24000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  92%|█████████▏| 92/100 [00:16<00:01,  5.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 27000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 100/100 [00:17<00:00,  5.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6 entities appearing >= 5 times\n",
            "\n",
            "Testing generated labeling functions for vaccination history...\n",
            "lf_disease_vaccination_history applied to row 0: ABSTAIN\n",
            "lf_chemical_vaccination_history applied to row 0: ABSTAIN\n",
            "\n",
            "=== DEBUG: Check extracted vaccination entities ===\n",
            "Shape of df_vaccination_entities: (129, 7)\n",
            "\n",
            "Column names: ['text', 'label', 'start', 'end', 'original_text', 'row_idx', 'source_column']\n",
            "\n",
            "First few rows:\n",
            "                text    label  start  end  \\\n",
            "0            Tetanus  DISEASE      0    7   \n",
            "1            tetanus  DISEASE     25   32   \n",
            "2       hyposplenism  DISEASE     39   51   \n",
            "3            tetanus  DISEASE     14   21   \n",
            "4  tetanus infection  DISEASE     37   54   \n",
            "\n",
            "                                       original_text  row_idx  \\\n",
            "0  Tetanus vaccination with tetanus immunoglobuli...   119386   \n",
            "1  Tetanus vaccination with tetanus immunoglobuli...   119386   \n",
            "2  Vaccinated post-treatment for presumed hypospl...    13774   \n",
            "3  No history of tetanus vaccination or tetanus i...   157338   \n",
            "4  No history of tetanus vaccination or tetanus i...   157338   \n",
            "\n",
            "         source_column  \n",
            "0  vaccination history  \n",
            "1  vaccination history  \n",
            "2  vaccination history  \n",
            "3  vaccination history  \n",
            "4  vaccination history  \n",
            "\n",
            "=== Entity Labels Found in Vaccination History ===\n",
            "label\n",
            "DISEASE     106\n",
            "CHEMICAL     23\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top CHEMICAL/Vaccine entities ===\n",
            "text\n",
            "vitamin K                6\n",
            "Calmette                 3\n",
            "Calmette-Guérin          2\n",
            "tetanus                  2\n",
            "Vitamin K                2\n",
            "Guérin                   2\n",
            "benzathine penicillin    1\n",
            "penicillin               1\n",
            "DTaP                     1\n",
            "DPT                      1\n",
            "Vaccine                  1\n",
            "diphtheria pertussis     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top DISEASE entities (conditions) ===\n",
            "text\n",
            "tetanus                     28\n",
            "Tetanus                     13\n",
            "hepatitis B                  8\n",
            "Anti-D                       5\n",
            "left buttock                 5\n",
            "varicella                    4\n",
            "fever                        3\n",
            "chickenpox                   3\n",
            "hepatitis A                  3\n",
            "poliomyelitis                2\n",
            "tuberculosis infection       2\n",
            "malaria                      2\n",
            "Fever                        1\n",
            "TB                           1\n",
            "Streptococcus pneumoniae     1\n",
            "Herpes simplex               1\n",
            "mumps infection              1\n",
            "COVID-19 infection           1\n",
            "encephalitis B               1\n",
            "zoster                       1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Vaccine-related entities found: ['Vaccine', 'acute respiratory syndrome coronavirus 2 vaccine', 'vaccine-associated']\n",
            "Disease-related entities found: ['tetanus', 'Tetanus', 'hepatitis B', 'varicella', 'hepatitis A', 'poliomyelitis', 'mumps infection', 'COVID-19 infection', 'diphtheria pertussis', 'Anti-tetanus']\n",
            "\n",
            "=== Testing Refined Vaccination Labeling Functions ===\n",
            "\n",
            "=== Labeling Function Coverage ===\n",
            "lf_covid_vaccination: 1.9% coverage (8/415)\n",
            "lf_childhood_vaccines: 20.2% coverage (84/415)\n",
            "lf_influenza_vaccination: 3.9% coverage (16/415)\n",
            "lf_hepatitis_vaccination: 2.7% coverage (11/415)\n",
            "lf_tetanus_vaccination: 10.8% coverage (45/415)\n",
            "lf_pneumococcal_vaccination: 3.1% coverage (13/415)\n",
            "lf_travel_vaccines: 2.9% coverage (12/415)\n",
            "lf_vaccination_timing: 23.1% coverage (96/415)\n",
            "lf_no_vaccination: 2.2% coverage (9/415)\n",
            "lf_vaccine_reaction: 2.4% coverage (10/415)\n",
            "lf_recent_vaccination: 1.0% coverage (4/415)\n",
            "lf_historical_vaccination: 7.5% coverage (31/415)\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # BC5CDR model will identify vaccines (CHEMICAL) and diseases (DISEASE)\n",
        "    df_vaccination_entities, vaccination_summary, vaccination_rules = run_medical_ner_extraction(\n",
        "        df_medical, \n",
        "        text_column='vaccination history',\n",
        "        model_name=\"en_ner_bc5cdr_md\",  # This model recognizes DISEASE and CHEMICAL entities\n",
        "        batch_size=300,\n",
        "        id_column='idx'  # Use 'idx' column for row identifiers\n",
        "    )\n",
        "\n",
        "    # Test the generated rules\n",
        "    print(\"\\nTesting generated labeling functions for vaccination history...\")\n",
        "\n",
        "    # Select a sample row from the original df_medical to test the rules\n",
        "    if not df_medical.empty:\n",
        "        sample_row = df_medical.iloc[0]\n",
        "\n",
        "        for rule_name, rule_func in vaccination_rules.items():\n",
        "            try:\n",
        "                test_result = rule_func(sample_row)\n",
        "                print(f\"{rule_name} applied to row 0: {test_result}\")\n",
        "            except KeyError as e:\n",
        "                print(f\"Error applying rule {rule_name}: {e}. Make sure the column 'vaccination_history' exists in df_medical.\")\n",
        "    else:\n",
        "        print(\"df_medical is empty, cannot test rules.\")\n",
        "\n",
        "    # Debug: Check extracted entities\n",
        "    print(\"\\n=== DEBUG: Check extracted vaccination entities ===\")\n",
        "    print(f\"Shape of df_vaccination_entities: {df_vaccination_entities.shape}\")\n",
        "    print(f\"\\nColumn names: {df_vaccination_entities.columns.tolist()}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(df_vaccination_entities.head())\n",
        "\n",
        "    # Check entity label distribution\n",
        "    print(\"\\n=== Entity Labels Found in Vaccination History ===\")\n",
        "    if not df_vaccination_entities.empty:\n",
        "        print(df_vaccination_entities['label'].value_counts())\n",
        "\n",
        "        # Look at CHEMICAL entities (likely vaccines)\n",
        "        if 'CHEMICAL' in df_vaccination_entities['label'].values:\n",
        "            print(\"\\n=== Top CHEMICAL/Vaccine entities ===\")\n",
        "            vaccine_entities = df_vaccination_entities[df_vaccination_entities['label'] == 'CHEMICAL']['text'].value_counts().head(20)\n",
        "            print(vaccine_entities)\n",
        "\n",
        "        # Look at DISEASE entities (conditions vaccines prevent)\n",
        "        if 'DISEASE' in df_vaccination_entities['label'].values:\n",
        "            print(\"\\n=== Top DISEASE entities (conditions) ===\")\n",
        "            disease_entities = df_vaccination_entities[df_vaccination_entities['label'] == 'DISEASE']['text'].value_counts().head(20)\n",
        "            print(disease_entities)\n",
        "    else:\n",
        "        print(\"df_vaccination_entities is empty.\")\n",
        "\n",
        "def create_vaccination_labeling_functions(entities_df):\n",
        "    \"\"\"Create specific labeling functions for vaccination history based on actual entities found\"\"\"\n",
        "\n",
        "    # First, let's see what vaccine-related entities were actually extracted\n",
        "    vaccine_related_terms = []\n",
        "    disease_related_terms = []\n",
        "\n",
        "    # Analyze the top entities to identify vaccine patterns\n",
        "    top_entities = entities_df['text'].value_counts().head(100)\n",
        "\n",
        "    for entity, count in top_entities.items():\n",
        "        entity_lower = entity.lower()\n",
        "\n",
        "        # Identify vaccine-related terms\n",
        "        if any(term in entity_lower for term in ['vaccin', 'immuniz', 'shot', 'injection', 'dose']):\n",
        "            vaccine_related_terms.append(entity)\n",
        "\n",
        "        # Identify disease/condition terms that vaccines prevent\n",
        "        if any(term in entity_lower for term in ['tetanus', 'hepatitis', 'measles', 'influenza',\n",
        "                                                  'covid', 'polio', 'pertussis', 'mumps', 'rubella',\n",
        "                                                  'pneumococcal', 'meningitis', 'hpv', 'varicella',\n",
        "                                                  'diphtheria', 'rotavirus']):\n",
        "            disease_related_terms.append(entity)\n",
        "\n",
        "    print(f\"\\nVaccine-related entities found: {vaccine_related_terms[:10]}\")\n",
        "    print(f\"Disease-related entities found: {disease_related_terms[:10]}\")\n",
        "\n",
        "    # Create labeling functions based on patterns in data\n",
        "    def lf_covid_vaccination(row):\n",
        "        \"\"\"Detect COVID-19 vaccination\"\"\"\n",
        "        text = str(row['vaccination history']).lower()\n",
        "        covid_patterns = [\n",
        "            'covid', 'coronavirus', 'sars-cov-2', 'pfizer', 'moderna',\n",
        "            'astrazeneca', 'johnson', 'mrna-1273', 'bnt162b2'\n",
        "        ]\n",
        "        if any(pattern in text for pattern in covid_patterns):\n",
        "            return 'COVID_VACCINE'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    def lf_childhood_vaccines(row):\n",
        "        \"\"\"Detect standard childhood vaccinations\"\"\"\n",
        "        text = str(row['vaccination history']).lower()\n",
        "        childhood_vaccines = [\n",
        "            'mmr', 'measles', 'mumps', 'rubella', 'varicella', 'chickenpox',\n",
        "            'polio', 'dtap', 'diphtheria', 'tetanus', 'pertussis', 'whooping',\n",
        "            'hib', 'hepatitis b', 'rotavirus', 'pcv', 'ipv'\n",
        "        ]\n",
        "        if any(vaccine in text for vaccine in childhood_vaccines):\n",
        "            return 'CHILDHOOD_VACCINES'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    def lf_influenza_vaccination(row):\n",
        "        \"\"\"Detect flu vaccination\"\"\"\n",
        "        text = str(row['vaccination history']).lower()\n",
        "        flu_patterns = ['influenza', 'flu vaccine', 'flu shot', 'seasonal flu', 'h1n1']\n",
        "        if any(pattern in text for pattern in flu_patterns):\n",
        "            return 'FLU_VACCINE'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    def lf_hepatitis_vaccination(row):\n",
        "        \"\"\"Detect hepatitis vaccinations\"\"\"\n",
        "        text = str(row['vaccination history']).lower()\n",
        "        if any(hep in text for hep in ['hepatitis a', 'hepatitis b', 'hep a', 'hep b', 'havrix', 'engerix']):\n",
        "            return 'HEPATITIS_VACCINE'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    def lf_tetanus_vaccination(row):\n",
        "        \"\"\"Detect tetanus/Td/Tdap vaccinations\"\"\"\n",
        "        text = str(row['vaccination history']).lower()\n",
        "        if any(tet in text for tet in ['tetanus', 'tdap', 'td ', 'boostrix', 'adacel']):\n",
        "            return 'TETANUS_VACCINE'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    def lf_pneumococcal_vaccination(row):\n",
        "        \"\"\"Detect pneumococcal vaccinations\"\"\"\n",
        "        text = str(row['vaccination history']).lower()\n",
        "        if any(pneumo in text for pneumo in ['pneumococcal', 'pneumonia vaccine', 'prevnar', 'pneumovax']):\n",
        "            return 'PNEUMO_VACCINE'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    def lf_travel_vaccines(row):\n",
        "        \"\"\"Detect travel-related vaccinations\"\"\"\n",
        "        text = str(row['vaccination history']).lower()\n",
        "        travel_vaccines = ['yellow fever', 'typhoid', 'japanese encephalitis', 'rabies',\n",
        "                          'meningococcal', 'cholera']\n",
        "        if any(vaccine in text for vaccine in travel_vaccines):\n",
        "            return 'TRAVEL_VACCINES'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    def lf_vaccination_timing(row):\n",
        "        \"\"\"Detect vaccination timing information\"\"\"\n",
        "        text = str(row['vaccination history']).lower()\n",
        "        timing_patterns = ['booster', 'dose', 'series', 'schedule', 'up to date',\n",
        "                          'fully vaccinated', 'partially vaccinated']\n",
        "        if any(pattern in text for pattern in timing_patterns):\n",
        "            return 'VACCINATION_TIMING'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    def lf_no_vaccination(row):\n",
        "        \"\"\"Detect absence of vaccination\"\"\"\n",
        "        text = str(row['vaccination history']).lower()\n",
        "        no_vax_patterns = ['no vaccination', 'not vaccinated', 'unvaccinated',\n",
        "                          'declined', 'refused', 'no history of vaccination']\n",
        "        if any(pattern in text for pattern in no_vax_patterns):\n",
        "            return 'UNVACCINATED'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    def lf_vaccine_reaction(row):\n",
        "        \"\"\"Detect vaccine reactions/side effects\"\"\"\n",
        "        text = str(row['vaccination history']).lower()\n",
        "        reaction_patterns = ['reaction', 'allergy', 'side effect', 'adverse', 'anaphylaxis']\n",
        "        if any(pattern in text for pattern in reaction_patterns):\n",
        "            return 'VACCINE_REACTION'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    # Since we have \"years\", \"months\", \"weeks\" as top entities, let's create time-based functions\n",
        "    def lf_recent_vaccination(row):\n",
        "        \"\"\"Detect recent vaccinations\"\"\"\n",
        "        text = str(row['vaccination history']).lower()\n",
        "        # Look for patterns indicating recent vaccination\n",
        "        if any(recent in text for recent in ['weeks ago', 'months ago', 'recently',\n",
        "                                             'last month', 'last week', 'this year']):\n",
        "            return 'RECENT_VACCINATION'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    def lf_historical_vaccination(row):\n",
        "        \"\"\"Detect historical vaccination information\"\"\"\n",
        "        text = str(row['vaccination history']).lower()\n",
        "        if 'history' in text and any(vax in text for vax in ['vaccin', 'immuniz']):\n",
        "            return 'VACCINATION_HISTORY'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    return [\n",
        "        lf_covid_vaccination,\n",
        "        lf_childhood_vaccines,\n",
        "        lf_influenza_vaccination,\n",
        "        lf_hepatitis_vaccination,\n",
        "        lf_tetanus_vaccination,\n",
        "        lf_pneumococcal_vaccination,\n",
        "        lf_travel_vaccines,\n",
        "        lf_vaccination_timing,\n",
        "        lf_no_vaccination,\n",
        "        lf_vaccine_reaction,\n",
        "        lf_recent_vaccination,\n",
        "        lf_historical_vaccination\n",
        "    ]\n",
        "\n",
        "vaccination_lfs = create_vaccination_labeling_functions(df_vaccination_entities)\n",
        "\n",
        "print(\"\\n=== Testing Refined Vaccination Labeling Functions ===\")\n",
        "if not df_medical.empty and 'vaccination history' in df_medical.columns:\n",
        "    # Test on multiple rows to see coverage\n",
        "    test_rows = min(10, len(df_medical))\n",
        "    results_summary = {lf.__name__: [] for lf in vaccination_lfs}\n",
        "\n",
        "    for i in range(test_rows):\n",
        "        row = df_medical.iloc[i]\n",
        "        if pd.notna(row['vaccination history']):\n",
        "            print(f\"\\nRow {i} vaccination history: {row['vaccination history'][:100]}...\")\n",
        "            for lf in vaccination_lfs:\n",
        "                result = lf(row)\n",
        "                if result != 'ABSTAIN':\n",
        "                    print(f\"  {lf.__name__}: {result}\")\n",
        "                    results_summary[lf.__name__].append(result)\n",
        "\n",
        "# Analyze coverage\n",
        "print(\"\\n=== Labeling Function Coverage ===\")\n",
        "total_non_na = df_medical['vaccination history'].notna().sum()\n",
        "for lf in vaccination_lfs:\n",
        "    labeled_count = sum(lf(row) != 'ABSTAIN' for _, row in df_medical.iterrows()\n",
        "                       if pd.notna(row.get('vaccination history', '')))\n",
        "    coverage = (labeled_count / total_non_na * 100) if total_non_na > 0 else 0\n",
        "    print(f\"{lf.__name__}: {coverage:.1f}% coverage ({labeled_count}/{total_non_na})\")\n",
        "\n",
        "# Save result\n",
        "df_vaccination_entities.to_csv('vaccination_entities_comprehensive.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>source_column</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tetanus</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>Tetanus vaccination with tetanus immunoglobuli...</td>\n",
              "      <td>119386</td>\n",
              "      <td>vaccination history</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tetanus</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>25</td>\n",
              "      <td>32</td>\n",
              "      <td>Tetanus vaccination with tetanus immunoglobuli...</td>\n",
              "      <td>119386</td>\n",
              "      <td>vaccination history</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hyposplenism</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>39</td>\n",
              "      <td>51</td>\n",
              "      <td>Vaccinated post-treatment for presumed hypospl...</td>\n",
              "      <td>13774</td>\n",
              "      <td>vaccination history</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tetanus</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>14</td>\n",
              "      <td>21</td>\n",
              "      <td>No history of tetanus vaccination or tetanus i...</td>\n",
              "      <td>157338</td>\n",
              "      <td>vaccination history</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tetanus infection</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>37</td>\n",
              "      <td>54</td>\n",
              "      <td>No history of tetanus vaccination or tetanus i...</td>\n",
              "      <td>157338</td>\n",
              "      <td>vaccination history</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>Calmette</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>9</td>\n",
              "      <td>17</td>\n",
              "      <td>bacillus Calmette–Guérin (BCG)</td>\n",
              "      <td>42118</td>\n",
              "      <td>vaccination history</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>Guérin</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>18</td>\n",
              "      <td>24</td>\n",
              "      <td>bacillus Calmette–Guérin (BCG)</td>\n",
              "      <td>42118</td>\n",
              "      <td>vaccination history</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>pandemic</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>49</td>\n",
              "      <td>57</td>\n",
              "      <td>Had not received seasonal influenza or 2009 H1...</td>\n",
              "      <td>74950</td>\n",
              "      <td>vaccination history</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>tetanus</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>16</td>\n",
              "      <td>23</td>\n",
              "      <td>Vaccinated with tetanus toxoid once</td>\n",
              "      <td>198046</td>\n",
              "      <td>vaccination history</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>Tetanus</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>Tetanus vaccination administered during curren...</td>\n",
              "      <td>68442</td>\n",
              "      <td>vaccination history</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>129 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  text     label  start  end  \\\n",
              "0              Tetanus   DISEASE      0    7   \n",
              "1              tetanus   DISEASE     25   32   \n",
              "2         hyposplenism   DISEASE     39   51   \n",
              "3              tetanus   DISEASE     14   21   \n",
              "4    tetanus infection   DISEASE     37   54   \n",
              "..                 ...       ...    ...  ...   \n",
              "124           Calmette  CHEMICAL      9   17   \n",
              "125             Guérin  CHEMICAL     18   24   \n",
              "126           pandemic   DISEASE     49   57   \n",
              "127            tetanus   DISEASE     16   23   \n",
              "128            Tetanus   DISEASE      0    7   \n",
              "\n",
              "                                         original_text  row_idx  \\\n",
              "0    Tetanus vaccination with tetanus immunoglobuli...   119386   \n",
              "1    Tetanus vaccination with tetanus immunoglobuli...   119386   \n",
              "2    Vaccinated post-treatment for presumed hypospl...    13774   \n",
              "3    No history of tetanus vaccination or tetanus i...   157338   \n",
              "4    No history of tetanus vaccination or tetanus i...   157338   \n",
              "..                                                 ...      ...   \n",
              "124                     bacillus Calmette–Guérin (BCG)    42118   \n",
              "125                     bacillus Calmette–Guérin (BCG)    42118   \n",
              "126  Had not received seasonal influenza or 2009 H1...    74950   \n",
              "127                Vaccinated with tetanus toxoid once   198046   \n",
              "128  Tetanus vaccination administered during curren...    68442   \n",
              "\n",
              "           source_column  \n",
              "0    vaccination history  \n",
              "1    vaccination history  \n",
              "2    vaccination history  \n",
              "3    vaccination history  \n",
              "4    vaccination history  \n",
              "..                   ...  \n",
              "124  vaccination history  \n",
              "125  vaccination history  \n",
              "126  vaccination history  \n",
              "127  vaccination history  \n",
              "128  vaccination history  \n",
              "\n",
              "[129 rows x 7 columns]"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_vaccination_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a1jNMwsRO5z"
      },
      "source": [
        "##### Allergies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymvhuE8cRUk9",
        "outputId": "020c83ca-765f-40ee-e857-69ed48147e9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading en_ner_bc5cdr_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 29755 texts in 100 batches...\n",
            "Using model: en_ner_bc5cdr_md for column: allergies\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   2%|▏         | 2/100 [00:01<00:44,  2.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  12%|█▏        | 12/100 [00:02<00:15,  5.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 3000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  22%|██▏       | 22/100 [00:04<00:13,  5.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 6000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  32%|███▏      | 32/100 [00:06<00:12,  5.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 9000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  42%|████▏     | 42/100 [00:07<00:10,  5.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 12000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  52%|█████▏    | 52/100 [00:09<00:08,  5.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  62%|██████▏   | 62/100 [00:11<00:06,  5.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 18000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  72%|███████▏  | 72/100 [00:13<00:05,  5.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 21000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  82%|████████▏ | 82/100 [00:14<00:03,  5.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 24000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  92%|█████████▏| 92/100 [00:16<00:01,  5.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 27000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 100/100 [00:18<00:00,  5.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 32 entities appearing >= 5 times\n",
            "\n",
            "Testing generated labeling functions for allergies...\n",
            "lf_disease_allergies applied to row 0: ABSTAIN\n",
            "lf_chemical_allergies applied to row 0: ABSTAIN\n",
            "\n",
            "=== DEBUG: Check extracted allergy entities ===\n",
            "Shape of df_allergies_entities: (934, 7)\n",
            "\n",
            "Column names: ['text', 'label', 'start', 'end', 'original_text', 'row_idx', 'source_column']\n",
            "\n",
            "First few rows:\n",
            "             text     label  start  end  \\\n",
            "0       allergies   DISEASE      9   18   \n",
            "1  drug allergies   DISEASE      9   23   \n",
            "2         allergy   DISEASE     18   25   \n",
            "3         Allergy   DISEASE      0    7   \n",
            "4     amoxicillin  CHEMICAL     11   22   \n",
            "\n",
            "                           original_text  row_idx source_column  \n",
            "0                     No known allergies    32488     allergies  \n",
            "1                No known drug allergies    77061     allergies  \n",
            "2  No sensitivity or allergy to any drug   149806     allergies  \n",
            "3                 Allergy to amoxicillin    83662     allergies  \n",
            "4                 Allergy to amoxicillin    83662     allergies  \n",
            "\n",
            "=== Entity Labels Found in Allergies ===\n",
            "label\n",
            "DISEASE     739\n",
            "CHEMICAL    195\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Allergy-related Entities ===\n",
            "text\n",
            "allergies                        291\n",
            "drug allergies                    92\n",
            "allergy                           73\n",
            "Allergy                           24\n",
            "penicillin                        24\n",
            "allergic reaction                 18\n",
            "Allergic                          16\n",
            "Penicillin                        16\n",
            "allergic                          14\n",
            "Allergic rhinitis                 12\n",
            "hypersensitivity                  12\n",
            "Seasonal allergies                11\n",
            "Allergic reaction                 10\n",
            "Penicillin allergy                 9\n",
            "allergic rhinitis                  9\n",
            "rash                               9\n",
            "anaphylaxis                        7\n",
            "vancomycin                         7\n",
            "penicillin allergy                 7\n",
            "paracetamol                        6\n",
            "trimethoprim/sulfamethoxazole      6\n",
            "Allergic reactions                 6\n",
            "Allergies                          6\n",
            "macrolide                          5\n",
            "drug intolerance                   5\n",
            "Calpol                             5\n",
            "angioedema                         5\n",
            "eczema                             5\n",
            "milk allergy                       5\n",
            "Allergic rhinoconjunctivitis       5\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Analyzing allergy entities for patterns...\n",
            "\n",
            "=== Testing Allergy Labeling Functions ===\n",
            "\n",
            "=== Allergy Labeling Function Coverage ===\n",
            "lf_drug_allergy: 12.9% coverage (106/819)\n",
            "lf_food_allergy: 10.7% coverage (88/819)\n",
            "lf_environmental_allergy: 9.0% coverage (74/819)\n",
            "lf_no_allergies: 31.3% coverage (256/819)\n",
            "lf_allergy_severity: 4.5% coverage (37/819)\n",
            "lf_allergy_reaction_type: 2.3% coverage (19/819)\n",
            "lf_seasonal_allergy: 1.8% coverage (15/819)\n",
            "lf_chemical_sensitivity: 0.1% coverage (1/819)\n",
            "lf_multiple_allergies: 6.3% coverage (52/819)\n",
            "lf_allergy_testing: 0.5% coverage (4/819)\n",
            "\n",
            "=== Common Allergy Patterns ===\n",
            "Penicillin allergy mentions: 56\n",
            "No known allergies mentions: 14\n",
            "Food allergy mentions: 19\n",
            "Total allergy records: 819\n",
            "\n",
            "=== Allergen Type Summary ===\n",
            "\n",
            "DRUGS: ['penicillin', 'Penicillin', 'Penicillin allergy', 'vancomycin', 'penicillin allergy', 'trimethoprim/sulfamethoxazole', 'clindamycin', 'amoxicillin', 'colomycin']\n",
            "\n",
            "FOODS: ['milk allergy']\n",
            "\n",
            "OTHER: ['allergies', 'drug allergies', 'allergy', 'Allergy', 'allergic reaction', 'Allergic', 'allergic', 'Allergic rhinitis', 'hypersensitivity', 'Seasonal allergies']\n"
          ]
        }
      ],
      "source": [
        "# Process allergies using BC5CDR model (recognizes DISEASE and CHEMICAL)\n",
        "if __name__ == \"__main__\":\n",
        "    # Run extraction for the 'allergies' column\n",
        "    # BC5CDR model will identify allergens (often CHEMICAL entities)\n",
        "    df_allergies_entities, allergies_summary, allergies_rules = run_medical_ner_extraction(\n",
        "        df_medical, \n",
        "        text_column='allergies',\n",
        "        model_name=\"en_ner_bc5cdr_md\",  # This model recognizes DISEASE and CHEMICAL entities\n",
        "        batch_size=300,\n",
        "        id_column='idx' \n",
        "    )\n",
        "\n",
        "    # Test the generated rules\n",
        "    print(\"\\nTesting generated labeling functions for allergies...\")\n",
        "\n",
        "    # Select a sample row from the original df_medical to test the rules\n",
        "    if not df_medical.empty:\n",
        "        sample_row = df_medical.iloc[0]\n",
        "\n",
        "        for rule_name, rule_func in allergies_rules.items():\n",
        "            try:\n",
        "                test_result = rule_func(sample_row)\n",
        "                print(f\"{rule_name} applied to row 0: {test_result}\")\n",
        "            except KeyError as e:\n",
        "                print(f\"Error applying rule {rule_name}: {e}. Make sure the column 'allergies' exists in df_medical.\")\n",
        "    else:\n",
        "        print(\"df_medical is empty, cannot test rules.\")\n",
        "\n",
        "    # Debug: Check extracted entities\n",
        "    print(\"\\n=== DEBUG: Check extracted allergy entities ===\")\n",
        "    print(f\"Shape of df_allergies_entities: {df_allergies_entities.shape}\")\n",
        "    print(f\"\\nColumn names: {df_allergies_entities.columns.tolist()}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(df_allergies_entities.head())\n",
        "\n",
        "    # Check entity label distribution\n",
        "    print(\"\\n=== Entity Labels Found in Allergies ===\")\n",
        "    if not df_allergies_entities.empty:\n",
        "        print(df_allergies_entities['label'].value_counts())\n",
        "\n",
        "        # Let's look at the top entities\n",
        "        print(\"\\n=== Top Allergy-related Entities ===\")\n",
        "        allergy_entities = df_allergies_entities['text'].value_counts().head(30)\n",
        "        print(allergy_entities)\n",
        "\n",
        "    # Create specific labeling functions for allergy data\n",
        "    def create_allergy_labeling_functions(entities_df):\n",
        "        \"\"\"Create specific labeling functions for allergies\"\"\"\n",
        "\n",
        "        # Analyze entities to understand patterns\n",
        "        top_entities = entities_df['text'].value_counts().head(100)\n",
        "        print(f\"\\nAnalyzing allergy entities for patterns...\")\n",
        "\n",
        "        # Common allergen categories\n",
        "        def lf_drug_allergy(row):\n",
        "            \"\"\"Detect drug/medication allergies\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            drug_patterns = [\n",
        "                'penicillin', 'amoxicillin', 'ampicillin', 'antibiotic',\n",
        "                'sulfa', 'aspirin', 'nsaid', 'ibuprofen', 'morphine',\n",
        "                'codeine', 'contrast', 'iodine', 'latex', 'adhesive'\n",
        "            ]\n",
        "            if any(drug in text for drug in drug_patterns):\n",
        "                return 'DRUG_ALLERGY'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_food_allergy(row):\n",
        "            \"\"\"Detect food allergies\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            food_patterns = [\n",
        "                'peanut', 'nut', 'shellfish', 'fish', 'milk', 'dairy',\n",
        "                'egg', 'wheat', 'gluten', 'soy', 'sesame', 'food'\n",
        "            ]\n",
        "            if any(food in text for food in food_patterns):\n",
        "                return 'FOOD_ALLERGY'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_environmental_allergy(row):\n",
        "            \"\"\"Detect environmental allergies\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            env_patterns = [\n",
        "                'pollen', 'dust', 'mold', 'grass', 'tree', 'ragweed',\n",
        "                'cat', 'dog', 'animal', 'dander', 'environmental'\n",
        "            ]\n",
        "            if any(env in text for env in env_patterns):\n",
        "                return 'ENVIRONMENTAL_ALLERGY'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_no_allergies(row):\n",
        "            \"\"\"Detect absence of allergies\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            no_allergy_patterns = [\n",
        "                'no known allergies', 'no allergies', 'nka', 'nkda',\n",
        "                'no known drug allergies', 'denies allergies', 'none'\n",
        "            ]\n",
        "            if any(pattern in text for pattern in no_allergy_patterns):\n",
        "                return 'NO_ALLERGIES'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_allergy_severity(row):\n",
        "            \"\"\"Detect severe allergic reactions\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            severity_patterns = [\n",
        "                'anaphylaxis', 'anaphylactic', 'severe', 'life-threatening',\n",
        "                'epipen', 'epinephrine', 'emergency'\n",
        "            ]\n",
        "            if any(pattern in text for pattern in severity_patterns):\n",
        "                return 'SEVERE_ALLERGY'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_allergy_reaction_type(row):\n",
        "            \"\"\"Detect specific reaction types\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            reaction_patterns = [\n",
        "                'rash', 'hives', 'swelling', 'itching', 'breathing',\n",
        "                'wheezing', 'nausea', 'vomiting', 'throat'\n",
        "            ]\n",
        "            if any(reaction in text for reaction in reaction_patterns):\n",
        "                return 'ALLERGIC_REACTION_DESCRIBED'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_seasonal_allergy(row):\n",
        "            \"\"\"Detect seasonal allergies\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            if any(season in text for season in ['seasonal', 'spring', 'fall', 'hay fever']):\n",
        "                return 'SEASONAL_ALLERGY'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_chemical_sensitivity(row):\n",
        "            \"\"\"Detect chemical sensitivities\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            chemical_patterns = [\n",
        "                'chemical', 'perfume', 'fragrance', 'smoke', 'detergent',\n",
        "                'cleaning', 'formaldehyde'\n",
        "            ]\n",
        "            if any(chem in text for chem in chemical_patterns):\n",
        "                return 'CHEMICAL_SENSITIVITY'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_multiple_allergies(row):\n",
        "            \"\"\"Detect multiple allergies\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            # Count commas or \"and\" as indicators of multiple allergies\n",
        "            if (text.count(',') >= 2 or text.count(' and ') >= 2) and 'no known' not in text:\n",
        "                return 'MULTIPLE_ALLERGIES'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_allergy_testing(row):\n",
        "            \"\"\"Detect allergy testing mentions\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            if any(test in text for test in ['tested', 'skin test', 'patch test', 'ige']):\n",
        "                return 'ALLERGY_TESTED'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        return [\n",
        "            lf_drug_allergy,\n",
        "            lf_food_allergy,\n",
        "            lf_environmental_allergy,\n",
        "            lf_no_allergies,\n",
        "            lf_allergy_severity,\n",
        "            lf_allergy_reaction_type,\n",
        "            lf_seasonal_allergy,\n",
        "            lf_chemical_sensitivity,\n",
        "            lf_multiple_allergies,\n",
        "            lf_allergy_testing\n",
        "        ]\n",
        "\n",
        "    # Apply the allergy-specific labeling functions\n",
        "    allergy_lfs = create_allergy_labeling_functions(df_allergies_entities)\n",
        "\n",
        "    print(\"\\n=== Testing Allergy Labeling Functions ===\")\n",
        "    if not df_medical.empty and 'allergies' in df_medical.columns:\n",
        "        # Test on multiple rows to see coverage\n",
        "        test_rows = min(10, len(df_medical))\n",
        "\n",
        "        for i in range(test_rows):\n",
        "            row = df_medical.iloc[i]\n",
        "            if pd.notna(row['allergies']):\n",
        "                print(f\"\\nRow {i} allergies: {row['allergies'][:100]}...\")\n",
        "                for lf in allergy_lfs:\n",
        "                    result = lf(row)\n",
        "                    if result != 'ABSTAIN':\n",
        "                        print(f\"  {lf.__name__}: {result}\")\n",
        "\n",
        "    # Analyze coverage\n",
        "    print(\"\\n=== Allergy Labeling Function Coverage ===\")\n",
        "    total_non_na = df_medical['allergies'].notna().sum()\n",
        "    for lf in allergy_lfs:\n",
        "        labeled_count = sum(lf(row) != 'ABSTAIN' for _, row in df_medical.iterrows()\n",
        "                           if pd.notna(row.get('allergies', '')))\n",
        "        coverage = (labeled_count / total_non_na * 100) if total_non_na > 0 else 0\n",
        "        print(f\"{lf.__name__}: {coverage:.1f}% coverage ({labeled_count}/{total_non_na})\")\n",
        "\n",
        "    # Analyze specific patterns in allergies\n",
        "    print(\"\\n=== Common Allergy Patterns ===\")\n",
        "    if 'allergies' in df_medical.columns:\n",
        "        # Count specific allergen mentions\n",
        "        penicillin_mentions = df_medical['allergies'].str.contains('penicillin|Penicillin', na=False).sum()\n",
        "        no_allergy_mentions = df_medical['allergies'].str.contains('no known|NKA|NKDA', na=False, regex=True).sum()\n",
        "        food_allergy_mentions = df_medical['allergies'].str.contains('peanut|shellfish|milk|egg', na=False, regex=True).sum()\n",
        "\n",
        "        print(f\"Penicillin allergy mentions: {penicillin_mentions}\")\n",
        "        print(f\"No known allergies mentions: {no_allergy_mentions}\")\n",
        "        print(f\"Food allergy mentions: {food_allergy_mentions}\")\n",
        "        print(f\"Total allergy records: {df_medical['allergies'].notna().sum()}\")\n",
        "\n",
        "    # Create a summary of allergen types found\n",
        "    print(\"\\n=== Allergen Type Summary ===\")\n",
        "    allergen_summary = {\n",
        "        'drugs': [],\n",
        "        'foods': [],\n",
        "        'environmental': [],\n",
        "        'other': []\n",
        "    }\n",
        "\n",
        "    # Categorize top entities\n",
        "    for entity, count in df_allergies_entities['text'].value_counts().head(50).items():\n",
        "        entity_lower = entity.lower()\n",
        "        if any(drug in entity_lower for drug in ['cillin', 'mycin', 'zole', 'statin']):\n",
        "            allergen_summary['drugs'].append(entity)\n",
        "        elif any(food in entity_lower for food in ['nut', 'milk', 'egg', 'fish']):\n",
        "            allergen_summary['foods'].append(entity)\n",
        "        elif any(env in entity_lower for env in ['pollen', 'dust', 'grass']):\n",
        "            allergen_summary['environmental'].append(entity)\n",
        "        else:\n",
        "            allergen_summary['other'].append(entity)\n",
        "\n",
        "    for category, items in allergen_summary.items():\n",
        "        if items:\n",
        "            print(f\"\\n{category.upper()}: {items[:10]}\")  # Show top 10 in each category\n",
        "# Save result\n",
        "df_allergies_entities.to_csv('allergies_entities_comprehensive.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>source_column</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>allergies</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>No known allergies</td>\n",
              "      <td>32488</td>\n",
              "      <td>allergies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>drug allergies</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>9</td>\n",
              "      <td>23</td>\n",
              "      <td>No known drug allergies</td>\n",
              "      <td>77061</td>\n",
              "      <td>allergies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>allergy</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>No sensitivity or allergy to any drug</td>\n",
              "      <td>149806</td>\n",
              "      <td>allergies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Allergy</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>Allergy to amoxicillin</td>\n",
              "      <td>83662</td>\n",
              "      <td>allergies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>amoxicillin</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>11</td>\n",
              "      <td>22</td>\n",
              "      <td>Allergy to amoxicillin</td>\n",
              "      <td>83662</td>\n",
              "      <td>allergies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>929</th>\n",
              "      <td>docetaxel</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>28</td>\n",
              "      <td>37</td>\n",
              "      <td>Severe allergic reaction to docetaxel chemothe...</td>\n",
              "      <td>40349</td>\n",
              "      <td>allergies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>930</th>\n",
              "      <td>drug allergies</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>9</td>\n",
              "      <td>23</td>\n",
              "      <td>No known drug allergies</td>\n",
              "      <td>135761</td>\n",
              "      <td>allergies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>931</th>\n",
              "      <td>Allergic</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>Allergic to penicillin</td>\n",
              "      <td>138116</td>\n",
              "      <td>allergies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>932</th>\n",
              "      <td>penicillin</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>12</td>\n",
              "      <td>22</td>\n",
              "      <td>Allergic to penicillin</td>\n",
              "      <td>138116</td>\n",
              "      <td>allergies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>933</th>\n",
              "      <td>allergy</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>14</td>\n",
              "      <td>21</td>\n",
              "      <td>No history of allergy</td>\n",
              "      <td>38936</td>\n",
              "      <td>allergies</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>934 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               text     label  start  end  \\\n",
              "0         allergies   DISEASE      9   18   \n",
              "1    drug allergies   DISEASE      9   23   \n",
              "2           allergy   DISEASE     18   25   \n",
              "3           Allergy   DISEASE      0    7   \n",
              "4       amoxicillin  CHEMICAL     11   22   \n",
              "..              ...       ...    ...  ...   \n",
              "929       docetaxel  CHEMICAL     28   37   \n",
              "930  drug allergies   DISEASE      9   23   \n",
              "931        Allergic   DISEASE      0    8   \n",
              "932      penicillin  CHEMICAL     12   22   \n",
              "933         allergy   DISEASE     14   21   \n",
              "\n",
              "                                         original_text  row_idx source_column  \n",
              "0                                   No known allergies    32488     allergies  \n",
              "1                              No known drug allergies    77061     allergies  \n",
              "2                No sensitivity or allergy to any drug   149806     allergies  \n",
              "3                               Allergy to amoxicillin    83662     allergies  \n",
              "4                               Allergy to amoxicillin    83662     allergies  \n",
              "..                                                 ...      ...           ...  \n",
              "929  Severe allergic reaction to docetaxel chemothe...    40349     allergies  \n",
              "930                            No known drug allergies   135761     allergies  \n",
              "931                             Allergic to penicillin   138116     allergies  \n",
              "932                             Allergic to penicillin   138116     allergies  \n",
              "933                              No history of allergy    38936     allergies  \n",
              "\n",
              "[934 rows x 7 columns]"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_allergies_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoOiikgET1_Z"
      },
      "source": [
        "##### Drug Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zy78zi5T1hH",
        "outputId": "27e02f1c-aed5-4694-92f8-868805d99db5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading en_ner_bc5cdr_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 29755 texts in 100 batches...\n",
            "Using model: en_ner_bc5cdr_md for column: drug usage\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   2%|▏         | 2/100 [00:00<00:39,  2.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  12%|█▏        | 12/100 [00:02<00:17,  5.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 3000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  22%|██▏       | 22/100 [00:04<00:14,  5.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 6000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  32%|███▏      | 32/100 [00:06<00:12,  5.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 9000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  42%|████▏     | 42/100 [00:08<00:10,  5.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 12000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  52%|█████▏    | 52/100 [00:10<00:09,  5.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  62%|██████▏   | 62/100 [00:12<00:07,  5.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 18000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  72%|███████▏  | 72/100 [00:13<00:05,  5.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 21000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  82%|████████▏ | 82/100 [00:15<00:03,  5.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 24000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  92%|█████████▏| 92/100 [00:17<00:01,  5.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 27000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 100/100 [00:19<00:00,  5.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 27 entities appearing >= 5 times\n",
            "\n",
            "Testing generated labeling functions for drug usage...\n",
            "lf_disease_drug_usage applied to row 0: ABSTAIN\n",
            "lf_chemical_drug_usage applied to row 0: ABSTAIN\n",
            "\n",
            "=== DEBUG: Check extracted drug usage entities ===\n",
            "Shape of df_drug_usage_entities: (715, 7)\n",
            "\n",
            "Column names: ['text', 'label', 'start', 'end', 'original_text', 'row_idx', 'source_column']\n",
            "\n",
            "First few rows:\n",
            "                 text     label  start  end                    original_text  \\\n",
            "0            Diazepam  CHEMICAL      0    8  Diazepam and methadone overdose   \n",
            "1  methadone overdose  CHEMICAL     13   31  Diazepam and methadone overdose   \n",
            "2            zolpidem  CHEMICAL      9   17                Abuse of zolpidem   \n",
            "3          drug abuse   DISEASE     11   21            History of drug abuse   \n",
            "4          drug abuse   DISEASE     12   22           Intravenous drug abuse   \n",
            "\n",
            "   row_idx source_column  \n",
            "0   163624    drug usage  \n",
            "1   163624    drug usage  \n",
            "2    90815    drug usage  \n",
            "3    43921    drug usage  \n",
            "4    84350    drug usage  \n",
            "\n",
            "=== Entity Labels Found in Drug Usage ===\n",
            "label\n",
            "CHEMICAL    447\n",
            "DISEASE     268\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Drug Usage Entities ===\n",
            "text\n",
            "drug abuse                             113\n",
            "cocaine                                 92\n",
            "substance abuse                         47\n",
            "cannabis                                39\n",
            "methamphetamine                         31\n",
            "Cocaine                                 27\n",
            "steroid                                 17\n",
            "alcohol                                 15\n",
            "Heroin                                  14\n",
            "Cannabis                                10\n",
            "steroids                                10\n",
            "ecstasy                                  9\n",
            "methadone                                8\n",
            "benzodiazepines                          7\n",
            "amphetamines                             7\n",
            "caffeine                                 6\n",
            "LSD                                      6\n",
            "Methamphetamine                          6\n",
            "Substance abuse                          6\n",
            "cannabis abuse                           6\n",
            "Denies substance abuse                   5\n",
            "pain                                     5\n",
            "Polysubstance abuse                      5\n",
            "amphetamine                              5\n",
            "ketamine                                 5\n",
            "testosterone                             5\n",
            "fenethylline                             5\n",
            "cocaine abuse                            4\n",
            "accidental or intentional poisoning      4\n",
            "MDMA                                     4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Analyzing drug usage entities for patterns...\n",
            "\n",
            "=== Testing Drug Usage Labeling Functions ===\n",
            "\n",
            "=== Drug Usage Labeling Function Coverage ===\n",
            "lf_no_drug_use: 49.2% coverage (704/1430)\n",
            "lf_alcohol_use: 1.4% coverage (20/1430)\n",
            "lf_tobacco_use: 2.3% coverage (33/1430)\n",
            "lf_cannabis_use: 12.1% coverage (173/1430)\n",
            "lf_opioid_use: 7.3% coverage (105/1430)\n",
            "lf_stimulant_use: 12.5% coverage (179/1430)\n",
            "lf_iv_drug_use: 9.4% coverage (134/1430)\n",
            "lf_prescription_abuse: 0.0% coverage (0/1430)\n",
            "lf_polysubstance_use: 3.6% coverage (52/1430)\n",
            "lf_past_drug_use: 24.8% coverage (354/1430)\n",
            "lf_current_drug_use: 7.6% coverage (108/1430)\n",
            "lf_drug_treatment: 25.0% coverage (358/1430)\n",
            "lf_drug_screen_result: 0.4% coverage (6/1430)\n",
            "\n",
            "=== Common Drug Usage Patterns ===\n",
            "No drug use mentions: 46\n",
            "Alcohol mentions: 19\n",
            "Tobacco mentions: 23\n",
            "Illicit drug mentions: 186\n",
            "Total drug usage records: 1430\n",
            "\n",
            "=== Drug Use Risk Stratification ===\n",
            "UNKNOWN_RISK        28325\n",
            "UNSPECIFIED_RISK      850\n",
            "LOW_RISK              308\n",
            "HIGH_RISK             216\n",
            "MODERATE_RISK          56\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Process drug usage using BC5CDR model (recognizes DISEASE and CHEMICAL)\n",
        "if __name__ == \"__main__\":\n",
        "    # Run extraction for the 'drug usage' column\n",
        "    # BC5CDR model will identify drugs/substances (CHEMICAL entities)\n",
        "    df_drug_usage_entities, drug_usage_summary, drug_usage_rules = run_medical_ner_extraction(\n",
        "        df_medical,  \n",
        "        text_column='drug usage',\n",
        "        model_name=\"en_ner_bc5cdr_md\",  # This model recognizes DISEASE and CHEMICAL entities\n",
        "        batch_size=300, \n",
        "        id_column='idx'  )\n",
        "\n",
        "    # Test the generated rules\n",
        "    print(\"\\nTesting generated labeling functions for drug usage...\")\n",
        "\n",
        "    # Select a sample row from the original df_medical to test the rules\n",
        "    if not df_medical.empty:\n",
        "        sample_row = df_medical.iloc[0]\n",
        "\n",
        "        for rule_name, rule_func in drug_usage_rules.items():\n",
        "            try:\n",
        "                test_result = rule_func(sample_row)\n",
        "                print(f\"{rule_name} applied to row 0: {test_result}\")\n",
        "            except KeyError as e:\n",
        "                print(f\"Error applying rule {rule_name}: {e}. Make sure the column 'drug usage' exists in df_medical.\")\n",
        "    else:\n",
        "        print(\"df_medical is empty, cannot test rules.\")\n",
        "\n",
        "    # Debug: Check extracted entities\n",
        "    print(\"\\n=== DEBUG: Check extracted drug usage entities ===\")\n",
        "    print(f\"Shape of df_drug_usage_entities: {df_drug_usage_entities.shape}\")\n",
        "    print(f\"\\nColumn names: {df_drug_usage_entities.columns.tolist()}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(df_drug_usage_entities.head())\n",
        "\n",
        "    # Check entity label distribution\n",
        "    print(\"\\n=== Entity Labels Found in Drug Usage ===\")\n",
        "    if not df_drug_usage_entities.empty:\n",
        "        print(df_drug_usage_entities['label'].value_counts())\n",
        "\n",
        "        # Look at the top entities\n",
        "        print(\"\\n=== Top Drug Usage Entities ===\")\n",
        "        drug_entities = df_drug_usage_entities['text'].value_counts().head(30)\n",
        "        print(drug_entities)\n",
        "\n",
        "# Create specific labeling functions for drug usage data\n",
        "def create_drug_usage_labeling_functions(entities_df):\n",
        "        \"\"\"Create specific labeling functions for drug usage\"\"\"\n",
        "\n",
        "        # Analyze entities to understand patterns\n",
        "        top_entities = entities_df['text'].value_counts().head(100)\n",
        "        print(f\"\\nAnalyzing drug usage entities for patterns...\")\n",
        "\n",
        "        def lf_no_drug_use(row):\n",
        "            \"\"\"Detect absence of drug use\"\"\"\n",
        "            text = str(row['drug usage']).lower()\n",
        "            no_drug_patterns = [\n",
        "                'no drug', 'denies', 'denied', 'no history', 'no illicit',\n",
        "                'no substance', 'no recreational', 'never', 'none',\n",
        "                'no personal history', 'negative'\n",
        "            ]\n",
        "            if any(pattern in text for pattern in no_drug_patterns):\n",
        "                return 'NO_DRUG_USE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_alcohol_use(row):\n",
        "            \"\"\"Detect alcohol use patterns\"\"\"\n",
        "            text = str(row['drug usage']).lower()\n",
        "            alcohol_patterns = [\n",
        "                'alcohol', 'drinking', 'beer', 'wine', 'liquor', 'spirits',\n",
        "                'ethanol', 'etoh', 'drinks per', 'social drinking'\n",
        "            ]\n",
        "            if any(pattern in text for pattern in alcohol_patterns):\n",
        "                return 'ALCOHOL_USE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_tobacco_use(row):\n",
        "            \"\"\"Detect tobacco/nicotine use\"\"\"\n",
        "            text = str(row['drug usage']).lower()\n",
        "            tobacco_patterns = [\n",
        "                'tobacco', 'smoking', 'cigarette', 'nicotine', 'pack',\n",
        "                'cigar', 'chewing tobacco', 'vaping', 'e-cigarette'\n",
        "            ]\n",
        "            if any(pattern in text for pattern in tobacco_patterns):\n",
        "                return 'TOBACCO_USE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_cannabis_use(row):\n",
        "            \"\"\"Detect cannabis/marijuana use\"\"\"\n",
        "            text = str(row['drug usage']).lower()\n",
        "            cannabis_patterns = [\n",
        "                'cannabis', 'marijuana', 'thc', 'weed', 'pot', 'hemp',\n",
        "                'mary jane', 'ganja', 'hash', 'cannabinoid'\n",
        "            ]\n",
        "            if any(pattern in text for pattern in cannabis_patterns):\n",
        "                return 'CANNABIS_USE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_opioid_use(row):\n",
        "            \"\"\"Detect opioid use\"\"\"\n",
        "            text = str(row['drug usage']).lower()\n",
        "            opioid_patterns = [\n",
        "                'opioid', 'opiate', 'heroin', 'morphine', 'oxycodone',\n",
        "                'hydrocodone', 'fentanyl', 'codeine', 'tramadol', 'methadone',\n",
        "                'percocet', 'vicodin', 'oxycontin'\n",
        "            ]\n",
        "            if any(pattern in text for pattern in opioid_patterns):\n",
        "                return 'OPIOID_USE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_stimulant_use(row):\n",
        "            \"\"\"Detect stimulant use\"\"\"\n",
        "            text = str(row['drug usage']).lower()\n",
        "            stimulant_patterns = [\n",
        "                'cocaine', 'crack', 'amphetamine', 'methamphetamine', 'meth',\n",
        "                'speed', 'crystal', 'adderall', 'ritalin', 'mdma', 'ecstasy'\n",
        "            ]\n",
        "            if any(pattern in text for pattern in stimulant_patterns):\n",
        "                return 'STIMULANT_USE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_iv_drug_use(row):\n",
        "            \"\"\"Detect intravenous drug use\"\"\"\n",
        "            text = str(row['drug usage']).lower()\n",
        "            iv_patterns = [\n",
        "                'iv drug', 'intravenous', 'injection', 'needle', 'inject',\n",
        "                'ivdu', 'shooting up'\n",
        "            ]\n",
        "            if any(pattern in text for pattern in iv_patterns):\n",
        "                return 'IV_DRUG_USE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_prescription_abuse(row):\n",
        "            \"\"\"Detect prescription drug abuse\"\"\"\n",
        "            text = str(row['drug usage']).lower()\n",
        "            if ('prescription' in text or 'prescribed' in text) and \\\n",
        "               any(abuse in text for abuse in ['abuse', 'misuse', 'dependency', 'addiction']):\n",
        "                return 'PRESCRIPTION_ABUSE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_polysubstance_use(row):\n",
        "            \"\"\"Detect multiple substance use\"\"\"\n",
        "            text = str(row['drug usage']).lower()\n",
        "            # Count different drug mentions\n",
        "            substances = ['alcohol', 'tobacco', 'cannabis', 'cocaine', 'heroin', 'meth']\n",
        "            substance_count = sum(1 for sub in substances if sub in text)\n",
        "            if substance_count >= 2:\n",
        "                return 'POLYSUBSTANCE_USE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_past_drug_use(row):\n",
        "            \"\"\"Detect past/former drug use\"\"\"\n",
        "            text = str(row['drug usage']).lower()\n",
        "            past_patterns = [\n",
        "                'former', 'past', 'history of', 'previously', 'quit',\n",
        "                'stopped', 'used to', 'years ago', 'in recovery', 'sober'\n",
        "            ]\n",
        "            if any(pattern in text for pattern in past_patterns) and \\\n",
        "               not any(current in text for current in ['current', 'active', 'ongoing']):\n",
        "                return 'PAST_DRUG_USE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_current_drug_use(row):\n",
        "            \"\"\"Detect current/active drug use\"\"\"\n",
        "            text = str(row['drug usage']).lower()\n",
        "            current_patterns = [\n",
        "                'current', 'active', 'ongoing', 'continues', 'daily',\n",
        "                'regular', 'frequent', 'occasional'\n",
        "            ]\n",
        "            if any(pattern in text for pattern in current_patterns):\n",
        "                return 'CURRENT_DRUG_USE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_drug_treatment(row):\n",
        "            \"\"\"Detect drug treatment/rehabilitation\"\"\"\n",
        "            text = str(row['drug usage']).lower()\n",
        "            treatment_patterns = [\n",
        "                'rehab', 'treatment', 'recovery', 'aa', 'na', 'methadone clinic',\n",
        "                'suboxone', 'detox', 'counseling', 'therapy'\n",
        "            ]\n",
        "            if any(pattern in text for pattern in treatment_patterns):\n",
        "                return 'DRUG_TREATMENT'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_drug_screen_result(row):\n",
        "            \"\"\"Detect drug screening results\"\"\"\n",
        "            text = str(row['drug usage']).lower()\n",
        "            if any(screen in text for screen in ['drug screen', 'urine test', 'tested positive', 'tested negative']):\n",
        "                return 'DRUG_SCREEN_MENTIONED'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        return [\n",
        "            lf_no_drug_use,\n",
        "            lf_alcohol_use,\n",
        "            lf_tobacco_use,\n",
        "            lf_cannabis_use,\n",
        "            lf_opioid_use,\n",
        "            lf_stimulant_use,\n",
        "            lf_iv_drug_use,\n",
        "            lf_prescription_abuse,\n",
        "            lf_polysubstance_use,\n",
        "            lf_past_drug_use,\n",
        "            lf_current_drug_use,\n",
        "            lf_drug_treatment,\n",
        "            lf_drug_screen_result\n",
        "        ]\n",
        "# Apply the drug usage-specific labeling functions\n",
        "drug_usage_lfs = create_drug_usage_labeling_functions(df_drug_usage_entities)\n",
        "\n",
        "print(\"\\n=== Testing Drug Usage Labeling Functions ===\")\n",
        "if not df_medical.empty and 'drug usage' in df_medical.columns:\n",
        "        # Test on multiple rows to see coverage\n",
        "        test_rows = min(10, len(df_medical))\n",
        "\n",
        "        for i in range(test_rows):\n",
        "            row = df_medical.iloc[i]\n",
        "            if pd.notna(row['drug usage']):\n",
        "                print(f\"\\nRow {i} drug usage: {row['drug usage'][:100]}...\")\n",
        "                for lf in drug_usage_lfs:\n",
        "                    result = lf(row)\n",
        "                    if result != 'ABSTAIN':\n",
        "                        print(f\"  {lf.__name__}: {result}\")\n",
        "\n",
        "    # Analyze coverage\n",
        "print(\"\\n=== Drug Usage Labeling Function Coverage ===\")\n",
        "total_non_na = df_medical['drug usage'].notna().sum()\n",
        "for lf in drug_usage_lfs:\n",
        "    labeled_count = sum(lf(row) != 'ABSTAIN' for _, row in df_medical.iterrows()\n",
        "                        if pd.notna(row.get('drug usage', '')))\n",
        "    coverage = (labeled_count / total_non_na * 100) if total_non_na > 0 else 0\n",
        "    print(f\"{lf.__name__}: {coverage:.1f}% coverage ({labeled_count}/{total_non_na})\")\n",
        "\n",
        "# Analyze specific patterns in drug usage\n",
        "print(\"\\n=== Common Drug Usage Patterns ===\")\n",
        "if 'drug usage' in df_medical.columns:\n",
        "    # Count specific substance mentions\n",
        "    no_drug_mentions = df_medical['drug usage'].str.contains('no drug|denied|no history', na=False, regex=True).sum()\n",
        "    alcohol_mentions = df_medical['drug usage'].str.contains('alcohol|drinking|beer|wine', na=False, regex=True).sum()\n",
        "    tobacco_mentions = df_medical['drug usage'].str.contains('tobacco|smoking|cigarette', na=False, regex=True).sum()\n",
        "    illicit_mentions = df_medical['drug usage'].str.contains('cocaine|heroin|meth|cannabis', na=False, regex=True).sum()\n",
        "\n",
        "    print(f\"No drug use mentions: {no_drug_mentions}\")\n",
        "    print(f\"Alcohol mentions: {alcohol_mentions}\")\n",
        "    print(f\"Tobacco mentions: {tobacco_mentions}\")\n",
        "    print(f\"Illicit drug mentions: {illicit_mentions}\")\n",
        "    print(f\"Total drug usage records: {df_medical['drug usage'].notna().sum()}\")\n",
        "\n",
        "# Create risk stratification based on drug usage\n",
        "def stratify_drug_use_risk(row):\n",
        "    \"\"\"Stratify risk based on drug usage patterns\"\"\"\n",
        "    if pd.isna(row.get('drug usage', '')):\n",
        "        return 'UNKNOWN_RISK'\n",
        "\n",
        "    text = str(row['drug usage']).lower()\n",
        "\n",
        "    # High risk indicators\n",
        "    high_risk = ['iv drug', 'heroin', 'cocaine', 'meth', 'overdose', 'daily use']\n",
        "    if any(risk in text for risk in high_risk):\n",
        "        return 'HIGH_RISK'\n",
        "\n",
        "    # Moderate risk\n",
        "    moderate_risk = ['alcohol', 'cannabis', 'prescription']\n",
        "    if any(risk in text for risk in moderate_risk):\n",
        "        return 'MODERATE_RISK'\n",
        "\n",
        "    # Low risk\n",
        "    if any(pattern in text for pattern in ['no drug', 'denied', 'none']):\n",
        "        return 'LOW_RISK'\n",
        "\n",
        "    return 'UNSPECIFIED_RISK'\n",
        "\n",
        "# Apply risk stratification\n",
        "print(\"\\n=== Drug Use Risk Stratification ===\")\n",
        "if 'drug usage' in df_medical.columns:\n",
        "    risk_levels = df_medical.apply(stratify_drug_use_risk, axis=1)\n",
        "    print(risk_levels.value_counts())\n",
        "\n",
        "# save result\n",
        "df_drug_usage_entities.to_csv('drug_usage_entities_comprehensive.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>source_column</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Diazepam</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>Diazepam and methadone overdose</td>\n",
              "      <td>163624</td>\n",
              "      <td>drug usage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>methadone overdose</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>13</td>\n",
              "      <td>31</td>\n",
              "      <td>Diazepam and methadone overdose</td>\n",
              "      <td>163624</td>\n",
              "      <td>drug usage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>zolpidem</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>9</td>\n",
              "      <td>17</td>\n",
              "      <td>Abuse of zolpidem</td>\n",
              "      <td>90815</td>\n",
              "      <td>drug usage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>drug abuse</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>11</td>\n",
              "      <td>21</td>\n",
              "      <td>History of drug abuse</td>\n",
              "      <td>43921</td>\n",
              "      <td>drug usage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>drug abuse</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>12</td>\n",
              "      <td>22</td>\n",
              "      <td>Intravenous drug abuse</td>\n",
              "      <td>84350</td>\n",
              "      <td>drug usage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>710</th>\n",
              "      <td>bipolar disorder</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>34</td>\n",
              "      <td>50</td>\n",
              "      <td>Remote history of lithium use for bipolar diso...</td>\n",
              "      <td>113022</td>\n",
              "      <td>drug usage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>711</th>\n",
              "      <td>cocaine</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>24</td>\n",
              "      <td>31</td>\n",
              "      <td>Occasional recreational cocaine use, most rece...</td>\n",
              "      <td>137819</td>\n",
              "      <td>drug usage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>712</th>\n",
              "      <td>cannabis</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>93</td>\n",
              "      <td>101</td>\n",
              "      <td>Heavy e-cigarette use for the previous 2 years...</td>\n",
              "      <td>99885</td>\n",
              "      <td>drug usage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>713</th>\n",
              "      <td>neck pain</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>61</td>\n",
              "      <td>70</td>\n",
              "      <td>Used heroin, street bought oral opiates to sel...</td>\n",
              "      <td>97753</td>\n",
              "      <td>drug usage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>714</th>\n",
              "      <td>cocaine</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>9</td>\n",
              "      <td>16</td>\n",
              "      <td>Previous cocaine abuse, ceased ten years ago</td>\n",
              "      <td>38570</td>\n",
              "      <td>drug usage</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>715 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   text     label  start  end  \\\n",
              "0              Diazepam  CHEMICAL      0    8   \n",
              "1    methadone overdose  CHEMICAL     13   31   \n",
              "2              zolpidem  CHEMICAL      9   17   \n",
              "3            drug abuse   DISEASE     11   21   \n",
              "4            drug abuse   DISEASE     12   22   \n",
              "..                  ...       ...    ...  ...   \n",
              "710    bipolar disorder   DISEASE     34   50   \n",
              "711             cocaine  CHEMICAL     24   31   \n",
              "712            cannabis  CHEMICAL     93  101   \n",
              "713           neck pain   DISEASE     61   70   \n",
              "714             cocaine  CHEMICAL      9   16   \n",
              "\n",
              "                                         original_text  row_idx source_column  \n",
              "0                      Diazepam and methadone overdose   163624    drug usage  \n",
              "1                      Diazepam and methadone overdose   163624    drug usage  \n",
              "2                                    Abuse of zolpidem    90815    drug usage  \n",
              "3                                History of drug abuse    43921    drug usage  \n",
              "4                               Intravenous drug abuse    84350    drug usage  \n",
              "..                                                 ...      ...           ...  \n",
              "710  Remote history of lithium use for bipolar diso...   113022    drug usage  \n",
              "711  Occasional recreational cocaine use, most rece...   137819    drug usage  \n",
              "712  Heavy e-cigarette use for the previous 2 years...    99885    drug usage  \n",
              "713  Used heroin, street bought oral opiates to sel...    97753    drug usage  \n",
              "714       Previous cocaine abuse, ceased ten years ago    38570    drug usage  \n",
              "\n",
              "[715 rows x 7 columns]"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_drug_usage_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVItZWQ_7Cb-"
      },
      "source": [
        "### Extracting Surgeries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        },
        "id": "h9RTUlzN7HRr",
        "outputId": "9ce66ad4-8450-41c5-ec06-ace74eb10761"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>has_surgery</th>\n",
              "      <th>reason</th>\n",
              "      <th>Type</th>\n",
              "      <th>time</th>\n",
              "      <th>outcome</th>\n",
              "      <th>details</th>\n",
              "      <th>combined_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155216</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>nan nan nan nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>133948</td>\n",
              "      <td>True</td>\n",
              "      <td>Idiopathic osteonecrosis of the femoral head</td>\n",
              "      <td>Total Hip Arthroplasty (THA)</td>\n",
              "      <td>After diagnosis</td>\n",
              "      <td>Discharged in good condition without specific ...</td>\n",
              "      <td>First THA on the left hip</td>\n",
              "      <td>Idiopathic osteonecrosis of the femoral head T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133948</td>\n",
              "      <td>True</td>\n",
              "      <td>Pain and limited ROM in the contralateral hip ...</td>\n",
              "      <td>Total Hip Arthroplasty (THA)</td>\n",
              "      <td>One year after the first THA</td>\n",
              "      <td>Discharged in good condition without specific ...</td>\n",
              "      <td>Second THA on the contralateral hip</td>\n",
              "      <td>Pain and limited ROM in the contralateral hip ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80176</td>\n",
              "      <td>True</td>\n",
              "      <td>Posttraumatic arthritis</td>\n",
              "      <td>Left elbow arthrodesis</td>\n",
              "      <td>At the age of 18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Elbow was fused at 90 degrees</td>\n",
              "      <td>Posttraumatic arthritis Left elbow arthrodesis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>80176</td>\n",
              "      <td>True</td>\n",
              "      <td>Hypertrophic nonunion of ulnar shaft fracture ...</td>\n",
              "      <td>Repair of nonunion and conversion of elbow art...</td>\n",
              "      <td>Three months after the fall and subsequent con...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The stem of the ulnar component would act as a...</td>\n",
              "      <td>Hypertrophic nonunion of ulnar shaft fracture ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35859</th>\n",
              "      <td>98004</td>\n",
              "      <td>True</td>\n",
              "      <td>Inferior segment elevation (ST) elevation myoc...</td>\n",
              "      <td>Primary percutaneous coronary intervention (dr...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Successful treatment of right coronary artery ...</td>\n",
              "      <td>Procedure complicated by Ventricular Fibrillat...</td>\n",
              "      <td>Inferior segment elevation (ST) elevation myoc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35860</th>\n",
              "      <td>133320</td>\n",
              "      <td>True</td>\n",
              "      <td>Leiomyosarcoma</td>\n",
              "      <td>Wide tumor resection</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Successful with no adjuvant chemotherapy and r...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Leiomyosarcoma Wide tumor resection nan Succes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35861</th>\n",
              "      <td>133320</td>\n",
              "      <td>True</td>\n",
              "      <td>Lung nodules</td>\n",
              "      <td>Excisional biopsy</td>\n",
              "      <td>One year and 3 months postoperatively</td>\n",
              "      <td>Histopathological diagnosis was consistent wit...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Lung nodules Excisional biopsy nan Histopathol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35862</th>\n",
              "      <td>133320</td>\n",
              "      <td>True</td>\n",
              "      <td>Bone metastasis of the right femur</td>\n",
              "      <td>Cryoablation under CT guidance</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ablation needles were inserted into the proxim...</td>\n",
              "      <td>Bone metastasis of the right femur Cryoablatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35863</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Acute severe aortic insufficiency from endocar...</td>\n",
              "      <td>Emergent mechanical aortic valve replacement s...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Uncomplicated postoperative course</td>\n",
              "      <td>Patient was extubated postoperative day 4, neu...</td>\n",
              "      <td>Acute severe aortic insufficiency from endocar...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35864 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          idx  has_surgery                                             reason  \\\n",
              "0      155216        False                                                NaN   \n",
              "1      133948         True       Idiopathic osteonecrosis of the femoral head   \n",
              "2      133948         True  Pain and limited ROM in the contralateral hip ...   \n",
              "3       80176         True                            Posttraumatic arthritis   \n",
              "4       80176         True  Hypertrophic nonunion of ulnar shaft fracture ...   \n",
              "...       ...          ...                                                ...   \n",
              "35859   98004         True  Inferior segment elevation (ST) elevation myoc...   \n",
              "35860  133320         True                                     Leiomyosarcoma   \n",
              "35861  133320         True                                       Lung nodules   \n",
              "35862  133320         True                 Bone metastasis of the right femur   \n",
              "35863   97973         True  Acute severe aortic insufficiency from endocar...   \n",
              "\n",
              "                                                    Type  \\\n",
              "0                                                    NaN   \n",
              "1                           Total Hip Arthroplasty (THA)   \n",
              "2                           Total Hip Arthroplasty (THA)   \n",
              "3                                 Left elbow arthrodesis   \n",
              "4      Repair of nonunion and conversion of elbow art...   \n",
              "...                                                  ...   \n",
              "35859  Primary percutaneous coronary intervention (dr...   \n",
              "35860                               Wide tumor resection   \n",
              "35861                                  Excisional biopsy   \n",
              "35862                     Cryoablation under CT guidance   \n",
              "35863  Emergent mechanical aortic valve replacement s...   \n",
              "\n",
              "                                                    time  \\\n",
              "0                                                    NaN   \n",
              "1                                        After diagnosis   \n",
              "2                           One year after the first THA   \n",
              "3                                       At the age of 18   \n",
              "4      Three months after the fall and subsequent con...   \n",
              "...                                                  ...   \n",
              "35859                                                NaN   \n",
              "35860                                                NaN   \n",
              "35861              One year and 3 months postoperatively   \n",
              "35862                                                NaN   \n",
              "35863                                                NaN   \n",
              "\n",
              "                                                 outcome  \\\n",
              "0                                                    NaN   \n",
              "1      Discharged in good condition without specific ...   \n",
              "2      Discharged in good condition without specific ...   \n",
              "3                                                    NaN   \n",
              "4                                                    NaN   \n",
              "...                                                  ...   \n",
              "35859  Successful treatment of right coronary artery ...   \n",
              "35860  Successful with no adjuvant chemotherapy and r...   \n",
              "35861  Histopathological diagnosis was consistent wit...   \n",
              "35862                                                NaN   \n",
              "35863                 Uncomplicated postoperative course   \n",
              "\n",
              "                                                 details  \\\n",
              "0                                                    NaN   \n",
              "1                              First THA on the left hip   \n",
              "2                    Second THA on the contralateral hip   \n",
              "3                          Elbow was fused at 90 degrees   \n",
              "4      The stem of the ulnar component would act as a...   \n",
              "...                                                  ...   \n",
              "35859  Procedure complicated by Ventricular Fibrillat...   \n",
              "35860                                                NaN   \n",
              "35861                                                NaN   \n",
              "35862  Ablation needles were inserted into the proxim...   \n",
              "35863  Patient was extubated postoperative day 4, neu...   \n",
              "\n",
              "                                           combined_text  \n",
              "0                                        nan nan nan nan  \n",
              "1      Idiopathic osteonecrosis of the femoral head T...  \n",
              "2      Pain and limited ROM in the contralateral hip ...  \n",
              "3      Posttraumatic arthritis Left elbow arthrodesis...  \n",
              "4      Hypertrophic nonunion of ulnar shaft fracture ...  \n",
              "...                                                  ...  \n",
              "35859  Inferior segment elevation (ST) elevation myoc...  \n",
              "35860  Leiomyosarcoma Wide tumor resection nan Succes...  \n",
              "35861  Lung nodules Excisional biopsy nan Histopathol...  \n",
              "35862  Bone metastasis of the right femur Cryoablatio...  \n",
              "35863  Acute severe aortic insufficiency from endocar...  \n",
              "\n",
              "[35864 rows x 8 columns]"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_surgery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "kPOQefZw9O04"
      },
      "outputs": [],
      "source": [
        "class TemporalStandardizer:\n",
        "    \"\"\"Extract and standardize temporal expressions from medical text\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Load spaCy model\n",
        "        try:\n",
        "            self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "        except:\n",
        "            self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "        # Conversion mappings - Define this BEFORE adding patterns\n",
        "        self.time_units = {\n",
        "            'day': 1, 'days': 1, 'd': 1,\n",
        "            'week': 7, 'weeks': 7, 'wk': 7, 'wks': 7,\n",
        "            'month': 30, 'months': 30, 'mo': 30, 'mos': 30,\n",
        "            'year': 365, 'years': 365, 'yr': 365, 'yrs': 365,\n",
        "            'hour': 1/24, 'hours': 1/24, 'hr': 1/24, 'hrs': 1/24,\n",
        "            'minute': 1/1440, 'minutes': 1/1440, 'min': 1/1440, 'mins': 1/1440\n",
        "        }\n",
        "\n",
        "        # Initialize matcher for temporal patterns\n",
        "        self.matcher = Matcher(self.nlp.vocab)\n",
        "        # Now call _add_temporal_patterns AFTER time_units is defined\n",
        "        self._add_temporal_patterns()\n",
        "\n",
        "\n",
        "    def _add_temporal_patterns(self):\n",
        "        \"\"\"Add temporal patterns to spaCy matcher\"\"\"\n",
        "\n",
        "        # Pattern: \"X days/weeks/months\"\n",
        "        pattern1 = [\n",
        "            {\"LIKE_NUM\": True},\n",
        "            # Access self.time_units here is now safe\n",
        "            {\"LOWER\": {\"IN\": list(self.time_units.keys())}}\n",
        "        ]\n",
        "        self.matcher.add(\"DURATION\", [pattern1])\n",
        "\n",
        "        # Pattern: \"past X days/weeks\"\n",
        "        pattern2 = [\n",
        "            {\"LOWER\": {\"IN\": [\"past\", \"last\", \"previous\"]}},\n",
        "            {\"LIKE_NUM\": True},\n",
        "            {\"LOWER\": {\"IN\": list(self.time_units.keys())}}\n",
        "        ]\n",
        "        self.matcher.add(\"PAST_DURATION\", [pattern2])\n",
        "\n",
        "        # Pattern: \"X days/weeks ago\"\n",
        "        pattern3 = [\n",
        "            {\"LIKE_NUM\": True},\n",
        "            {\"LOWER\": {\"IN\": list(self.time_units.keys())}},\n",
        "            {\"LOWER\": \"ago\"}\n",
        "        ]\n",
        "        self.matcher.add(\"AGO_DURATION\", [pattern3])\n",
        "\n",
        "    def extract_all_temporal_info(self, text):\n",
        "        \"\"\"Extract all temporal information from text\"\"\"\n",
        "        if pd.isna(text) or text == '':\n",
        "            return {\n",
        "                'duration_days': None,\n",
        "                'is_ongoing': False,\n",
        "                'has_date': False,\n",
        "                'temporal_type': None,\n",
        "                'original_text': text\n",
        "            }\n",
        "\n",
        "        text = str(text)\n",
        "        info = {\n",
        "            'duration_days': None,\n",
        "            'is_ongoing': False,\n",
        "            'has_date': False,\n",
        "            'temporal_type': None,\n",
        "            'original_text': text\n",
        "        }\n",
        "\n",
        "        # Check for ongoing conditions\n",
        "        ongoing_patterns = [\n",
        "            'persisting', 'continuing', 'ongoing', 'current',\n",
        "            'still', 'continues', 'persistent', 'chronic'\n",
        "        ]\n",
        "        info['is_ongoing'] = any(pattern in text.lower() for pattern in ongoing_patterns)\n",
        "\n",
        "        # Try to extract specific dates\n",
        "        dates = self._extract_dates(text)\n",
        "        if dates:\n",
        "            info['has_date'] = True\n",
        "            info['extracted_dates'] = dates\n",
        "\n",
        "        # Extract duration\n",
        "        duration = self._extract_duration(text)\n",
        "        if duration:\n",
        "            info['duration_days'] = duration\n",
        "\n",
        "        # Classify temporal type\n",
        "        info['temporal_type'] = self._classify_temporal_type(text)\n",
        "\n",
        "        return info\n",
        "\n",
        "    def _extract_dates(self, text):\n",
        "        \"\"\"Extract actual dates from text\"\"\"\n",
        "        dates = []\n",
        "\n",
        "        # Common date patterns\n",
        "        date_patterns = [\n",
        "            r'\\b\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}\\b',  # MM/DD/YYYY or MM-DD-YYYY\n",
        "            r'\\b\\d{4}[-/]\\d{1,2}[-/]\\d{1,2}\\b',    # YYYY-MM-DD\n",
        "            r'\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\\s+\\d{1,2},?\\s+\\d{4}\\b',  # Month DD, YYYY\n",
        "            r'\\b\\d{1,2}\\s+(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\\s+\\d{4}\\b',     # DD Month YYYY\n",
        "        ]\n",
        "\n",
        "        for pattern in date_patterns:\n",
        "            matches = re.finditer(pattern, text, re.IGNORECASE)\n",
        "            for match in matches:\n",
        "                try:\n",
        "                    parsed_date = parser.parse(match.group(), fuzzy=False)\n",
        "                    dates.append(parsed_date)\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        return dates\n",
        "\n",
        "    def _extract_duration(self, text):\n",
        "        \"\"\"Extract duration in days from temporal expressions\"\"\"\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        # Use regex to find duration patterns\n",
        "        patterns = [\n",
        "            # \"X days/weeks/months\"\n",
        "            r'(\\d+)\\s*(day|days|week|weeks|month|months|year|years|hour|hours)',\n",
        "            # \"a few days/weeks\"\n",
        "            r'(a few|several|couple of)\\s*(day|days|week|weeks|month|months)',\n",
        "            # Written numbers\n",
        "            r'(one|two|three|four|five|six|seven|eight|nine|ten)\\s*(day|days|week|weeks|month|months|year|years)',\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, text_lower)\n",
        "            if match:\n",
        "                # Extract number\n",
        "                number_text = match.group(1)\n",
        "                unit = match.group(2)\n",
        "\n",
        "                # Convert to number\n",
        "                if number_text.isdigit():\n",
        "                    number = int(number_text)\n",
        "                elif number_text in ['a few', 'several']:\n",
        "                    number = 3  # Approximate\n",
        "                elif number_text == 'couple of':\n",
        "                    number = 2\n",
        "                else:\n",
        "                    # Convert written numbers\n",
        "                    number_map = {\n",
        "                        'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5,\n",
        "                        'six': 6, 'seven': 7, 'eight': 8, 'nine': 9, 'ten': 10\n",
        "                    }\n",
        "                    number = number_map.get(number_text, 1)\n",
        "\n",
        "                # Convert to days\n",
        "                if unit in self.time_units:\n",
        "                    return number * self.time_units[unit]\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _classify_temporal_type(self, text):\n",
        "        \"\"\"Classify the type of temporal expression\"\"\"\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        if any(word in text_lower for word in ['ago', 'before', 'prior', 'previously']):\n",
        "            return 'past_reference'\n",
        "        elif any(word in text_lower for word in ['since', 'from', 'started']):\n",
        "            return 'onset_reference'\n",
        "        elif any(word in text_lower for word in ['for', 'duration', 'lasted']):\n",
        "            return 'duration_reference'\n",
        "        elif any(word in text_lower for word in ['until', 'through', 'to']):\n",
        "            return 'range_reference'\n",
        "        elif any(word in text_lower for word in ['after', 'following', 'post']):\n",
        "            return 'post_event'\n",
        "        elif re.search(r'\\d{4}', text):  # Contains year\n",
        "            return 'absolute_date'\n",
        "        else:\n",
        "            return 'unspecified'\n",
        "\n",
        "    def standardize_temporal_column(self, df, column_name):\n",
        "        \"\"\"Standardize an entire temporal column\"\"\"\n",
        "\n",
        "        print(f\"\\nProcessing temporal column: {column_name}\")\n",
        "\n",
        "        # Apply extraction to all values\n",
        "        temporal_data = df[column_name].apply(self.extract_all_temporal_info)\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        temporal_df = pd.DataFrame(temporal_data.tolist())\n",
        "\n",
        "        # Add prefix to column names\n",
        "        temporal_df.columns = [f\"{column_name}_{col}\" for col in temporal_df.columns]\n",
        "\n",
        "        # Concatenate with original dataframe\n",
        "        result_df = pd.concat([df, temporal_df], axis=1)\n",
        "\n",
        "        # Generate report\n",
        "        report = self._generate_temporal_report(temporal_df, column_name)\n",
        "\n",
        "        return result_df, report\n",
        "\n",
        "    def _generate_temporal_report(self, temporal_df, column_name):\n",
        "        \"\"\"Generate report on temporal extraction\"\"\"\n",
        "\n",
        "        duration_col = f\"{column_name}_duration_days\"\n",
        "        type_col = f\"{column_name}_temporal_type\"\n",
        "\n",
        "        report = {\n",
        "            'column': column_name,\n",
        "            'total_entries': len(temporal_df),\n",
        "            'extracted_durations': temporal_df[duration_col].notna().sum(),\n",
        "            'ongoing_conditions': temporal_df[f\"{column_name}_is_ongoing\"].sum(),\n",
        "            'has_specific_dates': temporal_df[f\"{column_name}_has_date\"].sum(),\n",
        "            'temporal_types': temporal_df[type_col].value_counts().to_dict()\n",
        "        }\n",
        "\n",
        "        # Duration statistics\n",
        "        if temporal_df[duration_col].notna().any():\n",
        "            report['duration_stats'] = {\n",
        "                'min_days': temporal_df[duration_col].min(),\n",
        "                'max_days': temporal_df[duration_col].max(),\n",
        "                'mean_days': temporal_df[duration_col].mean(),\n",
        "                'median_days': temporal_df[duration_col].median()\n",
        "            }\n",
        "\n",
        "        return report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZ9x09Gfp0aC",
        "outputId": "94333c67-b472-478f-d9fa-f10ad95c963b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing temporal column: time\n",
            "\n",
            "Temporal extraction results:\n",
            "Successfully extracted duration: 6388\n",
            "Temporal types: {'unspecified': 3554, 'absolute_date': 2836, 'post_event': 2806, 'past_reference': 2754, 'range_reference': 654, 'duration_reference': 261, 'onset_reference': 191}\n",
            "Loading en_ner_bionlp13cg_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 35864 texts in 120 batches...\n",
            "Using model: en_ner_bionlp13cg_md for column: combined_text\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   1%|          | 1/120 [00:03<06:41,  3.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   9%|▉         | 11/120 [00:22<03:26,  1.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 3000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  18%|█▊        | 21/120 [00:40<03:04,  1.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 6000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  26%|██▌       | 31/120 [00:58<02:50,  1.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 9000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  34%|███▍      | 41/120 [01:16<02:31,  1.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 12000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  42%|████▎     | 51/120 [01:34<02:20,  2.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  51%|█████     | 61/120 [01:55<02:13,  2.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 18000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  58%|█████▊    | 70/120 [02:12<01:36,  1.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 21000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  68%|██████▊   | 81/120 [02:36<01:23,  2.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 24000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  76%|███████▌  | 91/120 [02:54<00:58,  2.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 27000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  84%|████████▍ | 101/120 [03:13<00:40,  2.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 30000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  92%|█████████▎| 111/120 [03:32<00:18,  2.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 33000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 120/120 [03:49<00:00,  1.91s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3452 entities appearing >= 5 times\n",
            "\n",
            "=== Entity Types Found ===\n",
            "{'MULTI_TISSUE_STRUCTURE': 32237, 'CANCER': 17003, 'TISSUE': 16665, 'ORGAN': 14854, 'PATHOLOGICAL_FORMATION': 14321, 'ORGANISM_SUBDIVISION': 4084, 'GENE_OR_GENE_PRODUCT': 3097, 'CELL': 2784, 'SIMPLE_CHEMICAL': 2742, 'ORGANISM': 2378, 'IMMATERIAL_ANATOMICAL_ENTITY': 1800, 'CELLULAR_COMPONENT': 1777, 'ORGANISM_SUBSTANCE': 1306, 'AMINO_ACID': 111, 'ANATOMICAL_SYSTEM': 48, 'DEVELOPING_ANATOMICAL_STRUCTURE': 1}\n",
            "\n",
            "=== CUSTOM ANATOMY & PROCEDURE EXTRACTION ===\n",
            "\n",
            "Custom extraction found:\n",
            "label\n",
            "PROCEDURE     24770\n",
            "ANATOMY       20351\n",
            "LATERALITY    19618\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== COMBINED Entity Distribution ===\n",
            "label\n",
            "MULTI_TISSUE_STRUCTURE             32237\n",
            "PROCEDURE                          24770\n",
            "ANATOMY                            20351\n",
            "LATERALITY                         19618\n",
            "CANCER                             17003\n",
            "TISSUE                             16665\n",
            "ORGAN                              14854\n",
            "PATHOLOGICAL_FORMATION             14321\n",
            "ORGANISM_SUBDIVISION                4084\n",
            "GENE_OR_GENE_PRODUCT                3097\n",
            "CELL                                2784\n",
            "SIMPLE_CHEMICAL                     2742\n",
            "ORGANISM                            2378\n",
            "IMMATERIAL_ANATOMICAL_ENTITY        1800\n",
            "CELLULAR_COMPONENT                  1777\n",
            "ORGANISM_SUBSTANCE                  1306\n",
            "AMINO_ACID                           111\n",
            "ANATOMICAL_SYSTEM                     48\n",
            "DEVELOPING_ANATOMICAL_STRUCTURE        1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Anatomical Entities ===\n",
            "text\n",
            "artery      3347\n",
            "bone        1868\n",
            "vein        1316\n",
            "nerve       1267\n",
            "liver       1058\n",
            "knee         933\n",
            "muscle       890\n",
            "lung         860\n",
            "hip          827\n",
            "kidney       805\n",
            "joint        700\n",
            "cervical     654\n",
            "vascular     602\n",
            "tendon       563\n",
            "femur        459\n",
            "heart        443\n",
            "ligament     370\n",
            "tibia        276\n",
            "lumbar       261\n",
            "veins        251\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Anatomy by Category ===\n",
            "category\n",
            "vessel    5753\n",
            "organ     3474\n",
            "bone      2799\n",
            "muscle    2167\n",
            "nerve     1505\n",
            "knee      1494\n",
            "spine     1380\n",
            "hip       1015\n",
            "joint      764\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Surgical Procedures ===\n",
            "text\n",
            "resection         5026\n",
            "excision          3459\n",
            "removal           3193\n",
            "repair            1755\n",
            "biopsy            1636\n",
            "graft             1628\n",
            "reconstruction    1309\n",
            "fixation          1250\n",
            "replacement        957\n",
            "implantation       608\n",
            "exploration        577\n",
            "implant            498\n",
            "decompression      407\n",
            "transplant         387\n",
            "arthroplasty       334\n",
            "osteotomy          331\n",
            "fusion             321\n",
            "diagnostic         285\n",
            "implants           183\n",
            "release            176\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Procedures by Category ===\n",
            "category\n",
            "removal          11789\n",
            "repair            4345\n",
            "transplant        2789\n",
            "diagnostic        2502\n",
            "replacement       2010\n",
            "fusion             716\n",
            "decompression      619\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Testing surgical labeling functions:\n",
            "\n",
            "Row 0: nan...\n",
            "\n",
            "Row 1: Total Hip Arthroplasty (THA)...\n",
            "  lf_hip_surgery: HIP_SURGERY\n",
            "\n",
            "Row 2: Total Hip Arthroplasty (THA)...\n",
            "  lf_hip_surgery: HIP_SURGERY\n",
            "\n",
            "Row 3: Left elbow arthrodesis...\n",
            "  lf_emergency_procedure: EMERGENCY_SURGERY\n",
            "\n",
            "Row 4: Repair of nonunion and conversion of elbow arthrod...\n",
            "  lf_fracture_surgery: FRACTURE_SURGERY\n",
            "\n",
            "=== Extracting Surgical Relations ===\n",
            "Found 10712 surgical relations\n",
            "\n",
            "Sample relations:\n",
            "  resection -> lung (row 209)\n",
            "  resection -> lung (row 209)\n",
            "  fixation -> femur (row 239)\n",
            "  fixation -> bone (row 284)\n",
            "  Removal -> Cervical (row 422)\n",
            "  arthroplasty -> hip (row 529)\n",
            "  arthroplasty -> hip (row 529)\n",
            "  arthroplasty -> hip (row 529)\n",
            "  arthroplasty -> hip (row 529)\n",
            "  fixation -> Tibia (row 611)\n",
            "\n",
            "Saved: surgery_entities_comprehensive.csv\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Apply temporal standardization\n",
        "    temporal_standardizer = TemporalStandardizer()\n",
        "    df_surgery_processed, temporal_report = temporal_standardizer.standardize_temporal_column(\n",
        "        df_surgery, \n",
        "        'time'\n",
        "    )\n",
        "   \n",
        "    print(f\"\\nTemporal extraction results:\")\n",
        "    print(f\"Successfully extracted duration: {temporal_report['extracted_durations']}\")\n",
        "    print(f\"Temporal types: {temporal_report['temporal_types']}\")\n",
        "\n",
        "    # Combine surgery text columns\n",
        "    # (use str() to be tolerant to NaNs)\n",
        "    df_surgery['combined_text'] = df_surgery.apply(\n",
        "        lambda row: f\"{str(row.get('reason',''))} {str(row.get('Type',''))} {str(row.get('details',''))} {str(row.get('outcome',''))}\",\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Copy combined_text to processed dataframe (keeps alignment with df_surgery by index)\n",
        "    df_surgery_processed['combined_text'] = df_surgery['combined_text']\n",
        "\n",
        "    # Add temporal features to combined text\n",
        "    df_surgery_processed['combined_text_enriched'] = df_surgery_processed.apply(\n",
        "        lambda row: f\"{row['combined_text']} {'lasting ' + str(row.get('time_duration_days', '')) + ' days' if pd.notna(row.get('time_duration_days')) else ''}\",\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # NER over the (non-enriched) combined_text in df_surgery\n",
        "    df_surgery_entities, surgery_summary, surgery_rules = run_medical_ner_extraction(\n",
        "        df_surgery,\n",
        "        text_column='combined_text',\n",
        "        model_name='en_ner_bionlp13cg_md', \n",
        "        batch_size=300,\n",
        "        id_column='idx'\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== Entity Types Found ===\")\n",
        "    print(surgery_summary['entity_types'])\n",
        "\n",
        "    # ========== CUSTOM ANATOMY & PROCEDURE EXTRACTION (with correct row_idx) ==========\n",
        "    print(\"\\n=== CUSTOM ANATOMY & PROCEDURE EXTRACTION ===\")\n",
        "\n",
        "    def extract_surgical_entities_custom(df_surgery):\n",
        "        \"\"\"\n",
        "        Custom extraction for anatomy and procedures not caught by the model.\n",
        "        Uses 'idx' column for row identity when available; falls back to df.index otherwise.\n",
        "        Adds 'row_idx' to every extracted entity.\n",
        "        Uses regex word-boundary matching; allows simple plurals (e.g., hips, arteries).\n",
        "        \"\"\"\n",
        "\n",
        "        custom_entities = []\n",
        "\n",
        "        # Anatomy vocab by category\n",
        "        anatomy_patterns = {\n",
        "            'hip':        ['hip', 'acetabul', 'femoral head'],\n",
        "            'knee':       ['knee', 'meniscus', 'patella', 'tibia'],\n",
        "            'bone':       ['bone', 'femur', 'humerus', 'radius', 'ulna'],\n",
        "            'joint':      ['joint', 'articulation'],\n",
        "            'spine':      ['spine', 'vertebra', 'disc', 'lumbar', 'cervical'],\n",
        "            'organ':      ['kidney', 'liver', 'heart', 'lung', 'spleen'],\n",
        "            'vessel':     ['artery', 'vein', 'vessel', 'vascular'],\n",
        "            'nerve':      ['nerve', 'neural', 'plexus'],\n",
        "            'muscle':     ['muscle', 'tendon', 'ligament']\n",
        "        }\n",
        "\n",
        "        # Procedure vocab by category\n",
        "        procedure_patterns = {\n",
        "            'replacement':   ['arthroplasty', 'replacement', 'implant'],\n",
        "            'repair':        ['repair', 'reconstruction', 'fixation'],\n",
        "            'removal':       ['removal', 'excision', 'resection', 'ectomy'],\n",
        "            'fusion':        ['fusion', 'arthrodesis', 'osteotomy'],\n",
        "            'diagnostic':    ['biopsy', 'exploration', 'diagnostic'],\n",
        "            'decompression': ['decompression', 'release', 'neurolysis'],\n",
        "            'transplant':    ['transplant', 'graft', 'implantation']\n",
        "        }\n",
        "\n",
        "        laterality_terms = ['left', 'right', 'bilateral', 'unilateral']\n",
        "\n",
        "        for df_idx, row in df_surgery.iterrows():\n",
        "            # ---- choose the correct row id from 'idx' with fallback to the DataFrame index\n",
        "            if 'idx' in row and pd.notna(row['idx']):\n",
        "                row_id = row['idx']\n",
        "            else:\n",
        "                row_id = df_idx\n",
        "\n",
        "            # ---- text (keep original for offsets; search on lowercased copy)\n",
        "            original_text = str(row.get('combined_text', ''))\n",
        "            text = original_text.lower()\n",
        "\n",
        "            # ---- Anatomy extraction (regex with word boundaries; allow simple plural 's')\n",
        "            for category, terms in anatomy_patterns.items():\n",
        "                for term in terms:\n",
        "                    # allow plural 's' for basic nouns (skip stems like 'acetabul' where 's' doesn't apply cleanly)\n",
        "                    plural_opt = 's?' if term.isalpha() and not term.endswith(('al','el','ul')) else ''\n",
        "                    pattern = r'\\b' + re.escape(term.lower()) + plural_opt + r'\\b'\n",
        "                    for m in re.finditer(pattern, text):\n",
        "                        custom_entities.append({\n",
        "                            'text': original_text[m.start():m.end()],\n",
        "                            'label': 'ANATOMY',\n",
        "                            'category': category,\n",
        "                            'start': m.start(),\n",
        "                            'end': m.end(),\n",
        "                            'original_text': original_text,\n",
        "                            'source': 'custom_extraction',\n",
        "                            'row_idx': row_id,   # <-- correct ID retained\n",
        "                        })\n",
        "\n",
        "            # ---- Procedure extraction (also boundary-based)\n",
        "            for category, terms in procedure_patterns.items():\n",
        "                for term in terms:\n",
        "                    plural_opt = 's?' if term.isalpha() else ''\n",
        "                    pattern = r'\\b' + re.escape(term.lower()) + plural_opt + r'\\b'\n",
        "                    for m in re.finditer(pattern, text):\n",
        "                        custom_entities.append({\n",
        "                            'text': original_text[m.start():m.end()],\n",
        "                            'label': 'PROCEDURE',\n",
        "                            'category': category,\n",
        "                            'start': m.start(),\n",
        "                            'end': m.end(),\n",
        "                            'original_text': original_text,\n",
        "                            'source': 'custom_extraction',\n",
        "                            'row_idx': row_id,   # <-- correct ID retained\n",
        "                        })\n",
        "\n",
        "            # ---- Laterality extraction\n",
        "            for lat in laterality_terms:\n",
        "                pattern = r'\\b' + re.escape(lat) + r'\\b'\n",
        "                for m in re.finditer(pattern, text):\n",
        "                    custom_entities.append({\n",
        "                        'text': original_text[m.start():m.end()],\n",
        "                        'label': 'LATERALITY',\n",
        "                        'category': 'laterality',\n",
        "                        'start': m.start(),\n",
        "                        'end': m.end(),\n",
        "                        'original_text': original_text,\n",
        "                        'source': 'custom_extraction',\n",
        "                        'row_idx': row_id,   # <-- correct ID retained\n",
        "                    })\n",
        "\n",
        "        return pd.DataFrame(custom_entities)\n",
        "\n",
        "    # Extract custom entities\n",
        "    df_custom_entities = extract_surgical_entities_custom(df_surgery)\n",
        "\n",
        "    print(f\"\\nCustom extraction found:\")\n",
        "    if not df_custom_entities.empty and 'label' in df_custom_entities.columns:\n",
        "        print(df_custom_entities['label'].value_counts())\n",
        "    else:\n",
        "        print(\"No custom entities found.\")\n",
        "\n",
        "    # Combine model entities and custom entities\n",
        "    # (keep row_idx/category when present for traceability)\n",
        "    df_all_surgery_entities = pd.concat(\n",
        "        [df_surgery_entities, df_custom_entities],\n",
        "        ignore_index=True,\n",
        "        sort=False\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== COMBINED Entity Distribution ===\")\n",
        "    if not df_all_surgery_entities.empty and 'label' in df_all_surgery_entities.columns:\n",
        "        print(df_all_surgery_entities['label'].value_counts())\n",
        "    else:\n",
        "        print(\"No combined entities to show.\")\n",
        "\n",
        "    # Analyze anatomy entities\n",
        "    anatomy_entities = df_all_surgery_entities[df_all_surgery_entities['label'] == 'ANATOMY'] if not df_all_surgery_entities.empty else pd.DataFrame()\n",
        "    if not anatomy_entities.empty:\n",
        "        print(f\"\\n=== Top Anatomical Entities ===\")\n",
        "        print(anatomy_entities['text'].str.lower().value_counts().head(20))\n",
        "\n",
        "        if 'category' in anatomy_entities.columns:\n",
        "            print(f\"\\n=== Anatomy by Category ===\")\n",
        "            print(anatomy_entities['category'].value_counts())\n",
        "\n",
        "    # Analyze procedure entities\n",
        "    procedure_entities = df_all_surgery_entities[df_all_surgery_entities['label'] == 'PROCEDURE'] if not df_all_surgery_entities.empty else pd.DataFrame()\n",
        "    if not procedure_entities.empty:\n",
        "        print(f\"\\n=== Top Surgical Procedures ===\")\n",
        "        print(procedure_entities['text'].str.lower().value_counts().head(20))\n",
        "\n",
        "        if 'category' in procedure_entities.columns:\n",
        "            print(f\"\\n=== Procedures by Category ===\")\n",
        "            print(procedure_entities['category'].value_counts())\n",
        "\n",
        "    # ========== Labeling functions (unchanged logic) ==========\n",
        "    def create_surgical_labeling_functions():\n",
        "        \"\"\"Create labeling functions specific to surgical data\"\"\"\n",
        "\n",
        "        def lf_hip_surgery(row):\n",
        "            text = str(row.get('combined_text','')).lower()\n",
        "            if 'hip' in text and any(proc in text for proc in ['arthroplasty', 'replacement', 'repair']):\n",
        "                return 'HIP_SURGERY'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_knee_surgery(row):\n",
        "            text = str(row.get('combined_text','')).lower()\n",
        "            if 'knee' in text and any(proc in text for proc in ['arthroplasty', 'replacement', 'arthroscopy']):\n",
        "                return 'KNEE_SURGERY'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_fracture_surgery(row):\n",
        "            text = str(row.get('combined_text','')).lower()\n",
        "            if 'fracture' in text and any(proc in text for proc in ['fixation', 'repair', 'reduction']):\n",
        "                return 'FRACTURE_SURGERY'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_bilateral_procedure(row):\n",
        "            text = str(row.get('combined_text','')).lower()\n",
        "            if 'bilateral' in text:\n",
        "                return 'BILATERAL_PROCEDURE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_minimally_invasive(row):\n",
        "            text = str(row.get('combined_text','')).lower()\n",
        "            if any(term in text for term in ['arthroscopic', 'endoscopic', 'laparoscopic', 'minimally invasive']):\n",
        "                return 'MINIMALLY_INVASIVE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_emergency_procedure(row):\n",
        "            reason = str(row.get('reason', '')).lower()\n",
        "            if any(term in reason for term in ['emergency', 'urgent', 'acute', 'trauma']):\n",
        "                return 'EMERGENCY_SURGERY'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        return [lf_hip_surgery, lf_knee_surgery, lf_fracture_surgery,\n",
        "                lf_bilateral_procedure, lf_minimally_invasive, lf_emergency_procedure]\n",
        "\n",
        "    # Test labeling functions\n",
        "    surgical_lfs = create_surgical_labeling_functions()\n",
        "\n",
        "    print(\"\\nTesting surgical labeling functions:\")\n",
        "    for i in range(min(5, len(df_surgery))):\n",
        "        row = df_surgery.iloc[i]\n",
        "        print(f\"\\nRow {i}: {str(row.get('Type',''))[:50]}...\")\n",
        "        for lf in surgical_lfs:\n",
        "            result = lf(row)\n",
        "            if result != 'ABSTAIN':\n",
        "                print(f\"  {lf.__name__}: {result}\")\n",
        "\n",
        "    # ========== Extract relations (now per row_idx to avoid cross-row mixing) ==========\n",
        "    print(\"\\n=== Extracting Surgical Relations ===\")\n",
        "\n",
        "    def extract_surgical_relations(df_entities):\n",
        "        \"\"\"\n",
        "        Extract relations between anatomy and procedures within the same row (row_idx).\n",
        "        Uses character proximity (< 50 chars) heuristic.\n",
        "        \"\"\"\n",
        "        relations = []\n",
        "        if df_entities.empty:\n",
        "            return relations\n",
        "\n",
        "        # Ensure row grouping key exists\n",
        "        group_key = 'row_idx' if 'row_idx' in df_entities.columns else 'original_text'\n",
        "\n",
        "        for key, group in df_entities.groupby(group_key):\n",
        "            if 'label' not in group.columns or 'start' not in group.columns:\n",
        "                continue\n",
        "\n",
        "            anatomy_ents = group[group['label'] == 'ANATOMY']\n",
        "            procedure_ents = group[group['label'] == 'PROCEDURE']\n",
        "            if anatomy_ents.empty or procedure_ents.empty:\n",
        "                continue\n",
        "\n",
        "            # Pick a representative text (for preview only)\n",
        "            sample_text = group['original_text'].iloc[0] if 'original_text' in group.columns else ''\n",
        "\n",
        "            for _, anat in anatomy_ents.iterrows():\n",
        "                for _, proc in procedure_ents.iterrows():\n",
        "                    try:\n",
        "                        if abs(int(anat['start']) - int(proc['start'])) < 50:\n",
        "                            relations.append({\n",
        "                                'type': 'PROCEDURE_ON_ANATOMY',\n",
        "                                'procedure': str(proc['text']),\n",
        "                                'anatomy': str(anat['text']),\n",
        "                                'row_idx': key if group_key == 'row_idx' else None,\n",
        "                                'text': sample_text[:120]\n",
        "                            })\n",
        "                    except Exception:\n",
        "                        # skip malformed rows without numeric offsets\n",
        "                        pass\n",
        "\n",
        "        return relations\n",
        "\n",
        "    surgical_relations = extract_surgical_relations(df_all_surgery_entities)\n",
        "\n",
        "    print(f\"Found {len(surgical_relations)} surgical relations\")\n",
        "    if surgical_relations:\n",
        "        print(\"\\nSample relations:\")\n",
        "        for rel in surgical_relations[:10]:\n",
        "            rid = f\" (row {rel['row_idx']})\" if rel.get('row_idx') is not None else ''\n",
        "            print(f\"  {rel['procedure']} -> {rel['anatomy']}{rid}\")\n",
        "\n",
        "    # Save results\n",
        "    df_all_surgery_entities.to_csv('surgery_entities_comprehensive.csv', index=False)\n",
        "    print(\"\\nSaved: surgery_entities_comprehensive.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "id": "uniu23sqp0SV",
        "outputId": "a61f1782-077f-4077-8e0b-882c30d3ce70"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>source_column</th>\n",
              "      <th>category</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>femoral head</td>\n",
              "      <td>PATHOLOGICAL_FORMATION</td>\n",
              "      <td>32</td>\n",
              "      <td>44</td>\n",
              "      <td>Idiopathic osteonecrosis of the femoral head T...</td>\n",
              "      <td>133948</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>left hip</td>\n",
              "      <td>PATHOLOGICAL_FORMATION</td>\n",
              "      <td>91</td>\n",
              "      <td>99</td>\n",
              "      <td>Idiopathic osteonecrosis of the femoral head T...</td>\n",
              "      <td>133948</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>joint Total</td>\n",
              "      <td>MULTI_TISSUE_STRUCTURE</td>\n",
              "      <td>46</td>\n",
              "      <td>57</td>\n",
              "      <td>Pain and limited ROM in the contralateral hip ...</td>\n",
              "      <td>133948</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Left elbow</td>\n",
              "      <td>TISSUE</td>\n",
              "      <td>24</td>\n",
              "      <td>34</td>\n",
              "      <td>Posttraumatic arthritis Left elbow arthrodesis...</td>\n",
              "      <td>80176</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ulnar shaft</td>\n",
              "      <td>MULTI_TISSUE_STRUCTURE</td>\n",
              "      <td>25</td>\n",
              "      <td>36</td>\n",
              "      <td>Hypertrophic nonunion of ulnar shaft fracture ...</td>\n",
              "      <td>80176</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179942</th>\n",
              "      <td>biopsy</td>\n",
              "      <td>PROCEDURE</td>\n",
              "      <td>24</td>\n",
              "      <td>30</td>\n",
              "      <td>Lung nodules Excisional biopsy nan Histopathol...</td>\n",
              "      <td>133320</td>\n",
              "      <td>NaN</td>\n",
              "      <td>diagnostic</td>\n",
              "      <td>custom_extraction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179943</th>\n",
              "      <td>Bone</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Bone metastasis of the right femur Cryoablatio...</td>\n",
              "      <td>133320</td>\n",
              "      <td>NaN</td>\n",
              "      <td>bone</td>\n",
              "      <td>custom_extraction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179944</th>\n",
              "      <td>femur</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>29</td>\n",
              "      <td>34</td>\n",
              "      <td>Bone metastasis of the right femur Cryoablatio...</td>\n",
              "      <td>133320</td>\n",
              "      <td>NaN</td>\n",
              "      <td>bone</td>\n",
              "      <td>custom_extraction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179945</th>\n",
              "      <td>right</td>\n",
              "      <td>LATERALITY</td>\n",
              "      <td>23</td>\n",
              "      <td>28</td>\n",
              "      <td>Bone metastasis of the right femur Cryoablatio...</td>\n",
              "      <td>133320</td>\n",
              "      <td>NaN</td>\n",
              "      <td>laterality</td>\n",
              "      <td>custom_extraction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179946</th>\n",
              "      <td>replacement</td>\n",
              "      <td>PROCEDURE</td>\n",
              "      <td>85</td>\n",
              "      <td>96</td>\n",
              "      <td>Acute severe aortic insufficiency from endocar...</td>\n",
              "      <td>97973</td>\n",
              "      <td>NaN</td>\n",
              "      <td>replacement</td>\n",
              "      <td>custom_extraction</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>179947 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                text                   label  start  end  \\\n",
              "0       femoral head  PATHOLOGICAL_FORMATION     32   44   \n",
              "1           left hip  PATHOLOGICAL_FORMATION     91   99   \n",
              "2        joint Total  MULTI_TISSUE_STRUCTURE     46   57   \n",
              "3         Left elbow                  TISSUE     24   34   \n",
              "4        ulnar shaft  MULTI_TISSUE_STRUCTURE     25   36   \n",
              "...              ...                     ...    ...  ...   \n",
              "179942        biopsy               PROCEDURE     24   30   \n",
              "179943          Bone                 ANATOMY      0    4   \n",
              "179944         femur                 ANATOMY     29   34   \n",
              "179945         right              LATERALITY     23   28   \n",
              "179946   replacement               PROCEDURE     85   96   \n",
              "\n",
              "                                            original_text  row_idx  \\\n",
              "0       Idiopathic osteonecrosis of the femoral head T...   133948   \n",
              "1       Idiopathic osteonecrosis of the femoral head T...   133948   \n",
              "2       Pain and limited ROM in the contralateral hip ...   133948   \n",
              "3       Posttraumatic arthritis Left elbow arthrodesis...    80176   \n",
              "4       Hypertrophic nonunion of ulnar shaft fracture ...    80176   \n",
              "...                                                   ...      ...   \n",
              "179942  Lung nodules Excisional biopsy nan Histopathol...   133320   \n",
              "179943  Bone metastasis of the right femur Cryoablatio...   133320   \n",
              "179944  Bone metastasis of the right femur Cryoablatio...   133320   \n",
              "179945  Bone metastasis of the right femur Cryoablatio...   133320   \n",
              "179946  Acute severe aortic insufficiency from endocar...    97973   \n",
              "\n",
              "        source_column     category             source  \n",
              "0       combined_text          NaN                NaN  \n",
              "1       combined_text          NaN                NaN  \n",
              "2       combined_text          NaN                NaN  \n",
              "3       combined_text          NaN                NaN  \n",
              "4       combined_text          NaN                NaN  \n",
              "...               ...          ...                ...  \n",
              "179942            NaN   diagnostic  custom_extraction  \n",
              "179943            NaN         bone  custom_extraction  \n",
              "179944            NaN         bone  custom_extraction  \n",
              "179945            NaN   laterality  custom_extraction  \n",
              "179946            NaN  replacement  custom_extraction  \n",
              "\n",
              "[179947 rows x 9 columns]"
            ]
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_all_surgery_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting Symptoms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 963
        },
        "id": "gfbXYJpJ7Rqj",
        "outputId": "086917d6-7022-4c5b-a9ae-7c754bbd349a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>has_symptom</th>\n",
              "      <th>name of symptom</th>\n",
              "      <th>intensity of symptom</th>\n",
              "      <th>location</th>\n",
              "      <th>time</th>\n",
              "      <th>temporalisation</th>\n",
              "      <th>behaviours affecting the symptom</th>\n",
              "      <th>details</th>\n",
              "      <th>duration_days</th>\n",
              "      <th>temporal_pattern</th>\n",
              "      <th>combined_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155216</td>\n",
              "      <td>True</td>\n",
              "      <td>Discomfort in the neck and lower back, restric...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Neck and lower back</td>\n",
              "      <td>Past four months</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Standing up from a sitting position</td>\n",
              "      <td>Head turned to the right and upwards due to su...</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>Discomfort in the neck and lower back, restric...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>133948</td>\n",
              "      <td>True</td>\n",
              "      <td>Pain</td>\n",
              "      <td>Severe</td>\n",
              "      <td>Left hip joint</td>\n",
              "      <td>Persisting for two months</td>\n",
              "      <td>Increased over the following three weeks</td>\n",
              "      <td>Aggravated by hip joint flexion or rotation</td>\n",
              "      <td>Also complained of pain and limited ROM in the...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Increased over the following three weeks</td>\n",
              "      <td>Pain with Severe intensity located in Left hip...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133948</td>\n",
              "      <td>True</td>\n",
              "      <td>Restricted range of motion</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Left hip joint</td>\n",
              "      <td>Persisting for two months</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>Restricted range of motion with nan intensity ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>133948</td>\n",
              "      <td>True</td>\n",
              "      <td>Gait disturbance</td>\n",
              "      <td>Severe</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Secondary to hip pain</td>\n",
              "      <td>Continued for two months and increased over th...</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>Gait disturbance with Severe intensity located...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>133948</td>\n",
              "      <td>True</td>\n",
              "      <td>Moderate moon face</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Face</td>\n",
              "      <td>At the time of the second surgery</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Initially overlooked as weight gain</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>Moderate moon face with Moderate intensity loc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54939</th>\n",
              "      <td>137017</td>\n",
              "      <td>True</td>\n",
              "      <td>Left-sided weakness</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Left side</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>Left-sided weakness with nan intensity located...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54940</th>\n",
              "      <td>98004</td>\n",
              "      <td>True</td>\n",
              "      <td>Chest pain</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Chest</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Cardiac sounding</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>Chest pain with nan intensity located in Chest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54941</th>\n",
              "      <td>133320</td>\n",
              "      <td>True</td>\n",
              "      <td>Mass in right thigh</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Lateral side of the right thigh</td>\n",
              "      <td>Noticed four years prior to presentation</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Diameter of 4 cm, no adhesion with skin and no...</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>Mass in right thigh with nan intensity located...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54942</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Crushing substernal chest pressure</td>\n",
              "      <td>Acute onset</td>\n",
              "      <td>Substernal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Following 1-week-long febrile illness</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Accompanied by dyspnea and profuse sweating</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Following 1-week-long febrile illness</td>\n",
              "      <td>Crushing substernal chest pressure with Acute ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54943</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Dyspnea</td>\n",
              "      <td>Rapidly developed</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Patient developed dyspnea, tachypnea, and tach...</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>Dyspnea with Rapidly developed intensity locat...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>54944 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          idx  has_symptom                                    name of symptom  \\\n",
              "0      155216         True  Discomfort in the neck and lower back, restric...   \n",
              "1      133948         True                                               Pain   \n",
              "2      133948         True                         Restricted range of motion   \n",
              "3      133948         True                                   Gait disturbance   \n",
              "4      133948         True                                 Moderate moon face   \n",
              "...       ...          ...                                                ...   \n",
              "54939  137017         True                                Left-sided weakness   \n",
              "54940   98004         True                                         Chest pain   \n",
              "54941  133320         True                                Mass in right thigh   \n",
              "54942   97973         True                 Crushing substernal chest pressure   \n",
              "54943   97973         True                                            Dyspnea   \n",
              "\n",
              "      intensity of symptom                         location  \\\n",
              "0                      NaN              Neck and lower back   \n",
              "1                   Severe                   Left hip joint   \n",
              "2                      NaN                   Left hip joint   \n",
              "3                   Severe                              NaN   \n",
              "4                 Moderate                             Face   \n",
              "...                    ...                              ...   \n",
              "54939                  NaN                        Left side   \n",
              "54940                  NaN                            Chest   \n",
              "54941                  NaN  Lateral side of the right thigh   \n",
              "54942          Acute onset                       Substernal   \n",
              "54943    Rapidly developed                              NaN   \n",
              "\n",
              "                                           time  \\\n",
              "0                              Past four months   \n",
              "1                     Persisting for two months   \n",
              "2                     Persisting for two months   \n",
              "3                                           NaN   \n",
              "4             At the time of the second surgery   \n",
              "...                                         ...   \n",
              "54939                                       NaN   \n",
              "54940                                       NaN   \n",
              "54941  Noticed four years prior to presentation   \n",
              "54942                                       NaN   \n",
              "54943                                       NaN   \n",
              "\n",
              "                                temporalisation  \\\n",
              "0                                           NaN   \n",
              "1      Increased over the following three weeks   \n",
              "2                                           NaN   \n",
              "3                                           NaN   \n",
              "4                                           NaN   \n",
              "...                                         ...   \n",
              "54939                                       NaN   \n",
              "54940                                       NaN   \n",
              "54941                                       NaN   \n",
              "54942     Following 1-week-long febrile illness   \n",
              "54943                                       NaN   \n",
              "\n",
              "                  behaviours affecting the symptom  \\\n",
              "0              Standing up from a sitting position   \n",
              "1      Aggravated by hip joint flexion or rotation   \n",
              "2                                              NaN   \n",
              "3                            Secondary to hip pain   \n",
              "4                                              NaN   \n",
              "...                                            ...   \n",
              "54939                                          NaN   \n",
              "54940                                          NaN   \n",
              "54941                                          NaN   \n",
              "54942                                          NaN   \n",
              "54943                                          NaN   \n",
              "\n",
              "                                                 details  duration_days  \\\n",
              "0      Head turned to the right and upwards due to su...            NaN   \n",
              "1      Also complained of pain and limited ROM in the...            NaN   \n",
              "2                                                    NaN            NaN   \n",
              "3      Continued for two months and increased over th...            NaN   \n",
              "4                    Initially overlooked as weight gain            NaN   \n",
              "...                                                  ...            ...   \n",
              "54939                                                NaN            NaN   \n",
              "54940                                   Cardiac sounding            NaN   \n",
              "54941  Diameter of 4 cm, no adhesion with skin and no...            NaN   \n",
              "54942        Accompanied by dyspnea and profuse sweating            NaN   \n",
              "54943  Patient developed dyspnea, tachypnea, and tach...            NaN   \n",
              "\n",
              "                               temporal_pattern  \\\n",
              "0                                                 \n",
              "1      Increased over the following three weeks   \n",
              "2                                                 \n",
              "3                                                 \n",
              "4                                                 \n",
              "...                                         ...   \n",
              "54939                                             \n",
              "54940                                             \n",
              "54941                                             \n",
              "54942     Following 1-week-long febrile illness   \n",
              "54943                                             \n",
              "\n",
              "                                           combined_text  \n",
              "0      Discomfort in the neck and lower back, restric...  \n",
              "1      Pain with Severe intensity located in Left hip...  \n",
              "2      Restricted range of motion with nan intensity ...  \n",
              "3      Gait disturbance with Severe intensity located...  \n",
              "4      Moderate moon face with Moderate intensity loc...  \n",
              "...                                                  ...  \n",
              "54939  Left-sided weakness with nan intensity located...  \n",
              "54940  Chest pain with nan intensity located in Chest...  \n",
              "54941  Mass in right thigh with nan intensity located...  \n",
              "54942  Crushing substernal chest pressure with Acute ...  \n",
              "54943  Dyspnea with Rapidly developed intensity locat...  \n",
              "\n",
              "[54944 rows x 12 columns]"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_symptoms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m5jzEN8EPnX",
        "outputId": "3a06cf64-4e26-4781-93d0-c3c608e923f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing temporal column: time\n",
            "\n",
            "Temporal extraction results:\n",
            "Successfully extracted duration: 18893\n",
            "Temporal types: {'unspecified': 13201, 'post_event': 6146, 'range_reference': 5023, 'past_reference': 4704, 'duration_reference': 4063, 'onset_reference': 2904, 'absolute_date': 1164}\n",
            "Loading en_ner_bc5cdr_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 54944 texts in 184 batches...\n",
            "Using model: en_ner_bc5cdr_md for column: combined_text\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   1%|          | 1/184 [00:01<05:38,  1.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   6%|▌         | 11/184 [00:20<05:04,  1.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 3000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  11%|█▏        | 21/184 [00:36<04:31,  1.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 6000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  17%|█▋        | 31/184 [00:58<06:17,  2.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 9000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  22%|██▏       | 41/184 [01:18<05:03,  2.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 12000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  28%|██▊       | 51/184 [01:37<04:28,  2.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  33%|███▎      | 61/184 [01:58<04:20,  2.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 18000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  39%|███▊      | 71/184 [02:17<03:54,  2.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 21000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  44%|████▍     | 81/184 [02:36<03:28,  2.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 24000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  49%|████▉     | 91/184 [02:56<03:12,  2.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 27000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  55%|█████▍    | 101/184 [03:12<02:22,  1.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 30000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  60%|██████    | 111/184 [03:30<02:18,  1.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 33000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  66%|██████▌   | 121/184 [03:49<02:21,  2.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 36000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  71%|███████   | 131/184 [04:05<01:26,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 39000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  77%|███████▋  | 141/184 [04:20<01:17,  1.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 42000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  82%|████████▏ | 151/184 [04:37<01:00,  1.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 45000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  88%|████████▊ | 161/184 [04:54<00:42,  1.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 48000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  93%|█████████▎| 171/184 [05:11<00:23,  1.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 51000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  98%|█████████▊| 181/184 [05:32<00:06,  2.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 54000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 184/184 [05:36<00:00,  1.83s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1857 entities appearing >= 5 times\n",
            "\n",
            "=== BC5CDR Entity Types Found ===\n",
            "{'DISEASE': 84179, 'CHEMICAL': 2286}\n",
            "\n",
            "=== CUSTOM SYMPTOM ENTITY EXTRACTION ===\n",
            "\n",
            "Custom extraction found:\n",
            "label\n",
            "ANATOMY             67817\n",
            "SYMPTOM_TYPE        56789\n",
            "SYMPTOM             53580\n",
            "LATERALITY          31971\n",
            "TEMPORAL_PATTERN    14118\n",
            "SEVERITY             5306\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== COMBINED Entity Distribution ===\n",
            "label\n",
            "DISEASE             84179\n",
            "ANATOMY             67817\n",
            "SYMPTOM_TYPE        56789\n",
            "SYMPTOM             53580\n",
            "LATERALITY          31971\n",
            "TEMPORAL_PATTERN    14118\n",
            "SEVERITY             5306\n",
            "CHEMICAL             2286\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Symptoms ===\n",
            "text\n",
            "pain                    1796\n",
            "abdominal pain          1182\n",
            "swelling                1146\n",
            "fever                    825\n",
            "headache                 722\n",
            "chest pain               576\n",
            "vomiting                 575\n",
            "dyspnea                  519\n",
            "shortness of breath      501\n",
            "weight loss              459\n",
            "nausea                   399\n",
            "dysphagia                313\n",
            "fatigue                  307\n",
            "weakness                 291\n",
            "cough                    284\n",
            "pain and swelling        257\n",
            "back pain                257\n",
            "dizziness                225\n",
            "numbness                 224\n",
            "abdominal distension     207\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Symptom Locations ===\n",
            "text\n",
            "abdomen     4733\n",
            "chest       4489\n",
            "back        3187\n",
            "neck        2776\n",
            "leg         2034\n",
            "knee        1829\n",
            "face        1580\n",
            "hand        1244\n",
            "hip         1213\n",
            "head        1171\n",
            "shoulder    1075\n",
            "arm         1058\n",
            "joint        942\n",
            "thigh        930\n",
            "foot         915\n",
            "legs         828\n",
            "ankle        722\n",
            "throat       694\n",
            "left eye     617\n",
            "elbow        577\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Severity Distribution ===\n",
            "text\n",
            "severe         3508\n",
            "mild           1245\n",
            "significant     306\n",
            "moderate        196\n",
            "extreme          32\n",
            "minimal          19\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Creating Symptom-Specific Labeling Functions ===\n",
            "\n",
            "Testing symptom labeling functions:\n",
            "\n",
            "Row 0: Discomfort in the neck and lower back, restriction of body movements, inability to maintain an erect posture - Neck and lower back\n",
            "  lf_chronic_symptom: CHRONIC_SYMPTOM\n",
            "  lf_mobility_issue: MOBILITY_ISSUE\n",
            "\n",
            "Row 1: Pain - Left hip joint\n",
            "  lf_severe_pain: SEVERE_PAIN\n",
            "  lf_chronic_symptom: CHRONIC_SYMPTOM\n",
            "  lf_pain_with_location: HIP_PAIN\n",
            "\n",
            "Row 2: Restricted range of motion - Left hip joint\n",
            "  lf_chronic_symptom: CHRONIC_SYMPTOM\n",
            "\n",
            "Row 3: Gait disturbance - nan\n",
            "  lf_mobility_issue: MOBILITY_ISSUE\n",
            "\n",
            "Row 4: Moderate moon face - Face\n",
            "\n",
            "Row 5: Central obesity - Central body\n",
            "\n",
            "Row 6: Muscle mass reduction - Both the upper and lower limbs\n",
            "  lf_bilateral_symptom: BILATERAL_SYMPTOM\n",
            "\n",
            "Row 7: Pain - Left proximal forearm\n",
            "  lf_pain_with_location: LOCALIZED_PAIN\n",
            "\n",
            "Row 8: Pain - Medial aspect of the left knee, lateral aspect of the left knee, medial side of the right knee\n",
            "  lf_severe_pain: SEVERE_PAIN\n",
            "  lf_pain_with_location: KNEE_PAIN\n",
            "  lf_symptom_duration: CHRONIC_DURATION\n",
            "\n",
            "Row 9: Inability to walk - Legs\n",
            "  lf_chronic_symptom: CHRONIC_SYMPTOM\n",
            "  lf_neurological_symptom: NEUROLOGICAL\n",
            "  lf_progressive_symptom: PROGRESSIVE_SYMPTOM\n",
            "  lf_mobility_issue: MOBILITY_ISSUE\n",
            "  lf_symptom_duration: CHRONIC_DURATION\n",
            "\n",
            "=== Extracting Symptom Relations ===\n",
            "Found 73581 symptom relations\n",
            "\n",
            "Relation type distribution:\n",
            "type\n",
            "SYMPTOM_LOCATED_IN              33074\n",
            "SYMPTOM_HAS_SEVERITY            16909\n",
            "SYMPTOM_HAS_TEMPORAL_PATTERN    12813\n",
            "SYMPTOM_HAS_DURATION            10785\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sample relations:\n",
            "  Discomfort in the neck and lower back, restriction of body movements, inability to maintain an erect posture -> located in -> Neck and lower back (row 155216)\n",
            "  Pain -> located in -> Left hip joint (row 133948)\n",
            "  Pain -> has severity -> Severe (row 133948)\n",
            "  Restricted range of motion -> located in -> Left hip joint (row 133948)\n",
            "  Gait disturbance -> has severity -> Severe (row 133948)\n",
            "  Moderate moon face -> located in -> Face (row 133948)\n",
            "  Moderate moon face -> has severity -> Moderate (row 133948)\n",
            "  Central obesity -> located in -> Central body (row 133948)\n",
            "  Muscle mass reduction -> located in -> Both the upper and lower limbs (row 133948)\n",
            "\n",
            "\n",
            "Symptom entity extraction and labeling complete!\n",
            "Saved 316046 entities and 73581 relations.\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Apply temporal standardization\n",
        "    temporal_standardizer = TemporalStandardizer()\n",
        "    df_symptoms_processed, temporal_report = temporal_standardizer.standardize_temporal_column(\n",
        "        df_symptoms, \n",
        "        'time'\n",
        "    )\n",
        "   \n",
        "    print(f\"\\nTemporal extraction results:\")\n",
        "    print(f\"Successfully extracted duration: {temporal_report['extracted_durations']}\")\n",
        "    print(f\"Temporal types: {temporal_report['temporal_types']}\")\n",
        "\n",
        "    # Combine symptom information into comprehensive text (robust to NaNs)\n",
        "    df_symptoms['combined_text'] = df_symptoms.apply(\n",
        "        lambda row: f\"{str(row.get('name of symptom',''))} with {str(row.get('intensity of symptom',''))} \"\n",
        "                    f\"intensity located in {str(row.get('location',''))} lasting {str(row.get('time',''))} \"\n",
        "                    f\"{str(row.get('temporalisation',''))} {str(row.get('details',''))}\",\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Copy combined_text to processed dataframe (corrected to use df_symptoms)\n",
        "    df_symptoms_processed['combined_text'] = df_symptoms['combined_text']\n",
        "\n",
        "    # Add temporal features to combined text (uses time_duration_days if present)\n",
        "    df_symptoms_processed['combined_text_enriched'] = df_symptoms_processed.apply(\n",
        "        lambda row: f\"{row['combined_text']} \"\n",
        "                    f\"{'lasting ' + str(row.get('time_duration_days', '')) + ' days' if pd.notna(row.get('time_duration_days')) else ''}\",\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Run NER extraction with BC5CDR over combined_text\n",
        "    df_symptoms_entities, symptoms_summary, symptoms_rules = run_medical_ner_extraction(\n",
        "        df_symptoms,\n",
        "        text_column='combined_text',\n",
        "        model_name=\"en_ner_bc5cdr_md\",\n",
        "        batch_size=300,\n",
        "        id_column='idx'\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== BC5CDR Entity Types Found ===\")\n",
        "    print(symptoms_summary['entity_types'])\n",
        "\n",
        "    # ================= CUSTOM SYMPTOM ENTITY EXTRACTION (keeps correct row_idx) =================\n",
        "    print(\"\\n=== CUSTOM SYMPTOM ENTITY EXTRACTION ===\")\n",
        "\n",
        "    def extract_symptom_entities_custom(df_symptoms):\n",
        "        \"\"\"\n",
        "        Extract symptom-specific entities not caught by BC5CDR.\n",
        "        Uses 'idx' for row identity when available; falls back to df.index otherwise.\n",
        "        Adds 'row_idx' to every extracted entity.\n",
        "        Regex with word boundaries is used to avoid substring false positives.\n",
        "        \"\"\"\n",
        "        custom_entities = []\n",
        "\n",
        "        # Symptom type patterns\n",
        "        symptom_patterns = {\n",
        "            'pain':         ['pain', 'ache', 'soreness', 'tenderness', 'discomfort'],\n",
        "            'neurological': ['numbness', 'tingling', 'weakness', 'paralysis', 'tremor'],\n",
        "            'mobility':     ['inability to walk', 'gait disturbance', 'limited range of motion', 'stiffness'],\n",
        "            'swelling':     ['swelling', 'edema', 'inflammation', 'mass', 'lump'],\n",
        "            'sensory':      ['vision', 'hearing', 'taste', 'smell', 'sensation'],\n",
        "            'systemic':     ['fever', 'fatigue', 'malaise', 'weight loss', 'night sweats'],\n",
        "            'respiratory':  ['dyspnea', 'cough', 'wheezing', 'shortness of breath'],\n",
        "            'gi':           ['nausea', 'vomiting', 'diarrhea', 'constipation', 'abdominal'],\n",
        "            'skin':         ['rash', 'itching', 'lesion', 'discoloration', 'bruising']\n",
        "        }\n",
        "\n",
        "        # Anatomical location patterns\n",
        "        anatomy_patterns = {\n",
        "            'head_neck':      ['head', 'neck', 'scalp', 'face', 'throat', 'cervical'],\n",
        "            'upper_extremity': ['shoulder', 'arm', 'elbow', 'forearm', 'wrist', 'hand', 'finger'],\n",
        "            'lower_extremity': ['hip', 'thigh', 'knee', 'leg', 'ankle', 'foot', 'toe'],\n",
        "            'trunk':           ['chest', 'back', 'abdomen', 'pelvis', 'spine', 'lumbar'],\n",
        "            'joint':           ['joint', 'articulation'],\n",
        "            'internal':        ['heart', 'lung', 'liver', 'kidney', 'stomach']\n",
        "        }\n",
        "\n",
        "        # Severity/Intensity (column-driven)\n",
        "        severity_values = {'mild', 'moderate', 'severe', 'extreme', 'minimal', 'significant'}\n",
        "\n",
        "        # Temporal patterns\n",
        "        temporal_patterns = {\n",
        "            'acute':        ['acute', 'sudden', 'abrupt', 'rapid'],\n",
        "            'chronic':      ['chronic', 'persistent', 'ongoing', 'continuous'],\n",
        "            'intermittent': ['intermittent', 'episodic', 'recurrent', 'periodic'],\n",
        "            'progressive':  ['progressive', 'worsening', 'increasing', 'deteriorating']\n",
        "        }\n",
        "\n",
        "        laterality_terms = ['left', 'right', 'bilateral', 'both']\n",
        "\n",
        "        for df_index, row in df_symptoms.iterrows():\n",
        "            # ---- choose the correct row id from 'idx' with fallback to the DataFrame index\n",
        "            row_id = row['idx'] if ('idx' in row and pd.notna(row['idx'])) else df_index\n",
        "\n",
        "            original_text = str(row.get('combined_text', ''))\n",
        "            combined = original_text.lower()\n",
        "\n",
        "            # Columns (original + lower)\n",
        "            symptom_name_orig = str(row.get('name of symptom', ''))\n",
        "            symptom_name = symptom_name_orig.lower()\n",
        "            location_orig = str(row.get('location', ''))\n",
        "            location = location_orig.lower()\n",
        "            intensity_orig = str(row.get('intensity of symptom', ''))\n",
        "            intensity = intensity_orig.lower()\n",
        "            temporalisation_orig = str(row.get('temporalisation', ''))\n",
        "            temporalisation = temporalisation_orig.lower()\n",
        "\n",
        "            # ---- Primary SYMPTOM from name column (if present)\n",
        "            if pd.notna(row.get('name of symptom')) and symptom_name.strip() != '' and symptom_name != 'nan':\n",
        "                # try to find position in combined; if not found, set to 0\n",
        "                start = combined.find(symptom_name)\n",
        "                if start < 0:\n",
        "                    start = 0\n",
        "                end = start + len(symptom_name_orig)\n",
        "                end = min(end, len(original_text))\n",
        "                custom_entities.append({\n",
        "                    'text': symptom_name_orig,\n",
        "                    'label': 'SYMPTOM',\n",
        "                    'category': 'primary_symptom',\n",
        "                    'start': start,\n",
        "                    'end': end,\n",
        "                    'original_text': original_text,\n",
        "                    'source': 'symptom_name_column',\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "\n",
        "            # ---- Symptom types (regex boundary matches)\n",
        "            for category, terms in symptom_patterns.items():\n",
        "                for term in terms:\n",
        "                    pattern = r'\\b' + re.escape(term.lower()) + r'\\b'\n",
        "                    for m in re.finditer(pattern, combined):\n",
        "                        custom_entities.append({\n",
        "                            'text': original_text[m.start():m.end()],\n",
        "                            'label': 'SYMPTOM_TYPE',\n",
        "                            'category': category,\n",
        "                            'start': m.start(),\n",
        "                            'end': m.end(),\n",
        "                            'original_text': original_text,\n",
        "                            'source': 'pattern_matching',\n",
        "                            'row_idx': row_id\n",
        "                        })\n",
        "\n",
        "            # ---- Anatomical location from location column\n",
        "            if pd.notna(row.get('location')) and location.strip() != '' and location != 'nan':\n",
        "                start = combined.find(location)\n",
        "                if start >= 0:\n",
        "                    end = start + len(location)\n",
        "                    custom_entities.append({\n",
        "                        'text': location_orig,\n",
        "                        'label': 'ANATOMY',\n",
        "                        'category': 'symptom_location',\n",
        "                        'start': start,\n",
        "                        'end': end,\n",
        "                        'original_text': original_text,\n",
        "                        'source': 'location_column',\n",
        "                        'row_idx': row_id\n",
        "                    })\n",
        "\n",
        "            # ---- Additional anatomy from patterns\n",
        "            for category, terms in anatomy_patterns.items():\n",
        "                for term in terms:\n",
        "                    # allow simple plural 's' for nouns\n",
        "                    plural_opt = 's?' if term.isalpha() else ''\n",
        "                    pattern = r'\\b' + re.escape(term.lower()) + plural_opt + r'\\b'\n",
        "                    for m in re.finditer(pattern, combined):\n",
        "                        custom_entities.append({\n",
        "                            'text': original_text[m.start():m.end()],\n",
        "                            'label': 'ANATOMY',\n",
        "                            'category': category,\n",
        "                            'start': m.start(),\n",
        "                            'end': m.end(),\n",
        "                            'original_text': original_text,\n",
        "                            'source': 'pattern_matching',\n",
        "                            'row_idx': row_id\n",
        "                        })\n",
        "\n",
        "            # ---- Severity from intensity column (exact value match)\n",
        "            if pd.notna(row.get('intensity of symptom')) and intensity in severity_values:\n",
        "                start = combined.find(intensity)\n",
        "                if start >= 0:\n",
        "                    custom_entities.append({\n",
        "                        'text': intensity_orig,\n",
        "                        'label': 'SEVERITY',\n",
        "                        'category': 'intensity',\n",
        "                        'start': start,\n",
        "                        'end': start + len(intensity_orig),\n",
        "                        'original_text': original_text,\n",
        "                        'source': 'intensity_column',\n",
        "                        'row_idx': row_id\n",
        "                    })\n",
        "\n",
        "            # ---- Temporal patterns (look in temporalisation column and combined text)\n",
        "            for category, terms in temporal_patterns.items():\n",
        "                for term in terms:\n",
        "                    found = False\n",
        "                    # search in combined first (to get offsets)\n",
        "                    m = re.search(r'\\b' + re.escape(term) + r'\\b', combined)\n",
        "                    if m:\n",
        "                        custom_entities.append({\n",
        "                            'text': original_text[m.start():m.end()],\n",
        "                            'label': 'TEMPORAL_PATTERN',\n",
        "                            'category': category,\n",
        "                            'start': m.start(),\n",
        "                            'end': m.end(),\n",
        "                            'original_text': original_text,\n",
        "                            'source': 'temporal_extraction',\n",
        "                            'row_idx': row_id\n",
        "                        })\n",
        "                        found = True\n",
        "                    # if not found in combined but present in temporalisation text, add without exact offset\n",
        "                    if not found and term in temporalisation:\n",
        "                        custom_entities.append({\n",
        "                            'text': term,\n",
        "                            'label': 'TEMPORAL_PATTERN',\n",
        "                            'category': category,\n",
        "                            'start': 0,\n",
        "                            'end': len(term),\n",
        "                            'original_text': original_text,\n",
        "                            'source': 'temporal_extraction',\n",
        "                            'row_idx': row_id\n",
        "                        })\n",
        "\n",
        "            # ---- Laterality (location or combined)\n",
        "            for lat in laterality_terms:\n",
        "                pattern = r'\\b' + re.escape(lat) + r'\\b'\n",
        "                for m in re.finditer(pattern, combined):\n",
        "                    custom_entities.append({\n",
        "                        'text': original_text[m.start():m.end()],\n",
        "                        'label': 'LATERALITY',\n",
        "                        'category': 'laterality',\n",
        "                        'start': m.start(),\n",
        "                        'end': m.end(),\n",
        "                        'original_text': original_text,\n",
        "                        'source': 'laterality_extraction',\n",
        "                        'row_idx': row_id\n",
        "                    })\n",
        "\n",
        "        return pd.DataFrame(custom_entities)\n",
        "\n",
        "    # Extract custom entities\n",
        "    df_custom_symptom_entities = extract_symptom_entities_custom(df_symptoms)\n",
        "\n",
        "    print(f\"\\nCustom extraction found:\")\n",
        "    if not df_custom_symptom_entities.empty and 'label' in df_custom_symptom_entities.columns:\n",
        "        print(df_custom_symptom_entities['label'].value_counts())\n",
        "    else:\n",
        "        print(\"No custom symptom entities found.\")\n",
        "\n",
        "    # Combine all entities (preserve row_idx/category when present)\n",
        "    df_all_symptom_entities = pd.concat(\n",
        "        [df_symptoms_entities, df_custom_symptom_entities],\n",
        "        ignore_index=True,\n",
        "        sort=False\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== COMBINED Entity Distribution ===\")\n",
        "    if not df_all_symptom_entities.empty and 'label' in df_all_symptom_entities.columns:\n",
        "        print(df_all_symptom_entities['label'].value_counts())\n",
        "    else:\n",
        "        print(\"No combined entities to show.\")\n",
        "\n",
        "    # Analyze symptom entities\n",
        "    symptom_entities = df_all_symptom_entities[df_all_symptom_entities['label'] == 'SYMPTOM'] if not df_all_symptom_entities.empty else pd.DataFrame()\n",
        "    if not symptom_entities.empty:\n",
        "        print(f\"\\n=== Top Symptoms ===\")\n",
        "        print(symptom_entities['text'].str.lower().value_counts().head(20))\n",
        "\n",
        "    # Analyze anatomical locations\n",
        "    anatomy_entities = df_all_symptom_entities[df_all_symptom_entities['label'] == 'ANATOMY'] if not df_all_symptom_entities.empty else pd.DataFrame()\n",
        "    if not anatomy_entities.empty:\n",
        "        print(f\"\\n=== Top Symptom Locations ===\")\n",
        "        print(anatomy_entities['text'].str.lower().value_counts().head(20))\n",
        "\n",
        "    # Analyze severity\n",
        "    severity_entities = df_all_symptom_entities[df_all_symptom_entities['label'] == 'SEVERITY'] if not df_all_symptom_entities.empty else pd.DataFrame()\n",
        "    if not severity_entities.empty:\n",
        "        print(f\"\\n=== Severity Distribution ===\")\n",
        "        print(severity_entities['text'].str.lower().value_counts())\n",
        "\n",
        "    # ================= Symptom-specific labeling functions =================\n",
        "    print(\"\\n=== Creating Symptom-Specific Labeling Functions ===\")\n",
        "\n",
        "    def create_symptom_labeling_functions():\n",
        "        \"\"\"Create labeling functions for symptom patterns\"\"\"\n",
        "\n",
        "        def lf_severe_pain(row):\n",
        "            symptom = str(row.get('name of symptom', '')).lower()\n",
        "            intensity = str(row.get('intensity of symptom', '')).lower()\n",
        "            if 'pain' in symptom and intensity == 'severe':\n",
        "                return 'SEVERE_PAIN'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_chronic_symptom(row):\n",
        "            temporal = str(row.get('temporalisation', '')).lower()\n",
        "            time_text = str(row.get('time', '')).lower()\n",
        "            chronic_indicators = ['chronic', 'persistent', 'ongoing', 'months', 'years']\n",
        "            if any(ind in (temporal + \" \" + time_text) for ind in chronic_indicators):\n",
        "                return 'CHRONIC_SYMPTOM'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_neurological_symptom(row):\n",
        "            symptom = str(row.get('name of symptom', '')).lower()\n",
        "            details = str(row.get('details', '')).lower()\n",
        "            neuro_terms = ['numbness', 'tingling', 'weakness', 'paralysis', 'sensation']\n",
        "            if any(term in (symptom + \" \" + details) for term in neuro_terms):\n",
        "                return 'NEUROLOGICAL'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_bilateral_symptom(row):\n",
        "            location = str(row.get('location', '')).lower()\n",
        "            if any(term in location for term in ['bilateral', 'both', 'left and right']):\n",
        "                return 'BILATERAL_SYMPTOM'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_acute_onset(row):\n",
        "            temporal = str(row.get('temporalisation', '')).lower()\n",
        "            details = str(row.get('details', '')).lower()\n",
        "            acute_terms = ['sudden', 'acute', 'abrupt', 'rapid onset']\n",
        "            if any(term in (temporal + \" \" + details) for term in acute_terms):\n",
        "                return 'ACUTE_ONSET'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_progressive_symptom(row):\n",
        "            temporal = str(row.get('temporalisation', '')).lower()\n",
        "            details = str(row.get('details', '')).lower()\n",
        "            if any(term in (temporal + \" \" + details) for term in ['worsening', 'progressive', 'increasing']):\n",
        "                return 'PROGRESSIVE_SYMPTOM'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_mobility_issue(row):\n",
        "            symptom = str(row.get('name of symptom', '')).lower()\n",
        "            if any(term in symptom for term in ['walk', 'gait', 'mobility', 'movement']):\n",
        "                return 'MOBILITY_ISSUE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_pain_with_location(row):\n",
        "            symptom = str(row.get('name of symptom', '')).lower()\n",
        "            location = str(row.get('location', '')).lower()\n",
        "            if 'pain' in symptom and location not in ('', 'nan'):\n",
        "                if 'hip' in location:\n",
        "                    return 'HIP_PAIN'\n",
        "                elif 'knee' in location:\n",
        "                    return 'KNEE_PAIN'\n",
        "                elif 'back' in location:\n",
        "                    return 'BACK_PAIN'\n",
        "                else:\n",
        "                    return 'LOCALIZED_PAIN'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_systemic_symptom(row):\n",
        "            symptom = str(row.get('name of symptom', '')).lower()\n",
        "            systemic_terms = ['fever', 'fatigue', 'weight loss', 'malaise']\n",
        "            if any(term in symptom for term in systemic_terms):\n",
        "                return 'SYSTEMIC_SYMPTOM'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_symptom_duration(row):\n",
        "            # Accept either 'time_duration_days' or 'duration_days'\n",
        "            duration = row.get('time_duration_days')\n",
        "            if pd.isna(duration):\n",
        "                duration = row.get('duration_days')\n",
        "            if pd.notna(duration):\n",
        "                try:\n",
        "                    d = float(duration)\n",
        "                except Exception:\n",
        "                    return 'ABSTAIN'\n",
        "                if d <= 7:\n",
        "                    return 'ACUTE_DURATION'\n",
        "                elif d <= 30:\n",
        "                    return 'SUBACUTE_DURATION'\n",
        "                else:\n",
        "                    return 'CHRONIC_DURATION'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        return [\n",
        "            lf_severe_pain, lf_chronic_symptom, lf_neurological_symptom,\n",
        "            lf_bilateral_symptom, lf_acute_onset, lf_progressive_symptom,\n",
        "            lf_mobility_issue, lf_pain_with_location, lf_systemic_symptom,\n",
        "            lf_symptom_duration\n",
        "        ]\n",
        "\n",
        "    # Test labeling functions\n",
        "    symptom_lfs = create_symptom_labeling_functions()\n",
        "\n",
        "    print(\"\\nTesting symptom labeling functions:\")\n",
        "    for i in range(min(10, len(df_symptoms))):\n",
        "        row = df_symptoms.iloc[i]\n",
        "        print(f\"\\nRow {i}: {str(row.get('name of symptom',''))} - {str(row.get('location',''))}\")\n",
        "        for lf in symptom_lfs:\n",
        "            result = lf(row)\n",
        "            if result != 'ABSTAIN':\n",
        "                print(f\"  {lf.__name__}: {result}\")\n",
        "\n",
        "    # ================= Extract symptom relations (use correct row_idx) =================\n",
        "    print(\"\\n=== Extracting Symptom Relations ===\")\n",
        "\n",
        "    def extract_symptom_relations(df_symptoms):\n",
        "        \"\"\"\n",
        "        Build row-level relations from structured columns.\n",
        "        Uses 'idx' for row identity when available; falls back to df.index.\n",
        "        \"\"\"\n",
        "        relations = []\n",
        "        for df_index, row in df_symptoms.iterrows():\n",
        "            row_id = row['idx'] if ('idx' in row and pd.notna(row['idx'])) else df_index\n",
        "            symptom = row.get('name of symptom')\n",
        "            location = row.get('location')\n",
        "            intensity = row.get('intensity of symptom')\n",
        "            duration = row.get('time_duration_days') if pd.notna(row.get('time_duration_days', pd.NA)) else row.get('duration_days')\n",
        "            temporal = row.get('temporalisation')\n",
        "\n",
        "            # SYMPTOM_LOCATED_IN\n",
        "            if pd.notna(symptom) and pd.notna(location) and str(location).lower() != 'nan':\n",
        "                relations.append({\n",
        "                    'type': 'SYMPTOM_LOCATED_IN',\n",
        "                    'symptom': symptom,\n",
        "                    'location': location,\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "\n",
        "            # SYMPTOM_HAS_SEVERITY\n",
        "            if pd.notna(symptom) and pd.notna(intensity) and str(intensity).lower() != 'nan':\n",
        "                relations.append({\n",
        "                    'type': 'SYMPTOM_HAS_SEVERITY',\n",
        "                    'symptom': symptom,\n",
        "                    'severity': intensity,\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "\n",
        "            # SYMPTOM_HAS_DURATION\n",
        "            if pd.notna(symptom) and pd.notna(duration):\n",
        "                relations.append({\n",
        "                    'type': 'SYMPTOM_HAS_DURATION',\n",
        "                    'symptom': symptom,\n",
        "                    'duration_days': duration,\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "\n",
        "            # SYMPTOM_HAS_TEMPORAL_PATTERN\n",
        "            if pd.notna(symptom) and pd.notna(temporal) and str(temporal).lower() != 'nan':\n",
        "                relations.append({\n",
        "                    'type': 'SYMPTOM_HAS_TEMPORAL_PATTERN',\n",
        "                    'symptom': symptom,\n",
        "                    'pattern': temporal,\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "\n",
        "        return relations\n",
        "\n",
        "    symptom_relations = extract_symptom_relations(df_symptoms)\n",
        "\n",
        "    print(f\"Found {len(symptom_relations)} symptom relations\")\n",
        "    if symptom_relations:\n",
        "        relation_types = pd.DataFrame(symptom_relations)['type'].value_counts()\n",
        "        print(\"\\nRelation type distribution:\")\n",
        "        print(relation_types)\n",
        "\n",
        "        print(\"\\nSample relations:\")\n",
        "        for rel in symptom_relations[:10]:\n",
        "            if rel['type'] == 'SYMPTOM_LOCATED_IN':\n",
        "                print(f\"  {rel['symptom']} -> located in -> {rel['location']} (row {rel['row_idx']})\")\n",
        "            elif rel['type'] == 'SYMPTOM_HAS_SEVERITY':\n",
        "                print(f\"  {rel['symptom']} -> has severity -> {rel['severity']} (row {rel['row_idx']})\")\n",
        "\n",
        "    # Save results\n",
        "    df_all_symptom_entities.to_csv('symptom_entities_comprehensive.csv', index=False)\n",
        "    pd.DataFrame(symptom_relations).to_csv('symptom_relations.csv', index=False)\n",
        "\n",
        "    print(\"\\n\\nSymptom entity extraction and labeling complete!\")\n",
        "    print(f\"Saved {len(df_all_symptom_entities)} entities and {len(symptom_relations)} relations.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>source_column</th>\n",
              "      <th>category</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pain</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Pain with Severe intensity located in Left hip...</td>\n",
              "      <td>133948</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pain</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>147</td>\n",
              "      <td>151</td>\n",
              "      <td>Pain with Severe intensity located in Left hip...</td>\n",
              "      <td>133948</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>weight gain</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>129</td>\n",
              "      <td>140</td>\n",
              "      <td>Moderate moon face with Moderate intensity loc...</td>\n",
              "      <td>133948</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Central obesity</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>Central obesity with nan intensity located in ...</td>\n",
              "      <td>133948</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Muscle mass reduction</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>Muscle mass reduction with nan intensity locat...</td>\n",
              "      <td>133948</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316041</th>\n",
              "      <td>chest</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>20</td>\n",
              "      <td>25</td>\n",
              "      <td>Crushing substernal chest pressure with Acute ...</td>\n",
              "      <td>97973</td>\n",
              "      <td>NaN</td>\n",
              "      <td>trunk</td>\n",
              "      <td>pattern_matching</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316042</th>\n",
              "      <td>Acute</td>\n",
              "      <td>TEMPORAL_PATTERN</td>\n",
              "      <td>40</td>\n",
              "      <td>45</td>\n",
              "      <td>Crushing substernal chest pressure with Acute ...</td>\n",
              "      <td>97973</td>\n",
              "      <td>NaN</td>\n",
              "      <td>acute</td>\n",
              "      <td>temporal_extraction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316043</th>\n",
              "      <td>Dyspnea</td>\n",
              "      <td>SYMPTOM</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>Dyspnea with Rapidly developed intensity locat...</td>\n",
              "      <td>97973</td>\n",
              "      <td>NaN</td>\n",
              "      <td>primary_symptom</td>\n",
              "      <td>symptom_name_column</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316044</th>\n",
              "      <td>Dyspnea</td>\n",
              "      <td>SYMPTOM_TYPE</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>Dyspnea with Rapidly developed intensity locat...</td>\n",
              "      <td>97973</td>\n",
              "      <td>NaN</td>\n",
              "      <td>respiratory</td>\n",
              "      <td>pattern_matching</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316045</th>\n",
              "      <td>dyspnea</td>\n",
              "      <td>SYMPTOM_TYPE</td>\n",
              "      <td>90</td>\n",
              "      <td>97</td>\n",
              "      <td>Dyspnea with Rapidly developed intensity locat...</td>\n",
              "      <td>97973</td>\n",
              "      <td>NaN</td>\n",
              "      <td>respiratory</td>\n",
              "      <td>pattern_matching</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>316046 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         text             label  start  end  \\\n",
              "0                        Pain           DISEASE      0    4   \n",
              "1                        pain           DISEASE    147  151   \n",
              "2                 weight gain           DISEASE    129  140   \n",
              "3             Central obesity           DISEASE      0   15   \n",
              "4       Muscle mass reduction           DISEASE      0   21   \n",
              "...                       ...               ...    ...  ...   \n",
              "316041                  chest           ANATOMY     20   25   \n",
              "316042                  Acute  TEMPORAL_PATTERN     40   45   \n",
              "316043                Dyspnea           SYMPTOM      0    7   \n",
              "316044                Dyspnea      SYMPTOM_TYPE      0    7   \n",
              "316045                dyspnea      SYMPTOM_TYPE     90   97   \n",
              "\n",
              "                                            original_text  row_idx  \\\n",
              "0       Pain with Severe intensity located in Left hip...   133948   \n",
              "1       Pain with Severe intensity located in Left hip...   133948   \n",
              "2       Moderate moon face with Moderate intensity loc...   133948   \n",
              "3       Central obesity with nan intensity located in ...   133948   \n",
              "4       Muscle mass reduction with nan intensity locat...   133948   \n",
              "...                                                   ...      ...   \n",
              "316041  Crushing substernal chest pressure with Acute ...    97973   \n",
              "316042  Crushing substernal chest pressure with Acute ...    97973   \n",
              "316043  Dyspnea with Rapidly developed intensity locat...    97973   \n",
              "316044  Dyspnea with Rapidly developed intensity locat...    97973   \n",
              "316045  Dyspnea with Rapidly developed intensity locat...    97973   \n",
              "\n",
              "        source_column         category               source  \n",
              "0       combined_text              NaN                  NaN  \n",
              "1       combined_text              NaN                  NaN  \n",
              "2       combined_text              NaN                  NaN  \n",
              "3       combined_text              NaN                  NaN  \n",
              "4       combined_text              NaN                  NaN  \n",
              "...               ...              ...                  ...  \n",
              "316041            NaN            trunk     pattern_matching  \n",
              "316042            NaN            acute  temporal_extraction  \n",
              "316043            NaN  primary_symptom  symptom_name_column  \n",
              "316044            NaN      respiratory     pattern_matching  \n",
              "316045            NaN      respiratory     pattern_matching  \n",
              "\n",
              "[316046 rows x 9 columns]"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_all_symptom_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting Diagnosis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "id": "xK0iHDeMoHg6",
        "outputId": "0d334c5a-89db-43b8-be57-92d556df35e6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>has_diagnosis</th>\n",
              "      <th>test</th>\n",
              "      <th>severity</th>\n",
              "      <th>result</th>\n",
              "      <th>condition</th>\n",
              "      <th>time</th>\n",
              "      <th>details</th>\n",
              "      <th>combined_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155216</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>nan performed with nan severity showed nan ind...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>133948</td>\n",
              "      <td>True</td>\n",
              "      <td>Magnetic resonance imaging (MRI) scan</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Increased amount of joint fluid and bone marro...</td>\n",
              "      <td>Idiopathic osteonecrosis of the femoral head</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Patient did not complain of any pain on the co...</td>\n",
              "      <td>Magnetic resonance imaging (MRI) scan performe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133948</td>\n",
              "      <td>True</td>\n",
              "      <td>Repeat MRI</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Similar findings to those noted previously in ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>One year after the initial surgery and symptom...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Repeat MRI performed with nan severity showed ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80176</td>\n",
              "      <td>True</td>\n",
              "      <td>Radiographs</td>\n",
              "      <td>Minimally displaced</td>\n",
              "      <td>Proximal ulnar shaft fracture</td>\n",
              "      <td>Proximal ulnar shaft fracture, hypertrophic no...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Elbow arthrodesis at 90 degrees with retained ...</td>\n",
              "      <td>Radiographs performed with Minimally displaced...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72232</td>\n",
              "      <td>True</td>\n",
              "      <td>MRI</td>\n",
              "      <td>Moderate-sized</td>\n",
              "      <td>Focal area of marrow edema/contusion involving...</td>\n",
              "      <td>Bone marrow edema</td>\n",
              "      <td>September 2016, three months later, April 2017...</td>\n",
              "      <td>Involvement of medial femoral condyle in mid a...</td>\n",
              "      <td>MRI performed with Moderate-sized severity sho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61350</th>\n",
              "      <td>133320</td>\n",
              "      <td>True</td>\n",
              "      <td>Histopathological examination</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Consistent with lung metastasis of leiomyosarcoma</td>\n",
              "      <td>Lung metastasis of leiomyosarcoma</td>\n",
              "      <td>One year and 3 months postoperatively</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Histopathological examination performed with n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61351</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Electrocardiogram (ECG)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Diffuse ST depressions in all precordial leads</td>\n",
              "      <td>Consistent with an acute coronary syndrome</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Electrocardiogram (ECG) performed with nan sev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61352</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Transthoracic echocardiogram</td>\n",
              "      <td>Ejection fraction (EF) of 45% with severe aort...</td>\n",
              "      <td>Torn right coronary cusp</td>\n",
              "      <td>Severe aortic insufficiency</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Emergent transthoracic echocardiogram performed</td>\n",
              "      <td>Transthoracic echocardiogram performed with Ej...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61353</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Blood cultures</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Positive for S.\\nlugdunensis in both bottles</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Blood cultures performed with nan severity sho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61354</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Transesophageal echocardiogram</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Large vegetation prolapsing into the left vent...</td>\n",
              "      <td>Acute severe aortic insufficiency from endocar...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Performed while patient was intubated</td>\n",
              "      <td>Transesophageal echocardiogram performed with ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>61355 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          idx  has_diagnosis                                   test  \\\n",
              "0      155216          False                                    NaN   \n",
              "1      133948           True  Magnetic resonance imaging (MRI) scan   \n",
              "2      133948           True                             Repeat MRI   \n",
              "3       80176           True                            Radiographs   \n",
              "4       72232           True                                    MRI   \n",
              "...       ...            ...                                    ...   \n",
              "61350  133320           True          Histopathological examination   \n",
              "61351   97973           True                Electrocardiogram (ECG)   \n",
              "61352   97973           True           Transthoracic echocardiogram   \n",
              "61353   97973           True                         Blood cultures   \n",
              "61354   97973           True         Transesophageal echocardiogram   \n",
              "\n",
              "                                                severity  \\\n",
              "0                                                    NaN   \n",
              "1                                                    NaN   \n",
              "2                                                    NaN   \n",
              "3                                    Minimally displaced   \n",
              "4                                         Moderate-sized   \n",
              "...                                                  ...   \n",
              "61350                                                NaN   \n",
              "61351                                                NaN   \n",
              "61352  Ejection fraction (EF) of 45% with severe aort...   \n",
              "61353                                                NaN   \n",
              "61354                                                NaN   \n",
              "\n",
              "                                                  result  \\\n",
              "0                                                    NaN   \n",
              "1      Increased amount of joint fluid and bone marro...   \n",
              "2      Similar findings to those noted previously in ...   \n",
              "3                          Proximal ulnar shaft fracture   \n",
              "4      Focal area of marrow edema/contusion involving...   \n",
              "...                                                  ...   \n",
              "61350  Consistent with lung metastasis of leiomyosarcoma   \n",
              "61351     Diffuse ST depressions in all precordial leads   \n",
              "61352                           Torn right coronary cusp   \n",
              "61353       Positive for S.\\nlugdunensis in both bottles   \n",
              "61354  Large vegetation prolapsing into the left vent...   \n",
              "\n",
              "                                               condition  \\\n",
              "0                                                    NaN   \n",
              "1           Idiopathic osteonecrosis of the femoral head   \n",
              "2                                                    NaN   \n",
              "3      Proximal ulnar shaft fracture, hypertrophic no...   \n",
              "4                                      Bone marrow edema   \n",
              "...                                                  ...   \n",
              "61350                  Lung metastasis of leiomyosarcoma   \n",
              "61351         Consistent with an acute coronary syndrome   \n",
              "61352                        Severe aortic insufficiency   \n",
              "61353                                                NaN   \n",
              "61354  Acute severe aortic insufficiency from endocar...   \n",
              "\n",
              "                                                    time  \\\n",
              "0                                                    NaN   \n",
              "1                                                    NaN   \n",
              "2      One year after the initial surgery and symptom...   \n",
              "3                                                    NaN   \n",
              "4      September 2016, three months later, April 2017...   \n",
              "...                                                  ...   \n",
              "61350              One year and 3 months postoperatively   \n",
              "61351                                                NaN   \n",
              "61352                                                NaN   \n",
              "61353                                                NaN   \n",
              "61354                                                NaN   \n",
              "\n",
              "                                                 details  \\\n",
              "0                                                    NaN   \n",
              "1      Patient did not complain of any pain on the co...   \n",
              "2                                                    NaN   \n",
              "3      Elbow arthrodesis at 90 degrees with retained ...   \n",
              "4      Involvement of medial femoral condyle in mid a...   \n",
              "...                                                  ...   \n",
              "61350                                                NaN   \n",
              "61351                                                NaN   \n",
              "61352    Emergent transthoracic echocardiogram performed   \n",
              "61353                                                NaN   \n",
              "61354              Performed while patient was intubated   \n",
              "\n",
              "                                           combined_text  \n",
              "0      nan performed with nan severity showed nan ind...  \n",
              "1      Magnetic resonance imaging (MRI) scan performe...  \n",
              "2      Repeat MRI performed with nan severity showed ...  \n",
              "3      Radiographs performed with Minimally displaced...  \n",
              "4      MRI performed with Moderate-sized severity sho...  \n",
              "...                                                  ...  \n",
              "61350  Histopathological examination performed with n...  \n",
              "61351  Electrocardiogram (ECG) performed with nan sev...  \n",
              "61352  Transthoracic echocardiogram performed with Ej...  \n",
              "61353  Blood cultures performed with nan severity sho...  \n",
              "61354  Transesophageal echocardiogram performed with ...  \n",
              "\n",
              "[61355 rows x 9 columns]"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_diagnosis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing temporal column: time\n",
            "\n",
            "Temporal extraction results:\n",
            "Successfully extracted duration: 3879\n",
            "Temporal types: {'unspecified': 4734, 'post_event': 3354, 'absolute_date': 1766, 'past_reference': 1280, 'range_reference': 1258, 'duration_reference': 299, 'onset_reference': 155}\n",
            "Loading en_ner_bc5cdr_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 61355 texts in 205 batches...\n",
            "Using model: en_ner_bc5cdr_md for column: combined_text\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   0%|          | 1/205 [00:03<10:23,  3.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   5%|▌         | 11/205 [00:21<06:05,  1.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 3000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  10%|█         | 21/205 [00:39<05:51,  1.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 6000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  15%|█▌        | 31/205 [00:59<05:47,  2.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 9000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  20%|██        | 41/205 [01:17<05:11,  1.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 12000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  25%|██▍       | 51/205 [01:36<04:54,  1.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  30%|██▉       | 61/205 [01:54<04:36,  1.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 18000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  35%|███▍      | 71/205 [02:14<04:19,  1.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 21000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  40%|███▉      | 81/205 [02:38<04:58,  2.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 24000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  44%|████▍     | 91/205 [02:59<04:04,  2.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 27000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  49%|████▉     | 101/205 [03:18<03:22,  1.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 30000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  54%|█████▍    | 111/205 [03:37<03:03,  1.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 33000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  59%|█████▉    | 121/205 [03:55<02:45,  1.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 36000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  64%|██████▍   | 131/205 [04:14<02:26,  1.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 39000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  69%|██████▉   | 141/205 [04:34<02:23,  2.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 42000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  74%|███████▎  | 151/205 [04:52<01:47,  2.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 45000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  79%|███████▊  | 161/205 [05:12<01:28,  2.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 48000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  83%|████████▎ | 171/205 [05:30<01:10,  2.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 51000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  88%|████████▊ | 181/205 [05:49<00:47,  1.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 54000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  93%|█████████▎| 191/205 [06:08<00:28,  2.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 57000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  98%|█████████▊| 201/205 [06:27<00:08,  2.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 60000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 205/205 [06:34<00:00,  1.92s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2745 entities appearing >= 5 times\n",
            "\n",
            "=== BC5CDR Entity Types Found ===\n",
            "{'DISEASE': 77150, 'CHEMICAL': 8577}\n",
            "\n",
            "=== CUSTOM DIAGNOSIS ENTITY EXTRACTION ===\n",
            "\n",
            "Custom extraction found:\n",
            "label\n",
            "TEST           56150\n",
            "TEST_TYPE      51197\n",
            "FINDING        40916\n",
            "CONDITION      36529\n",
            "ANATOMY        27435\n",
            "LATERALITY     25373\n",
            "MEASUREMENT    10044\n",
            "SEVERITY        1054\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== COMBINED Entity Distribution ===\n",
            "label\n",
            "DISEASE        77150\n",
            "TEST           56150\n",
            "TEST_TYPE      51197\n",
            "FINDING        40916\n",
            "CONDITION      36529\n",
            "ANATOMY        27435\n",
            "LATERALITY     25373\n",
            "MEASUREMENT    10044\n",
            "CHEMICAL        8577\n",
            "SEVERITY        1054\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Diagnostic Tests ===\n",
            "text\n",
            "mri                                 1005\n",
            "ct scan                              786\n",
            "biopsy                               663\n",
            "magnetic resonance imaging (mri)     655\n",
            "histopathological examination        577\n",
            "chest x-ray                          537\n",
            "computed tomography (ct) scan        402\n",
            "laboratory tests                     397\n",
            "computed tomography (ct)             394\n",
            "radiographs                          318\n",
            "blood tests                          315\n",
            "histological examination             304\n",
            "ultrasound                           249\n",
            "colonoscopy                          239\n",
            "histopathology                       234\n",
            "brain mri                            233\n",
            "blood cultures                       232\n",
            "electrocardiogram                    224\n",
            "echocardiography                     218\n",
            "incisional biopsy                    217\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Diagnostic Findings ===\n",
            "text\n",
            "mass            7083\n",
            "lesion          5276\n",
            "tumor           4980\n",
            "carcinoma       2818\n",
            "fracture        2737\n",
            "cyst            1519\n",
            "aneurysm        1444\n",
            "stenosis        1440\n",
            "metastasis      1155\n",
            "malignant       1139\n",
            "hemorrhage       934\n",
            "occlusion        807\n",
            "effusion         752\n",
            "edema            702\n",
            "necrosis         701\n",
            "benign           642\n",
            "inflammation     611\n",
            "thrombosis       610\n",
            "infarction       560\n",
            "nodule           560\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Diagnosed Conditions ===\n",
            "text\n",
            "infection                  179\n",
            "squamous cell carcinoma    124\n",
            "anemia                     112\n",
            "coronary artery disease    110\n",
            "adenocarcinoma              86\n",
            "tuberculosis                74\n",
            "metastatic disease          73\n",
            "stroke                      71\n",
            "malignant melanoma          67\n",
            "pseudoaneurysm              63\n",
            "metastatic melanoma         57\n",
            "osteosarcoma                57\n",
            "covid-19                    55\n",
            "pregnancy                   52\n",
            "tumor                       50\n",
            "pulmonary embolism          50\n",
            "hiv                         48\n",
            "breast cancer               45\n",
            "fracture                    44\n",
            "prostate cancer             42\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Creating Diagnosis-Specific Labeling Functions ===\n",
            "\n",
            "Testing diagnosis labeling functions:\n",
            "\n",
            "Row 0: nan - nan\n",
            "\n",
            "Row 1: Magnetic resonance imaging (MRI) scan - Idiopathic osteonecrosis of the femoral head\n",
            "  lf_imaging_test: IMAGING_TEST\n",
            "  lf_bone_pathology: BONE_PATHOLOGY\n",
            "  lf_inflammatory_finding: INFLAMMATORY_FINDING\n",
            "\n",
            "Row 2: Repeat MRI - nan\n",
            "  lf_imaging_test: IMAGING_TEST\n",
            "\n",
            "Row 3: Radiographs - Proximal ulnar shaft fracture, hypertrophic nonunion\n",
            "  lf_imaging_test: IMAGING_TEST\n",
            "  lf_fracture_diagnosis: FRACTURE_PRESENT\n",
            "  lf_bone_pathology: BONE_PATHOLOGY\n",
            "\n",
            "Row 4: MRI - Bone marrow edema\n",
            "  lf_imaging_test: IMAGING_TEST\n",
            "  lf_bone_pathology: BONE_PATHOLOGY\n",
            "  lf_inflammatory_finding: INFLAMMATORY_FINDING\n",
            "\n",
            "Row 5: nan - Osteomalacia\n",
            "\n",
            "Row 6: Computed tomography (CT) of thorax - Diaphragmatic defect\n",
            "  lf_imaging_test: IMAGING_TEST\n",
            "  lf_normal_finding: NORMAL_FINDING\n",
            "\n",
            "Row 7: Imaging - Polyostotic fibrous dysplasia\n",
            "  lf_fracture_diagnosis: FRACTURE_PRESENT\n",
            "  lf_neoplastic_finding: NEOPLASTIC_FINDING\n",
            "  lf_bone_pathology: BONE_PATHOLOGY\n",
            "  lf_bilateral_finding: BILATERAL_FINDING\n",
            "\n",
            "Row 8: Magnetic resonance scanning - Fibrous dysplasia of the proximal femur shaft, sub-capital fracture of femur neck\n",
            "  lf_imaging_test: IMAGING_TEST\n",
            "  lf_fracture_diagnosis: FRACTURE_PRESENT\n",
            "  lf_bone_pathology: BONE_PATHOLOGY\n",
            "  lf_vascular_finding: VASCULAR_FINDING\n",
            "\n",
            "Row 9: Blood and serum biochemical investigations - nan\n",
            "  lf_normal_finding: NORMAL_FINDING\n",
            "\n",
            "=== Extracting Diagnosis Relations ===\n",
            "\n",
            "Found 125865 diagnosis relations\n",
            "\n",
            "Relation type distribution:\n",
            "type\n",
            "TEST_REVEALS            53912\n",
            "TEST_DIAGNOSES          34501\n",
            "FINDING_INDICATES       33304\n",
            "FINDING_HAS_SEVERITY     4148\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sample relations:\n",
            "  Magnetic resonance imaging (MRI) scan -> reveals -> Increased amount of joint fluid and bone marrow edema in the left hip, and femoral head necrosis on the contralateral side (row 133948)\n",
            "  Magnetic resonance imaging (MRI) scan -> diagnoses -> Idiopathic osteonecrosis of the femoral head (row 133948)\n",
            "  Repeat MRI -> reveals -> Similar findings to those noted previously in the left hip (row 133948)\n",
            "  Radiographs -> reveals -> Proximal ulnar shaft fracture (row 80176)\n",
            "  Radiographs -> diagnoses -> Proximal ulnar shaft fracture, hypertrophic nonunion (row 80176)\n",
            "  MRI -> reveals -> Focal area of marrow edema/contusion involving the medial femoral condyle, bone marrow edema involving the lateral femoral condyle, extensive marrow edema involving the medial femoral condyle (row 72232)\n",
            "  MRI -> diagnoses -> Bone marrow edema (row 72232)\n",
            "\n",
            "=== Test-Finding Pattern Analysis ===\n",
            "\n",
            "Common test-finding patterns:\n",
            "  Chest X-ray -> Normal: 53 occurrences\n",
            "  Blood cultures -> Negative: 43 occurrences\n",
            "  Complete blood count -> Normal: 30 occurrences\n",
            "  Chest radiograph -> Normal: 28 occurrences\n",
            "  Blood tests -> Normal: 25 occurrences\n",
            "  HIV test -> Negative: 25 occurrences\n",
            "  Liver function tests -> Normal: 25 occurrences\n",
            "  Mantoux test -> Negative: 24 occurrences\n",
            "  Laboratory tests -> Normal: 22 occurrences\n",
            "  Thyroid function tests -> Normal: 19 occurrences\n",
            "\n",
            "=== Labeling Function Coverage Analysis ===\n",
            "\n",
            "Labeling function coverage:\n",
            "  lf_imaging_test: 25761 labels (42.0% coverage)\n",
            "  lf_neoplastic_finding: 14057 labels (22.9% coverage)\n",
            "  lf_normal_finding: 10924 labels (17.8% coverage)\n",
            "  lf_vascular_finding: 6262 labels (10.2% coverage)\n",
            "  lf_inflammatory_finding: 3110 labels (5.1% coverage)\n",
            "  lf_bone_pathology: 2771 labels (4.5% coverage)\n",
            "  lf_bilateral_finding: 1826 labels (3.0% coverage)\n",
            "  lf_fracture_diagnosis: 1707 labels (2.8% coverage)\n",
            "  lf_followup_needed: 408 labels (0.7% coverage)\n",
            "  lf_critical_finding: 177 labels (0.3% coverage)\n",
            "\n",
            "=== Diagnostic Summary ===\n",
            "\n",
            "Test types distribution:\n",
            "category\n",
            "imaging       39202\n",
            "laboratory     9230\n",
            "functional     1556\n",
            "endoscopy      1209\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Finding categories:\n",
            "category\n",
            "structural      25035\n",
            "neoplastic       6904\n",
            "vascular         4255\n",
            "inflammatory     3118\n",
            "degenerative     1604\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n",
            "Diagnosis entity extraction and labeling complete!\n",
            "Saved 334425 entities and 125865 relations\n",
            "Diagnostic patterns exported to diagnostic_patterns.json\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Apply temporal standardization\n",
        "    temporal_standardizer = TemporalStandardizer()\n",
        "    df_diagnosis_processed, temporal_report = temporal_standardizer.standardize_temporal_column(\n",
        "        df_diagnosis, \n",
        "        'time'\n",
        "    )\n",
        "   \n",
        "    print(f\"\\nTemporal extraction results:\")\n",
        "    print(f\"Successfully extracted duration: {temporal_report['extracted_durations']}\")\n",
        "    print(f\"Temporal types: {temporal_report['temporal_types']}\")\n",
        "\n",
        "    # Combine diagnosis text columns (robust to NaNs)\n",
        "    df_diagnosis['combined_text'] = df_diagnosis.apply(\n",
        "        lambda row: f\"{str(row.get('test',''))} performed with {str(row.get('severity',''))} severity \"\n",
        "                    f\"showed {str(row.get('result',''))} indicating {str(row.get('condition',''))} \"\n",
        "                    f\"{str(row.get('details',''))} at {str(row.get('time',''))}\",\n",
        "        axis=1        \n",
        "    )\n",
        "\n",
        "    # Copy combined_text to processed dataframe\n",
        "    df_diagnosis_processed['combined_text'] = df_diagnosis['combined_text']\n",
        "\n",
        "    # Add temporal features to combined text\n",
        "    df_diagnosis_processed['combined_text_enriched'] = df_diagnosis_processed.apply(\n",
        "        lambda row: f\"{row['combined_text']} \"\n",
        "                    f\"{'lasting ' + str(row.get('time_duration_days', '')) + ' days' if pd.notna(row.get('time_duration_days')) else ''}\",\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Run NER extraction with BC5CDR\n",
        "    df_diagnosis_entities, diagnosis_summary, diagnosis_rules = run_medical_ner_extraction(\n",
        "        df_diagnosis,\n",
        "        text_column='combined_text',\n",
        "        model_name=\"en_ner_bc5cdr_md\",\n",
        "        batch_size=300, \n",
        "        id_column='idx'\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== BC5CDR Entity Types Found ===\")\n",
        "    print(diagnosis_summary['entity_types'])\n",
        "\n",
        "    # ================= CUSTOM DIAGNOSIS ENTITY EXTRACTION (keeps correct row_idx) =================\n",
        "    print(\"\\n=== CUSTOM DIAGNOSIS ENTITY EXTRACTION ===\")\n",
        "\n",
        "    def extract_diagnosis_entities_custom(df_diagnosis):\n",
        "        \"\"\"\n",
        "        Extract diagnosis-specific entities not (fully) caught by BC5CDR.\n",
        "        Uses 'idx' for row identity when available; falls back to df.index otherwise.\n",
        "        Adds 'row_idx' and character offsets for all extracted entities.\n",
        "        Regex with word boundaries is used to avoid substring false positives.\n",
        "        \"\"\"\n",
        "        custom_entities = []\n",
        "\n",
        "        # Test/Procedure patterns\n",
        "        test_patterns = {\n",
        "            'imaging': [\n",
        "                'mri', 'magnetic resonance', 'ct', 'computed tomography',\n",
        "                'x-ray', 'radiograph', 'ultrasound', 'sonography', 'scan',\n",
        "                'pet', 'spect', 'angiography', 'mammography'\n",
        "            ],\n",
        "            'laboratory': [\n",
        "                'blood test', 'serum', 'plasma', 'biochemical', 'hematology',\n",
        "                'urinalysis', 'culture', 'biopsy', 'cytology', 'pathology'\n",
        "            ],\n",
        "            'functional': [\n",
        "                'ecg', 'ekg', 'electrocardiogram', 'eeg', 'electroencephalogram',\n",
        "                'emg', 'electromyography', 'spirometry', 'pulmonary function'\n",
        "            ],\n",
        "            'endoscopy': [\n",
        "                'endoscopy', 'colonoscopy', 'gastroscopy', 'bronchoscopy',\n",
        "                'cystoscopy', 'arthroscopy', 'laparoscopy'\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        # Finding/Result patterns\n",
        "        finding_patterns = {\n",
        "            'structural': [\n",
        "                'fracture', 'lesion', 'mass', 'tumor', 'cyst', 'nodule',\n",
        "                'stenosis', 'occlusion', 'herniation', 'displacement'\n",
        "            ],\n",
        "            'inflammatory': [\n",
        "                'inflammation', 'edema', 'swelling', 'effusion', 'congestion',\n",
        "                'infiltration', 'consolidation'\n",
        "            ],\n",
        "            'degenerative': [\n",
        "                'degeneration', 'atrophy', 'necrosis', 'fibrosis', 'sclerosis',\n",
        "                'osteoarthritis', 'spondylosis'\n",
        "            ],\n",
        "            'vascular': [\n",
        "                'ischemia', 'infarction', 'hemorrhage', 'aneurysm', 'thrombosis',\n",
        "                'embolism', 'vasculitis'\n",
        "            ],\n",
        "            'neoplastic': [\n",
        "                'malignant', 'benign', 'metastasis', 'carcinoma', 'sarcoma',\n",
        "                'lymphoma', 'adenoma'\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        # Anatomical patterns specific to diagnosis\n",
        "        anatomy_patterns = {\n",
        "            'bone':   ['femur', 'tibia', 'fibula', 'humerus', 'radius', 'ulna', 'vertebra'],\n",
        "            'joint':  ['hip', 'knee', 'shoulder', 'elbow', 'ankle', 'wrist'],\n",
        "            'organ':  ['liver', 'kidney', 'heart', 'lung', 'brain', 'pancreas', 'spleen'],\n",
        "            'vessel': ['artery', 'vein', 'aorta', 'carotid', 'coronary'],\n",
        "            'region': ['parietal', 'temporal', 'frontal', 'occipital', 'cervical', 'lumbar']\n",
        "        }\n",
        "\n",
        "        # Severity/Grade patterns (from column)\n",
        "        severity_patterns = {\n",
        "            'mild':     ['mild', 'minimal', 'slight', 'minor'],\n",
        "            'moderate': ['moderate', 'medium', 'intermediate'],\n",
        "            'severe':   ['severe', 'significant', 'marked', 'extensive'],\n",
        "            'critical': ['critical', 'life-threatening', 'emergency']\n",
        "        }\n",
        "\n",
        "        # Laterality\n",
        "        laterality_terms = ['left', 'right', 'bilateral']\n",
        "\n",
        "        for df_index, row in df_diagnosis.iterrows():\n",
        "            # ---- choose the correct row id from 'idx' with fallback to the DataFrame index\n",
        "            row_id = row['idx'] if ('idx' in row and pd.notna(row['idx'])) else df_index\n",
        "\n",
        "            original_text = str(row.get('combined_text', ''))\n",
        "            combined = original_text.lower()\n",
        "\n",
        "            test_text_orig = str(row.get('test', ''))\n",
        "            test_text = test_text_orig.lower()\n",
        "            result_text = str(row.get('result', '')).lower()\n",
        "            condition_text_orig = str(row.get('condition', ''))\n",
        "            condition_text = condition_text_orig.lower()\n",
        "            severity_text_orig = str(row.get('severity', ''))\n",
        "            severity_text = severity_text_orig.lower()\n",
        "\n",
        "            # ---- TEST from test column (place in the combined text if possible)\n",
        "            if test_text and test_text != 'nan':\n",
        "                start = combined.find(test_text)\n",
        "                if start < 0:\n",
        "                    start = 0\n",
        "                end = min(start + len(test_text_orig), len(original_text))\n",
        "                custom_entities.append({\n",
        "                    'text': test_text_orig,\n",
        "                    'label': 'TEST',\n",
        "                    'category': 'diagnostic_test',\n",
        "                    'start': start,\n",
        "                    'end': end,\n",
        "                    'original_text': original_text,\n",
        "                    'source': 'test_column',\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "                # TEST_TYPE via patterns (regex boundaries)\n",
        "                for category, terms in test_patterns.items():\n",
        "                    for term in terms:\n",
        "                        pattern = r'\\b' + re.escape(term.lower()) + r'\\b'\n",
        "                        for m in re.finditer(pattern, combined):\n",
        "                            custom_entities.append({\n",
        "                                'text': original_text[m.start():m.end()],\n",
        "                                'label': 'TEST_TYPE',\n",
        "                                'category': category,\n",
        "                                'start': m.start(),\n",
        "                                'end': m.end(),\n",
        "                                'original_text': original_text,\n",
        "                                'source': 'pattern_matching',\n",
        "                                'row_idx': row_id\n",
        "                            })\n",
        "\n",
        "            # ---- FINDINGS from result (search in combined for offsets)\n",
        "            if result_text and result_text != 'nan':\n",
        "                for category, terms in finding_patterns.items():\n",
        "                    for term in terms:\n",
        "                        pattern = r'\\b' + re.escape(term.lower()) + r'\\b'\n",
        "                        for m in re.finditer(pattern, combined):\n",
        "                            custom_entities.append({\n",
        "                                'text': original_text[m.start():m.end()],\n",
        "                                'label': 'FINDING',\n",
        "                                'category': category,\n",
        "                                'start': m.start(),\n",
        "                                'end': m.end(),\n",
        "                                'original_text': original_text,\n",
        "                                'source': 'result_extraction',\n",
        "                                'row_idx': row_id\n",
        "                            })\n",
        "\n",
        "            # ---- CONDITION from condition column\n",
        "            if condition_text and condition_text != 'nan':\n",
        "                start = combined.find(condition_text)\n",
        "                if start < 0:\n",
        "                    start = 0\n",
        "                end = min(start + len(condition_text_orig), len(original_text))\n",
        "                custom_entities.append({\n",
        "                    'text': condition_text_orig,\n",
        "                    'label': 'CONDITION',\n",
        "                    'category': 'diagnosis',\n",
        "                    'start': start,\n",
        "                    'end': end,\n",
        "                    'original_text': original_text,\n",
        "                    'source': 'condition_column',\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "\n",
        "            # ---- ANATOMY patterns (allow simple plural 's')\n",
        "            for category, terms in anatomy_patterns.items():\n",
        "                for term in terms:\n",
        "                    plural_opt = 's?' if term.isalpha() else ''\n",
        "                    pattern = r'\\b' + re.escape(term.lower()) + plural_opt + r'\\b'\n",
        "                    for m in re.finditer(pattern, combined):\n",
        "                        custom_entities.append({\n",
        "                            'text': original_text[m.start():m.end()],\n",
        "                            'label': 'ANATOMY',\n",
        "                            'category': category,\n",
        "                            'start': m.start(),\n",
        "                            'end': m.end(),\n",
        "                            'original_text': original_text,\n",
        "                            'source': 'anatomy_extraction',\n",
        "                            'row_idx': row_id\n",
        "                        })\n",
        "\n",
        "            # ---- SEVERITY from severity column\n",
        "            if severity_text and severity_text != 'nan':\n",
        "                for category, terms in severity_patterns.items():\n",
        "                    if severity_text in terms:\n",
        "                        start = combined.find(severity_text)\n",
        "                        if start < 0:\n",
        "                            start = 0\n",
        "                        end = min(start + len(severity_text_orig), len(original_text))\n",
        "                        custom_entities.append({\n",
        "                            'text': severity_text_orig,\n",
        "                            'label': 'SEVERITY',\n",
        "                            'category': category,\n",
        "                            'start': start,\n",
        "                            'end': end,\n",
        "                            'original_text': original_text,\n",
        "                            'source': 'severity_column',\n",
        "                            'row_idx': row_id\n",
        "                        })\n",
        "                        break\n",
        "\n",
        "            # ---- LATERALITY\n",
        "            for lat in laterality_terms:\n",
        "                pattern = r'\\b' + re.escape(lat) + r'\\b'\n",
        "                for m in re.finditer(pattern, combined):\n",
        "                    custom_entities.append({\n",
        "                        'text': original_text[m.start():m.end()],\n",
        "                        'label': 'LATERALITY',\n",
        "                        'category': 'laterality',\n",
        "                        'start': m.start(),\n",
        "                        'end': m.end(),\n",
        "                        'original_text': original_text,\n",
        "                        'source': 'laterality_extraction',\n",
        "                        'row_idx': row_id\n",
        "                    })\n",
        "\n",
        "            # ---- MEASUREMENTS (capture full token with units)\n",
        "            # e.g., \"12 mm\", \"3.5 cm\", \"45%\", \"10 mg\", \"30 ml\"\n",
        "            measurement_pattern = r'\\b\\d+(?:\\.\\d+)?\\s*(?:mm|cm|ml|mg|%)\\b'\n",
        "            for m in re.finditer(measurement_pattern, combined):\n",
        "                custom_entities.append({\n",
        "                    'text': original_text[m.start():m.end()],\n",
        "                    'label': 'MEASUREMENT',\n",
        "                    'category': 'quantitative',\n",
        "                    'start': m.start(),\n",
        "                    'end': m.end(),\n",
        "                    'original_text': original_text,\n",
        "                    'source': 'measurement_extraction',\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "\n",
        "        return pd.DataFrame(custom_entities)\n",
        "\n",
        "    # Extract custom entities\n",
        "    df_custom_diagnosis_entities = extract_diagnosis_entities_custom(df_diagnosis)\n",
        "\n",
        "    print(f\"\\nCustom extraction found:\")\n",
        "    if not df_custom_diagnosis_entities.empty and 'label' in df_custom_diagnosis_entities.columns:\n",
        "        print(df_custom_diagnosis_entities['label'].value_counts())\n",
        "    else:\n",
        "        print(\"No custom diagnosis entities found.\")\n",
        "\n",
        "    # Combine all entities (preserve row_idx/category when present)\n",
        "    df_all_diagnosis_entities = pd.concat(\n",
        "        [df_diagnosis_entities, df_custom_diagnosis_entities],\n",
        "        ignore_index=True,\n",
        "        sort=False\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== COMBINED Entity Distribution ===\")\n",
        "    if not df_all_diagnosis_entities.empty and 'label' in df_all_diagnosis_entities.columns:\n",
        "        print(df_all_diagnosis_entities['label'].value_counts())\n",
        "    else:\n",
        "        print(\"No combined entities to show.\")\n",
        "\n",
        "    # Analyze test entities\n",
        "    test_entities = df_all_diagnosis_entities[df_all_diagnosis_entities['label'] == 'TEST'] if not df_all_diagnosis_entities.empty else pd.DataFrame()\n",
        "    if not test_entities.empty:\n",
        "        print(f\"\\n=== Top Diagnostic Tests ===\")\n",
        "        print(test_entities['text'].str.lower().value_counts().head(20))\n",
        "\n",
        "    # Analyze findings\n",
        "    finding_entities = df_all_diagnosis_entities[df_all_diagnosis_entities['label'] == 'FINDING'] if not df_all_diagnosis_entities.empty else pd.DataFrame()\n",
        "    if not finding_entities.empty:\n",
        "        print(f\"\\n=== Top Diagnostic Findings ===\")\n",
        "        print(finding_entities['text'].str.lower().value_counts().head(20))\n",
        "\n",
        "    # Analyze conditions\n",
        "    condition_entities = df_all_diagnosis_entities[df_all_diagnosis_entities['label'] == 'CONDITION'] if not df_all_diagnosis_entities.empty else pd.DataFrame()\n",
        "    if not condition_entities.empty:\n",
        "        print(f\"\\n=== Top Diagnosed Conditions ===\")\n",
        "        print(condition_entities['text'].str.lower().value_counts().head(20))\n",
        "\n",
        "    # ================= Diagnosis-specific labeling functions =================\n",
        "    print(\"\\n=== Creating Diagnosis-Specific Labeling Functions ===\")\n",
        "\n",
        "    def create_diagnosis_labeling_functions():\n",
        "        \"\"\"Create labeling functions for diagnosis patterns\"\"\"\n",
        "\n",
        "        def lf_imaging_test(row):\n",
        "            test = str(row.get('test', '')).lower()\n",
        "            imaging_keywords = ['mri', 'ct', 'x-ray', 'radiograph', 'ultrasound', 'scan']\n",
        "            if any(keyword in test for keyword in imaging_keywords):\n",
        "                return 'IMAGING_TEST'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_fracture_diagnosis(row):\n",
        "            result = str(row.get('result', '')).lower()\n",
        "            condition = str(row.get('condition', '')).lower()\n",
        "            if 'fracture' in result or 'fracture' in condition:\n",
        "                if 'no fracture' in result or 'no fracture' in condition:\n",
        "                    return 'NO_FRACTURE'\n",
        "                else:\n",
        "                    return 'FRACTURE_PRESENT'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_neoplastic_finding(row):\n",
        "            combined = str(row.get('combined_text', '')).lower()\n",
        "            neoplastic_terms = ['tumor', 'mass', 'lesion', 'malignant', 'benign', 'metastasis']\n",
        "            if any(term in combined for term in neoplastic_terms):\n",
        "                return 'NEOPLASTIC_FINDING'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_normal_finding(row):\n",
        "            result = str(row.get('result', '')).lower()\n",
        "            normal_terms = ['normal', 'negative', 'no abnormality', 'unremarkable']\n",
        "            if any(term in result for term in normal_terms):\n",
        "                return 'NORMAL_FINDING'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_critical_finding(row):\n",
        "            severity = str(row.get('severity', '')).lower()\n",
        "            details = str(row.get('details', '')).lower()\n",
        "            critical_terms = ['critical', 'emergency', 'urgent', 'life-threatening']\n",
        "            if any(term in (severity + details) for term in critical_terms):\n",
        "                return 'CRITICAL_FINDING'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_bone_pathology(row):\n",
        "            combined = str(row.get('combined_text', '')).lower()\n",
        "            bone_terms = ['bone', 'osseous', 'fracture', 'osteo', 'marrow']\n",
        "            pathology_terms = ['lesion', 'edema', 'necrosis', 'fracture']\n",
        "            if any(b in combined for b in bone_terms) and any(p in combined for p in pathology_terms):\n",
        "                return 'BONE_PATHOLOGY'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_vascular_finding(row):\n",
        "            combined = str(row.get('combined_text', '')).lower()\n",
        "            vascular_terms = ['vascular', 'artery', 'vein', 'aneurysm', 'stenosis', 'occlusion']\n",
        "            if any(term in combined for term in vascular_terms):\n",
        "                return 'VASCULAR_FINDING'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_inflammatory_finding(row):\n",
        "            combined = str(row.get('combined_text', '')).lower()\n",
        "            inflammatory_terms = ['inflammation', 'inflammatory', 'edema', 'effusion', 'swelling']\n",
        "            if any(term in combined for term in inflammatory_terms):\n",
        "                return 'INFLAMMATORY_FINDING'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_bilateral_finding(row):\n",
        "            combined = str(row.get('combined_text', '')).lower()\n",
        "            if 'bilateral' in combined:\n",
        "                return 'BILATERAL_FINDING'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_followup_needed(row):\n",
        "            details = str(row.get('details', '')).lower()\n",
        "            followup_terms = ['follow-up', 'followup', 'repeat', 'monitor', 'reassess']\n",
        "            if any(term in details for term in followup_terms):\n",
        "                return 'FOLLOWUP_NEEDED'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        return [\n",
        "            lf_imaging_test, lf_fracture_diagnosis, lf_neoplastic_finding,\n",
        "            lf_normal_finding, lf_critical_finding, lf_bone_pathology,\n",
        "            lf_vascular_finding, lf_inflammatory_finding, lf_bilateral_finding,\n",
        "            lf_followup_needed\n",
        "        ]\n",
        "\n",
        "    # Test labeling functions\n",
        "    diagnosis_lfs = create_diagnosis_labeling_functions()\n",
        "\n",
        "    print(\"\\nTesting diagnosis labeling functions:\")\n",
        "    for i in range(min(10, len(df_diagnosis))):\n",
        "        row = df_diagnosis.iloc[i]\n",
        "        print(f\"\\nRow {i}: {str(row.get('test',''))} - {str(row.get('condition',''))}\")\n",
        "        for lf in diagnosis_lfs:\n",
        "            result = lf(row)\n",
        "            if result != 'ABSTAIN':\n",
        "                print(f\"  {lf.__name__}: {result}\")\n",
        "\n",
        "    # ================= Extract diagnosis relations (use correct row_idx) =================\n",
        "    print(\"\\n=== Extracting Diagnosis Relations ===\")\n",
        "\n",
        "    def extract_diagnosis_relations(df_diagnosis):\n",
        "        \"\"\"\n",
        "        Extract relations between tests, findings, and conditions at the row level.\n",
        "        Uses 'idx' for row identity when available; falls back to df.index.\n",
        "        \"\"\"\n",
        "        relations = []\n",
        "        for df_index, row in df_diagnosis.iterrows():\n",
        "            row_id = row['idx'] if ('idx' in row and pd.notna(row['idx'])) else df_index\n",
        "            test = row.get('test')\n",
        "            result = row.get('result')\n",
        "            condition = row.get('condition')\n",
        "            severity = row.get('severity')\n",
        "\n",
        "            # TEST_REVEALS_FINDING\n",
        "            if pd.notna(test) and pd.notna(result) and str(result).lower() != 'nan':\n",
        "                relations.append({\n",
        "                    'type': 'TEST_REVEALS',\n",
        "                    'test': test,\n",
        "                    'finding': result,\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "\n",
        "            # TEST_DIAGNOSES_CONDITION\n",
        "            if pd.notna(test) and pd.notna(condition) and str(condition).lower() != 'nan':\n",
        "                relations.append({\n",
        "                    'type': 'TEST_DIAGNOSES',\n",
        "                    'test': test,\n",
        "                    'condition': condition,\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "\n",
        "            # FINDING_INDICATES_CONDITION\n",
        "            if pd.notna(result) and pd.notna(condition) and str(result).lower() != 'nan' and str(condition).lower() != 'nan':\n",
        "                relations.append({\n",
        "                    'type': 'FINDING_INDICATES',\n",
        "                    'finding': result,\n",
        "                    'condition': condition,\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "\n",
        "            # FINDING_HAS_SEVERITY\n",
        "            if pd.notna(result) and pd.notna(severity) and str(severity).lower() != 'nan':\n",
        "                relations.append({\n",
        "                    'type': 'FINDING_HAS_SEVERITY',\n",
        "                    'finding': result,\n",
        "                    'severity': severity,\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "\n",
        "            # Temporal relations (if available from temporal standardizer)\n",
        "            temporal_info = row.get('temporal_info')\n",
        "            if temporal_info and pd.notna(test):\n",
        "                relations.append({\n",
        "                    'type': 'TEST_PERFORMED_AT',\n",
        "                    'test': test,\n",
        "                    'time': row.get('time'),\n",
        "                    'temporal_type': temporal_info.get('type'),\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "\n",
        "        return relations\n",
        "\n",
        "    diagnosis_relations = extract_diagnosis_relations(df_diagnosis)\n",
        "\n",
        "    print(f\"\\nFound {len(diagnosis_relations)} diagnosis relations\")\n",
        "    if diagnosis_relations:\n",
        "        relation_types = pd.DataFrame(diagnosis_relations)['type'].value_counts()\n",
        "        print(\"\\nRelation type distribution:\")\n",
        "        print(relation_types)\n",
        "\n",
        "        print(\"\\nSample relations:\")\n",
        "        for rel in diagnosis_relations[:10]:\n",
        "            if rel['type'] == 'TEST_REVEALS':\n",
        "                print(f\"  {rel['test']} -> reveals -> {rel['finding']} (row {rel['row_idx']})\")\n",
        "            elif rel['type'] == 'TEST_DIAGNOSES':\n",
        "                print(f\"  {rel['test']} -> diagnoses -> {rel['condition']} (row {rel['row_idx']})\")\n",
        "\n",
        "    # Analyze test-finding patterns\n",
        "    print(\"\\n=== Test-Finding Pattern Analysis ===\")\n",
        "    test_finding_pairs = {}\n",
        "    for rel in diagnosis_relations:\n",
        "        if rel['type'] == 'TEST_REVEALS':\n",
        "            pair = f\"{rel['test']} -> {rel['finding']}\"\n",
        "            test_finding_pairs[pair] = test_finding_pairs.get(pair, 0) + 1\n",
        "\n",
        "    print(\"\\nCommon test-finding patterns:\")\n",
        "    for pair, count in sorted(test_finding_pairs.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
        "        print(f\"  {pair}: {count} occurrences\")\n",
        "\n",
        "    # Coverage analysis\n",
        "    print(\"\\n=== Labeling Function Coverage Analysis ===\")\n",
        "    coverage_results = {}\n",
        "    for lf in diagnosis_lfs:\n",
        "        labeled = sum(1 for _, row in df_diagnosis.iterrows() if lf(row) != 'ABSTAIN')\n",
        "        coverage = (labeled / len(df_diagnosis)) * 100 if len(df_diagnosis) else 0.0\n",
        "        coverage_results[lf.__name__] = {'labeled': labeled, 'coverage': coverage}\n",
        "\n",
        "    print(\"\\nLabeling function coverage:\")\n",
        "    for lf_name, stats in sorted(coverage_results.items(), key=lambda x: x[1]['coverage'], reverse=True):\n",
        "        print(f\"  {lf_name}: {stats['labeled']} labels ({stats['coverage']:.1f}% coverage)\")\n",
        "\n",
        "    # Diagnostic summary (guard against empties)\n",
        "    print(\"\\n=== Diagnostic Summary ===\")\n",
        "    if not df_custom_diagnosis_entities.empty:\n",
        "        if 'TEST_TYPE' in df_custom_diagnosis_entities['label'].values:\n",
        "            test_types = df_custom_diagnosis_entities[\n",
        "                df_custom_diagnosis_entities['label'] == 'TEST_TYPE'\n",
        "            ]['category'].value_counts()\n",
        "            print(\"\\nTest types distribution:\")\n",
        "            print(test_types)\n",
        "\n",
        "        if 'FINDING' in df_custom_diagnosis_entities['label'].values:\n",
        "            finding_categories = df_custom_diagnosis_entities[\n",
        "                df_custom_diagnosis_entities['label'] == 'FINDING'\n",
        "            ]['category'].value_counts()\n",
        "            print(\"\\nFinding categories:\")\n",
        "            print(finding_categories)\n",
        "\n",
        "    # Save results\n",
        "    df_all_diagnosis_entities.to_csv('diagnosis_entities_comprehensive.csv', index=False)\n",
        "    pd.DataFrame(diagnosis_relations).to_csv('diagnosis_relations.csv', index=False)\n",
        "\n",
        "    # Export diagnostic patterns for future use\n",
        "    diagnostic_patterns = {\n",
        "        'common_tests': test_entities['text'].value_counts().head(20).to_dict() if not test_entities.empty else {},\n",
        "        'common_findings': finding_entities['text'].value_counts().head(20).to_dict() if not finding_entities.empty else {},\n",
        "        'test_finding_pairs': test_finding_pairs\n",
        "    }\n",
        "    with open('diagnostic_patterns.json', 'w') as f:\n",
        "        json.dump(diagnostic_patterns, f, indent=2)\n",
        "\n",
        "    print(\"\\n\\nDiagnosis entity extraction and labeling complete!\")\n",
        "    print(f\"Saved {len(df_all_diagnosis_entities)} entities and {len(diagnosis_relations)} relations\")\n",
        "    print(\"Diagnostic patterns exported to diagnostic_patterns.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>source_column</th>\n",
              "      <th>category</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bone marrow edema</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>109</td>\n",
              "      <td>126</td>\n",
              "      <td>Magnetic resonance imaging (MRI) scan performe...</td>\n",
              "      <td>133948</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>femoral head necrosis</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>148</td>\n",
              "      <td>169</td>\n",
              "      <td>Magnetic resonance imaging (MRI) scan performe...</td>\n",
              "      <td>133948</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Idiopathic osteonecrosis of the femoral head P...</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>207</td>\n",
              "      <td>263</td>\n",
              "      <td>Magnetic resonance imaging (MRI) scan performe...</td>\n",
              "      <td>133948</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pain</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>284</td>\n",
              "      <td>288</td>\n",
              "      <td>Magnetic resonance imaging (MRI) scan performe...</td>\n",
              "      <td>133948</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fracture</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>84</td>\n",
              "      <td>92</td>\n",
              "      <td>Radiographs performed with Minimally displaced...</td>\n",
              "      <td>80176</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334420</th>\n",
              "      <td>right</td>\n",
              "      <td>LATERALITY</td>\n",
              "      <td>128</td>\n",
              "      <td>133</td>\n",
              "      <td>Transthoracic echocardiogram performed with Ej...</td>\n",
              "      <td>97973</td>\n",
              "      <td>NaN</td>\n",
              "      <td>laterality</td>\n",
              "      <td>laterality_extraction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334421</th>\n",
              "      <td>Blood cultures</td>\n",
              "      <td>TEST</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>Blood cultures performed with nan severity sho...</td>\n",
              "      <td>97973</td>\n",
              "      <td>NaN</td>\n",
              "      <td>diagnostic_test</td>\n",
              "      <td>test_column</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334422</th>\n",
              "      <td>Transesophageal echocardiogram</td>\n",
              "      <td>TEST</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>Transesophageal echocardiogram performed with ...</td>\n",
              "      <td>97973</td>\n",
              "      <td>NaN</td>\n",
              "      <td>diagnostic_test</td>\n",
              "      <td>test_column</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334423</th>\n",
              "      <td>Acute severe aortic insufficiency from endocar...</td>\n",
              "      <td>CONDITION</td>\n",
              "      <td>145</td>\n",
              "      <td>196</td>\n",
              "      <td>Transesophageal echocardiogram performed with ...</td>\n",
              "      <td>97973</td>\n",
              "      <td>NaN</td>\n",
              "      <td>diagnosis</td>\n",
              "      <td>condition_column</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334424</th>\n",
              "      <td>left</td>\n",
              "      <td>LATERALITY</td>\n",
              "      <td>103</td>\n",
              "      <td>107</td>\n",
              "      <td>Transesophageal echocardiogram performed with ...</td>\n",
              "      <td>97973</td>\n",
              "      <td>NaN</td>\n",
              "      <td>laterality</td>\n",
              "      <td>laterality_extraction</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>334425 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text       label  start  \\\n",
              "0                                       bone marrow edema     DISEASE    109   \n",
              "1                                   femoral head necrosis     DISEASE    148   \n",
              "2       Idiopathic osteonecrosis of the femoral head P...     DISEASE    207   \n",
              "3                                                    pain     DISEASE    284   \n",
              "4                                                fracture     DISEASE     84   \n",
              "...                                                   ...         ...    ...   \n",
              "334420                                              right  LATERALITY    128   \n",
              "334421                                     Blood cultures        TEST      0   \n",
              "334422                     Transesophageal echocardiogram        TEST      0   \n",
              "334423  Acute severe aortic insufficiency from endocar...   CONDITION    145   \n",
              "334424                                               left  LATERALITY    103   \n",
              "\n",
              "        end                                      original_text  row_idx  \\\n",
              "0       126  Magnetic resonance imaging (MRI) scan performe...   133948   \n",
              "1       169  Magnetic resonance imaging (MRI) scan performe...   133948   \n",
              "2       263  Magnetic resonance imaging (MRI) scan performe...   133948   \n",
              "3       288  Magnetic resonance imaging (MRI) scan performe...   133948   \n",
              "4        92  Radiographs performed with Minimally displaced...    80176   \n",
              "...     ...                                                ...      ...   \n",
              "334420  133  Transthoracic echocardiogram performed with Ej...    97973   \n",
              "334421   14  Blood cultures performed with nan severity sho...    97973   \n",
              "334422   30  Transesophageal echocardiogram performed with ...    97973   \n",
              "334423  196  Transesophageal echocardiogram performed with ...    97973   \n",
              "334424  107  Transesophageal echocardiogram performed with ...    97973   \n",
              "\n",
              "        source_column         category                 source  \n",
              "0       combined_text              NaN                    NaN  \n",
              "1       combined_text              NaN                    NaN  \n",
              "2       combined_text              NaN                    NaN  \n",
              "3       combined_text              NaN                    NaN  \n",
              "4       combined_text              NaN                    NaN  \n",
              "...               ...              ...                    ...  \n",
              "334420            NaN       laterality  laterality_extraction  \n",
              "334421            NaN  diagnostic_test            test_column  \n",
              "334422            NaN  diagnostic_test            test_column  \n",
              "334423            NaN        diagnosis       condition_column  \n",
              "334424            NaN       laterality  laterality_extraction  \n",
              "\n",
              "[334425 rows x 9 columns]"
            ]
          },
          "execution_count": 150,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_all_diagnosis_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting Treatments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>has_treatments</th>\n",
              "      <th>name</th>\n",
              "      <th>related condition</th>\n",
              "      <th>dosage</th>\n",
              "      <th>time</th>\n",
              "      <th>frequency</th>\n",
              "      <th>duration</th>\n",
              "      <th>reason for taking</th>\n",
              "      <th>reaction to treatment</th>\n",
              "      <th>details</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155216</td>\n",
              "      <td>True</td>\n",
              "      <td>Olanzapine tablets</td>\n",
              "      <td>Bipolar affective disorder</td>\n",
              "      <td>5 mg per day</td>\n",
              "      <td>Past four months</td>\n",
              "      <td>Daily</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Control of exacerbated mental illness</td>\n",
              "      <td>Pain and discomfort in neck, sustained and abn...</td>\n",
              "      <td>Previously managed with olanzapine tablets in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>155216</td>\n",
              "      <td>True</td>\n",
              "      <td>Trihexyphenidyl</td>\n",
              "      <td>Rigidity in upper limbs</td>\n",
              "      <td>4 mg per day</td>\n",
              "      <td>Brief period of around three weeks</td>\n",
              "      <td>Daily</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Rigidity in upper limbs</td>\n",
              "      <td>Good response</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133948</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80176</td>\n",
              "      <td>True</td>\n",
              "      <td>Closed treatment in a cast</td>\n",
              "      <td>Proximal ulnar shaft fracture</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Initially after the fall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>To treat the ulnar shaft fracture</td>\n",
              "      <td>Developed a hypertrophic nonunion</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>80176</td>\n",
              "      <td>True</td>\n",
              "      <td>Conservative treatment</td>\n",
              "      <td>Ulna nonunion</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Three months after the fall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>An additional three months</td>\n",
              "      <td>To treat the ulna nonunion</td>\n",
              "      <td>Worsening motion through the nonunion site</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50421</th>\n",
              "      <td>98004</td>\n",
              "      <td>True</td>\n",
              "      <td>Hypovolaemic shock treatment</td>\n",
              "      <td>Haemodynamic instability and hypovolaemic shock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>To maintain blood pressure and treat shock</td>\n",
              "      <td>Required large doses of vasopressor and blood ...</td>\n",
              "      <td>Treatment given after becoming haemodynamicall...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50422</th>\n",
              "      <td>133320</td>\n",
              "      <td>True</td>\n",
              "      <td>Systemic chemotherapy</td>\n",
              "      <td>Lung and bone metastases</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>To treat lung and bone metastases</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Using doxorubicin and ifosfamide</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50423</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Rapid sequence intubation</td>\n",
              "      <td>Cardiogenic shock and flash pulmonary edema</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>To manage suspected cardiogenic shock and flas...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50424</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Advanced cardiac life support (ACLS) protocol</td>\n",
              "      <td>Cardiac arrest</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13 min</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>To restore return of spontaneous circulation a...</td>\n",
              "      <td>Return of spontaneous circulation was restored</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50425</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Intravenous nafcillin</td>\n",
              "      <td>Endocarditis</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Postoperative</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>To treat S.\\nlugdunensis infection</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Patient was discharged home on intravenous naf...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50426 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          idx  has_treatments                                           name  \\\n",
              "0      155216            True                             Olanzapine tablets   \n",
              "1      155216            True                                Trihexyphenidyl   \n",
              "2      133948           False                                            NaN   \n",
              "3       80176            True                     Closed treatment in a cast   \n",
              "4       80176            True                         Conservative treatment   \n",
              "...       ...             ...                                            ...   \n",
              "50421   98004            True                   Hypovolaemic shock treatment   \n",
              "50422  133320            True                          Systemic chemotherapy   \n",
              "50423   97973            True                      Rapid sequence intubation   \n",
              "50424   97973            True  Advanced cardiac life support (ACLS) protocol   \n",
              "50425   97973            True                          Intravenous nafcillin   \n",
              "\n",
              "                                     related condition        dosage  \\\n",
              "0                           Bipolar affective disorder  5 mg per day   \n",
              "1                              Rigidity in upper limbs  4 mg per day   \n",
              "2                                                  NaN           NaN   \n",
              "3                        Proximal ulnar shaft fracture           NaN   \n",
              "4                                        Ulna nonunion           NaN   \n",
              "...                                                ...           ...   \n",
              "50421  Haemodynamic instability and hypovolaemic shock           NaN   \n",
              "50422                         Lung and bone metastases           NaN   \n",
              "50423      Cardiogenic shock and flash pulmonary edema           NaN   \n",
              "50424                                   Cardiac arrest           NaN   \n",
              "50425                                     Endocarditis           NaN   \n",
              "\n",
              "                                     time frequency  \\\n",
              "0                        Past four months     Daily   \n",
              "1      Brief period of around three weeks     Daily   \n",
              "2                                     NaN       NaN   \n",
              "3                Initially after the fall       NaN   \n",
              "4             Three months after the fall       NaN   \n",
              "...                                   ...       ...   \n",
              "50421                                 NaN       NaN   \n",
              "50422                                 NaN       NaN   \n",
              "50423                                 NaN       NaN   \n",
              "50424                              13 min       NaN   \n",
              "50425                       Postoperative       NaN   \n",
              "\n",
              "                         duration  \\\n",
              "0                             NaN   \n",
              "1                             NaN   \n",
              "2                             NaN   \n",
              "3                             NaN   \n",
              "4      An additional three months   \n",
              "...                           ...   \n",
              "50421                         NaN   \n",
              "50422                         NaN   \n",
              "50423                         NaN   \n",
              "50424                         NaN   \n",
              "50425                         NaN   \n",
              "\n",
              "                                       reason for taking  \\\n",
              "0                  Control of exacerbated mental illness   \n",
              "1                                Rigidity in upper limbs   \n",
              "2                                                    NaN   \n",
              "3                      To treat the ulnar shaft fracture   \n",
              "4                             To treat the ulna nonunion   \n",
              "...                                                  ...   \n",
              "50421         To maintain blood pressure and treat shock   \n",
              "50422                  To treat lung and bone metastases   \n",
              "50423  To manage suspected cardiogenic shock and flas...   \n",
              "50424  To restore return of spontaneous circulation a...   \n",
              "50425                 To treat S.\\nlugdunensis infection   \n",
              "\n",
              "                                   reaction to treatment  \\\n",
              "0      Pain and discomfort in neck, sustained and abn...   \n",
              "1                                          Good response   \n",
              "2                                                    NaN   \n",
              "3                      Developed a hypertrophic nonunion   \n",
              "4             Worsening motion through the nonunion site   \n",
              "...                                                  ...   \n",
              "50421  Required large doses of vasopressor and blood ...   \n",
              "50422                                                NaN   \n",
              "50423                                                NaN   \n",
              "50424     Return of spontaneous circulation was restored   \n",
              "50425                                                NaN   \n",
              "\n",
              "                                                 details  \n",
              "0      Previously managed with olanzapine tablets in ...  \n",
              "1                                                    NaN  \n",
              "2                                                    NaN  \n",
              "3                                                    NaN  \n",
              "4                                                    NaN  \n",
              "...                                                  ...  \n",
              "50421  Treatment given after becoming haemodynamicall...  \n",
              "50422                   Using doxorubicin and ifosfamide  \n",
              "50423                                                NaN  \n",
              "50424                                                NaN  \n",
              "50425  Patient was discharged home on intravenous naf...  \n",
              "\n",
              "[50426 rows x 11 columns]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_treatments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_treatment_text(row):\n",
        "    \"\"\"Create comprehensive text from treatment row\"\"\"\n",
        "    parts = []\n",
        "    \n",
        "    if pd.notna(row.get('name')) and str(row['name']) != 'NaN':\n",
        "        parts.append(f\"Treatment: {row['name']}\")\n",
        "    \n",
        "    if pd.notna(row.get('related condition')) and str(row['related condition']) != 'NaN':\n",
        "        parts.append(f\"for {row['related condition']}\")\n",
        "    \n",
        "    if pd.notna(row.get('dosage')) and str(row['dosage']) != 'NaN':\n",
        "        parts.append(f\"dosage {row['dosage']}\")\n",
        "    \n",
        "    if pd.notna(row.get('frequency')) and str(row['frequency']) != 'NaN':\n",
        "        parts.append(f\"frequency {row['frequency']}\")\n",
        "    \n",
        "    if pd.notna(row.get('time')) and str(row['time']) != 'NaN':\n",
        "        parts.append(f\"time {row['time']}\")\n",
        "    \n",
        "    if pd.notna(row.get('duration')) and str(row['duration']) != 'NaN':\n",
        "        parts.append(f\"duration {row['duration']}\")\n",
        "    \n",
        "    if pd.notna(row.get('reason for taking')) and str(row['reason for taking']) != 'NaN':\n",
        "        parts.append(f\"reason: {row['reason for taking']}\")\n",
        "    \n",
        "    if pd.notna(row.get('reaction to treatment')) and str(row['reaction to treatment']) != 'NaN':\n",
        "        parts.append(f\"reaction: {row['reaction to treatment']}\")\n",
        "    \n",
        "    if pd.notna(row.get('details')) and str(row['details']) != 'NaN':\n",
        "        parts.append(f\"details: {row['details']}\")\n",
        "    \n",
        "    return \" \".join(parts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing temporal column: time\n",
            "\n",
            "Processing temporal column: duration\n",
            "\n",
            "Temporal extraction results:\n",
            "Duration extracted from 'time' column: 5037 rows\n",
            "Temporal types: {'unspecified': 6645, 'post_event': 5777, 'range_reference': 2315, 'past_reference': 2193, 'onset_reference': 2007, 'absolute_date': 1267, 'duration_reference': 914}\n",
            "Loading en_ner_bc5cdr_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 50426 texts in 169 batches...\n",
            "Using model: en_ner_bc5cdr_md for column: combined_text\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   1%|          | 1/169 [00:02<06:22,  2.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   7%|▋         | 11/169 [00:15<03:36,  1.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 3000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  12%|█▏        | 21/169 [00:28<03:24,  1.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 6000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  18%|█▊        | 31/169 [00:42<03:12,  1.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 9000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  24%|██▍       | 41/169 [00:55<02:57,  1.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 12000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  30%|███       | 51/169 [01:08<02:41,  1.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  36%|███▌      | 61/169 [01:21<02:25,  1.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 18000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  42%|████▏     | 71/169 [01:34<02:18,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 21000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  48%|████▊     | 81/169 [01:47<02:03,  1.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 24000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  54%|█████▍    | 91/169 [02:00<01:51,  1.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 27000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  60%|█████▉    | 101/169 [02:14<01:39,  1.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 30000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  66%|██████▌   | 111/169 [02:27<01:23,  1.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 33000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  72%|███████▏  | 121/169 [02:40<01:10,  1.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 36000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  78%|███████▊  | 131/169 [02:53<00:56,  1.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 39000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  83%|████████▎ | 141/169 [03:07<00:42,  1.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 42000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  89%|████████▉ | 151/169 [03:21<00:27,  1.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 45000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  95%|█████████▌| 161/169 [03:34<00:12,  1.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 48000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 169/169 [03:43<00:00,  1.32s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3696 entities appearing >= 5 times\n",
            "\n",
            "=== BC5CDR Entity Types Found ===\n",
            "{'DISEASE': 80940, 'CHEMICAL': 37907}\n",
            "\n",
            "=== CUSTOM SYMPTOM ENTITY EXTRACTION ===\n",
            "\n",
            "=== COMBINED Entity Distribution ===\n",
            "label\n",
            "DISEASE               80940\n",
            "TREATMENT             44086\n",
            "CONDITION             43157\n",
            "CHEMICAL              37907\n",
            "TREATMENT_TYPE        23652\n",
            "ROUTE                 18590\n",
            "TREATMENT_REASON      16765\n",
            "CONDITION_TYPE        13410\n",
            "DOSAGE                12320\n",
            "TEMPORAL_PATTERN      12264\n",
            "TREATMENT_RESPONSE     7463\n",
            "FREQUENCY              6705\n",
            "MEDICATION             1921\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Treatments ===\n",
            "text\n",
            "Antibiotics                502\n",
            "Chemotherapy               499\n",
            "Surgery                    272\n",
            "Conservative treatment     271\n",
            "Aspirin                    268\n",
            "Surgical excision          263\n",
            "Blood transfusion          251\n",
            "Conservative management    244\n",
            "Prednisone                 206\n",
            "Surgical resection         170\n",
            "Intravenous antibiotics    159\n",
            "Radiotherapy               153\n",
            "Adjuvant chemotherapy      149\n",
            "Prednisolone               146\n",
            "Dexamethasone              137\n",
            "Radiation therapy          133\n",
            "Warfarin                   133\n",
            "Surgical treatment         131\n",
            "Surgical intervention      131\n",
            "Intubation                 120\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Medications ===\n",
            "text\n",
            "vancomycin         326\n",
            "ceftriaxone        263\n",
            "amoxicillin        199\n",
            "ibuprofen          127\n",
            "acetaminophen      120\n",
            "risperidone        103\n",
            "morphine            98\n",
            "olanzapine          97\n",
            "penicillin          92\n",
            "vasopressor         81\n",
            "haloperidol         71\n",
            "fentanyl            64\n",
            "quetiapine          63\n",
            "oxycodone           45\n",
            "clozapine           40\n",
            "baclofen            33\n",
            "beta blocker        32\n",
            "inotrope            23\n",
            "trihexyphenidyl     17\n",
            "ace inhibitor       15\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Conditions Treated ===\n",
            "text\n",
            "Hypertension            419\n",
            "Pain management         112\n",
            "Hypotension             111\n",
            "Seizures                109\n",
            "Breast cancer           108\n",
            "Infection               108\n",
            "Respiratory distress    102\n",
            "Epilepsy                102\n",
            "Cardiac arrest           99\n",
            "Postoperative care       92\n",
            "Atrial fibrillation      90\n",
            "Schizophrenia            90\n",
            "Suspected infection      84\n",
            "Anemia                   84\n",
            "Hypothyroidism           74\n",
            "Abdominal pain           74\n",
            "Septic shock             73\n",
            "Pneumonia                69\n",
            "Metastatic melanoma      69\n",
            "Headache                 66\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Dosage Distribution ===\n",
            "text\n",
            "daily      1088\n",
            "/day        939\n",
            "10 mg       531\n",
            "500 mg      506\n",
            "100 mg      505\n",
            "50 mg       466\n",
            "5 mg        435\n",
            "20 mg       393\n",
            "40 mg       340\n",
            "per day     333\n",
            "1 mg        286\n",
            "200 mg      275\n",
            "400 mg      266\n",
            "60 mg       230\n",
            "300 mg      219\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Treatment Response Distribution ===\n",
            "category\n",
            "positive    3402\n",
            "neutral     2262\n",
            "negative    1615\n",
            "partial      184\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Treatment Type Distribution ===\n",
            "category\n",
            "procedure       11834\n",
            "medication       3602\n",
            "chemotherapy     3338\n",
            "supportive       2558\n",
            "conservative      933\n",
            "emergency         905\n",
            "diagnostic        482\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Creating Treatment-Specific Labeling Functions ===\n",
            "\n",
            "Testing treatment labeling functions:\n",
            "\n",
            "Row 0: Olanzapine tablets for Bipolar affective disorder\n",
            "  lf_has_treatment: HAS_TREATMENT\n",
            "  lf_medication_treatment: MEDICATION_TREATMENT\n",
            "  lf_psychiatric_treatment: PSYCHIATRIC_TREATMENT\n",
            "  lf_chronic_treatment: CHRONIC_TREATMENT\n",
            "  lf_daily_medication: DAILY_MEDICATION\n",
            "\n",
            "Row 1: Trihexyphenidyl for Rigidity in upper limbs\n",
            "  lf_has_treatment: HAS_TREATMENT\n",
            "  lf_medication_treatment: MEDICATION_TREATMENT\n",
            "  lf_psychiatric_treatment: PSYCHIATRIC_TREATMENT\n",
            "  lf_daily_medication: DAILY_MEDICATION\n",
            "  lf_positive_response: POSITIVE_RESPONSE\n",
            "\n",
            "Row 2: nan for nan\n",
            "  lf_has_treatment: NO_TREATMENT\n",
            "\n",
            "Row 3: Closed treatment in a cast for Proximal ulnar shaft fracture\n",
            "  lf_has_treatment: HAS_TREATMENT\n",
            "  lf_conservative_treatment: CONSERVATIVE_TREATMENT\n",
            "\n",
            "Row 4: Conservative treatment for Ulna nonunion\n",
            "  lf_has_treatment: HAS_TREATMENT\n",
            "  lf_chronic_treatment: CHRONIC_TREATMENT\n",
            "  lf_conservative_treatment: CONSERVATIVE_TREATMENT\n",
            "  lf_treatment_duration: LONG_TERM_TREATMENT\n",
            "\n",
            "Row 5: Diclofenac sodium for Bone marrow edema\n",
            "  lf_has_treatment: HAS_TREATMENT\n",
            "  lf_medication_treatment: MEDICATION_TREATMENT\n",
            "  lf_daily_medication: DAILY_MEDICATION\n",
            "  lf_positive_response: POSITIVE_RESPONSE\n",
            "\n",
            "Row 6: NSAIDs and physiotherapy for Bone marrow edema\n",
            "  lf_has_treatment: HAS_TREATMENT\n",
            "  lf_chronic_treatment: CHRONIC_TREATMENT\n",
            "\n",
            "Row 7: Conservative treatment for Bone marrow edema\n",
            "  lf_has_treatment: HAS_TREATMENT\n",
            "  lf_conservative_treatment: CONSERVATIVE_TREATMENT\n",
            "\n",
            "Row 8: Calcium and vitamin D for Osteomalacia\n",
            "  lf_has_treatment: HAS_TREATMENT\n",
            "\n",
            "Row 9: Calcitriol for Osteomalacia\n",
            "  lf_has_treatment: HAS_TREATMENT\n",
            "  lf_medication_treatment: MEDICATION_TREATMENT\n",
            "\n",
            "=== Extracting Treatment Relations ===\n",
            "Found 152806 treatment relations\n",
            "\n",
            "Relation type distribution:\n",
            "type\n",
            "TREATMENT_FOR_CONDITION       42750\n",
            "TREATMENT_HAS_REASON          41924\n",
            "TREATMENT_HAS_RESPONSE        21548\n",
            "TREATMENT_TEMPORAL_PATTERN    21101\n",
            "TREATMENT_HAS_DOSAGE          11968\n",
            "TREATMENT_HAS_FREQUENCY        9343\n",
            "TREATMENT_HAS_DURATION         4172\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sample relations:\n",
            "  Olanzapine tablets -> treats -> Bipolar affective disorder\n",
            "  Olanzapine tablets -> dosage -> 5 mg per day\n",
            "  Olanzapine tablets -> response -> Pain and discomfort in neck, sustained and abnormal contraction of neck muscles, requiring assistance in daily chores\n",
            "  Trihexyphenidyl -> treats -> Rigidity in upper limbs\n",
            "  Trihexyphenidyl -> dosage -> 4 mg per day\n",
            "  Trihexyphenidyl -> response -> Good response\n",
            "\n",
            "=== Labeling Function Coverage Analysis ===\n",
            "\n",
            "Labeling function coverage:\n",
            "  lf_has_treatment: 50426 labels (100.0% coverage)\n",
            "  lf_medication_treatment: 8350 labels (16.6% coverage)\n",
            "  lf_cancer_treatment: 4864 labels (9.6% coverage)\n",
            "  lf_surgical_treatment: 4502 labels (8.9% coverage)\n",
            "  lf_infection_treatment: 4194 labels (8.3% coverage)\n",
            "  lf_treatment_duration: 4173 labels (8.3% coverage)\n",
            "  lf_chronic_treatment: 3880 labels (7.7% coverage)\n",
            "  lf_daily_medication: 3569 labels (7.1% coverage)\n",
            "  lf_positive_response: 3336 labels (6.6% coverage)\n",
            "  lf_emergency_treatment: 1377 labels (2.7% coverage)\n",
            "  lf_cardiovascular_treatment: 1197 labels (2.4% coverage)\n",
            "  lf_conservative_treatment: 736 labels (1.5% coverage)\n",
            "  lf_psychiatric_treatment: 733 labels (1.5% coverage)\n",
            "\n",
            "=== Additional Treatment Analysis ===\n",
            "\n",
            "Has treatments distribution:\n",
            "has_treatments\n",
            "True     44790\n",
            "False     5636\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Frequency Distribution ===\n",
            "text\n",
            "daily           3367\n",
            "every           1064\n",
            "once             771\n",
            "twice daily      585\n",
            "three times      343\n",
            "continuous       208\n",
            "as needed        164\n",
            "bid               92\n",
            "intermittent      52\n",
            "tid               35\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Route of Administration ===\n",
            "text\n",
            "iv               6823\n",
            "im               4937\n",
            "intravenous      2817\n",
            "oral             2738\n",
            "topical           520\n",
            "nasal             229\n",
            "subcutaneous      221\n",
            "intramuscular     160\n",
            "inhaled            94\n",
            "rectal             51\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n",
            "Treatment entity extraction and labeling complete!\n",
            "Saved 319180 entities and 152806 relations\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Use the global TemporalStandardizer class \n",
        "    temporal_standardizer = TemporalStandardizer()\n",
        "\n",
        "    # Process temporal information using the standardize_temporal_column method\n",
        "    df_treatments_processed, temporal_report = temporal_standardizer.standardize_temporal_column(\n",
        "        df_treatments, \n",
        "        'time'\n",
        "    )\n",
        "    \n",
        "    # Process duration column as well\n",
        "    df_treatments_processed, duration_report = temporal_standardizer.standardize_temporal_column(\n",
        "        df_treatments_processed, \n",
        "        'duration'\n",
        "    )\n",
        "\n",
        "    # Ensure original idx is preserved in the processed dataframe\n",
        "    if ('idx' in df_treatments.columns) and ('idx' not in df_treatments_processed.columns):\n",
        "        df_treatments_processed['idx'] = df_treatments['idx']\n",
        "\n",
        "    print(f\"\\nTemporal extraction results:\")\n",
        "    print(f\"Duration extracted from 'time' column: {temporal_report['extracted_durations']} rows\")\n",
        "    print(f\"Temporal types: {temporal_report['temporal_types']}\")\n",
        "\n",
        "    # Combine treatments information into comprehensive text\n",
        "    df_treatments_processed['combined_text'] = df_treatments_processed.apply(\n",
        "        lambda row: create_treatment_text(row),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Run NER extraction with BC5CDR\n",
        "    df_treatments_entities, treatments_summary, treatments_rules = run_medical_ner_extraction(\n",
        "        df_treatments_processed,\n",
        "        text_column='combined_text',\n",
        "        model_name=\"en_ner_bc5cdr_md\",\n",
        "        batch_size=300,\n",
        "        id_column='idx'\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== BC5CDR Entity Types Found ===\")\n",
        "    print(treatments_summary['entity_types'])\n",
        "\n",
        "    # Custom entity extraction for treatment-specific entities (keeps correct row_idx)\n",
        "    print(\"\\n=== CUSTOM TREATMENT ENTITY EXTRACTION ===\")\n",
        "\n",
        "    def extract_treatment_entities_custom(df_treatments):\n",
        "        \"\"\"Extract treatment-specific entities not caught by BC5CDR.\n",
        "           Uses 'idx' for row identity when available; falls back to df.index otherwise.\n",
        "           Adds 'row_idx' to every extracted entity.\n",
        "        \"\"\"\n",
        "        custom_entities = []\n",
        "        \n",
        "        # Treatment type patterns\n",
        "        treatment_type_patterns = {\n",
        "            'medication': ['tablet', 'tablets', 'pill', 'pills', 'capsule', 'injection', 'infusion', 'medication', 'drug'],\n",
        "            'procedure': ['surgery', 'surgical', 'operation', 'procedure', 'therapy', 'intubation', 'resection', 'removal', 'repair'],\n",
        "            'supportive': ['support', 'life support', 'ventilation', 'oxygen', 'fluid', 'nutrition', 'acls', 'protocol'],\n",
        "            'chemotherapy': ['chemotherapy', 'chemo', 'cytotoxic', 'antineoplastic', 'systemic chemotherapy'],\n",
        "            'conservative': ['conservative', 'non-operative', 'non-surgical', 'observation', 'closed treatment'],\n",
        "            'emergency': ['emergency', 'urgent', 'rapid', 'resuscitation', 'life-saving'],\n",
        "            'diagnostic': ['biopsy', 'exploration', 'diagnostic', 'assessment']\n",
        "        }\n",
        "        \n",
        "        # Drug/medication patterns\n",
        "        medication_patterns = {\n",
        "            'antipsychotic': ['olanzapine', 'risperidone', 'quetiapine', 'haloperidol', 'clozapine'],\n",
        "            'muscle_relaxant': ['trihexyphenidyl', 'baclofen', 'tizanidine', 'cyclobenzaprine'],\n",
        "            'antibiotic': ['nafcillin', 'vancomycin', 'ceftriaxone', 'penicillin', 'amoxicillin'],\n",
        "            'cardiovascular': ['vasopressor', 'inotrope', 'beta blocker', 'ace inhibitor', 'hypovolaemic'],\n",
        "            'analgesic': ['morphine', 'fentanyl', 'oxycodone', 'acetaminophen', 'ibuprofen']\n",
        "        }\n",
        "        \n",
        "        # Condition patterns (treated conditions)\n",
        "        condition_patterns = {\n",
        "            'psychiatric': ['bipolar', 'affective disorder', 'psychosis', 'mania', 'depression', 'mental illness'],\n",
        "            'orthopedic': ['fracture', 'joint', 'bone', 'hip', 'knee', 'spine', 'ulnar shaft'],\n",
        "            'cardiovascular': ['cardiac', 'heart', 'arrhythmia', 'shock', 'arrest', 'hypovolaemic', 'endocarditis'],\n",
        "            'oncological': ['cancer', 'metastases', 'tumor', 'malignancy', 'carcinoma'],\n",
        "            'neurological': ['rigidity', 'tremor', 'paralysis', 'nerve', 'neurological'],\n",
        "            'infectious': ['infection', 'sepsis', 'endocarditis', 'abscess', 'pneumonia']\n",
        "        }\n",
        "        \n",
        "        # Dosage unit patterns\n",
        "        dosage_patterns = {\n",
        "            'mg': r'\\b(\\d+\\.?\\d*)\\s*mg\\b',\n",
        "            'mcg': r'\\b(\\d+\\.?\\d*)\\s*mcg\\b',\n",
        "            'units': r'\\b(\\d+\\.?\\d*)\\s*units?\\b',\n",
        "            'ml': r'\\b(\\d+\\.?\\d*)\\s*ml\\b',\n",
        "            'per_day': r'\\b(?:per\\s*day|/day|daily)\\b',\n",
        "            'min': r'\\b(\\d+\\.?\\d*)\\s*min(?:utes?)?\\b'\n",
        "        }\n",
        "        \n",
        "        # Frequency patterns\n",
        "        frequency_terms = ['daily', 'twice daily', 'three times', 'qid', 'bid', 'tid', 'prn', \n",
        "                           'as needed', 'every', 'once', 'continuous', 'intermittent']\n",
        "        \n",
        "        # Route of administration patterns\n",
        "        route_terms = ['oral', 'intravenous', 'iv', 'im', 'intramuscular', 'subcutaneous', \n",
        "                       'topical', 'inhaled', 'nasal', 'rectal']\n",
        "        \n",
        "        # Treatment response/outcome patterns\n",
        "        response_patterns = {\n",
        "            'positive': ['good response', 'improved', 'resolved', 'successful', 'effective', \n",
        "                         'restored', 'return of', 'recovered'],\n",
        "            'negative': ['worsening', 'failed', 'no response', 'adverse', 'side effect', \n",
        "                         'complication', 'deterioration'],\n",
        "            'neutral': ['no change', 'stable', 'maintained', 'sustained', 'continued'],\n",
        "            'partial': ['partial response', 'some improvement', 'limited response']\n",
        "        }\n",
        "        \n",
        "        # Temporal patterns specific to treatments\n",
        "        temporal_patterns = {\n",
        "            'acute': ['acute', 'sudden', 'rapid', 'emergency', 'immediate'],\n",
        "            'chronic': ['chronic', 'long-term', 'maintenance', 'ongoing', 'continuous'],\n",
        "            'perioperative': ['preoperative', 'postoperative', 'intraoperative', 'perioperative'],\n",
        "            'duration': ['months', 'weeks', 'days', 'hours', 'years']\n",
        "        }\n",
        "        \n",
        "        for df_index, row in df_treatments.iterrows():\n",
        "            # ---- choose the correct row id from 'idx' with fallback to the DataFrame index\n",
        "            row_id = row['idx'] if ('idx' in row and pd.notna(row['idx'])) else df_index\n",
        "\n",
        "            # Get relevant text fields with safe string conversion\n",
        "            name_orig = str(row.get('name', ''))\n",
        "            name = name_orig.lower() if pd.notna(row.get('name')) else ''\n",
        "            condition_orig = str(row.get('related condition', ''))\n",
        "            condition = condition_orig.lower() if pd.notna(row.get('related condition')) else ''\n",
        "            dosage_orig = str(row.get('dosage', ''))\n",
        "            dosage = dosage_orig.lower() if pd.notna(row.get('dosage')) else ''\n",
        "            frequency_orig = str(row.get('frequency', ''))\n",
        "            frequency = frequency_orig.lower() if pd.notna(row.get('frequency')) else ''\n",
        "            time_orig = str(row.get('time', ''))\n",
        "            time_l = time_orig.lower() if pd.notna(row.get('time')) else ''\n",
        "            duration_orig = str(row.get('duration', ''))\n",
        "            duration_l = duration_orig.lower() if pd.notna(row.get('duration')) else ''\n",
        "            reason_orig = str(row.get('reason for taking', ''))\n",
        "            reason = reason_orig.lower() if pd.notna(row.get('reason for taking')) else ''\n",
        "            reaction_orig = str(row.get('reaction to treatment', ''))\n",
        "            reaction = reaction_orig.lower() if pd.notna(row.get('reaction to treatment')) else ''\n",
        "            details_orig = str(row.get('details', ''))\n",
        "            details = details_orig.lower() if pd.notna(row.get('details')) else ''\n",
        "            combined_orig = str(row.get('combined_text', ''))\n",
        "            combined = combined_orig.lower()\n",
        "\n",
        "            # Primary TREATMENT from name column (position in combined if possible)\n",
        "            if name and name != 'nan':\n",
        "                start = combined.find(name)\n",
        "                if start < 0:\n",
        "                    start = 0\n",
        "                end = min(start + len(name_orig), len(combined_orig))\n",
        "                custom_entities.append({\n",
        "                    'text': name_orig,\n",
        "                    'label': 'TREATMENT',\n",
        "                    'category': 'primary_treatment',\n",
        "                    'start': start,\n",
        "                    'end': end,\n",
        "                    'original_text': combined_orig if combined_orig else name_orig,\n",
        "                    'source': 'name_column',\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "            \n",
        "            # CONDITION (indication)\n",
        "            if condition and condition != 'nan':\n",
        "                start = combined.find(condition)\n",
        "                if start < 0:\n",
        "                    start = 0\n",
        "                end = min(start + len(condition_orig), len(combined_orig))\n",
        "                custom_entities.append({\n",
        "                    'text': condition_orig,\n",
        "                    'label': 'CONDITION',\n",
        "                    'category': 'treatment_indication',\n",
        "                    'start': start,\n",
        "                    'end': end,\n",
        "                    'original_text': combined_orig if combined_orig else condition_orig,\n",
        "                    'source': 'condition_column',\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "            \n",
        "            # TREATMENT_TYPE (search in combined)\n",
        "            for category, terms in treatment_type_patterns.items():\n",
        "                for term in terms:\n",
        "                    pattern = r'\\b' + re.escape(term) + r'\\b'\n",
        "                    for m in re.finditer(pattern, combined):\n",
        "                        custom_entities.append({\n",
        "                            'text': combined_orig[m.start():m.end()],\n",
        "                            'label': 'TREATMENT_TYPE',\n",
        "                            'category': category,\n",
        "                            'start': m.start(),\n",
        "                            'end': m.end(),\n",
        "                            'original_text': combined_orig,\n",
        "                            'source': 'pattern_matching',\n",
        "                            'row_idx': row_id\n",
        "                        })\n",
        "            \n",
        "            # MEDICATION names/classes (search in combined)\n",
        "            for drug_class, drugs in medication_patterns.items():\n",
        "                for drug in drugs:\n",
        "                    pattern = r'\\b' + re.escape(drug) + r'\\b'\n",
        "                    for m in re.finditer(pattern, combined):\n",
        "                        custom_entities.append({\n",
        "                            'text': combined_orig[m.start():m.end()],\n",
        "                            'label': 'MEDICATION',\n",
        "                            'category': drug_class,\n",
        "                            'start': m.start(),\n",
        "                            'end': m.end(),\n",
        "                            'original_text': combined_orig,\n",
        "                            'source': 'medication_pattern',\n",
        "                            'row_idx': row_id\n",
        "                        })\n",
        "            \n",
        "            # DOSAGE (from dosage column)\n",
        "            if dosage and dosage != 'nan':\n",
        "                for unit, pattern in dosage_patterns.items():\n",
        "                    for match in re.finditer(pattern, dosage, re.IGNORECASE):\n",
        "                        custom_entities.append({\n",
        "                            'text': match.group(0),\n",
        "                            'label': 'DOSAGE',\n",
        "                            'category': unit,\n",
        "                            'start': match.start(),\n",
        "                            'end': match.end(),\n",
        "                            'original_text': dosage_orig,\n",
        "                            'source': 'dosage_column',\n",
        "                            'row_idx': row_id\n",
        "                        })\n",
        "            \n",
        "            # FREQUENCY (from frequency column)\n",
        "            if frequency and frequency != 'nan':\n",
        "                for freq_term in frequency_terms:\n",
        "                    pattern = r'\\b' + re.escape(freq_term) + r'\\b'\n",
        "                    for m in re.finditer(pattern, frequency):\n",
        "                        custom_entities.append({\n",
        "                            'text': frequency_orig[m.start():m.end()],\n",
        "                            'label': 'FREQUENCY',\n",
        "                            'category': 'dosing_frequency',\n",
        "                            'start': m.start(),\n",
        "                            'end': m.end(),\n",
        "                            'original_text': frequency_orig,\n",
        "                            'source': 'frequency_column',\n",
        "                            'row_idx': row_id\n",
        "                        })\n",
        "            \n",
        "            # ROUTE (search across combined context)\n",
        "            for route in route_terms:\n",
        "                pattern = r'\\b' + re.escape(route) + r'\\b'\n",
        "                for m in re.finditer(pattern, combined):\n",
        "                    custom_entities.append({\n",
        "                        'text': combined_orig[m.start():m.end()],\n",
        "                        'label': 'ROUTE',\n",
        "                        'category': 'administration_route',\n",
        "                        'start': m.start(),\n",
        "                        'end': m.end(),\n",
        "                        'original_text': combined_orig,\n",
        "                        'source': 'route_extraction',\n",
        "                        'row_idx': row_id\n",
        "                    })\n",
        "            \n",
        "            # TREATMENT_RESPONSE (reaction + details + combined)\n",
        "            response_text_orig = ' '.join([reaction_orig, details_orig, combined_orig])\n",
        "            response_text = response_text_orig.lower()\n",
        "            for response_type, patterns in response_patterns.items():\n",
        "                for phrase in patterns:\n",
        "                    pattern = r'\\b' + re.escape(phrase) + r'\\b'\n",
        "                    for m in re.finditer(pattern, response_text):\n",
        "                        custom_entities.append({\n",
        "                            'text': response_text_orig[m.start():m.end()],\n",
        "                            'label': 'TREATMENT_RESPONSE',\n",
        "                            'category': response_type,\n",
        "                            'start': m.start(),\n",
        "                            'end': m.end(),\n",
        "                            'original_text': response_text_orig,\n",
        "                            'source': 'response_extraction',\n",
        "                            'row_idx': row_id\n",
        "                        })\n",
        "            \n",
        "            # CONDITION_TYPE categories (condition or reason)\n",
        "            for condition_type, condition_terms in condition_patterns.items():\n",
        "                for term in condition_terms:\n",
        "                    pattern = r'\\b' + re.escape(term) + r'\\b'\n",
        "                    # search in condition text first, then reason, else combined\n",
        "                    found = False\n",
        "                    for text_orig, text_l, source in [\n",
        "                        (condition_orig, condition, 'condition_pattern'),\n",
        "                        (reason_orig, reason, 'reason_pattern'),\n",
        "                        (combined_orig, combined, 'combined_pattern'),\n",
        "                    ]:\n",
        "                        m = re.search(pattern, text_l)\n",
        "                        if m:\n",
        "                            custom_entities.append({\n",
        "                                'text': text_orig[m.start():m.end()],\n",
        "                                'label': 'CONDITION_TYPE',\n",
        "                                'category': condition_type,\n",
        "                                'start': m.start(),\n",
        "                                'end': m.end(),\n",
        "                                'original_text': text_orig,\n",
        "                                'source': source,\n",
        "                                'row_idx': row_id\n",
        "                            })\n",
        "                            found = True\n",
        "                            break\n",
        "            \n",
        "            # TEMPORAL_PATTERN\n",
        "            temporal_text_orig = ' '.join([time_orig, duration_orig, details_orig])\n",
        "            temporal_text = temporal_text_orig.lower()\n",
        "            for temp_category, temp_terms in temporal_patterns.items():\n",
        "                for term in temp_terms:\n",
        "                    pattern = r'\\b' + re.escape(term) + r'\\b'\n",
        "                    for m in re.finditer(pattern, temporal_text):\n",
        "                        custom_entities.append({\n",
        "                            'text': temporal_text_orig[m.start():m.end()],\n",
        "                            'label': 'TEMPORAL_PATTERN',\n",
        "                            'category': temp_category,\n",
        "                            'start': m.start(),\n",
        "                            'end': m.end(),\n",
        "                            'original_text': temporal_text_orig,\n",
        "                            'source': 'temporal_extraction',\n",
        "                            'row_idx': row_id\n",
        "                        })\n",
        "            \n",
        "            # TREATMENT_REASON (from reason column specific patterns)\n",
        "            if reason and reason != 'nan':\n",
        "                reason_patterns = [\n",
        "                    (r'to\\s+treat\\s+(\\w+(?:\\s+\\w+)*)', 'treatment_goal'),\n",
        "                    (r'to\\s+manage\\s+(\\w+(?:\\s+\\w+)*)', 'management_goal'),\n",
        "                    (r'control\\s+of\\s+(\\w+(?:\\s+\\w+)*)', 'control_goal'),\n",
        "                    (r'for\\s+(\\w+(?:\\s+\\w+)*)', 'indication')\n",
        "                ]\n",
        "                for pattern, category in reason_patterns:\n",
        "                    for match in re.finditer(pattern, reason, re.IGNORECASE):\n",
        "                        custom_entities.append({\n",
        "                            'text': match.group(0),\n",
        "                            'label': 'TREATMENT_REASON',\n",
        "                            'category': category,\n",
        "                            'start': match.start(),\n",
        "                            'end': match.end(),\n",
        "                            'original_text': reason_orig,\n",
        "                            'source': 'reason_column',\n",
        "                            'row_idx': row_id\n",
        "                        })\n",
        "        \n",
        "        return pd.DataFrame(custom_entities)\n",
        "\n",
        "    # Extract custom entities\n",
        "    df_custom_treatments_entities = extract_treatment_entities_custom(df_treatments_processed)\n",
        "\n",
        "    # Combine all entities (preserve row_idx/category when present)\n",
        "    df_all_treatments_entities = pd.concat(\n",
        "        [df_treatments_entities, df_custom_treatments_entities],\n",
        "        ignore_index=True,\n",
        "        sort=False\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== COMBINED Entity Distribution ===\")\n",
        "    if not df_all_treatments_entities.empty and 'label' in df_all_treatments_entities.columns:\n",
        "        print(df_all_treatments_entities['label'].value_counts())\n",
        "    else:\n",
        "        print(\"No combined entities to show.\")\n",
        "\n",
        "    # Analyze treatment entities\n",
        "    treatment_entities = df_all_treatments_entities[df_all_treatments_entities['label'] == 'TREATMENT'] if not df_all_treatments_entities.empty else pd.DataFrame()\n",
        "    if not treatment_entities.empty:\n",
        "        print(f\"\\n=== Top Treatments ===\")\n",
        "        print(treatment_entities['text'].str.lower().value_counts().head(20))\n",
        "\n",
        "    # Analyze medications\n",
        "    medication_entities = df_all_treatments_entities[df_all_treatments_entities['label'] == 'MEDICATION'] if not df_all_treatments_entities.empty else pd.DataFrame()\n",
        "    if not medication_entities.empty:\n",
        "        print(f\"\\n=== Top Medications ===\")\n",
        "        print(medication_entities['text'].str.lower().value_counts().head(20))\n",
        "\n",
        "    # Analyze conditions being treated\n",
        "    condition_entities = df_all_treatments_entities[df_all_treatments_entities['label'] == 'CONDITION'] if not df_all_treatments_entities.empty else pd.DataFrame()\n",
        "    if not condition_entities.empty:\n",
        "        print(f\"\\n=== Top Conditions Treated ===\")\n",
        "        print(condition_entities['text'].str.lower().value_counts().head(20))\n",
        "\n",
        "    # Analyze dosages\n",
        "    dosage_entities = df_all_treatments_entities[df_all_treatments_entities['label'] == 'DOSAGE'] if not df_all_treatments_entities.empty else pd.DataFrame()\n",
        "    if not dosage_entities.empty:\n",
        "        print(f\"\\n=== Dosage Distribution ===\")\n",
        "        print(dosage_entities['text'].str.lower().value_counts().head(15))\n",
        "\n",
        "    # Analyze treatment responses\n",
        "    response_entities = df_all_treatments_entities[df_all_treatments_entities['label'] == 'TREATMENT_RESPONSE'] if not df_all_treatments_entities.empty else pd.DataFrame()\n",
        "    if not response_entities.empty:\n",
        "        print(f\"\\n=== Treatment Response Distribution ===\")\n",
        "        print(response_entities['category'].value_counts())\n",
        "\n",
        "    # Analyze treatment types\n",
        "    treatment_type_entities = df_all_treatments_entities[df_all_treatments_entities['label'] == 'TREATMENT_TYPE'] if not df_all_treatments_entities.empty else pd.DataFrame()\n",
        "    if not treatment_type_entities.empty:\n",
        "        print(f\"\\n=== Treatment Type Distribution ===\")\n",
        "        print(treatment_type_entities['category'].value_counts())\n",
        "\n",
        "    # Create treatment-specific labeling functions (unchanged logic)\n",
        "    print(\"\\n=== Creating Treatment-Specific Labeling Functions ===\")\n",
        "\n",
        "    def create_treatment_labeling_functions():\n",
        "        \"\"\"Create labeling functions for treatment patterns\"\"\"\n",
        "\n",
        "        def lf_has_treatment(row):\n",
        "            if row.get('has_treatments') is True:\n",
        "                return 'HAS_TREATMENT'\n",
        "            elif row.get('has_treatments') is False:\n",
        "                return 'NO_TREATMENT'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_medication_treatment(row):\n",
        "            name = str(row.get('name', '')).lower()\n",
        "            dosage = str(row.get('dosage', '')).lower()\n",
        "            medication_terms = ['tablet', 'tablets', 'pill', 'mg', 'mcg', 'capsule', 'injection', 'infusion']\n",
        "            if any(term in (name + \" \" + dosage) for term in medication_terms):\n",
        "                return 'MEDICATION_TREATMENT'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_surgical_treatment(row):\n",
        "            name = str(row.get('name', '')).lower()\n",
        "            details = str(row.get('details', '')).lower()\n",
        "            surgical_terms = ['surgery', 'surgical', 'operation', 'resection', 'removal', 'repair', 'intubation']\n",
        "            if any(term in (name + \" \" + details) for term in surgical_terms):\n",
        "                return 'SURGICAL_TREATMENT'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_emergency_treatment(row):\n",
        "            name = str(row.get('name', '')).lower()\n",
        "            condition = str(row.get('related condition', '')).lower()\n",
        "            details = str(row.get('details', '')).lower()\n",
        "            emergency_terms = ['emergency', 'urgent', 'cardiac arrest', 'shock', 'life support', 'acls', 'resuscitation', 'rapid sequence']\n",
        "            if any(term in (name + \" \" + condition + \" \" + details) for term in emergency_terms):\n",
        "                return 'EMERGENCY_TREATMENT'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_cancer_treatment(row):\n",
        "            name = str(row.get('name', '')).lower()\n",
        "            condition = str(row.get('related condition', '')).lower()\n",
        "            reason = str(row.get('reason for taking', '')).lower()\n",
        "            cancer_terms = ['chemotherapy', 'cancer', 'metastases', 'tumor', 'oncology', 'malignant', 'carcinoma']\n",
        "            if any(term in (name + \" \" + condition + \" \" + reason) for term in cancer_terms):\n",
        "                return 'CANCER_TREATMENT'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_psychiatric_treatment(row):\n",
        "            name = str(row.get('name', '')).lower()\n",
        "            condition = str(row.get('related condition', '')).lower()\n",
        "            psych_drugs = ['olanzapine', 'risperidone', 'haloperidol', 'quetiapine', 'trihexyphenidyl']\n",
        "            psych_conditions = ['bipolar', 'psychosis', 'mania', 'depression', 'anxiety', 'affective disorder']\n",
        "            if any(drug in name for drug in psych_drugs) or any(cond in condition for cond in psych_conditions):\n",
        "                return 'PSYCHIATRIC_TREATMENT'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_chronic_treatment(row):\n",
        "            time = str(row.get('time', '')).lower()\n",
        "            duration = str(row.get('duration', '')).lower()\n",
        "            chronic_indicators = ['months', 'years', 'chronic', 'long-term', 'maintenance', 'past four months']\n",
        "            if any(indicator in (time + \" \" + duration) for indicator in chronic_indicators):\n",
        "                return 'CHRONIC_TREATMENT'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_daily_medication(row):\n",
        "            frequency = str(row.get('frequency', '')).lower()\n",
        "            if any(term in frequency for term in ['daily', 'every day', 'per day']):\n",
        "                return 'DAILY_MEDICATION'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_positive_response(row):\n",
        "            reaction = str(row.get('reaction to treatment', '')).lower()\n",
        "            details = str(row.get('details', '')).lower()\n",
        "            positive_terms = ['good response', 'improved', 'resolved', 'successful', 'effective', 'restored', 'return of', 'recovered']\n",
        "            if any(term in (reaction + \" \" + details) for term in positive_terms):\n",
        "                return 'POSITIVE_RESPONSE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_conservative_treatment(row):\n",
        "            name = str(row.get('name', '')).lower()\n",
        "            if any(t in name for t in ['conservative', 'non-operative', 'closed treatment']):\n",
        "                return 'CONSERVATIVE_TREATMENT'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_infection_treatment(row):\n",
        "            name = str(row.get('name', '')).lower()\n",
        "            condition = str(row.get('related condition', '')).lower()\n",
        "            reason = str(row.get('reason for taking', '')).lower()\n",
        "            infection_terms = ['antibiotic', 'infection', 'endocarditis', 'sepsis', 'nafcillin', 'antimicrobial']\n",
        "            if any(term in (name + \" \" + condition + \" \" + reason) for term in infection_terms):\n",
        "                return 'INFECTION_TREATMENT'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_cardiovascular_treatment(row):\n",
        "            name = str(row.get('name', '')).lower()\n",
        "            condition = str(row.get('related condition', '')).lower()\n",
        "            cardio_terms = ['cardiac', 'heart', 'hypovolaemic', 'shock', 'arrest', 'vasopressor', 'arrhythmia']\n",
        "            if any(term in (name + \" \" + condition) for term in cardio_terms):\n",
        "                return 'CARDIOVASCULAR_TREATMENT'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_treatment_duration(row):\n",
        "            # Prefer standardized duration if present\n",
        "            duration_days = row.get('duration_duration_days')\n",
        "            if pd.isna(duration_days):\n",
        "                duration_days = row.get('time_duration_days')\n",
        "            if pd.notna(duration_days):\n",
        "                try:\n",
        "                    d = float(duration_days)\n",
        "                except Exception:\n",
        "                    return 'ABSTAIN'\n",
        "                if d <= 7:\n",
        "                    return 'SHORT_TERM_TREATMENT'\n",
        "                elif d <= 30:\n",
        "                    return 'MEDIUM_TERM_TREATMENT'\n",
        "                else:\n",
        "                    return 'LONG_TERM_TREATMENT'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        return [\n",
        "            lf_has_treatment, lf_medication_treatment, lf_surgical_treatment,\n",
        "            lf_emergency_treatment, lf_cancer_treatment, lf_psychiatric_treatment,\n",
        "            lf_chronic_treatment, lf_daily_medication, lf_positive_response,\n",
        "            lf_conservative_treatment, lf_infection_treatment, lf_cardiovascular_treatment,\n",
        "            lf_treatment_duration\n",
        "        ]\n",
        "\n",
        "    # Test labeling functions\n",
        "    treatment_lfs = create_treatment_labeling_functions()\n",
        "\n",
        "    print(\"\\nTesting treatment labeling functions:\")\n",
        "    for i in range(min(10, len(df_treatments_processed))):\n",
        "        row = df_treatments_processed.iloc[i]\n",
        "        treatment_name = row.get('name', 'No treatment')\n",
        "        condition = row.get('related condition', 'No condition')\n",
        "        print(f\"\\nRow {i}: {treatment_name} for {condition}\")\n",
        "        for lf in treatment_lfs:\n",
        "            result = lf(row)\n",
        "            if result != 'ABSTAIN':\n",
        "                print(f\"  {lf.__name__}: {result}\")\n",
        "\n",
        "    # Extract treatment relations (use correct row_idx)\n",
        "    print(\"\\n=== Extracting Treatment Relations ===\")\n",
        "\n",
        "    def extract_treatment_relations(df_treatments):\n",
        "        \"\"\"Extract relations between treatments, conditions, and outcomes.\n",
        "           Uses 'idx' for row identity when available; falls back to df.index.\n",
        "        \"\"\"\n",
        "        relations = []\n",
        "\n",
        "        for df_index, row in df_treatments.iterrows():\n",
        "            row_id = row['idx'] if ('idx' in row and pd.notna(row['idx'])) else df_index\n",
        "\n",
        "            treatment = row.get('name')\n",
        "            condition = row.get('related condition')\n",
        "            dosage = row.get('dosage')\n",
        "            frequency = row.get('frequency')\n",
        "            reaction = row.get('reaction to treatment')\n",
        "            reason = row.get('reason for taking')\n",
        "\n",
        "            # TREATMENT_FOR_CONDITION\n",
        "            if pd.notna(treatment) and pd.notna(condition) and str(condition).lower() != 'nan':\n",
        "                relations.append({\n",
        "                    'type': 'TREATMENT_FOR_CONDITION',\n",
        "                    'treatment': treatment,\n",
        "                    'condition': condition,\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "\n",
        "            # TREATMENT_HAS_DOSAGE\n",
        "            if pd.notna(treatment) and pd.notna(dosage) and str(dosage).lower() != 'nan':\n",
        "                relations.append({\n",
        "                    'type': 'TREATMENT_HAS_DOSAGE',\n",
        "                    'treatment': treatment,\n",
        "                    'dosage': dosage,\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "\n",
        "            # TREATMENT_HAS_FREQUENCY\n",
        "            if pd.notna(treatment) and pd.notna(frequency) and str(frequency).lower() != 'nan':\n",
        "                relations.append({\n",
        "                    'type': 'TREATMENT_HAS_FREQUENCY',\n",
        "                    'treatment': treatment,\n",
        "                    'frequency': frequency,\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "\n",
        "            # TREATMENT_HAS_RESPONSE\n",
        "            if pd.notna(treatment) and pd.notna(reaction) and str(reaction).lower() != 'nan':\n",
        "                relations.append({\n",
        "                    'type': 'TREATMENT_HAS_RESPONSE',\n",
        "                    'treatment': treatment,\n",
        "                    'response': reaction,\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "\n",
        "            # TREATMENT_HAS_DURATION (standardized days)\n",
        "            duration_days = row.get('duration_duration_days') or row.get('time_duration_days')\n",
        "            if pd.notna(treatment) and pd.notna(duration_days):\n",
        "                relations.append({\n",
        "                    'type': 'TREATMENT_HAS_DURATION',\n",
        "                    'treatment': treatment,\n",
        "                    'duration_days': duration_days,\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "\n",
        "            # TREATMENT_HAS_REASON\n",
        "            if pd.notna(treatment) and pd.notna(reason) and str(reason).lower() != 'nan':\n",
        "                relations.append({\n",
        "                    'type': 'TREATMENT_HAS_REASON',\n",
        "                    'treatment': treatment,\n",
        "                    'reason': reason,\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "\n",
        "            # TREATMENT_TEMPORAL_PATTERN (raw time text)\n",
        "            time_info = row.get('time', '')\n",
        "            if pd.notna(treatment) and pd.notna(time_info) and str(time_info).lower() != 'nan':\n",
        "                relations.append({\n",
        "                    'type': 'TREATMENT_TEMPORAL_PATTERN',\n",
        "                    'treatment': treatment,\n",
        "                    'temporal_info': time_info,\n",
        "                    'row_idx': row_id\n",
        "                })\n",
        "\n",
        "        return relations\n",
        "\n",
        "    treatment_relations = extract_treatment_relations(df_treatments_processed)\n",
        "\n",
        "    print(f\"Found {len(treatment_relations)} treatment relations\")\n",
        "    if treatment_relations:\n",
        "        relation_types = pd.DataFrame(treatment_relations)['type'].value_counts()\n",
        "        print(\"\\nRelation type distribution:\")\n",
        "        print(relation_types)\n",
        "\n",
        "        # Sample relations\n",
        "        print(\"\\nSample relations:\")\n",
        "        for rel in treatment_relations[:10]:\n",
        "            if rel['type'] == 'TREATMENT_FOR_CONDITION':\n",
        "                print(f\"  {rel['treatment']} -> treats -> {rel['condition']} (row {rel['row_idx']})\")\n",
        "            elif rel['type'] == 'TREATMENT_HAS_DOSAGE':\n",
        "                print(f\"  {rel['treatment']} -> dosage -> {rel['dosage']} (row {rel['row_idx']})\")\n",
        "            elif rel['type'] == 'TREATMENT_HAS_RESPONSE':\n",
        "                print(f\"  {rel['treatment']} -> response -> {rel['response']} (row {rel['row_idx']})\")\n",
        "\n",
        "    # Coverage analysis\n",
        "    print(\"\\n=== Labeling Function Coverage Analysis ===\")\n",
        "    coverage_results = {}\n",
        "    for lf in treatment_lfs:\n",
        "        labeled = sum(1 for _, row in df_treatments_processed.iterrows() if lf(row) != 'ABSTAIN')\n",
        "        coverage = (labeled / len(df_treatments_processed)) * 100 if len(df_treatments_processed) > 0 else 0\n",
        "        coverage_results[lf.__name__] = {'labeled': labeled, 'coverage': coverage}\n",
        "\n",
        "    print(\"\\nLabeling function coverage:\")\n",
        "    for lf_name, stats in sorted(coverage_results.items(), key=lambda x: x[1]['coverage'], reverse=True):\n",
        "        print(f\"  {lf_name}: {stats['labeled']} labels ({stats['coverage']:.1f}% coverage)\")\n",
        "\n",
        "    # Additional analysis for treatments\n",
        "    print(\"\\n=== Additional Treatment Analysis ===\")\n",
        "    \n",
        "    if 'has_treatments' in df_treatments_processed.columns:\n",
        "        print(\"\\nHas treatments distribution:\")\n",
        "        print(df_treatments_processed['has_treatments'].value_counts())\n",
        "    \n",
        "    if 'frequency' in df_treatments_processed.columns and not df_all_treatments_entities.empty:\n",
        "        freq_entities = df_all_treatments_entities[df_all_treatments_entities['label'] == 'FREQUENCY']\n",
        "        if not freq_entities.empty:\n",
        "            print(\"\\n=== Frequency Distribution ===\")\n",
        "            print(freq_entities['text'].str.lower().value_counts().head(10))\n",
        "    \n",
        "    route_entities = df_all_treatments_entities[df_all_treatments_entities['label'] == 'ROUTE'] if not df_all_treatments_entities.empty else pd.DataFrame()\n",
        "    if not route_entities.empty:\n",
        "        print(\"\\n=== Route of Administration ===\")\n",
        "        print(route_entities['text'].str.lower().value_counts())\n",
        "\n",
        "    # Save results\n",
        "    df_all_treatments_entities.to_csv('treatment_entities_comprehensive.csv', index=False)\n",
        "    pd.DataFrame(treatment_relations).to_csv('treatment_relations.csv', index=False)\n",
        "\n",
        "    print(\"\\n\\nTreatment entity extraction and labeling complete!\")\n",
        "    print(f\"Saved {len(df_all_treatments_entities)} entities and {len(treatment_relations)} relations\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>source_column</th>\n",
              "      <th>category</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Olanzapine</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>11</td>\n",
              "      <td>21</td>\n",
              "      <td>Treatment: Olanzapine tablets for Bipolar affe...</td>\n",
              "      <td>155216</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bipolar affective disorder</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>34</td>\n",
              "      <td>60</td>\n",
              "      <td>Treatment: Olanzapine tablets for Bipolar affe...</td>\n",
              "      <td>155216</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mental illness reaction</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>150</td>\n",
              "      <td>173</td>\n",
              "      <td>Treatment: Olanzapine tablets for Bipolar affe...</td>\n",
              "      <td>155216</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pain</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>175</td>\n",
              "      <td>179</td>\n",
              "      <td>Treatment: Olanzapine tablets for Bipolar affe...</td>\n",
              "      <td>155216</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>olanzapine</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>326</td>\n",
              "      <td>336</td>\n",
              "      <td>Treatment: Olanzapine tablets for Bipolar affe...</td>\n",
              "      <td>155216</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319175</th>\n",
              "      <td>endocarditis</td>\n",
              "      <td>CONDITION_TYPE</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>endocarditis</td>\n",
              "      <td>50425</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cardiovascular</td>\n",
              "      <td>condition_pattern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319176</th>\n",
              "      <td>infection</td>\n",
              "      <td>CONDITION_TYPE</td>\n",
              "      <td>24</td>\n",
              "      <td>33</td>\n",
              "      <td>to treat s.\\nlugdunensis infection</td>\n",
              "      <td>50425</td>\n",
              "      <td>NaN</td>\n",
              "      <td>infectious</td>\n",
              "      <td>condition_pattern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319177</th>\n",
              "      <td>endocarditis</td>\n",
              "      <td>CONDITION_TYPE</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>endocarditis</td>\n",
              "      <td>50425</td>\n",
              "      <td>NaN</td>\n",
              "      <td>infectious</td>\n",
              "      <td>condition_pattern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319178</th>\n",
              "      <td>postoperative</td>\n",
              "      <td>TEMPORAL_PATTERN</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>postoperative  patient was discharged home on ...</td>\n",
              "      <td>50425</td>\n",
              "      <td>NaN</td>\n",
              "      <td>perioperative</td>\n",
              "      <td>temporal_extraction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319179</th>\n",
              "      <td>to treat s</td>\n",
              "      <td>TREATMENT_REASON</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>to treat s.\\nlugdunensis infection</td>\n",
              "      <td>50425</td>\n",
              "      <td>NaN</td>\n",
              "      <td>treatment_goal</td>\n",
              "      <td>reason_column</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>319180 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                              text             label  start  end  \\\n",
              "0                       Olanzapine          CHEMICAL     11   21   \n",
              "1       Bipolar affective disorder           DISEASE     34   60   \n",
              "2          mental illness reaction           DISEASE    150  173   \n",
              "3                             Pain           DISEASE    175  179   \n",
              "4                       olanzapine          CHEMICAL    326  336   \n",
              "...                            ...               ...    ...  ...   \n",
              "319175                endocarditis    CONDITION_TYPE      0   12   \n",
              "319176                   infection    CONDITION_TYPE     24   33   \n",
              "319177                endocarditis    CONDITION_TYPE      0   12   \n",
              "319178               postoperative  TEMPORAL_PATTERN      0   13   \n",
              "319179                  to treat s  TREATMENT_REASON      0   10   \n",
              "\n",
              "                                            original_text  row_idx  \\\n",
              "0       Treatment: Olanzapine tablets for Bipolar affe...   155216   \n",
              "1       Treatment: Olanzapine tablets for Bipolar affe...   155216   \n",
              "2       Treatment: Olanzapine tablets for Bipolar affe...   155216   \n",
              "3       Treatment: Olanzapine tablets for Bipolar affe...   155216   \n",
              "4       Treatment: Olanzapine tablets for Bipolar affe...   155216   \n",
              "...                                                   ...      ...   \n",
              "319175                                       endocarditis    50425   \n",
              "319176                 to treat s.\\nlugdunensis infection    50425   \n",
              "319177                                       endocarditis    50425   \n",
              "319178  postoperative  patient was discharged home on ...    50425   \n",
              "319179                 to treat s.\\nlugdunensis infection    50425   \n",
              "\n",
              "        source_column        category               source  \n",
              "0       combined_text             NaN                  NaN  \n",
              "1       combined_text             NaN                  NaN  \n",
              "2       combined_text             NaN                  NaN  \n",
              "3       combined_text             NaN                  NaN  \n",
              "4       combined_text             NaN                  NaN  \n",
              "...               ...             ...                  ...  \n",
              "319175            NaN  cardiovascular    condition_pattern  \n",
              "319176            NaN      infectious    condition_pattern  \n",
              "319177            NaN      infectious    condition_pattern  \n",
              "319178            NaN   perioperative  temporal_extraction  \n",
              "319179            NaN  treatment_goal        reason_column  \n",
              "\n",
              "[319180 rows x 9 columns]"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_all_treatments_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155216</td>\n",
              "      <td>Sixteen years old</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133948</td>\n",
              "      <td>36 years old</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80176</td>\n",
              "      <td>49</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72232</td>\n",
              "      <td>47</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>31864</td>\n",
              "      <td>24 years</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>39279</td>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>137017</td>\n",
              "      <td>82</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>98004</td>\n",
              "      <td>54</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>133320</td>\n",
              "      <td>49</td>\n",
              "      <td>Woman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>97973</td>\n",
              "      <td>31</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29755 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          idx                age     sex\n",
              "0      155216  Sixteen years old  Female\n",
              "2      133948       36 years old  Female\n",
              "3       80176                 49    male\n",
              "4       72232                 47    Male\n",
              "5       31864           24 years  Female\n",
              "...       ...                ...     ...\n",
              "29995   39279                 28    male\n",
              "29996  137017                 82    Male\n",
              "29997   98004                 54    Male\n",
              "29998  133320                 49   Woman\n",
              "29999   97973                 31    male\n",
              "\n",
              "[29755 rows x 3 columns]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sex\n",
              "Female                                                             10077\n",
              "Male                                                                9974\n",
              "male                                                                4588\n",
              "Woman                                                               2486\n",
              "female                                                               993\n",
              "man                                                                  497\n",
              "woman                                                                391\n",
              "boy                                                                  190\n",
              "Boy                                                                   78\n",
              "Girl                                                                  77\n",
              "girl                                                                  72\n",
              "Man                                                                   68\n",
              "Gentleman                                                              7\n",
              "Trans man                                                              6\n",
              "gentleman                                                              6\n",
              "Trans woman                                                            5\n",
              "Neutered male                                                          4\n",
              "lady                                                                   3\n",
              "Entire male                                                            2\n",
              "Female neutered                                                        2\n",
              "Male for the first patient, Female for the second patient              2\n",
              "Male for both patients                                                 2\n",
              "Castrated male                                                         2\n",
              "Female phenotype                                                       1\n",
              "Twin A (sex not specified)                                             1\n",
              "Male and Female                                                        1\n",
              "Transgender woman                                                      1\n",
              "Not specified                                                          1\n",
              "Phenotypical male                                                      1\n",
              "Male (after legal gender change)                                       1\n",
              "Male (transgender)                                                     1\n",
              "Female (social gender)                                                 1\n",
              "Female (46,XX)                                                         1\n",
              "Lady                                                                   1\n",
              "Female, spayed                                                         1\n",
              "neutered male                                                          1\n",
              "Male for the second and third cases, Female for the fourth case        1\n",
              "Female spayed                                                          1\n",
              "Neutered female                                                        1\n",
              "Sex not specified                                                      1\n",
              "Two men and one woman                                                  1\n",
              "Female; Male; Male                                                     1\n",
              "Assigned female at birth, raised as male                               1\n",
              "Male; Female                                                           1\n",
              "Female / Male                                                          1\n",
              "One female and one male                                                1\n",
              "Female and Male                                                        1\n",
              "Cisgender woman                                                        1\n",
              "Brother (male) and sister (female)                                     1\n",
              "man, woman, woman                                                      1\n",
              "female spayed                                                          1\n",
              "Biological male                                                        1\n",
              "Male (Geminus A)                                                       1\n",
              "Male neutered                                                          1\n",
              "Female for Patient Case 1, Male for Patient Case 2                     1\n",
              "Assigned female at birth                                               1\n",
              "Designated female at birth, transitioned to male                       1\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_info['sex'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "age\n",
              "62                                                                                  474\n",
              "65                                                                                  465\n",
              "35                                                                                  432\n",
              "63                                                                                  432\n",
              "45                                                                                  429\n",
              "                                                                                   ... \n",
              "Initially 21 years old, 33 years old at last mention                                  1\n",
              "29 at first admission, 55 at the time of the last mentioned clinical examination      1\n",
              "18 yr old                                                                             1\n",
              "37-years old                                                                          1\n",
              "Almost three-year old                                                                 1\n",
              "Name: count, Length: 1296, dtype: int64"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_info['age'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Standardized Sex Distribution:\n",
            "sex_standardized\n",
            "Male                15429\n",
            "Female              14129\n",
            "Multiple_Records        5\n",
            "Other                   3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Age Distribution:\n",
            "age_category\n",
            "Adult         19376\n",
            "Elderly        6153\n",
            "Child          2566\n",
            "Adolescent     1489\n",
            "Infant           89\n",
            "Unknown          82\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Special Cases:\n",
            "Veterinary cases: 13\n",
            "Multiple patient records: 5\n",
            "Complex age descriptions: 120\n"
          ]
        }
      ],
      "source": [
        "def standardize_sex(sex_str):\n",
        "    \"\"\"\n",
        "    Standardize sex/gender values based on the variations in your data.\n",
        "    \n",
        "    Special cases handled:\n",
        "    - Veterinary cases (neutered/castrated)\n",
        "    - Multiple patients in one record\n",
        "    - Trans individuals\n",
        "    - Various capitalizations and terms\n",
        "    \"\"\"\n",
        "    if pd.isna(sex_str):\n",
        "        return None\n",
        "    \n",
        "    sex_str = str(sex_str).strip().lower()\n",
        "    \n",
        "    # Handle multiple patients first\n",
        "    if 'both' in sex_str or 'second patient' in sex_str or 'patient case' in sex_str:\n",
        "        return 'Multiple_Patients'\n",
        "    \n",
        "    # Map variations to standard values\n",
        "    female_terms = ['female', 'woman', 'girl', 'lady']\n",
        "    male_terms = ['male', 'man', 'boy', 'gentleman']\n",
        "    \n",
        "    # Check for trans individuals\n",
        "    if 'trans' in sex_str:\n",
        "        if 'trans man' in sex_str or 'transitioned to male' in sex_str:\n",
        "            return 'Trans_Male'\n",
        "        elif 'trans woman' in sex_str:\n",
        "            return 'Trans_Female'\n",
        "    \n",
        "    # Check for assigned at birth\n",
        "    if 'assigned female at birth' in sex_str:\n",
        "        return 'AFAB'\n",
        "    \n",
        "    # Check for phenotype mentions\n",
        "    if 'phenotype' in sex_str:\n",
        "        if 'female' in sex_str:\n",
        "            return 'Female_Phenotype'\n",
        "    \n",
        "    # Check for veterinary cases (neutered/castrated)\n",
        "    if 'neutered' in sex_str or 'castrated' in sex_str or 'entire' in sex_str:\n",
        "        if any(term in sex_str for term in female_terms):\n",
        "            if 'neutered' in sex_str:\n",
        "                return 'Female_Neutered'\n",
        "            else:\n",
        "                return 'Female_Intact'\n",
        "        elif any(term in sex_str for term in male_terms):\n",
        "            if 'neutered' in sex_str or 'castrated' in sex_str:\n",
        "                return 'Male_Neutered'\n",
        "            else:\n",
        "                return 'Male_Intact'\n",
        "    \n",
        "    # Standard cases\n",
        "    for term in female_terms:\n",
        "        if term == sex_str:\n",
        "            return 'Female'\n",
        "    \n",
        "    for term in male_terms:\n",
        "        if term == sex_str:\n",
        "            return 'Male'\n",
        "    \n",
        "    # If we can't classify, return as unclassified\n",
        "    return 'Unclassified'\n",
        "\n",
        "\n",
        "def standardize_sex_simple(sex_str):\n",
        "    \"\"\"\n",
        "    Simplified version that maps to just Male/Female/Other categories\n",
        "    \"\"\"\n",
        "    if pd.isna(sex_str):\n",
        "        return None\n",
        "    \n",
        "    sex_str = str(sex_str).strip().lower()\n",
        "    \n",
        "    # Handle multiple patients\n",
        "    if 'both' in sex_str or 'second patient' in sex_str or 'patient case' in sex_str:\n",
        "        return 'Multiple_Records'\n",
        "    \n",
        "    # Simple mapping\n",
        "    female_terms = ['female', 'woman', 'girl', 'lady', 'trans woman', 'female phenotype']\n",
        "    male_terms = ['male', 'man', 'boy', 'gentleman', 'trans man']\n",
        "    \n",
        "    # Check for main terms\n",
        "    for term in female_terms:\n",
        "        if term in sex_str:\n",
        "            return 'Female'\n",
        "    \n",
        "    for term in male_terms:\n",
        "        if term in sex_str:\n",
        "            return 'Male'\n",
        "    \n",
        "    return 'Other'\n",
        "\n",
        "\n",
        "def extract_age_from_text(age_str):\n",
        "    \"\"\"\n",
        "    Extract numeric age from various text formats in your data.\n",
        "    \n",
        "    Handles cases like:\n",
        "    - Simple numbers: \"62\", \"35\"\n",
        "    - Years old format: \"18 yr old\", \"37-years old\"\n",
        "    - Written numbers: \"Sixteen years old\", \"Almost three-year old\"\n",
        "    - Complex cases: \"Initially 21 years old, 33 years old at last mention\"\n",
        "    - Age ranges: \"29 at first admission, 55 at the time of the last mentioned clinical examination\"\n",
        "    \"\"\"\n",
        "    if pd.isna(age_str):\n",
        "        return None\n",
        "    \n",
        "    age_str = str(age_str).strip()\n",
        "    \n",
        "    # First check if it's already a simple number\n",
        "    if age_str.isdigit():\n",
        "        return int(age_str)\n",
        "    \n",
        "    # Convert written numbers to digits\n",
        "    written_numbers = {\n",
        "        'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5,\n",
        "        'six': 6, 'seven': 7, 'eight': 8, 'nine': 9, 'ten': 10,\n",
        "        'eleven': 11, 'twelve': 12, 'thirteen': 13, 'fourteen': 14,\n",
        "        'fifteen': 15, 'sixteen': 16, 'seventeen': 17, 'eighteen': 18,\n",
        "        'nineteen': 19, 'twenty': 20, 'thirty': 30, 'forty': 40,\n",
        "        'fifty': 50, 'sixty': 60, 'seventy': 70, 'eighty': 80,\n",
        "        'ninety': 90\n",
        "    }\n",
        "    \n",
        "    # Replace written numbers with digits\n",
        "    age_str_lower = age_str.lower()\n",
        "    for word, num in written_numbers.items():\n",
        "        age_str_lower = age_str_lower.replace(word, str(num))\n",
        "    \n",
        "    # Handle compound written numbers (e.g., \"twenty-one\")\n",
        "    age_str_lower = re.sub(r'(\\d+)\\s*-\\s*(\\d+)', lambda m: str(int(m.group(1)) + int(m.group(2))), age_str_lower)\n",
        "    \n",
        "    # Extract all numbers from the text\n",
        "    numbers = re.findall(r'\\d+', age_str_lower)\n",
        "    \n",
        "    if not numbers:\n",
        "        return None\n",
        "    \n",
        "    # For multiple ages (patient history), typically want the first mentioned age\n",
        "    # You might want to change this logic based on your needs\n",
        "    if 'initially' in age_str_lower or 'first' in age_str_lower:\n",
        "        # Return the first number\n",
        "        return int(numbers[0])\n",
        "    elif 'last' in age_str_lower or 'current' in age_str_lower:\n",
        "        # Return the last number\n",
        "        return int(numbers[-1])\n",
        "    else:\n",
        "        # Default to first number found\n",
        "        return int(numbers[0])\n",
        "\n",
        "\n",
        "def get_age_category(age):\n",
        "    \"\"\"\n",
        "    Categorize age into standard medical categories\n",
        "    \"\"\"\n",
        "    if pd.isna(age):\n",
        "        return 'Unknown'\n",
        "    \n",
        "    if age < 2:\n",
        "        return 'Infant'\n",
        "    elif age < 13:\n",
        "        return 'Child'\n",
        "    elif age < 18:\n",
        "        return 'Adolescent'\n",
        "    elif age < 65:\n",
        "        return 'Adult'\n",
        "    else:\n",
        "        return 'Elderly'\n",
        "\n",
        "\n",
        "def standardize_demographics(df):\n",
        "    \"\"\"\n",
        "    Apply all standardization to the dataframe\n",
        "    \"\"\"\n",
        "    # Create a copy to avoid modifying original\n",
        "    df_clean = df.copy()\n",
        "    \n",
        "    # Standardize sex - both detailed and simple versions\n",
        "    df_clean['sex_detailed'] = df_clean['sex'].apply(standardize_sex)\n",
        "    df_clean['sex_standardized'] = df_clean['sex'].apply(standardize_sex_simple)\n",
        "    \n",
        "    # Extract numeric age\n",
        "    df_clean['age_numeric'] = df_clean['age'].apply(extract_age_from_text)\n",
        "    \n",
        "    # Add age category\n",
        "    df_clean['age_category'] = df_clean['age_numeric'].apply(get_age_category)\n",
        "    \n",
        "    # Create flags for special cases\n",
        "    df_clean['is_veterinary'] = df_clean['sex_detailed'].str.contains('Neutered|Intact', na=False)\n",
        "    df_clean['is_multiple_patients'] = df_clean['sex_detailed'] == 'Multiple_Patients'\n",
        "    df_clean['has_complex_age'] = df_clean['age'].str.contains('initially|first|last|mention', case=False, na=False)\n",
        "    \n",
        "    return df_clean\n",
        "\n",
        "\n",
        "    \n",
        "# Apply to your dataframe:\n",
        "df_info_clean = standardize_demographics(df_info)\n",
        "\n",
        "# View results:\n",
        "print(\"\\nStandardized Sex Distribution:\")\n",
        "print(df_info_clean['sex_standardized'].value_counts())\n",
        "print(\"\\nAge Distribution:\")\n",
        "print(df_info_clean['age_category'].value_counts())\n",
        "print(\"\\nSpecial Cases:\")\n",
        "print(f\"Veterinary cases: {df_info_clean['is_veterinary'].sum()}\")\n",
        "print(f\"Multiple patient records: {df_info_clean['is_multiple_patients'].sum()}\")\n",
        "print(f\"Complex age descriptions: {df_info_clean['has_complex_age'].sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>sex_detailed</th>\n",
              "      <th>sex_standardized</th>\n",
              "      <th>age_numeric</th>\n",
              "      <th>age_category</th>\n",
              "      <th>is_veterinary</th>\n",
              "      <th>is_multiple_patients</th>\n",
              "      <th>has_complex_age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155216</td>\n",
              "      <td>Sixteen years old</td>\n",
              "      <td>Female</td>\n",
              "      <td>Female</td>\n",
              "      <td>Female</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Child</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133948</td>\n",
              "      <td>36 years old</td>\n",
              "      <td>Female</td>\n",
              "      <td>Female</td>\n",
              "      <td>Female</td>\n",
              "      <td>36.0</td>\n",
              "      <td>Adult</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80176</td>\n",
              "      <td>49</td>\n",
              "      <td>male</td>\n",
              "      <td>Male</td>\n",
              "      <td>Male</td>\n",
              "      <td>49.0</td>\n",
              "      <td>Adult</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72232</td>\n",
              "      <td>47</td>\n",
              "      <td>Male</td>\n",
              "      <td>Male</td>\n",
              "      <td>Male</td>\n",
              "      <td>47.0</td>\n",
              "      <td>Adult</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>31864</td>\n",
              "      <td>24 years</td>\n",
              "      <td>Female</td>\n",
              "      <td>Female</td>\n",
              "      <td>Female</td>\n",
              "      <td>24.0</td>\n",
              "      <td>Adult</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>39279</td>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>Male</td>\n",
              "      <td>Male</td>\n",
              "      <td>28.0</td>\n",
              "      <td>Adult</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>137017</td>\n",
              "      <td>82</td>\n",
              "      <td>Male</td>\n",
              "      <td>Male</td>\n",
              "      <td>Male</td>\n",
              "      <td>82.0</td>\n",
              "      <td>Elderly</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>98004</td>\n",
              "      <td>54</td>\n",
              "      <td>Male</td>\n",
              "      <td>Male</td>\n",
              "      <td>Male</td>\n",
              "      <td>54.0</td>\n",
              "      <td>Adult</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>133320</td>\n",
              "      <td>49</td>\n",
              "      <td>Woman</td>\n",
              "      <td>Female</td>\n",
              "      <td>Female</td>\n",
              "      <td>49.0</td>\n",
              "      <td>Adult</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>97973</td>\n",
              "      <td>31</td>\n",
              "      <td>male</td>\n",
              "      <td>Male</td>\n",
              "      <td>Male</td>\n",
              "      <td>31.0</td>\n",
              "      <td>Adult</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29755 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          idx                age     sex sex_detailed sex_standardized  \\\n",
              "0      155216  Sixteen years old  Female       Female           Female   \n",
              "2      133948       36 years old  Female       Female           Female   \n",
              "3       80176                 49    male         Male             Male   \n",
              "4       72232                 47    Male         Male             Male   \n",
              "5       31864           24 years  Female       Female           Female   \n",
              "...       ...                ...     ...          ...              ...   \n",
              "29995   39279                 28    male         Male             Male   \n",
              "29996  137017                 82    Male         Male             Male   \n",
              "29997   98004                 54    Male         Male             Male   \n",
              "29998  133320                 49   Woman       Female           Female   \n",
              "29999   97973                 31    male         Male             Male   \n",
              "\n",
              "       age_numeric age_category  is_veterinary  is_multiple_patients  \\\n",
              "0              6.0        Child          False                 False   \n",
              "2             36.0        Adult          False                 False   \n",
              "3             49.0        Adult          False                 False   \n",
              "4             47.0        Adult          False                 False   \n",
              "5             24.0        Adult          False                 False   \n",
              "...            ...          ...            ...                   ...   \n",
              "29995         28.0        Adult          False                 False   \n",
              "29996         82.0      Elderly          False                 False   \n",
              "29997         54.0        Adult          False                 False   \n",
              "29998         49.0        Adult          False                 False   \n",
              "29999         31.0        Adult          False                 False   \n",
              "\n",
              "       has_complex_age  \n",
              "0                False  \n",
              "2                False  \n",
              "3                False  \n",
              "4                False  \n",
              "5                False  \n",
              "...                ...  \n",
              "29995            False  \n",
              "29996            False  \n",
              "29997            False  \n",
              "29998            False  \n",
              "29999            False  \n",
              "\n",
              "[29755 rows x 10 columns]"
            ]
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_info_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(910897, 4) label\n",
            "AgeSex    707568\n",
            "Age       203321\n",
            "Sex            8\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# df_info_clean has: idx, age, sex, sex_detailed, sex_standardized, age_numeric, ...\n",
        "\n",
        "info = df_info_clean.rename(columns={\"idx\":\"row_idx\"}).copy()\n",
        "\n",
        "def age_variants(n: int):\n",
        "    n = int(n)\n",
        "    return [\n",
        "        f\"{n} years old\", f\"{n} year old\",\n",
        "        f\"{n}-year-old\", f\"{n} yo\", f\"{n} y/o\", f\"aged {n}\"\n",
        "    ]\n",
        "\n",
        "SEX_SYNONYMS = {\n",
        "    \"female\": [\"female\", \"woman\", \"female patient\", \"women\"],\n",
        "    \"male\":   [\"male\", \"man\", \"male patient\", \"men\"],\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for r in info.itertuples(index=False):\n",
        "    rid = r.row_idx\n",
        "\n",
        "    # 1) Use the raw age text if present\n",
        "    if isinstance(r.age, str) and r.age.strip():\n",
        "        rows.append({\"row_idx\": rid, \"text\": r.age.strip(), \"label\": \"Age\", \"table\": \"info\"})\n",
        "\n",
        "    # 2) Generate common age variants from numeric\n",
        "    if pd.notna(r.age_numeric):\n",
        "        for t in age_variants(r.age_numeric):\n",
        "            rows.append({\"row_idx\": rid, \"text\": t, \"label\": \"Age\", \"table\": \"info\"})\n",
        "\n",
        "    # 3) Sex synonyms (driven by standardized sex if available)\n",
        "    sex_std = None\n",
        "    for s in (getattr(r, \"sex_standardized\", None), getattr(r, \"sex_detailed\", None), getattr(r, \"sex\", None)):\n",
        "        if isinstance(s, str) and s.strip():\n",
        "            sex_std = s.strip().lower()\n",
        "            break\n",
        "    if sex_std in SEX_SYNONYMS:\n",
        "        for t in SEX_SYNONYMS[sex_std]:\n",
        "            rows.append({\"row_idx\": nid, \"text\": t, \"label\": \"Sex\", \"table\": \"info\"})\n",
        "\n",
        "        # 4) Age+sex combos (very common in narratives, e.g., \"36-year-old female\")\n",
        "        if pd.notna(r.age_numeric):\n",
        "            for av in age_variants(r.age_numeric):\n",
        "                for sx in SEX_SYNONYMS[sex_std]:\n",
        "                    rows.append({\"row_idx\": rid, \"text\": f\"{av} {sx}\", \"label\": \"AgeSex\", \"table\": \"info\"})\n",
        "\n",
        "df_info_entities = pd.DataFrame(rows).drop_duplicates([\"row_idx\",\"text\",\"label\"])\n",
        "print(df_info_entities.shape, df_info_entities.label.value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total entities across all tables: 2,113,057\n",
            "\n",
            "Entity distribution by table:\n",
            "table\n",
            "info             910897\n",
            "diagnosis        334425\n",
            "treatments       319180\n",
            "symptoms         316046\n",
            "surgery          179947\n",
            "physiological     47382\n",
            "psychological      3402\n",
            "allergies           934\n",
            "drug_usage          715\n",
            "vaccination         129\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Entity types found:\n",
            "label\n",
            "AgeSex                             707568\n",
            "DISEASE                            281269\n",
            "Age                                203321\n",
            "ANATOMY                            125820\n",
            "CONDITION                           79686\n",
            "LATERALITY                          76962\n",
            "SYMPTOM_TYPE                        56789\n",
            "TEST                                56150\n",
            "SYMPTOM                             53580\n",
            "CHEMICAL                            51222\n",
            "TEST_TYPE                           51197\n",
            "TREATMENT                           44086\n",
            "FINDING                             40916\n",
            "MULTI_TISSUE_STRUCTURE              32237\n",
            "TEMPORAL_PATTERN                    26382\n",
            "PROCEDURE                           24770\n",
            "TREATMENT_TYPE                      23652\n",
            "ROUTE                               18590\n",
            "CANCER                              17003\n",
            "TREATMENT_REASON                    16765\n",
            "TISSUE                              16665\n",
            "ORGAN                               14854\n",
            "PATHOLOGICAL_FORMATION              14321\n",
            "CONDITION_TYPE                      13410\n",
            "DOSAGE                              12320\n",
            "MEASUREMENT                         10044\n",
            "TREATMENT_RESPONSE                   7463\n",
            "FREQUENCY                            6705\n",
            "SEVERITY                             6360\n",
            "ORGANISM_SUBDIVISION                 4084\n",
            "GENE_OR_GENE_PRODUCT                 3097\n",
            "CELL                                 2784\n",
            "SIMPLE_CHEMICAL                      2742\n",
            "ORGANISM                             2378\n",
            "MEDICATION                           1921\n",
            "IMMATERIAL_ANATOMICAL_ENTITY         1800\n",
            "CELLULAR_COMPONENT                   1777\n",
            "ORGANISM_SUBSTANCE                   1306\n",
            "ANATOMY_WITH_LATERALITY               893\n",
            "AMINO_ACID                            111\n",
            "ANATOMICAL_SYSTEM                      48\n",
            "Sex                                     8\n",
            "DEVELOPING_ANATOMICAL_STRUCTURE         1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "all_entities = pd.concat([\n",
        "    df_all_physiological_entities.assign(table='physiological'),\n",
        "    df_psychological_entities.assign(table='psychological'),\n",
        "    df_vaccination_entities.assign(table='vaccination'),\n",
        "    df_allergies_entities.assign(table='allergies'),\n",
        "    df_drug_usage_entities.assign(table='drug_usage'),\n",
        "    df_all_surgery_entities.assign(table='surgery'),\n",
        "    df_all_symptom_entities.assign(table='symptoms'),\n",
        "    df_all_diagnosis_entities.assign(table='diagnosis'),\n",
        "    df_all_treatments_entities.assign(table='treatments'),\n",
        "    df_info_entities.assign(table='info')\n",
        "], ignore_index=True)\n",
        "\n",
        "print(f\"Total entities across all tables: {len(all_entities):,}\")\n",
        "print(\"\\nEntity distribution by table:\")\n",
        "print(all_entities['table'].value_counts())\n",
        "print(\"\\nEntity types found:\")\n",
        "print(all_entities['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>source_column</th>\n",
              "      <th>category</th>\n",
              "      <th>table</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>posttraumatic arthritis</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>48.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>History of left elbow arthrodesis performed fo...</td>\n",
              "      <td>80176</td>\n",
              "      <td>physiological context</td>\n",
              "      <td>NaN</td>\n",
              "      <td>physiological</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pain</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>116.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>Inability to walk since babyhood, did not walk...</td>\n",
              "      <td>31864</td>\n",
              "      <td>physiological context</td>\n",
              "      <td>NaN</td>\n",
              "      <td>physiological</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fracture</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>151.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>Inability to walk since babyhood, did not walk...</td>\n",
              "      <td>31864</td>\n",
              "      <td>physiological context</td>\n",
              "      <td>NaN</td>\n",
              "      <td>physiological</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Coxa vara deformity</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>Coxa vara deformity of bilateral hips, bilater...</td>\n",
              "      <td>149866</td>\n",
              "      <td>physiological context</td>\n",
              "      <td>NaN</td>\n",
              "      <td>physiological</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fracture</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>75.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>Coxa vara deformity of bilateral hips, bilater...</td>\n",
              "      <td>149866</td>\n",
              "      <td>physiological context</td>\n",
              "      <td>NaN</td>\n",
              "      <td>physiological</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2113052</th>\n",
              "      <td>31 y/o men</td>\n",
              "      <td>AgeSex</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>97973</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>info</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2113053</th>\n",
              "      <td>aged 31 male</td>\n",
              "      <td>AgeSex</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>97973</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>info</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2113054</th>\n",
              "      <td>aged 31 man</td>\n",
              "      <td>AgeSex</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>97973</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>info</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2113055</th>\n",
              "      <td>aged 31 male patient</td>\n",
              "      <td>AgeSex</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>97973</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>info</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2113056</th>\n",
              "      <td>aged 31 men</td>\n",
              "      <td>AgeSex</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>97973</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>info</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2113057 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            text    label  start    end  \\\n",
              "0        posttraumatic arthritis  DISEASE   48.0   71.0   \n",
              "1                           pain  DISEASE  116.0  120.0   \n",
              "2                       fracture  DISEASE  151.0  159.0   \n",
              "3            Coxa vara deformity  DISEASE    0.0   19.0   \n",
              "4                       fracture  DISEASE   75.0   83.0   \n",
              "...                          ...      ...    ...    ...   \n",
              "2113052               31 y/o men   AgeSex    NaN    NaN   \n",
              "2113053             aged 31 male   AgeSex    NaN    NaN   \n",
              "2113054              aged 31 man   AgeSex    NaN    NaN   \n",
              "2113055     aged 31 male patient   AgeSex    NaN    NaN   \n",
              "2113056              aged 31 men   AgeSex    NaN    NaN   \n",
              "\n",
              "                                             original_text  row_idx  \\\n",
              "0        History of left elbow arthrodesis performed fo...    80176   \n",
              "1        Inability to walk since babyhood, did not walk...    31864   \n",
              "2        Inability to walk since babyhood, did not walk...    31864   \n",
              "3        Coxa vara deformity of bilateral hips, bilater...   149866   \n",
              "4        Coxa vara deformity of bilateral hips, bilater...   149866   \n",
              "...                                                    ...      ...   \n",
              "2113052                                                NaN    97973   \n",
              "2113053                                                NaN    97973   \n",
              "2113054                                                NaN    97973   \n",
              "2113055                                                NaN    97973   \n",
              "2113056                                                NaN    97973   \n",
              "\n",
              "                 source_column category          table source  \n",
              "0        physiological context      NaN  physiological    NaN  \n",
              "1        physiological context      NaN  physiological    NaN  \n",
              "2        physiological context      NaN  physiological    NaN  \n",
              "3        physiological context      NaN  physiological    NaN  \n",
              "4        physiological context      NaN  physiological    NaN  \n",
              "...                        ...      ...            ...    ...  \n",
              "2113052                    NaN      NaN           info    NaN  \n",
              "2113053                    NaN      NaN           info    NaN  \n",
              "2113054                    NaN      NaN           info    NaN  \n",
              "2113055                    NaN      NaN           info    NaN  \n",
              "2113056                    NaN      NaN           info    NaN  \n",
              "\n",
              "[2113057 rows x 10 columns]"
            ]
          },
          "execution_count": 158,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_entities.to_csv('all_entities.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp_clinical",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
