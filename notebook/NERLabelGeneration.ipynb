{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "viVUeCs_w87G"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sys\n",
        "import gc\n",
        "import os\n",
        "import spacy\n",
        "import scispacy\n",
        "from dateutil import parser\n",
        "from spacy.matcher import Matcher\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.4.4\n",
            "0.5.1\n",
            "3.4.0\n",
            "/opt/anaconda3/envs/nlp_clinical/bin/python\n"
          ]
        }
      ],
      "source": [
        "print(spacy.__version__)\n",
        "print(scispacy.__version__)\n",
        "import en_core_web_sm\n",
        "print(en_core_web_sm.__version__)\n",
        "import sys\n",
        "print(sys.executable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_data_path(filename):\n",
        "    \"\"\"\n",
        "    Returns the path to a file in the data/clean directory.\n",
        "    \n",
        "    Args:\n",
        "        filename (str): Name of the file (including extension)\n",
        "    \n",
        "    Returns:\n",
        "        str: Full path to the file\n",
        "    \"\"\"\n",
        "    cwd = os.getcwd()\n",
        "    parent_dir = os.path.dirname(cwd)\n",
        "    file_path = os.path.join(parent_dir, 'data', 'clean', filename)\n",
        "    return file_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MW9AtVsMxHf2"
      },
      "outputs": [],
      "source": [
        "df_medical_expanded = get_data_path('df_medical_expanded.csv')\n",
        "df_medical = pd.read_csv(df_medical_expanded, index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "e83tzaAQyjT0"
      },
      "outputs": [],
      "source": [
        "df_diagnosis_expanded = get_data_path('df_diagnosis_expanded.csv')\n",
        "df_diagnosis = pd.read_csv(df_diagnosis_expanded, index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "o_wuhPP_ynrx"
      },
      "outputs": [],
      "source": [
        "df_surgery_expanded = get_data_path('df_surgery_expanded.csv')\n",
        "df_surgery = pd.read_csv(df_surgery_expanded, index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OA923I2boKGO"
      },
      "outputs": [],
      "source": [
        "df_symptoms_expanded = get_data_path('df_symptoms_expanded.csv')\n",
        "df_symptoms = pd.read_csv(df_symptoms_expanded, index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_treatments_expanded = get_data_path('df_treatments_expanded.csv')\n",
        "df_treatments = pd.read_csv(df_treatments_expanded, index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_info_expanded = get_data_path('df_info_expanded.csv')\n",
        "df_info = pd.read_csv(df_info_expanded, index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV6EH4ZwyfA2"
      },
      "source": [
        "### Medical Entity Extractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "j0cxD2sCydnw"
      },
      "outputs": [],
      "source": [
        "class MedicalEntityExtractor:\n",
        "    def __init__(self, model_name=\"en_core_sci_sm\", batch_size=500):\n",
        "        \"\"\"\n",
        "        Initialize the medical entity extractor.\n",
        "\n",
        "        Args:\n",
        "            model_name: ScispaCy model to use. Options:\n",
        "                       - \"en_core_sci_sm\" (smaller, faster, generic entities)\n",
        "                       - \"en_core_sci_md\" (medium)\n",
        "                       - \"en_ner_bc5cdr_md\" (disease/chemical focused - BEST FOR MEDICAL)\n",
        "                       - \"en_ner_bionlp13cg_md\" (multiple bio entity types)\n",
        "            batch_size: Number of texts to process at once\n",
        "        \"\"\"\n",
        "        self.batch_size = batch_size\n",
        "        self.model_name = model_name\n",
        "        self.nlp = None\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"Load the SpaCy model with optimizations for memory efficiency.\"\"\"\n",
        "        print(f\"Loading {self.model_name}...\")\n",
        "        try:\n",
        "            self.nlp = spacy.load(self.model_name)\n",
        "        except:\n",
        "            print(f\"Model {self.model_name} not found. Installing...\")\n",
        "            import os\n",
        "            # Install the appropriate model\n",
        "            if self.model_name == \"en_ner_bc5cdr_md\":\n",
        "                os.system(\"pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bc5cdr_md-0.5.1.tar.gz\")\n",
        "            elif self.model_name == \"en_ner_bionlp13cg_md\":\n",
        "                os.system(\"pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bionlp13cg_md-0.5.1.tar.gz\")\n",
        "            else:\n",
        "                os.system(f\"pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/{self.model_name}-0.5.1.tar.gz\")\n",
        "            self.nlp = spacy.load(self.model_name)\n",
        "\n",
        "        # Disable unnecessary pipeline components to save memory\n",
        "        pipes_to_disable = [\"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"]\n",
        "        for pipe in pipes_to_disable:\n",
        "            if pipe in self.nlp.pipe_names:\n",
        "                self.nlp.disable_pipe(pipe)\n",
        "\n",
        "        print(f\"Model loaded. Active pipes: {self.nlp.pipe_names}\")\n",
        "\n",
        "    def process_batch(self, texts):\n",
        "        \"\"\"Process a batch of texts and extract entities.\"\"\"\n",
        "        batch_results = []\n",
        "\n",
        "        # Process texts through spaCy pipeline\n",
        "        docs = list(self.nlp.pipe(texts, batch_size=50))\n",
        "\n",
        "        for doc, original_text in zip(docs, texts):\n",
        "            entities = []\n",
        "            for ent in doc.ents:\n",
        "                entities.append({\n",
        "                    'text': ent.text,\n",
        "                    'label': ent.label_,\n",
        "                    'start': ent.start_char,\n",
        "                    'end': ent.end_char,\n",
        "                    'original_text': original_text\n",
        "                })\n",
        "            batch_results.extend(entities)\n",
        "\n",
        "        # Clear memory\n",
        "        del docs\n",
        "        gc.collect()\n",
        "\n",
        "        return batch_results\n",
        "\n",
        "    def extract_entities_from_df(self, df, text_column,\n",
        "                                save_checkpoints=True, checkpoint_dir='./ner_checkpoints'):\n",
        "        \"\"\"\n",
        "        Extract medical entities from a dataframe column in batches.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame containing the text data\n",
        "            text_column: Name of the column containing text (NOW REQUIRED, NO DEFAULT)\n",
        "            save_checkpoints: Whether to save progress periodically\n",
        "            checkpoint_dir: Directory to save checkpoints\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with extracted entities\n",
        "        \"\"\"\n",
        "        if self.nlp is None:\n",
        "            self.load_model()\n",
        "\n",
        "        # Prepare texts\n",
        "        texts = df[text_column].fillna('').astype(str).tolist()\n",
        "        total_batches = (len(texts) + self.batch_size - 1) // self.batch_size\n",
        "\n",
        "        all_results = []\n",
        "\n",
        "        # Create checkpoint directory if needed\n",
        "        if save_checkpoints:\n",
        "            import os\n",
        "            os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "        print(f\"Processing {len(texts)} texts in {total_batches} batches...\")\n",
        "        print(f\"Using model: {self.model_name} for column: {text_column}\")\n",
        "\n",
        "        # Process in batches with progress bar\n",
        "        for batch_idx in tqdm(range(0, len(texts), self.batch_size),\n",
        "                              desc=\"Processing batches\"):\n",
        "            batch_texts = texts[batch_idx:batch_idx + self.batch_size]\n",
        "\n",
        "            try:\n",
        "                batch_results = self.process_batch(batch_texts)\n",
        "                all_results.extend(batch_results)\n",
        "\n",
        "                # Save checkpoint every 10 batches\n",
        "                if save_checkpoints and (batch_idx // self.batch_size) % 10 == 0:\n",
        "                    checkpoint_df = pd.DataFrame(all_results)\n",
        "                    # Sanitize column name for filename\n",
        "                    safe_column_name = text_column.replace(' ', '_').replace('/', '_')\n",
        "                    checkpoint_df.to_csv(\n",
        "                        f\"{checkpoint_dir}/checkpoint_{safe_column_name}_{batch_idx}.csv\",\n",
        "                        index=False\n",
        "                    )\n",
        "                    print(f\"\\nCheckpoint saved at batch {batch_idx}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"\\nError processing batch {batch_idx}: {e}\")\n",
        "                continue\n",
        "\n",
        "            # Aggressive memory cleanup every 5 batches\n",
        "            if (batch_idx // self.batch_size) % 5 == 0:\n",
        "                gc.collect()\n",
        "\n",
        "        # Create final results DataFrame\n",
        "        results_df = pd.DataFrame(all_results)\n",
        "        results_df['source_column'] = text_column  # Track which column this came from\n",
        "\n",
        "        return results_df\n",
        "\n",
        "    def get_entity_summary(self, entities_df):\n",
        "        \"\"\"Generate summary statistics of extracted entities.\"\"\"\n",
        "        summary = {\n",
        "            'total_entities': len(entities_df),\n",
        "            'unique_entities': entities_df['text'].nunique(),\n",
        "            'entity_types': entities_df['label'].value_counts().to_dict(),\n",
        "            'top_entities': entities_df['text'].value_counts().head(20).to_dict()\n",
        "        }\n",
        "        return summary\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MedicalEntityExtractor:\n",
        "    def __init__(self, model_name=\"en_core_sci_sm\", batch_size=500):\n",
        "        \"\"\"\n",
        "        Initialize the medical entity extractor.\n",
        "\n",
        "        Args:\n",
        "            model_name: ScispaCy model to use. Options:\n",
        "                       - \"en_core_sci_sm\" (smaller, faster, generic entities)\n",
        "                       - \"en_core_sci_md\" (medium)\n",
        "                       - \"en_ner_bc5cdr_md\" (disease/chemical focused - BEST FOR MEDICAL)\n",
        "                       - \"en_ner_bionlp13cg_md\" (multiple bio entity types)\n",
        "            batch_size: Number of texts to process at once\n",
        "        \"\"\"\n",
        "        self.batch_size = batch_size\n",
        "        self.model_name = model_name\n",
        "        self.nlp = None\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"Load the SpaCy model with optimizations for memory efficiency.\"\"\"\n",
        "        print(f\"Loading {self.model_name}...\")\n",
        "        try:\n",
        "            self.nlp = spacy.load(self.model_name)\n",
        "        except:\n",
        "            print(f\"Model {self.model_name} not found. Installing...\")\n",
        "            import os\n",
        "            # Install the appropriate model\n",
        "            if self.model_name == \"en_ner_bc5cdr_md\":\n",
        "                os.system(\"pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bc5cdr_md-0.5.1.tar.gz\")\n",
        "            elif self.model_name == \"en_ner_bionlp13cg_md\":\n",
        "                os.system(\"pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bionlp13cg_md-0.5.1.tar.gz\")\n",
        "            else:\n",
        "                os.system(f\"pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/{self.model_name}-0.5.1.tar.gz\")\n",
        "            self.nlp = spacy.load(self.model_name)\n",
        "\n",
        "        # Disable unnecessary pipeline components to save memory\n",
        "        pipes_to_disable = [\"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"]\n",
        "        for pipe in pipes_to_disable:\n",
        "            if pipe in self.nlp.pipe_names:\n",
        "                self.nlp.disable_pipe(pipe)\n",
        "\n",
        "        print(f\"Model loaded. Active pipes: {self.nlp.pipe_names}\")\n",
        "\n",
        "    def process_batch(self, texts, ids):  # renamed 'indices' -> 'ids' for clarity\n",
        "        batch_results = []\n",
        "        docs = list(self.nlp.pipe(texts, batch_size=50))\n",
        "        for doc, original_text, rid in zip(docs, texts, ids):\n",
        "            for ent in doc.ents:\n",
        "                batch_results.append({\n",
        "                    'text': ent.text,\n",
        "                    'label': ent.label_,\n",
        "                    'start': ent.start_char,\n",
        "                    'end': ent.end_char,\n",
        "                    'original_text': original_text,\n",
        "                    'row_idx': rid,   # <- comes from the provided id column\n",
        "                })\n",
        "        del docs\n",
        "        gc.collect()\n",
        "        return batch_results\n",
        "\n",
        "    def extract_entities_from_df(\n",
        "        self, df, text_column, *,\n",
        "        save_checkpoints=True, checkpoint_dir='./ner_checkpoints',\n",
        "        id_column='idx'                    # <- NEW\n",
        "    ):\n",
        "        if self.nlp is None:\n",
        "            self.load_model()\n",
        "\n",
        "        texts = df[text_column].fillna('').astype(str).tolist()\n",
        "\n",
        "        # --- NEW: choose row IDs from the given column; fallback to df.index ---\n",
        "        if id_column is not None and id_column in df.columns:\n",
        "            ids_series = df[id_column]\n",
        "            # if there are NaNs in idx, fall back to positional index for those rows\n",
        "            ids_series = ids_series.where(pd.notna(ids_series), df.index)\n",
        "            ids = ids_series.tolist()\n",
        "            print(f\"Stamping row identifier from column: '{id_column}'\")\n",
        "        else:\n",
        "            ids = df.index.tolist()\n",
        "            print(\"Stamping row identifier from DataFrame index\")\n",
        "\n",
        "        total_batches = (len(texts) + self.batch_size - 1) // self.batch_size\n",
        "        all_results = []\n",
        "\n",
        "        if save_checkpoints:\n",
        "            import os\n",
        "            os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "        print(f\"Processing {len(texts)} texts in {total_batches} batches...\")\n",
        "        print(f\"Using model: {self.model_name} for column: {text_column}\")\n",
        "\n",
        "        for batch_start in tqdm(range(0, len(texts), self.batch_size), desc=\"Processing batches\"):\n",
        "            batch_end   = batch_start + self.batch_size\n",
        "            batch_texts = texts[batch_start:batch_end]\n",
        "            batch_ids   = ids[batch_start:batch_end]\n",
        "\n",
        "            try:\n",
        "                batch_results = self.process_batch(batch_texts, batch_ids)\n",
        "                all_results.extend(batch_results)\n",
        "\n",
        "                if save_checkpoints and ((batch_start // self.batch_size) % 10 == 0):\n",
        "                    checkpoint_df = pd.DataFrame(all_results)\n",
        "                    safe_column_name = text_column.replace(' ', '_').replace('/', '_')\n",
        "                    checkpoint_df.to_csv(\n",
        "                        f\"{checkpoint_dir}/checkpoint_{safe_column_name}_{batch_start}.csv\",\n",
        "                        index=False\n",
        "                    )\n",
        "                    print(f\"\\nCheckpoint saved at batch {batch_start}\")\n",
        "            except Exception as e:\n",
        "                print(f\"\\nError processing batch {batch_start}: {e}\")\n",
        "                continue\n",
        "\n",
        "            if (batch_start // self.batch_size) % 5 == 0:\n",
        "                gc.collect()\n",
        "\n",
        "        results_df = pd.DataFrame(all_results)\n",
        "        results_df['source_column'] = text_column\n",
        "        return results_df\n",
        "\n",
        "    def get_entity_summary(self, entities_df):\n",
        "        \"\"\"Generate summary statistics of extracted entities.\"\"\"\n",
        "        summary = {\n",
        "            'total_entities': len(entities_df),\n",
        "            'unique_entities': entities_df['text'].nunique(),\n",
        "            'entity_types': entities_df['label'].value_counts().to_dict(),\n",
        "            'top_entities': entities_df['text'].value_counts().head(20).to_dict()\n",
        "        }\n",
        "        return summary\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "FMIFtI9oxaEr"
      },
      "outputs": [],
      "source": [
        "# Helper functions for analysis\n",
        "def analyze_medical_entities(entities_df, min_frequency=5):\n",
        "    \"\"\"Analyze extracted entities and create labeling functions.\"\"\"\n",
        "    \n",
        "    # Find frequent medical conditions\n",
        "    frequent_entities = entities_df['text'].value_counts()\n",
        "    frequent_entities = frequent_entities[frequent_entities >= min_frequency]\n",
        "    \n",
        "    print(f\"Found {len(frequent_entities)} entities appearing >= {min_frequency} times\")\n",
        "    \n",
        "    # Group by entity type\n",
        "    entity_groups = {}\n",
        "    for label in entities_df['label'].unique():\n",
        "        label_entities = entities_df[entities_df['label'] == label]['text'].value_counts()\n",
        "        entity_groups[label] = label_entities.head(10).to_dict()\n",
        "    \n",
        "    return frequent_entities, entity_groups\n",
        "\n",
        "def create_entity_based_rules(entities_df, target_labels=['DISEASE', 'CHEMICAL'], source_column=None):\n",
        "    \"\"\"Create labeling functions based on extracted entities.\"\"\"\n",
        "    \n",
        "    # Get the source column from the entities_df if not provided\n",
        "    if source_column is None:\n",
        "        if 'source_column' in entities_df.columns:\n",
        "            source_column = entities_df['source_column'].iloc[0]\n",
        "        else:\n",
        "            raise ValueError(\"source_column must be provided or available in entities_df\")\n",
        "    \n",
        "    # Get top entities for each label type\n",
        "    rules = {}\n",
        "    \n",
        "    for label in target_labels:\n",
        "        if label in entities_df['label'].unique():\n",
        "            top_entities = entities_df[entities_df['label'] == label]['text'].value_counts().head(20)\n",
        "            \n",
        "            # Create a labeling function for this entity type\n",
        "            def make_labeling_function(entity_list, label_name, column_name):\n",
        "                def lf(row):\n",
        "                    # Handle column names with spaces\n",
        "                    if column_name in row:\n",
        "                        text = str(row[column_name]).lower()\n",
        "                    else:\n",
        "                        # Try alternative column names\n",
        "                        alt_column = column_name.replace('_', ' ')\n",
        "                        if alt_column in row:\n",
        "                            text = str(row[alt_column]).lower()\n",
        "                        else:\n",
        "                            return 'ABSTAIN'\n",
        "                    \n",
        "                    for entity in entity_list:\n",
        "                        if entity.lower() in text:\n",
        "                            return label_name\n",
        "                    return 'ABSTAIN'\n",
        "                \n",
        "                # Create safe function name\n",
        "                safe_column_name = column_name.replace(' ', '_').replace('/', '_')\n",
        "                lf.__name__ = f\"lf_{label_name.lower()}_{safe_column_name}\"\n",
        "                return lf\n",
        "            \n",
        "            rules[f'lf_{label.lower()}_{source_column.replace(\" \", \"_\")}'] = make_labeling_function(\n",
        "                top_entities.index.tolist(),\n",
        "                label,\n",
        "                source_column\n",
        "            )\n",
        "    \n",
        "    return rules\n",
        "\n",
        "# Main execution function for single column\n",
        "def run_medical_ner_extraction(df, text_column,\n",
        "                               model_name=\"en_ner_bc5cdr_md\", batch_size=500,id_column='idx'):\n",
        "    \"\"\"\n",
        "    Complete pipeline to extract medical entities from dataframe.\n",
        "    \n",
        "    Args:\n",
        "        df: dataframe with medical text\n",
        "        text_column: Column containing the text (NOW REQUIRED, NO DEFAULT)\n",
        "        model_name: Which ScispaCy model to use\n",
        "        batch_size: Batch size for processing\n",
        "    \n",
        "    Returns:\n",
        "        entities_df: DataFrame with all extracted entities\n",
        "        summary: Summary statistics\n",
        "        rules: Generated labeling functions\n",
        "    \"\"\"\n",
        "    if text_column not in df.columns:\n",
        "        raise ValueError(f\"Column '{text_column}' not found in dataframe.\")\n",
        "\n",
        "    extractor = MedicalEntityExtractor(model_name=model_name, batch_size=batch_size)\n",
        "    entities_df = extractor.extract_entities_from_df(\n",
        "        df, text_column, id_column=id_column\n",
        "    )\n",
        "    summary = extractor.get_entity_summary(entities_df)\n",
        "    frequent_entities, entity_groups = analyze_medical_entities(entities_df)\n",
        "    rules = create_entity_based_rules(entities_df, source_column=text_column)\n",
        "    return entities_df, summary, rules\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXFksOxYy3nJ"
      },
      "source": [
        "#### Extracting Entities From Patient Medical Record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        },
        "id": "AGXyAGvVGsRo",
        "outputId": "c2c61f27-c2c1-4b3f-bdfe-d1c19d76075e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>has_medical_history</th>\n",
              "      <th>physiological context</th>\n",
              "      <th>psychological context</th>\n",
              "      <th>vaccination history</th>\n",
              "      <th>allergies</th>\n",
              "      <th>exercise frequency</th>\n",
              "      <th>nutrition</th>\n",
              "      <th>sexual history</th>\n",
              "      <th>alcohol consumption</th>\n",
              "      <th>drug usage</th>\n",
              "      <th>smoking status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155216</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Diagnosed with bipolar affective disorder at t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133948</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Intensifying feelings of helplessness</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80176</td>\n",
              "      <td>True</td>\n",
              "      <td>History of left elbow arthrodesis performed fo...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72232</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>31864</td>\n",
              "      <td>True</td>\n",
              "      <td>Inability to walk since babyhood, did not walk...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Got married at the age of 15 and became pregna...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>39279</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>137017</td>\n",
              "      <td>True</td>\n",
              "      <td>Atrial fibrillation, Parkinson's disease, prev...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Non-smoker</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>98004</td>\n",
              "      <td>True</td>\n",
              "      <td>No past medical history</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>133320</td>\n",
              "      <td>True</td>\n",
              "      <td>Noticed the mass four years prior to presentation</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>No significant past medical history</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Denied any intravenous drug use, urine drug sc...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29755 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          idx  has_medical_history  \\\n",
              "0      155216                 True   \n",
              "2      133948                 True   \n",
              "3       80176                 True   \n",
              "4       72232                 True   \n",
              "5       31864                 True   \n",
              "...       ...                  ...   \n",
              "29995   39279                 True   \n",
              "29996  137017                 True   \n",
              "29997   98004                 True   \n",
              "29998  133320                 True   \n",
              "29999   97973                 True   \n",
              "\n",
              "                                   physiological context  \\\n",
              "0                                                    NaN   \n",
              "2                                                    NaN   \n",
              "3      History of left elbow arthrodesis performed fo...   \n",
              "4                                                    NaN   \n",
              "5      Inability to walk since babyhood, did not walk...   \n",
              "...                                                  ...   \n",
              "29995                                                NaN   \n",
              "29996  Atrial fibrillation, Parkinson's disease, prev...   \n",
              "29997                            No past medical history   \n",
              "29998  Noticed the mass four years prior to presentation   \n",
              "29999                No significant past medical history   \n",
              "\n",
              "                                   psychological context vaccination history  \\\n",
              "0      Diagnosed with bipolar affective disorder at t...                 NaN   \n",
              "2                  Intensifying feelings of helplessness                 NaN   \n",
              "3                                                    NaN                 NaN   \n",
              "4                                                    NaN                 NaN   \n",
              "5                                                    NaN                 NaN   \n",
              "...                                                  ...                 ...   \n",
              "29995                                                NaN                 NaN   \n",
              "29996                                                NaN                 NaN   \n",
              "29997                                                NaN                 NaN   \n",
              "29998                                                NaN                 NaN   \n",
              "29999                                                NaN                 NaN   \n",
              "\n",
              "      allergies exercise frequency nutrition  \\\n",
              "0           NaN                NaN       NaN   \n",
              "2           NaN                NaN       NaN   \n",
              "3           NaN                NaN       NaN   \n",
              "4           NaN                NaN       NaN   \n",
              "5           NaN                NaN       NaN   \n",
              "...         ...                ...       ...   \n",
              "29995       NaN                NaN       NaN   \n",
              "29996       NaN                NaN       NaN   \n",
              "29997       NaN                NaN       NaN   \n",
              "29998       NaN                NaN       NaN   \n",
              "29999       NaN                NaN       NaN   \n",
              "\n",
              "                                          sexual history alcohol consumption  \\\n",
              "0                                                    NaN                 NaN   \n",
              "2                                                    NaN                 NaN   \n",
              "3                                                    NaN                 NaN   \n",
              "4                                                    NaN                 NaN   \n",
              "5      Got married at the age of 15 and became pregna...                 NaN   \n",
              "...                                                  ...                 ...   \n",
              "29995                                                NaN                 NaN   \n",
              "29996                                                NaN                 NaN   \n",
              "29997                                                NaN                 NaN   \n",
              "29998                                                NaN                 NaN   \n",
              "29999                                                NaN                 NaN   \n",
              "\n",
              "                                              drug usage smoking status  \n",
              "0                                                    NaN            NaN  \n",
              "2                                                    NaN            NaN  \n",
              "3                                                    NaN            NaN  \n",
              "4                                                    NaN            NaN  \n",
              "5                                                    NaN            NaN  \n",
              "...                                                  ...            ...  \n",
              "29995                                                NaN            NaN  \n",
              "29996                                                NaN     Non-smoker  \n",
              "29997                                                NaN            NaN  \n",
              "29998                                                NaN            NaN  \n",
              "29999  Denied any intravenous drug use, urine drug sc...            NaN  \n",
              "\n",
              "[29755 rows x 12 columns]"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_medical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "psychological context\n",
              "Depression                                                               85\n",
              "Bipolar disorder                                                         30\n",
              "Schizophrenia                                                            29\n",
              "Anxiety                                                                  27\n",
              "No significant psychosocial history                                      14\n",
              "                                                                         ..\n",
              "Paranoid schizophrenia and bipolar disorder                               1\n",
              "Mentally retarded with aggressive behavior                                1\n",
              "Mental retardation grade 2, intelligence quotient of 23                   1\n",
              "mild phantom limb pain and very frequent nonpainful phantom sensation     1\n",
              "Exhibiting a tortured expression                                          1\n",
              "Name: count, Length: 2231, dtype: int64"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_medical['psychological context'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lrp60uMUy-bz"
      },
      "source": [
        "##### Physiological Contexts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoCanH92yzl_",
        "outputId": "dc25f9e7-9e35-423e-a81b-159aeba11064"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading en_ner_bc5cdr_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 29755 texts in 60 batches...\n",
            "Using model: en_ner_bc5cdr_md for column: physiological context\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   2%|▏         | 1/60 [00:01<01:05,  1.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  18%|█▊        | 11/60 [00:10<00:46,  1.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 5000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  35%|███▌      | 21/60 [00:19<00:37,  1.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 10000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  52%|█████▏    | 31/60 [00:29<00:27,  1.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  68%|██████▊   | 41/60 [00:38<00:18,  1.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 20000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  85%|████████▌ | 51/60 [00:47<00:08,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 25000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 60/60 [00:55<00:00,  1.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1249 entities appearing >= 5 times\n",
            "\n",
            "Testing generated labeling functions on df_medical...\n",
            "lf_disease_physiological_context applied to row 0: ABSTAIN\n",
            "lf_chemical_physiological_context applied to row 0: ABSTAIN\n",
            "\n",
            "=== DEBUG: Check extracted entities dataframe ===\n",
            "Shape of df_physiological_entities: (36272, 7)\n",
            "\n",
            "Column names: ['text', 'label', 'start', 'end', 'original_text', 'row_idx', 'source_column']\n",
            "\n",
            "First few rows:\n",
            "                      text    label  start  end  \\\n",
            "0  posttraumatic arthritis  DISEASE     48   71   \n",
            "1                     pain  DISEASE    116  120   \n",
            "2                 fracture  DISEASE    151  159   \n",
            "3      Coxa vara deformity  DISEASE      0   19   \n",
            "4                 fracture  DISEASE     75   83   \n",
            "\n",
            "                                       original_text  row_idx  \\\n",
            "0  History of left elbow arthrodesis performed fo...    80176   \n",
            "1  Inability to walk since babyhood, did not walk...    31864   \n",
            "2  Inability to walk since babyhood, did not walk...    31864   \n",
            "3  Coxa vara deformity of bilateral hips, bilater...   149866   \n",
            "4  Coxa vara deformity of bilateral hips, bilater...   149866   \n",
            "\n",
            "           source_column  \n",
            "0  physiological context  \n",
            "1  physiological context  \n",
            "2  physiological context  \n",
            "3  physiological context  \n",
            "4  physiological context  \n",
            "\n",
            "=== ACTUAL Entity Labels Found in df_physiological_entities ===\n",
            "label\n",
            "DISEASE     34647\n",
            "CHEMICAL     1625\n",
            "Name: count, dtype: int64\n",
            "\n",
            "============================================================\n",
            "CUSTOM ANATOMY EXTRACTION FOR PHYSIOLOGICAL CONTEXT\n",
            "============================================================\n",
            "\n",
            "Extracting anatomy entities...\n",
            "\n",
            "Custom anatomy extraction found 11110 anatomy mentions\n",
            "\n",
            "=== Anatomy Entity Distribution ===\n",
            "label\n",
            "ANATOMY                    10217\n",
            "ANATOMY_WITH_LATERALITY      893\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Anatomy Terms ===\n",
            "text\n",
            "coronary      763\n",
            "artery        747\n",
            "pulmonary     687\n",
            "heart         609\n",
            "back          584\n",
            "kidney        544\n",
            "liver         400\n",
            "valve         357\n",
            "lung          335\n",
            "knee          304\n",
            "neck          245\n",
            "hip           244\n",
            "cerebral      207\n",
            "cardiac       200\n",
            "thyroid       194\n",
            "bone          193\n",
            "skin          186\n",
            "vein          176\n",
            "bladder       173\n",
            "prostate      165\n",
            "chest         145\n",
            "colon         143\n",
            "limb          136\n",
            "joint         118\n",
            "muscle        107\n",
            "lobe          106\n",
            "extremity     103\n",
            "brain         100\n",
            "lymph node     98\n",
            "femur          97\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Anatomy by Category ===\n",
            "category\n",
            "cardiovascular    3293\n",
            "organs            3075\n",
            "joints            2220\n",
            "bones              811\n",
            "regions            591\n",
            "tissues            481\n",
            "neurological       428\n",
            "muscles            211\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Examples of Anatomy with Laterality ===\n",
            "              text laterality    anatomy\n",
            "1       left elbow       left      elbow\n",
            "4   bilateral hips  bilateral       hips\n",
            "19        left hip       left        hip\n",
            "28  right coronary      right   coronary\n",
            "30        left hip       left        hip\n",
            "32        left hip       left        hip\n",
            "37       left knee       left       knee\n",
            "39        left hip       left        hip\n",
            "44        left hip       left        hip\n",
            "51  left ventricle       left  ventricle\n",
            "\n",
            "=== COMBINING BC5CDR AND CUSTOM ENTITIES ===\n",
            "\n",
            "Total combined entities: 47382\n",
            "\n",
            "Combined entity distribution:\n",
            "label\n",
            "DISEASE                    34647\n",
            "ANATOMY                    10217\n",
            "CHEMICAL                    1625\n",
            "ANATOMY_WITH_LATERALITY      893\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Creating Anatomy-Specific Labeling Functions ===\n",
            "\n",
            "Testing anatomy labeling functions:\n",
            "\n",
            "\n",
            "Entity extraction complete! Saved:\n",
            "- physiological_entities_with_anatomy.csv (combined BC5CDR + anatomy)\n",
            "- anatomy_entities_detailed.csv (detailed anatomy with categories)\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Run extraction for the 'physiological context' column\n",
        "    df_physiological_entities, disease_summary, rules = run_medical_ner_extraction(\n",
        "        df_medical,\n",
        "        text_column='physiological context',\n",
        "        model_name=\"en_ner_bc5cdr_md\",\n",
        "        batch_size=500,\n",
        "        id_column='idx')\n",
        "    \n",
        "    # Test the generated rules\n",
        "    print(\"\\nTesting generated labeling functions on df_medical...\")\n",
        "    \n",
        "    # Select a sample row from the original df_medical to test the rules\n",
        "    # Ensure df_medical is not empty before accessing iloc[0]\n",
        "    if not df_medical.empty:\n",
        "        sample_row = df_medical.iloc[0]\n",
        "        \n",
        "        for rule_name, rule_func in rules.items():\n",
        "            # Apply the rule function to a row from the original df_medical\n",
        "            try:\n",
        "                test_result = rule_func(sample_row)\n",
        "                print(f\"{rule_name} applied to row 0: {test_result}\")\n",
        "            except KeyError as e:\n",
        "                print(f\"Error applying rule {rule_name}: {e}. Make sure the column '{e}' exists in df_medical.\")\n",
        "    else:\n",
        "        print(\"df_medical is empty, cannot test rules.\")\n",
        "    \n",
        "    print(\"\\n=== DEBUG: Check extracted entities dataframe ===\")\n",
        "    print(f\"Shape of df_physiological_entities: {df_physiological_entities.shape}\")\n",
        "    print(f\"\\nColumn names: {df_physiological_entities.columns.tolist()}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(df_physiological_entities.head())\n",
        "    \n",
        "    # Check what labels ScispaCy actually found in the entities dataframe\n",
        "    print(\"\\n=== ACTUAL Entity Labels Found in df_physiological_entities ===\")\n",
        "    if not df_physiological_entities.empty:\n",
        "        print(df_physiological_entities['label'].value_counts())\n",
        "        \n",
        "        # Check for 'ENTITY' label if present\n",
        "        if 'ENTITY' in df_physiological_entities['label'].values:\n",
        "            print(\"\\n=== Top ENTITY type examples from df_physiological_entities ===\")\n",
        "            physiological_entity_examples = df_physiological_entities[df_physiological_entities['label'] == 'ENTITY']['text'].value_counts().head(20)\n",
        "            print(physiological_entity_examples)\n",
        "    else:\n",
        "        print(\"df_physiological_entities is empty.\")\n",
        "    \n",
        "    # ============= CUSTOM ANATOMY EXTRACTION =============\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"CUSTOM ANATOMY EXTRACTION FOR PHYSIOLOGICAL CONTEXT\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    def extract_anatomy_from_physiological_context(df_medical):\n",
        "        \"\"\"Extract anatomy entities from physiological context that BC5CDR might miss\"\"\"\n",
        "        \n",
        "        anatomy_entities = []\n",
        "        \n",
        "        # Comprehensive anatomy patterns\n",
        "        anatomy_patterns = {\n",
        "            'organs': [\n",
        "                'heart', 'lung', 'lungs', 'liver', 'kidney', 'kidneys', 'brain', \n",
        "                'pancreas', 'spleen', 'stomach', 'intestine', 'colon', 'bladder',\n",
        "                'gallbladder', 'thyroid', 'prostate', 'uterus', 'ovary', 'ovaries'\n",
        "            ],\n",
        "            'bones': [\n",
        "                'bone', 'femur', 'tibia', 'fibula', 'humerus', 'radius', 'ulna',\n",
        "                'skull', 'spine', 'vertebra', 'vertebrae', 'rib', 'ribs', 'pelvis',\n",
        "                'clavicle', 'scapula', 'sternum', 'patella'\n",
        "            ],\n",
        "            'joints': [\n",
        "                'joint', 'hip', 'knee', 'shoulder', 'elbow', 'wrist', 'ankle',\n",
        "                'knuckle', 'finger', 'toe', 'neck', 'back'\n",
        "            ],\n",
        "            'cardiovascular': [\n",
        "                'artery', 'arteries', 'vein', 'veins', 'vessel', 'vessels',\n",
        "                'aorta', 'carotid', 'coronary', 'pulmonary', 'cardiac',\n",
        "                'ventricle', 'atrium', 'valve'\n",
        "            ],\n",
        "            'neurological': [\n",
        "                'nerve', 'nerves', 'neural', 'spinal cord', 'brainstem',\n",
        "                'cerebral', 'cerebellum', 'cortex', 'lobe', 'ganglion'\n",
        "            ],\n",
        "            'muscles': [\n",
        "                'muscle', 'muscles', 'tendon', 'ligament', 'fascia',\n",
        "                'biceps', 'triceps', 'quadriceps', 'hamstring'\n",
        "            ],\n",
        "            'regions': [\n",
        "                'chest', 'abdomen', 'pelvis', 'thorax', 'cranium',\n",
        "                'extremity', 'limb', 'upper extremity', 'lower extremity'\n",
        "            ],\n",
        "            'tissues': [\n",
        "                'skin', 'tissue', 'membrane', 'mucosa', 'epithelium',\n",
        "                'cartilage', 'marrow', 'lymph node', 'gland'\n",
        "            ]\n",
        "        }\n",
        "        \n",
        "        # Laterality terms\n",
        "        laterality_terms = ['left', 'right', 'bilateral', 'unilateral']\n",
        "        \n",
        "        # Process each row\n",
        "        for idx, row in df_medical.iterrows():\n",
        "            if pd.notna(row['physiological context']):\n",
        "                text = str(row['physiological context']).lower()\n",
        "                \n",
        "                # Extract anatomy terms\n",
        "                for category, terms in anatomy_patterns.items():\n",
        "                    for term in terms:\n",
        "                        if term in text:\n",
        "                            # Find all occurrences\n",
        "                            import re\n",
        "                            for match in re.finditer(r'\\b' + re.escape(term) + r'\\b', text):\n",
        "                                anatomy_entities.append({\n",
        "                                    'text': term,\n",
        "                                    'label': 'ANATOMY',\n",
        "                                    'category': category,\n",
        "                                    'start': match.start(),\n",
        "                                    'end': match.end(),\n",
        "                                    'original_text': row['physiological context'],\n",
        "                                    'source': 'custom_anatomy_extraction',\n",
        "                                    'row_idx': idx\n",
        "                                })\n",
        "                \n",
        "                # Extract laterality + anatomy combinations\n",
        "                for lat_term in laterality_terms:\n",
        "                    # Pattern: \"left hip\", \"bilateral knees\", etc.\n",
        "                    pattern = rf'\\b{lat_term}\\s+(\\w+)\\b'\n",
        "                    matches = re.finditer(pattern, text)\n",
        "                    for match in matches:\n",
        "                        full_term = match.group(0)\n",
        "                        anatomy_part = match.group(1)\n",
        "                        \n",
        "                        # Check if the anatomy part is in our patterns\n",
        "                        for category, terms in anatomy_patterns.items():\n",
        "                            if any(anatomy_part.startswith(term) for term in terms):\n",
        "                                anatomy_entities.append({\n",
        "                                    'text': full_term,\n",
        "                                    'label': 'ANATOMY_WITH_LATERALITY',\n",
        "                                    'category': category,\n",
        "                                    'laterality': lat_term,\n",
        "                                    'anatomy': anatomy_part,\n",
        "                                    'start': match.start(),\n",
        "                                    'end': match.end(),\n",
        "                                    'original_text': row['physiological context'],\n",
        "                                    'source': 'custom_anatomy_extraction',\n",
        "                                    'row_idx': idx\n",
        "                                })\n",
        "                                break\n",
        "        \n",
        "        return pd.DataFrame(anatomy_entities)\n",
        "    \n",
        "    # Extract custom anatomy entities\n",
        "    print(\"\\nExtracting anatomy entities...\")\n",
        "    df_anatomy_custom = extract_anatomy_from_physiological_context(df_medical)\n",
        "    \n",
        "    print(f\"\\nCustom anatomy extraction found {len(df_anatomy_custom)} anatomy mentions\")\n",
        "    \n",
        "    if not df_anatomy_custom.empty:\n",
        "        print(\"\\n=== Anatomy Entity Distribution ===\")\n",
        "        print(df_anatomy_custom['label'].value_counts())\n",
        "        \n",
        "        print(\"\\n=== Top Anatomy Terms ===\")\n",
        "        print(df_anatomy_custom['text'].value_counts().head(30))\n",
        "        \n",
        "        print(\"\\n=== Anatomy by Category ===\")\n",
        "        print(df_anatomy_custom['category'].value_counts())\n",
        "        \n",
        "        # Show examples of laterality\n",
        "        laterality_examples = df_anatomy_custom[df_anatomy_custom['label'] == 'ANATOMY_WITH_LATERALITY']\n",
        "        if not laterality_examples.empty:\n",
        "            print(\"\\n=== Examples of Anatomy with Laterality ===\")\n",
        "            print(laterality_examples[['text', 'laterality', 'anatomy']].head(10))\n",
        "    \n",
        "    # Combine BC5CDR entities with custom anatomy entities\n",
        "    print(\"\\n=== COMBINING BC5CDR AND CUSTOM ENTITIES ===\")\n",
        "    df_all_physiological_entities = pd.concat([\n",
        "        df_physiological_entities,\n",
        "        df_anatomy_custom[['text', 'label', 'start', 'end', 'original_text']]\n",
        "    ], ignore_index=True)\n",
        "    \n",
        "    print(f\"\\nTotal combined entities: {len(df_all_physiological_entities)}\")\n",
        "    print(\"\\nCombined entity distribution:\")\n",
        "    print(df_all_physiological_entities['label'].value_counts())\n",
        "    \n",
        "    # Create anatomy-specific labeling functions\n",
        "    print(\"\\n=== Creating Anatomy-Specific Labeling Functions ===\")\n",
        "    \n",
        "    def create_anatomy_labeling_functions():\n",
        "        \"\"\"Create labeling functions for anatomy patterns\"\"\"\n",
        "        \n",
        "        def lf_cardiac_anatomy(row):\n",
        "            text = str(row.get('physiological context', '')).lower()\n",
        "            cardiac_terms = ['heart', 'cardiac', 'coronary', 'ventricle', 'atrium', 'valve']\n",
        "            if any(term in text for term in cardiac_terms):\n",
        "                return 'CARDIAC_ANATOMY'\n",
        "            return 'ABSTAIN'\n",
        "        \n",
        "        def lf_musculoskeletal(row):\n",
        "            text = str(row.get('physiological context', '')).lower()\n",
        "            msk_terms = ['bone', 'joint', 'muscle', 'tendon', 'ligament', 'cartilage']\n",
        "            if any(term in text for term in msk_terms):\n",
        "                return 'MUSCULOSKELETAL'\n",
        "            return 'ABSTAIN'\n",
        "        \n",
        "        def lf_bilateral_anatomy(row):\n",
        "            text = str(row.get('physiological context', '')).lower()\n",
        "            if 'bilateral' in text:\n",
        "                return 'BILATERAL_CONDITION'\n",
        "            return 'ABSTAIN'\n",
        "        \n",
        "        def lf_neurological_anatomy(row):\n",
        "            text = str(row.get('physiological context', '')).lower()\n",
        "            neuro_terms = ['brain', 'nerve', 'neural', 'spinal', 'cerebral']\n",
        "            if any(term in text for term in neuro_terms):\n",
        "                return 'NEUROLOGICAL_ANATOMY'\n",
        "            return 'ABSTAIN'\n",
        "        \n",
        "        return [lf_cardiac_anatomy, lf_musculoskeletal, lf_bilateral_anatomy, lf_neurological_anatomy]\n",
        "    \n",
        "    # Test anatomy labeling functions\n",
        "    anatomy_lfs = create_anatomy_labeling_functions()\n",
        "    \n",
        "    print(\"\\nTesting anatomy labeling functions:\")\n",
        "    if not df_medical.empty:\n",
        "        for lf in anatomy_lfs:\n",
        "            result = lf(df_medical.iloc[0])\n",
        "            if result != 'ABSTAIN':\n",
        "                print(f\"  {lf.__name__}: {result}\")\n",
        "    \n",
        "    # Save combined results\n",
        "    df_all_physiological_entities.to_csv('physiological_entities_comprehensive.csv', index=False)\n",
        "    df_anatomy_custom.to_csv('anatomy_entities_detailed.csv', index=False)\n",
        "    \n",
        "    print(\"\\n\\nEntity extraction complete! Saved:\")\n",
        "    print(\"- physiological_entities_with_anatomy.csv (combined BC5CDR + anatomy)\")\n",
        "    print(\"- anatomy_entities_detailed.csv (detailed anatomy with categories)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>source_column</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>posttraumatic arthritis</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>48</td>\n",
              "      <td>71</td>\n",
              "      <td>History of left elbow arthrodesis performed fo...</td>\n",
              "      <td>80176.0</td>\n",
              "      <td>physiological context</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pain</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>116</td>\n",
              "      <td>120</td>\n",
              "      <td>Inability to walk since babyhood, did not walk...</td>\n",
              "      <td>31864.0</td>\n",
              "      <td>physiological context</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fracture</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>151</td>\n",
              "      <td>159</td>\n",
              "      <td>Inability to walk since babyhood, did not walk...</td>\n",
              "      <td>31864.0</td>\n",
              "      <td>physiological context</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Coxa vara deformity</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>Coxa vara deformity of bilateral hips, bilater...</td>\n",
              "      <td>149866.0</td>\n",
              "      <td>physiological context</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fracture</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>75</td>\n",
              "      <td>83</td>\n",
              "      <td>Coxa vara deformity of bilateral hips, bilater...</td>\n",
              "      <td>149866.0</td>\n",
              "      <td>physiological context</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47377</th>\n",
              "      <td>colon</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>61</td>\n",
              "      <td>66</td>\n",
              "      <td>Coronary arteriosclerosis, spinal canal stenos...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47378</th>\n",
              "      <td>coronary</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>Coronary arteriosclerosis, spinal canal stenos...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47379</th>\n",
              "      <td>kidney</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>Kidney stone lithotripsy, hypertension treated...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47380</th>\n",
              "      <td>pulmonary</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>20</td>\n",
              "      <td>29</td>\n",
              "      <td>Chronic obstructive pulmonary disease, high bl...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47381</th>\n",
              "      <td>prostate</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>51</td>\n",
              "      <td>59</td>\n",
              "      <td>Atrial fibrillation, Parkinson's disease, prev...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47382 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                          text    label  start  end  \\\n",
              "0      posttraumatic arthritis  DISEASE     48   71   \n",
              "1                         pain  DISEASE    116  120   \n",
              "2                     fracture  DISEASE    151  159   \n",
              "3          Coxa vara deformity  DISEASE      0   19   \n",
              "4                     fracture  DISEASE     75   83   \n",
              "...                        ...      ...    ...  ...   \n",
              "47377                    colon  ANATOMY     61   66   \n",
              "47378                 coronary  ANATOMY      0    8   \n",
              "47379                   kidney  ANATOMY      0    6   \n",
              "47380                pulmonary  ANATOMY     20   29   \n",
              "47381                 prostate  ANATOMY     51   59   \n",
              "\n",
              "                                           original_text   row_idx  \\\n",
              "0      History of left elbow arthrodesis performed fo...   80176.0   \n",
              "1      Inability to walk since babyhood, did not walk...   31864.0   \n",
              "2      Inability to walk since babyhood, did not walk...   31864.0   \n",
              "3      Coxa vara deformity of bilateral hips, bilater...  149866.0   \n",
              "4      Coxa vara deformity of bilateral hips, bilater...  149866.0   \n",
              "...                                                  ...       ...   \n",
              "47377  Coronary arteriosclerosis, spinal canal stenos...       NaN   \n",
              "47378  Coronary arteriosclerosis, spinal canal stenos...       NaN   \n",
              "47379  Kidney stone lithotripsy, hypertension treated...       NaN   \n",
              "47380  Chronic obstructive pulmonary disease, high bl...       NaN   \n",
              "47381  Atrial fibrillation, Parkinson's disease, prev...       NaN   \n",
              "\n",
              "               source_column  \n",
              "0      physiological context  \n",
              "1      physiological context  \n",
              "2      physiological context  \n",
              "3      physiological context  \n",
              "4      physiological context  \n",
              "...                      ...  \n",
              "47377                    NaN  \n",
              "47378                    NaN  \n",
              "47379                    NaN  \n",
              "47380                    NaN  \n",
              "47381                    NaN  \n",
              "\n",
              "[47382 rows x 7 columns]"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_all_physiological_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Irq6-yqQD4Qr"
      },
      "source": [
        "##### Psychological Contexts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUt-GotMD7uV",
        "outputId": "56510d74-ad34-4de2-a826-51d307e0e632"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading en_ner_bc5cdr_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 29755 texts in 60 batches...\n",
            "Using model: en_ner_bc5cdr_md for column: psychological context\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   2%|▏         | 1/60 [00:01<01:09,  1.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  18%|█▊        | 11/60 [00:03<00:14,  3.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 5000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  35%|███▌      | 21/60 [00:06<00:10,  3.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 10000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  52%|█████▏    | 31/60 [00:08<00:07,  3.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  68%|██████▊   | 41/60 [00:11<00:05,  3.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 20000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  85%|████████▌ | 51/60 [00:14<00:02,  3.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 25000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 60/60 [00:16<00:00,  3.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 136 entities appearing >= 5 times\n",
            "\n",
            "Testing generated labeling functions on df_medical...\n",
            "lf_disease_psychological_context applied to row 0: ABSTAIN\n",
            "lf_chemical_psychological_context applied to row 0: ABSTAIN\n",
            "\n",
            "=== DEBUG: Check extracted entities dataframe ===\n",
            "Shape of df_medical_entities: (3402, 7)\n",
            "\n",
            "Column names: ['text', 'label', 'start', 'end', 'original_text', 'row_idx', 'source_column']\n",
            "\n",
            "First few rows:\n",
            "                         text    label  start  end  \\\n",
            "0  bipolar affective disorder  DISEASE     15   41   \n",
            "1                       mania  DISEASE     90   95   \n",
            "2           Parental distress  DISEASE      0   17   \n",
            "3                  depression  DISEASE     68   78   \n",
            "4                     anxiety  DISEASE     83   90   \n",
            "\n",
            "                                       original_text  row_idx  \\\n",
            "0  Diagnosed with bipolar affective disorder at t...   155216   \n",
            "1  Diagnosed with bipolar affective disorder at t...   155216   \n",
            "2                                  Parental distress    90928   \n",
            "3  Known to local mental health services for 20 y...    45433   \n",
            "4  Known to local mental health services for 20 y...    45433   \n",
            "\n",
            "           source_column  \n",
            "0  psychological context  \n",
            "1  psychological context  \n",
            "2  psychological context  \n",
            "3  psychological context  \n",
            "4  psychological context  \n",
            "\n",
            "=== ACTUAL Entity Labels Found in df_physiological_entities ===\n",
            "label\n",
            "DISEASE     3240\n",
            "CHEMICAL     162\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Run extraction for the 'psychological context' column\n",
        "    df_psychological_entities, disease_summary, rules = run_medical_ner_extraction(\n",
        "        df_medical,\n",
        "        text_column='psychological context',\n",
        "        model_name=\"en_ner_bc5cdr_md\",\n",
        "        batch_size=500,\n",
        "        id_column='idx')\n",
        "\n",
        "    # Test the generated rules\n",
        "    print(\"\\nTesting generated labeling functions on df_medical...\")\n",
        "\n",
        "    # Select a sample row from the original df_medical to test the rules\n",
        "    # Ensure df_medical is not empty before accessing iloc[0]\n",
        "    if not df_medical.empty:\n",
        "        sample_row = df_medical.iloc[0]\n",
        "\n",
        "        for rule_name, rule_func in rules.items():\n",
        "            # Apply the rule function to a row from the original df_medical\n",
        "            try:\n",
        "                test_result = rule_func(sample_row)\n",
        "                print(f\"{rule_name} applied to row 0: {test_result}\")\n",
        "            except KeyError as e:\n",
        "                print(f\"Error applying rule {rule_name}: {e}. Make sure the column '{e}' exists in df_medical.\")\n",
        "    else:\n",
        "        print(\"df_medical is empty, cannot test rules.\")\n",
        "\n",
        "\n",
        "print(\"\\n=== DEBUG: Check extracted entities dataframe ===\")\n",
        "print(f\"Shape of df_medical_entities: {df_psychological_entities.shape}\")\n",
        "print(f\"\\nColumn names: {df_psychological_entities.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(df_psychological_entities.head())\n",
        "\n",
        "# Check what labels ScispaCy actually found in the entities dataframe\n",
        "print(\"\\n=== ACTUAL Entity Labels Found in df_physiological_entities ===\")\n",
        "if not df_psychological_entities.empty:\n",
        "    print(df_psychological_entities['label'].value_counts())\n",
        "\n",
        "    # Check for 'ENTITY' label if present\n",
        "    if 'ENTITY' in df_psychological_entities['label'].values:\n",
        "        print(\"\\n=== Top ENTITY type examples from df_medical_entities ===\")\n",
        "        psychological_entity_examples = df_psychological_entities[df_psychological_entities['label'] == 'ENTITY']['text'].value_counts().head(20)\n",
        "        print(psychological_entity_examples)\n",
        "else:\n",
        "    print(\"df_psychological_entities is empty.\")\n",
        "\n",
        "    \n",
        "df_psychological_entities.to_csv('psychological_entities_comprehensive.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>source_column</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bipolar affective disorder</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>15</td>\n",
              "      <td>41</td>\n",
              "      <td>Diagnosed with bipolar affective disorder at t...</td>\n",
              "      <td>155216</td>\n",
              "      <td>psychological context</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mania</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>90</td>\n",
              "      <td>95</td>\n",
              "      <td>Diagnosed with bipolar affective disorder at t...</td>\n",
              "      <td>155216</td>\n",
              "      <td>psychological context</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Parental distress</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>Parental distress</td>\n",
              "      <td>90928</td>\n",
              "      <td>psychological context</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>depression</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>68</td>\n",
              "      <td>78</td>\n",
              "      <td>Known to local mental health services for 20 y...</td>\n",
              "      <td>45433</td>\n",
              "      <td>psychological context</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>anxiety</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>83</td>\n",
              "      <td>90</td>\n",
              "      <td>Known to local mental health services for 20 y...</td>\n",
              "      <td>45433</td>\n",
              "      <td>psychological context</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3397</th>\n",
              "      <td>Bipolar disorder</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>Bipolar disorder</td>\n",
              "      <td>87937</td>\n",
              "      <td>psychological context</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3398</th>\n",
              "      <td>Bipolar disorder</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>Bipolar disorder</td>\n",
              "      <td>113022</td>\n",
              "      <td>psychological context</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3399</th>\n",
              "      <td>psychiatric</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>No psychiatric symptoms or previous psychiatri...</td>\n",
              "      <td>160392</td>\n",
              "      <td>psychological context</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3400</th>\n",
              "      <td>psychiatric illness</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>36</td>\n",
              "      <td>55</td>\n",
              "      <td>No psychiatric symptoms or previous psychiatri...</td>\n",
              "      <td>160392</td>\n",
              "      <td>psychological context</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3401</th>\n",
              "      <td>Anxiety</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>60912</td>\n",
              "      <td>psychological context</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3402 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            text    label  start  end  \\\n",
              "0     bipolar affective disorder  DISEASE     15   41   \n",
              "1                          mania  DISEASE     90   95   \n",
              "2              Parental distress  DISEASE      0   17   \n",
              "3                     depression  DISEASE     68   78   \n",
              "4                        anxiety  DISEASE     83   90   \n",
              "...                          ...      ...    ...  ...   \n",
              "3397            Bipolar disorder  DISEASE      0   16   \n",
              "3398            Bipolar disorder  DISEASE      0   16   \n",
              "3399                 psychiatric  DISEASE      3   14   \n",
              "3400         psychiatric illness  DISEASE     36   55   \n",
              "3401                     Anxiety  DISEASE      0    7   \n",
              "\n",
              "                                          original_text  row_idx  \\\n",
              "0     Diagnosed with bipolar affective disorder at t...   155216   \n",
              "1     Diagnosed with bipolar affective disorder at t...   155216   \n",
              "2                                     Parental distress    90928   \n",
              "3     Known to local mental health services for 20 y...    45433   \n",
              "4     Known to local mental health services for 20 y...    45433   \n",
              "...                                                 ...      ...   \n",
              "3397                                   Bipolar disorder    87937   \n",
              "3398                                   Bipolar disorder   113022   \n",
              "3399  No psychiatric symptoms or previous psychiatri...   160392   \n",
              "3400  No psychiatric symptoms or previous psychiatri...   160392   \n",
              "3401                                            Anxiety    60912   \n",
              "\n",
              "              source_column  \n",
              "0     psychological context  \n",
              "1     psychological context  \n",
              "2     psychological context  \n",
              "3     psychological context  \n",
              "4     psychological context  \n",
              "...                     ...  \n",
              "3397  psychological context  \n",
              "3398  psychological context  \n",
              "3399  psychological context  \n",
              "3400  psychological context  \n",
              "3401  psychological context  \n",
              "\n",
              "[3402 rows x 7 columns]"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_psychological_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8eao_3OH9R4"
      },
      "source": [
        "##### Vaccination History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnTnQ8AQH84G",
        "outputId": "e66fbf8e-04a7-456a-e842-9ecd21f1b753"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading en_ner_bc5cdr_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 29755 texts in 100 batches...\n",
            "Using model: en_ner_bc5cdr_md for column: vaccination history\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   2%|▏         | 2/100 [00:01<00:44,  2.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  12%|█▏        | 12/100 [00:02<00:15,  5.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 3000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  22%|██▏       | 22/100 [00:04<00:13,  5.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 6000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  32%|███▏      | 32/100 [00:06<00:12,  5.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 9000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  41%|████      | 41/100 [00:07<00:11,  5.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 12000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  52%|█████▏    | 52/100 [00:09<00:08,  5.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  62%|██████▏   | 62/100 [00:11<00:06,  5.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 18000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  72%|███████▏  | 72/100 [00:12<00:04,  5.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 21000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  82%|████████▏ | 82/100 [00:14<00:03,  5.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 24000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  92%|█████████▏| 92/100 [00:16<00:01,  5.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 27000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 100/100 [00:17<00:00,  5.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6 entities appearing >= 5 times\n",
            "\n",
            "Testing generated labeling functions for vaccination history...\n",
            "lf_disease_vaccination_history applied to row 0: ABSTAIN\n",
            "lf_chemical_vaccination_history applied to row 0: ABSTAIN\n",
            "\n",
            "=== DEBUG: Check extracted vaccination entities ===\n",
            "Shape of df_vaccination_entities: (129, 7)\n",
            "\n",
            "Column names: ['text', 'label', 'start', 'end', 'original_text', 'row_idx', 'source_column']\n",
            "\n",
            "First few rows:\n",
            "                text    label  start  end  \\\n",
            "0            Tetanus  DISEASE      0    7   \n",
            "1            tetanus  DISEASE     25   32   \n",
            "2       hyposplenism  DISEASE     39   51   \n",
            "3            tetanus  DISEASE     14   21   \n",
            "4  tetanus infection  DISEASE     37   54   \n",
            "\n",
            "                                       original_text  row_idx  \\\n",
            "0  Tetanus vaccination with tetanus immunoglobuli...   119386   \n",
            "1  Tetanus vaccination with tetanus immunoglobuli...   119386   \n",
            "2  Vaccinated post-treatment for presumed hypospl...    13774   \n",
            "3  No history of tetanus vaccination or tetanus i...   157338   \n",
            "4  No history of tetanus vaccination or tetanus i...   157338   \n",
            "\n",
            "         source_column  \n",
            "0  vaccination history  \n",
            "1  vaccination history  \n",
            "2  vaccination history  \n",
            "3  vaccination history  \n",
            "4  vaccination history  \n",
            "\n",
            "=== Entity Labels Found in Vaccination History ===\n",
            "label\n",
            "DISEASE     106\n",
            "CHEMICAL     23\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top CHEMICAL/Vaccine entities ===\n",
            "text\n",
            "vitamin K                6\n",
            "Calmette                 3\n",
            "Calmette-Guérin          2\n",
            "tetanus                  2\n",
            "Vitamin K                2\n",
            "Guérin                   2\n",
            "benzathine penicillin    1\n",
            "penicillin               1\n",
            "DTaP                     1\n",
            "DPT                      1\n",
            "Vaccine                  1\n",
            "diphtheria pertussis     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top DISEASE entities (conditions) ===\n",
            "text\n",
            "tetanus                     28\n",
            "Tetanus                     13\n",
            "hepatitis B                  8\n",
            "Anti-D                       5\n",
            "left buttock                 5\n",
            "varicella                    4\n",
            "fever                        3\n",
            "chickenpox                   3\n",
            "hepatitis A                  3\n",
            "poliomyelitis                2\n",
            "tuberculosis infection       2\n",
            "malaria                      2\n",
            "Fever                        1\n",
            "TB                           1\n",
            "Streptococcus pneumoniae     1\n",
            "Herpes simplex               1\n",
            "mumps infection              1\n",
            "COVID-19 infection           1\n",
            "encephalitis B               1\n",
            "zoster                       1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Vaccine-related entities found: ['Vaccine', 'acute respiratory syndrome coronavirus 2 vaccine', 'vaccine-associated']\n",
            "Disease-related entities found: ['tetanus', 'Tetanus', 'hepatitis B', 'varicella', 'hepatitis A', 'poliomyelitis', 'mumps infection', 'COVID-19 infection', 'diphtheria pertussis', 'Anti-tetanus']\n",
            "\n",
            "=== Testing Refined Vaccination Labeling Functions ===\n",
            "\n",
            "=== Labeling Function Coverage ===\n",
            "lf_covid_vaccination: 1.9% coverage (8/415)\n",
            "lf_childhood_vaccines: 20.2% coverage (84/415)\n",
            "lf_influenza_vaccination: 3.9% coverage (16/415)\n",
            "lf_hepatitis_vaccination: 2.7% coverage (11/415)\n",
            "lf_tetanus_vaccination: 10.8% coverage (45/415)\n",
            "lf_pneumococcal_vaccination: 3.1% coverage (13/415)\n",
            "lf_travel_vaccines: 2.9% coverage (12/415)\n",
            "lf_vaccination_timing: 23.1% coverage (96/415)\n",
            "lf_no_vaccination: 2.2% coverage (9/415)\n",
            "lf_vaccine_reaction: 2.4% coverage (10/415)\n",
            "lf_recent_vaccination: 1.0% coverage (4/415)\n",
            "lf_historical_vaccination: 7.5% coverage (31/415)\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # BC5CDR model will identify vaccines (CHEMICAL) and diseases (DISEASE)\n",
        "    df_vaccination_entities, vaccination_summary, vaccination_rules = run_medical_ner_extraction(\n",
        "        df_medical, \n",
        "        text_column='vaccination history',\n",
        "        model_name=\"en_ner_bc5cdr_md\",  # This model recognizes DISEASE and CHEMICAL entities\n",
        "        batch_size=300,\n",
        "        id_column='idx'  # Use 'idx' column for row identifiers\n",
        "    )\n",
        "\n",
        "    # Test the generated rules\n",
        "    print(\"\\nTesting generated labeling functions for vaccination history...\")\n",
        "\n",
        "    # Select a sample row from the original df_medical to test the rules\n",
        "    if not df_medical.empty:\n",
        "        sample_row = df_medical.iloc[0]\n",
        "\n",
        "        for rule_name, rule_func in vaccination_rules.items():\n",
        "            try:\n",
        "                test_result = rule_func(sample_row)\n",
        "                print(f\"{rule_name} applied to row 0: {test_result}\")\n",
        "            except KeyError as e:\n",
        "                print(f\"Error applying rule {rule_name}: {e}. Make sure the column 'vaccination_history' exists in df_medical.\")\n",
        "    else:\n",
        "        print(\"df_medical is empty, cannot test rules.\")\n",
        "\n",
        "    # Debug: Check extracted entities\n",
        "    print(\"\\n=== DEBUG: Check extracted vaccination entities ===\")\n",
        "    print(f\"Shape of df_vaccination_entities: {df_vaccination_entities.shape}\")\n",
        "    print(f\"\\nColumn names: {df_vaccination_entities.columns.tolist()}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(df_vaccination_entities.head())\n",
        "\n",
        "    # Check entity label distribution\n",
        "    print(\"\\n=== Entity Labels Found in Vaccination History ===\")\n",
        "    if not df_vaccination_entities.empty:\n",
        "        print(df_vaccination_entities['label'].value_counts())\n",
        "\n",
        "        # Look at CHEMICAL entities (likely vaccines)\n",
        "        if 'CHEMICAL' in df_vaccination_entities['label'].values:\n",
        "            print(\"\\n=== Top CHEMICAL/Vaccine entities ===\")\n",
        "            vaccine_entities = df_vaccination_entities[df_vaccination_entities['label'] == 'CHEMICAL']['text'].value_counts().head(20)\n",
        "            print(vaccine_entities)\n",
        "\n",
        "        # Look at DISEASE entities (conditions vaccines prevent)\n",
        "        if 'DISEASE' in df_vaccination_entities['label'].values:\n",
        "            print(\"\\n=== Top DISEASE entities (conditions) ===\")\n",
        "            disease_entities = df_vaccination_entities[df_vaccination_entities['label'] == 'DISEASE']['text'].value_counts().head(20)\n",
        "            print(disease_entities)\n",
        "    else:\n",
        "        print(\"df_vaccination_entities is empty.\")\n",
        "\n",
        "def create_vaccination_labeling_functions(entities_df):\n",
        "    \"\"\"Create specific labeling functions for vaccination history based on actual entities found\"\"\"\n",
        "\n",
        "    # First, let's see what vaccine-related entities were actually extracted\n",
        "    vaccine_related_terms = []\n",
        "    disease_related_terms = []\n",
        "\n",
        "    # Analyze the top entities to identify vaccine patterns\n",
        "    top_entities = entities_df['text'].value_counts().head(100)\n",
        "\n",
        "    for entity, count in top_entities.items():\n",
        "        entity_lower = entity.lower()\n",
        "\n",
        "        # Identify vaccine-related terms\n",
        "        if any(term in entity_lower for term in ['vaccin', 'immuniz', 'shot', 'injection', 'dose']):\n",
        "            vaccine_related_terms.append(entity)\n",
        "\n",
        "        # Identify disease/condition terms that vaccines prevent\n",
        "        if any(term in entity_lower for term in ['tetanus', 'hepatitis', 'measles', 'influenza',\n",
        "                                                  'covid', 'polio', 'pertussis', 'mumps', 'rubella',\n",
        "                                                  'pneumococcal', 'meningitis', 'hpv', 'varicella',\n",
        "                                                  'diphtheria', 'rotavirus']):\n",
        "            disease_related_terms.append(entity)\n",
        "\n",
        "    print(f\"\\nVaccine-related entities found: {vaccine_related_terms[:10]}\")\n",
        "    print(f\"Disease-related entities found: {disease_related_terms[:10]}\")\n",
        "\n",
        "    # Create labeling functions based on patterns in data\n",
        "    def lf_covid_vaccination(row):\n",
        "        \"\"\"Detect COVID-19 vaccination\"\"\"\n",
        "        text = str(row['vaccination history']).lower()\n",
        "        covid_patterns = [\n",
        "            'covid', 'coronavirus', 'sars-cov-2', 'pfizer', 'moderna',\n",
        "            'astrazeneca', 'johnson', 'mrna-1273', 'bnt162b2'\n",
        "        ]\n",
        "        if any(pattern in text for pattern in covid_patterns):\n",
        "            return 'COVID_VACCINE'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    def lf_childhood_vaccines(row):\n",
        "        \"\"\"Detect standard childhood vaccinations\"\"\"\n",
        "        text = str(row['vaccination history']).lower()\n",
        "        childhood_vaccines = [\n",
        "            'mmr', 'measles', 'mumps', 'rubella', 'varicella', 'chickenpox',\n",
        "            'polio', 'dtap', 'diphtheria', 'tetanus', 'pertussis', 'whooping',\n",
        "            'hib', 'hepatitis b', 'rotavirus', 'pcv', 'ipv'\n",
        "        ]\n",
        "        if any(vaccine in text for vaccine in childhood_vaccines):\n",
        "            return 'CHILDHOOD_VACCINES'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    def lf_influenza_vaccination(row):\n",
        "        \"\"\"Detect flu vaccination\"\"\"\n",
        "        text = str(row['vaccination history']).lower()\n",
        "        flu_patterns = ['influenza', 'flu vaccine', 'flu shot', 'seasonal flu', 'h1n1']\n",
        "        if any(pattern in text for pattern in flu_patterns):\n",
        "            return 'FLU_VACCINE'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    def lf_hepatitis_vaccination(row):\n",
        "        \"\"\"Detect hepatitis vaccinations\"\"\"\n",
        "        text = str(row['vaccination history']).lower()\n",
        "        if any(hep in text for hep in ['hepatitis a', 'hepatitis b', 'hep a', 'hep b', 'havrix', 'engerix']):\n",
        "            return 'HEPATITIS_VACCINE'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    def lf_tetanus_vaccination(row):\n",
        "        \"\"\"Detect tetanus/Td/Tdap vaccinations\"\"\"\n",
        "        text = str(row['vaccination history']).lower()\n",
        "        if any(tet in text for tet in ['tetanus', 'tdap', 'td ', 'boostrix', 'adacel']):\n",
        "            return 'TETANUS_VACCINE'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    def lf_pneumococcal_vaccination(row):\n",
        "        \"\"\"Detect pneumococcal vaccinations\"\"\"\n",
        "        text = str(row['vaccination history']).lower()\n",
        "        if any(pneumo in text for pneumo in ['pneumococcal', 'pneumonia vaccine', 'prevnar', 'pneumovax']):\n",
        "            return 'PNEUMO_VACCINE'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    def lf_travel_vaccines(row):\n",
        "        \"\"\"Detect travel-related vaccinations\"\"\"\n",
        "        text = str(row['vaccination history']).lower()\n",
        "        travel_vaccines = ['yellow fever', 'typhoid', 'japanese encephalitis', 'rabies',\n",
        "                          'meningococcal', 'cholera']\n",
        "        if any(vaccine in text for vaccine in travel_vaccines):\n",
        "            return 'TRAVEL_VACCINES'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    def lf_vaccination_timing(row):\n",
        "        \"\"\"Detect vaccination timing information\"\"\"\n",
        "        text = str(row['vaccination history']).lower()\n",
        "        timing_patterns = ['booster', 'dose', 'series', 'schedule', 'up to date',\n",
        "                          'fully vaccinated', 'partially vaccinated']\n",
        "        if any(pattern in text for pattern in timing_patterns):\n",
        "            return 'VACCINATION_TIMING'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    def lf_no_vaccination(row):\n",
        "        \"\"\"Detect absence of vaccination\"\"\"\n",
        "        text = str(row['vaccination history']).lower()\n",
        "        no_vax_patterns = ['no vaccination', 'not vaccinated', 'unvaccinated',\n",
        "                          'declined', 'refused', 'no history of vaccination']\n",
        "        if any(pattern in text for pattern in no_vax_patterns):\n",
        "            return 'UNVACCINATED'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    def lf_vaccine_reaction(row):\n",
        "        \"\"\"Detect vaccine reactions/side effects\"\"\"\n",
        "        text = str(row['vaccination history']).lower()\n",
        "        reaction_patterns = ['reaction', 'allergy', 'side effect', 'adverse', 'anaphylaxis']\n",
        "        if any(pattern in text for pattern in reaction_patterns):\n",
        "            return 'VACCINE_REACTION'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    # Since we have \"years\", \"months\", \"weeks\" as top entities, let's create time-based functions\n",
        "    def lf_recent_vaccination(row):\n",
        "        \"\"\"Detect recent vaccinations\"\"\"\n",
        "        text = str(row['vaccination history']).lower()\n",
        "        # Look for patterns indicating recent vaccination\n",
        "        if any(recent in text for recent in ['weeks ago', 'months ago', 'recently',\n",
        "                                             'last month', 'last week', 'this year']):\n",
        "            return 'RECENT_VACCINATION'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    def lf_historical_vaccination(row):\n",
        "        \"\"\"Detect historical vaccination information\"\"\"\n",
        "        text = str(row['vaccination history']).lower()\n",
        "        if 'history' in text and any(vax in text for vax in ['vaccin', 'immuniz']):\n",
        "            return 'VACCINATION_HISTORY'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    return [\n",
        "        lf_covid_vaccination,\n",
        "        lf_childhood_vaccines,\n",
        "        lf_influenza_vaccination,\n",
        "        lf_hepatitis_vaccination,\n",
        "        lf_tetanus_vaccination,\n",
        "        lf_pneumococcal_vaccination,\n",
        "        lf_travel_vaccines,\n",
        "        lf_vaccination_timing,\n",
        "        lf_no_vaccination,\n",
        "        lf_vaccine_reaction,\n",
        "        lf_recent_vaccination,\n",
        "        lf_historical_vaccination\n",
        "    ]\n",
        "\n",
        "vaccination_lfs = create_vaccination_labeling_functions(df_vaccination_entities)\n",
        "\n",
        "print(\"\\n=== Testing Refined Vaccination Labeling Functions ===\")\n",
        "if not df_medical.empty and 'vaccination history' in df_medical.columns:\n",
        "    # Test on multiple rows to see coverage\n",
        "    test_rows = min(10, len(df_medical))\n",
        "    results_summary = {lf.__name__: [] for lf in vaccination_lfs}\n",
        "\n",
        "    for i in range(test_rows):\n",
        "        row = df_medical.iloc[i]\n",
        "        if pd.notna(row['vaccination history']):\n",
        "            print(f\"\\nRow {i} vaccination history: {row['vaccination history'][:100]}...\")\n",
        "            for lf in vaccination_lfs:\n",
        "                result = lf(row)\n",
        "                if result != 'ABSTAIN':\n",
        "                    print(f\"  {lf.__name__}: {result}\")\n",
        "                    results_summary[lf.__name__].append(result)\n",
        "\n",
        "# Analyze coverage\n",
        "print(\"\\n=== Labeling Function Coverage ===\")\n",
        "total_non_na = df_medical['vaccination history'].notna().sum()\n",
        "for lf in vaccination_lfs:\n",
        "    labeled_count = sum(lf(row) != 'ABSTAIN' for _, row in df_medical.iterrows()\n",
        "                       if pd.notna(row.get('vaccination history', '')))\n",
        "    coverage = (labeled_count / total_non_na * 100) if total_non_na > 0 else 0\n",
        "    print(f\"{lf.__name__}: {coverage:.1f}% coverage ({labeled_count}/{total_non_na})\")\n",
        "\n",
        "# Save result\n",
        "df_vaccination_entities.to_csv('vaccination_entities_comprehensive.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>source_column</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tetanus</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>Tetanus vaccination with tetanus immunoglobuli...</td>\n",
              "      <td>119386</td>\n",
              "      <td>vaccination history</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tetanus</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>25</td>\n",
              "      <td>32</td>\n",
              "      <td>Tetanus vaccination with tetanus immunoglobuli...</td>\n",
              "      <td>119386</td>\n",
              "      <td>vaccination history</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hyposplenism</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>39</td>\n",
              "      <td>51</td>\n",
              "      <td>Vaccinated post-treatment for presumed hypospl...</td>\n",
              "      <td>13774</td>\n",
              "      <td>vaccination history</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tetanus</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>14</td>\n",
              "      <td>21</td>\n",
              "      <td>No history of tetanus vaccination or tetanus i...</td>\n",
              "      <td>157338</td>\n",
              "      <td>vaccination history</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tetanus infection</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>37</td>\n",
              "      <td>54</td>\n",
              "      <td>No history of tetanus vaccination or tetanus i...</td>\n",
              "      <td>157338</td>\n",
              "      <td>vaccination history</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>Calmette</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>9</td>\n",
              "      <td>17</td>\n",
              "      <td>bacillus Calmette–Guérin (BCG)</td>\n",
              "      <td>42118</td>\n",
              "      <td>vaccination history</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>Guérin</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>18</td>\n",
              "      <td>24</td>\n",
              "      <td>bacillus Calmette–Guérin (BCG)</td>\n",
              "      <td>42118</td>\n",
              "      <td>vaccination history</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>pandemic</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>49</td>\n",
              "      <td>57</td>\n",
              "      <td>Had not received seasonal influenza or 2009 H1...</td>\n",
              "      <td>74950</td>\n",
              "      <td>vaccination history</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>tetanus</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>16</td>\n",
              "      <td>23</td>\n",
              "      <td>Vaccinated with tetanus toxoid once</td>\n",
              "      <td>198046</td>\n",
              "      <td>vaccination history</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>Tetanus</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>Tetanus vaccination administered during curren...</td>\n",
              "      <td>68442</td>\n",
              "      <td>vaccination history</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>129 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  text     label  start  end  \\\n",
              "0              Tetanus   DISEASE      0    7   \n",
              "1              tetanus   DISEASE     25   32   \n",
              "2         hyposplenism   DISEASE     39   51   \n",
              "3              tetanus   DISEASE     14   21   \n",
              "4    tetanus infection   DISEASE     37   54   \n",
              "..                 ...       ...    ...  ...   \n",
              "124           Calmette  CHEMICAL      9   17   \n",
              "125             Guérin  CHEMICAL     18   24   \n",
              "126           pandemic   DISEASE     49   57   \n",
              "127            tetanus   DISEASE     16   23   \n",
              "128            Tetanus   DISEASE      0    7   \n",
              "\n",
              "                                         original_text  row_idx  \\\n",
              "0    Tetanus vaccination with tetanus immunoglobuli...   119386   \n",
              "1    Tetanus vaccination with tetanus immunoglobuli...   119386   \n",
              "2    Vaccinated post-treatment for presumed hypospl...    13774   \n",
              "3    No history of tetanus vaccination or tetanus i...   157338   \n",
              "4    No history of tetanus vaccination or tetanus i...   157338   \n",
              "..                                                 ...      ...   \n",
              "124                     bacillus Calmette–Guérin (BCG)    42118   \n",
              "125                     bacillus Calmette–Guérin (BCG)    42118   \n",
              "126  Had not received seasonal influenza or 2009 H1...    74950   \n",
              "127                Vaccinated with tetanus toxoid once   198046   \n",
              "128  Tetanus vaccination administered during curren...    68442   \n",
              "\n",
              "           source_column  \n",
              "0    vaccination history  \n",
              "1    vaccination history  \n",
              "2    vaccination history  \n",
              "3    vaccination history  \n",
              "4    vaccination history  \n",
              "..                   ...  \n",
              "124  vaccination history  \n",
              "125  vaccination history  \n",
              "126  vaccination history  \n",
              "127  vaccination history  \n",
              "128  vaccination history  \n",
              "\n",
              "[129 rows x 7 columns]"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_vaccination_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a1jNMwsRO5z"
      },
      "source": [
        "##### Allergies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymvhuE8cRUk9",
        "outputId": "020c83ca-765f-40ee-e857-69ed48147e9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading en_ner_bc5cdr_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 29755 texts in 100 batches...\n",
            "Using model: en_ner_bc5cdr_md for column: allergies\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   2%|▏         | 2/100 [00:01<00:44,  2.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  12%|█▏        | 12/100 [00:02<00:15,  5.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 3000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  22%|██▏       | 22/100 [00:04<00:13,  5.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 6000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  32%|███▏      | 32/100 [00:06<00:12,  5.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 9000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  42%|████▏     | 42/100 [00:07<00:10,  5.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 12000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  52%|█████▏    | 52/100 [00:09<00:08,  5.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  62%|██████▏   | 62/100 [00:11<00:06,  5.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 18000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  72%|███████▏  | 72/100 [00:13<00:05,  5.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 21000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  82%|████████▏ | 82/100 [00:14<00:03,  5.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 24000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  92%|█████████▏| 92/100 [00:16<00:01,  5.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 27000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 100/100 [00:18<00:00,  5.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 32 entities appearing >= 5 times\n",
            "\n",
            "Testing generated labeling functions for allergies...\n",
            "lf_disease_allergies applied to row 0: ABSTAIN\n",
            "lf_chemical_allergies applied to row 0: ABSTAIN\n",
            "\n",
            "=== DEBUG: Check extracted allergy entities ===\n",
            "Shape of df_allergies_entities: (934, 7)\n",
            "\n",
            "Column names: ['text', 'label', 'start', 'end', 'original_text', 'row_idx', 'source_column']\n",
            "\n",
            "First few rows:\n",
            "             text     label  start  end  \\\n",
            "0       allergies   DISEASE      9   18   \n",
            "1  drug allergies   DISEASE      9   23   \n",
            "2         allergy   DISEASE     18   25   \n",
            "3         Allergy   DISEASE      0    7   \n",
            "4     amoxicillin  CHEMICAL     11   22   \n",
            "\n",
            "                           original_text  row_idx source_column  \n",
            "0                     No known allergies    32488     allergies  \n",
            "1                No known drug allergies    77061     allergies  \n",
            "2  No sensitivity or allergy to any drug   149806     allergies  \n",
            "3                 Allergy to amoxicillin    83662     allergies  \n",
            "4                 Allergy to amoxicillin    83662     allergies  \n",
            "\n",
            "=== Entity Labels Found in Allergies ===\n",
            "label\n",
            "DISEASE     739\n",
            "CHEMICAL    195\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Allergy-related Entities ===\n",
            "text\n",
            "allergies                        291\n",
            "drug allergies                    92\n",
            "allergy                           73\n",
            "Allergy                           24\n",
            "penicillin                        24\n",
            "allergic reaction                 18\n",
            "Allergic                          16\n",
            "Penicillin                        16\n",
            "allergic                          14\n",
            "Allergic rhinitis                 12\n",
            "hypersensitivity                  12\n",
            "Seasonal allergies                11\n",
            "Allergic reaction                 10\n",
            "Penicillin allergy                 9\n",
            "allergic rhinitis                  9\n",
            "rash                               9\n",
            "anaphylaxis                        7\n",
            "vancomycin                         7\n",
            "penicillin allergy                 7\n",
            "paracetamol                        6\n",
            "trimethoprim/sulfamethoxazole      6\n",
            "Allergic reactions                 6\n",
            "Allergies                          6\n",
            "macrolide                          5\n",
            "drug intolerance                   5\n",
            "Calpol                             5\n",
            "angioedema                         5\n",
            "eczema                             5\n",
            "milk allergy                       5\n",
            "Allergic rhinoconjunctivitis       5\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Analyzing allergy entities for patterns...\n",
            "\n",
            "=== Testing Allergy Labeling Functions ===\n",
            "\n",
            "=== Allergy Labeling Function Coverage ===\n",
            "lf_drug_allergy: 12.9% coverage (106/819)\n",
            "lf_food_allergy: 10.7% coverage (88/819)\n",
            "lf_environmental_allergy: 9.0% coverage (74/819)\n",
            "lf_no_allergies: 31.3% coverage (256/819)\n",
            "lf_allergy_severity: 4.5% coverage (37/819)\n",
            "lf_allergy_reaction_type: 2.3% coverage (19/819)\n",
            "lf_seasonal_allergy: 1.8% coverage (15/819)\n",
            "lf_chemical_sensitivity: 0.1% coverage (1/819)\n",
            "lf_multiple_allergies: 6.3% coverage (52/819)\n",
            "lf_allergy_testing: 0.5% coverage (4/819)\n",
            "\n",
            "=== Common Allergy Patterns ===\n",
            "Penicillin allergy mentions: 56\n",
            "No known allergies mentions: 14\n",
            "Food allergy mentions: 19\n",
            "Total allergy records: 819\n",
            "\n",
            "=== Allergen Type Summary ===\n",
            "\n",
            "DRUGS: ['penicillin', 'Penicillin', 'Penicillin allergy', 'vancomycin', 'penicillin allergy', 'trimethoprim/sulfamethoxazole', 'clindamycin', 'amoxicillin', 'colomycin']\n",
            "\n",
            "FOODS: ['milk allergy']\n",
            "\n",
            "OTHER: ['allergies', 'drug allergies', 'allergy', 'Allergy', 'allergic reaction', 'Allergic', 'allergic', 'Allergic rhinitis', 'hypersensitivity', 'Seasonal allergies']\n"
          ]
        }
      ],
      "source": [
        "# Process allergies using BC5CDR model (recognizes DISEASE and CHEMICAL)\n",
        "if __name__ == \"__main__\":\n",
        "    # Run extraction for the 'allergies' column\n",
        "    # BC5CDR model will identify allergens (often CHEMICAL entities)\n",
        "    df_allergies_entities, allergies_summary, allergies_rules = run_medical_ner_extraction(\n",
        "        df_medical, \n",
        "        text_column='allergies',\n",
        "        model_name=\"en_ner_bc5cdr_md\",  # This model recognizes DISEASE and CHEMICAL entities\n",
        "        batch_size=300,\n",
        "        id_column='idx' \n",
        "    )\n",
        "\n",
        "    # Test the generated rules\n",
        "    print(\"\\nTesting generated labeling functions for allergies...\")\n",
        "\n",
        "    # Select a sample row from the original df_medical to test the rules\n",
        "    if not df_medical.empty:\n",
        "        sample_row = df_medical.iloc[0]\n",
        "\n",
        "        for rule_name, rule_func in allergies_rules.items():\n",
        "            try:\n",
        "                test_result = rule_func(sample_row)\n",
        "                print(f\"{rule_name} applied to row 0: {test_result}\")\n",
        "            except KeyError as e:\n",
        "                print(f\"Error applying rule {rule_name}: {e}. Make sure the column 'allergies' exists in df_medical.\")\n",
        "    else:\n",
        "        print(\"df_medical is empty, cannot test rules.\")\n",
        "\n",
        "    # Debug: Check extracted entities\n",
        "    print(\"\\n=== DEBUG: Check extracted allergy entities ===\")\n",
        "    print(f\"Shape of df_allergies_entities: {df_allergies_entities.shape}\")\n",
        "    print(f\"\\nColumn names: {df_allergies_entities.columns.tolist()}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(df_allergies_entities.head())\n",
        "\n",
        "    # Check entity label distribution\n",
        "    print(\"\\n=== Entity Labels Found in Allergies ===\")\n",
        "    if not df_allergies_entities.empty:\n",
        "        print(df_allergies_entities['label'].value_counts())\n",
        "\n",
        "        # Let's look at the top entities\n",
        "        print(\"\\n=== Top Allergy-related Entities ===\")\n",
        "        allergy_entities = df_allergies_entities['text'].value_counts().head(30)\n",
        "        print(allergy_entities)\n",
        "\n",
        "    # Create specific labeling functions for allergy data\n",
        "    def create_allergy_labeling_functions(entities_df):\n",
        "        \"\"\"Create specific labeling functions for allergies\"\"\"\n",
        "\n",
        "        # Analyze entities to understand patterns\n",
        "        top_entities = entities_df['text'].value_counts().head(100)\n",
        "        print(f\"\\nAnalyzing allergy entities for patterns...\")\n",
        "\n",
        "        # Common allergen categories\n",
        "        def lf_drug_allergy(row):\n",
        "            \"\"\"Detect drug/medication allergies\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            drug_patterns = [\n",
        "                'penicillin', 'amoxicillin', 'ampicillin', 'antibiotic',\n",
        "                'sulfa', 'aspirin', 'nsaid', 'ibuprofen', 'morphine',\n",
        "                'codeine', 'contrast', 'iodine', 'latex', 'adhesive'\n",
        "            ]\n",
        "            if any(drug in text for drug in drug_patterns):\n",
        "                return 'DRUG_ALLERGY'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_food_allergy(row):\n",
        "            \"\"\"Detect food allergies\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            food_patterns = [\n",
        "                'peanut', 'nut', 'shellfish', 'fish', 'milk', 'dairy',\n",
        "                'egg', 'wheat', 'gluten', 'soy', 'sesame', 'food'\n",
        "            ]\n",
        "            if any(food in text for food in food_patterns):\n",
        "                return 'FOOD_ALLERGY'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_environmental_allergy(row):\n",
        "            \"\"\"Detect environmental allergies\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            env_patterns = [\n",
        "                'pollen', 'dust', 'mold', 'grass', 'tree', 'ragweed',\n",
        "                'cat', 'dog', 'animal', 'dander', 'environmental'\n",
        "            ]\n",
        "            if any(env in text for env in env_patterns):\n",
        "                return 'ENVIRONMENTAL_ALLERGY'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_no_allergies(row):\n",
        "            \"\"\"Detect absence of allergies\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            no_allergy_patterns = [\n",
        "                'no known allergies', 'no allergies', 'nka', 'nkda',\n",
        "                'no known drug allergies', 'denies allergies', 'none'\n",
        "            ]\n",
        "            if any(pattern in text for pattern in no_allergy_patterns):\n",
        "                return 'NO_ALLERGIES'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_allergy_severity(row):\n",
        "            \"\"\"Detect severe allergic reactions\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            severity_patterns = [\n",
        "                'anaphylaxis', 'anaphylactic', 'severe', 'life-threatening',\n",
        "                'epipen', 'epinephrine', 'emergency'\n",
        "            ]\n",
        "            if any(pattern in text for pattern in severity_patterns):\n",
        "                return 'SEVERE_ALLERGY'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_allergy_reaction_type(row):\n",
        "            \"\"\"Detect specific reaction types\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            reaction_patterns = [\n",
        "                'rash', 'hives', 'swelling', 'itching', 'breathing',\n",
        "                'wheezing', 'nausea', 'vomiting', 'throat'\n",
        "            ]\n",
        "            if any(reaction in text for reaction in reaction_patterns):\n",
        "                return 'ALLERGIC_REACTION_DESCRIBED'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_seasonal_allergy(row):\n",
        "            \"\"\"Detect seasonal allergies\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            if any(season in text for season in ['seasonal', 'spring', 'fall', 'hay fever']):\n",
        "                return 'SEASONAL_ALLERGY'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_chemical_sensitivity(row):\n",
        "            \"\"\"Detect chemical sensitivities\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            chemical_patterns = [\n",
        "                'chemical', 'perfume', 'fragrance', 'smoke', 'detergent',\n",
        "                'cleaning', 'formaldehyde'\n",
        "            ]\n",
        "            if any(chem in text for chem in chemical_patterns):\n",
        "                return 'CHEMICAL_SENSITIVITY'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_multiple_allergies(row):\n",
        "            \"\"\"Detect multiple allergies\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            # Count commas or \"and\" as indicators of multiple allergies\n",
        "            if (text.count(',') >= 2 or text.count(' and ') >= 2) and 'no known' not in text:\n",
        "                return 'MULTIPLE_ALLERGIES'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_allergy_testing(row):\n",
        "            \"\"\"Detect allergy testing mentions\"\"\"\n",
        "            text = str(row['allergies']).lower()\n",
        "            if any(test in text for test in ['tested', 'skin test', 'patch test', 'ige']):\n",
        "                return 'ALLERGY_TESTED'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        return [\n",
        "            lf_drug_allergy,\n",
        "            lf_food_allergy,\n",
        "            lf_environmental_allergy,\n",
        "            lf_no_allergies,\n",
        "            lf_allergy_severity,\n",
        "            lf_allergy_reaction_type,\n",
        "            lf_seasonal_allergy,\n",
        "            lf_chemical_sensitivity,\n",
        "            lf_multiple_allergies,\n",
        "            lf_allergy_testing\n",
        "        ]\n",
        "\n",
        "    # Apply the allergy-specific labeling functions\n",
        "    allergy_lfs = create_allergy_labeling_functions(df_allergies_entities)\n",
        "\n",
        "    print(\"\\n=== Testing Allergy Labeling Functions ===\")\n",
        "    if not df_medical.empty and 'allergies' in df_medical.columns:\n",
        "        # Test on multiple rows to see coverage\n",
        "        test_rows = min(10, len(df_medical))\n",
        "\n",
        "        for i in range(test_rows):\n",
        "            row = df_medical.iloc[i]\n",
        "            if pd.notna(row['allergies']):\n",
        "                print(f\"\\nRow {i} allergies: {row['allergies'][:100]}...\")\n",
        "                for lf in allergy_lfs:\n",
        "                    result = lf(row)\n",
        "                    if result != 'ABSTAIN':\n",
        "                        print(f\"  {lf.__name__}: {result}\")\n",
        "\n",
        "    # Analyze coverage\n",
        "    print(\"\\n=== Allergy Labeling Function Coverage ===\")\n",
        "    total_non_na = df_medical['allergies'].notna().sum()\n",
        "    for lf in allergy_lfs:\n",
        "        labeled_count = sum(lf(row) != 'ABSTAIN' for _, row in df_medical.iterrows()\n",
        "                           if pd.notna(row.get('allergies', '')))\n",
        "        coverage = (labeled_count / total_non_na * 100) if total_non_na > 0 else 0\n",
        "        print(f\"{lf.__name__}: {coverage:.1f}% coverage ({labeled_count}/{total_non_na})\")\n",
        "\n",
        "    # Analyze specific patterns in allergies\n",
        "    print(\"\\n=== Common Allergy Patterns ===\")\n",
        "    if 'allergies' in df_medical.columns:\n",
        "        # Count specific allergen mentions\n",
        "        penicillin_mentions = df_medical['allergies'].str.contains('penicillin|Penicillin', na=False).sum()\n",
        "        no_allergy_mentions = df_medical['allergies'].str.contains('no known|NKA|NKDA', na=False, regex=True).sum()\n",
        "        food_allergy_mentions = df_medical['allergies'].str.contains('peanut|shellfish|milk|egg', na=False, regex=True).sum()\n",
        "\n",
        "        print(f\"Penicillin allergy mentions: {penicillin_mentions}\")\n",
        "        print(f\"No known allergies mentions: {no_allergy_mentions}\")\n",
        "        print(f\"Food allergy mentions: {food_allergy_mentions}\")\n",
        "        print(f\"Total allergy records: {df_medical['allergies'].notna().sum()}\")\n",
        "\n",
        "    # Create a summary of allergen types found\n",
        "    print(\"\\n=== Allergen Type Summary ===\")\n",
        "    allergen_summary = {\n",
        "        'drugs': [],\n",
        "        'foods': [],\n",
        "        'environmental': [],\n",
        "        'other': []\n",
        "    }\n",
        "\n",
        "    # Categorize top entities\n",
        "    for entity, count in df_allergies_entities['text'].value_counts().head(50).items():\n",
        "        entity_lower = entity.lower()\n",
        "        if any(drug in entity_lower for drug in ['cillin', 'mycin', 'zole', 'statin']):\n",
        "            allergen_summary['drugs'].append(entity)\n",
        "        elif any(food in entity_lower for food in ['nut', 'milk', 'egg', 'fish']):\n",
        "            allergen_summary['foods'].append(entity)\n",
        "        elif any(env in entity_lower for env in ['pollen', 'dust', 'grass']):\n",
        "            allergen_summary['environmental'].append(entity)\n",
        "        else:\n",
        "            allergen_summary['other'].append(entity)\n",
        "\n",
        "    for category, items in allergen_summary.items():\n",
        "        if items:\n",
        "            print(f\"\\n{category.upper()}: {items[:10]}\")  # Show top 10 in each category\n",
        "# Save result\n",
        "df_allergies_entities.to_csv('allergies_entities_comprehensive.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>source_column</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>allergies</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>No known allergies</td>\n",
              "      <td>32488</td>\n",
              "      <td>allergies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>drug allergies</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>9</td>\n",
              "      <td>23</td>\n",
              "      <td>No known drug allergies</td>\n",
              "      <td>77061</td>\n",
              "      <td>allergies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>allergy</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>18</td>\n",
              "      <td>25</td>\n",
              "      <td>No sensitivity or allergy to any drug</td>\n",
              "      <td>149806</td>\n",
              "      <td>allergies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Allergy</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>Allergy to amoxicillin</td>\n",
              "      <td>83662</td>\n",
              "      <td>allergies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>amoxicillin</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>11</td>\n",
              "      <td>22</td>\n",
              "      <td>Allergy to amoxicillin</td>\n",
              "      <td>83662</td>\n",
              "      <td>allergies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>929</th>\n",
              "      <td>docetaxel</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>28</td>\n",
              "      <td>37</td>\n",
              "      <td>Severe allergic reaction to docetaxel chemothe...</td>\n",
              "      <td>40349</td>\n",
              "      <td>allergies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>930</th>\n",
              "      <td>drug allergies</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>9</td>\n",
              "      <td>23</td>\n",
              "      <td>No known drug allergies</td>\n",
              "      <td>135761</td>\n",
              "      <td>allergies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>931</th>\n",
              "      <td>Allergic</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>Allergic to penicillin</td>\n",
              "      <td>138116</td>\n",
              "      <td>allergies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>932</th>\n",
              "      <td>penicillin</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>12</td>\n",
              "      <td>22</td>\n",
              "      <td>Allergic to penicillin</td>\n",
              "      <td>138116</td>\n",
              "      <td>allergies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>933</th>\n",
              "      <td>allergy</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>14</td>\n",
              "      <td>21</td>\n",
              "      <td>No history of allergy</td>\n",
              "      <td>38936</td>\n",
              "      <td>allergies</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>934 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               text     label  start  end  \\\n",
              "0         allergies   DISEASE      9   18   \n",
              "1    drug allergies   DISEASE      9   23   \n",
              "2           allergy   DISEASE     18   25   \n",
              "3           Allergy   DISEASE      0    7   \n",
              "4       amoxicillin  CHEMICAL     11   22   \n",
              "..              ...       ...    ...  ...   \n",
              "929       docetaxel  CHEMICAL     28   37   \n",
              "930  drug allergies   DISEASE      9   23   \n",
              "931        Allergic   DISEASE      0    8   \n",
              "932      penicillin  CHEMICAL     12   22   \n",
              "933         allergy   DISEASE     14   21   \n",
              "\n",
              "                                         original_text  row_idx source_column  \n",
              "0                                   No known allergies    32488     allergies  \n",
              "1                              No known drug allergies    77061     allergies  \n",
              "2                No sensitivity or allergy to any drug   149806     allergies  \n",
              "3                               Allergy to amoxicillin    83662     allergies  \n",
              "4                               Allergy to amoxicillin    83662     allergies  \n",
              "..                                                 ...      ...           ...  \n",
              "929  Severe allergic reaction to docetaxel chemothe...    40349     allergies  \n",
              "930                            No known drug allergies   135761     allergies  \n",
              "931                             Allergic to penicillin   138116     allergies  \n",
              "932                             Allergic to penicillin   138116     allergies  \n",
              "933                              No history of allergy    38936     allergies  \n",
              "\n",
              "[934 rows x 7 columns]"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_allergies_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoOiikgET1_Z"
      },
      "source": [
        "##### Drug Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zy78zi5T1hH",
        "outputId": "27e02f1c-aed5-4694-92f8-868805d99db5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading en_ner_bc5cdr_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 29755 texts in 100 batches...\n",
            "Using model: en_ner_bc5cdr_md for column: drug usage\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   2%|▏         | 2/100 [00:00<00:39,  2.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  12%|█▏        | 12/100 [00:02<00:17,  5.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 3000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  22%|██▏       | 22/100 [00:04<00:14,  5.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 6000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  32%|███▏      | 32/100 [00:06<00:12,  5.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 9000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  42%|████▏     | 42/100 [00:08<00:10,  5.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 12000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  52%|█████▏    | 52/100 [00:10<00:09,  5.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  62%|██████▏   | 62/100 [00:12<00:07,  5.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 18000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  72%|███████▏  | 72/100 [00:13<00:05,  5.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 21000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  82%|████████▏ | 82/100 [00:15<00:03,  5.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 24000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  92%|█████████▏| 92/100 [00:17<00:01,  5.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 27000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 100/100 [00:19<00:00,  5.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 27 entities appearing >= 5 times\n",
            "\n",
            "Testing generated labeling functions for drug usage...\n",
            "lf_disease_drug_usage applied to row 0: ABSTAIN\n",
            "lf_chemical_drug_usage applied to row 0: ABSTAIN\n",
            "\n",
            "=== DEBUG: Check extracted drug usage entities ===\n",
            "Shape of df_drug_usage_entities: (715, 7)\n",
            "\n",
            "Column names: ['text', 'label', 'start', 'end', 'original_text', 'row_idx', 'source_column']\n",
            "\n",
            "First few rows:\n",
            "                 text     label  start  end                    original_text  \\\n",
            "0            Diazepam  CHEMICAL      0    8  Diazepam and methadone overdose   \n",
            "1  methadone overdose  CHEMICAL     13   31  Diazepam and methadone overdose   \n",
            "2            zolpidem  CHEMICAL      9   17                Abuse of zolpidem   \n",
            "3          drug abuse   DISEASE     11   21            History of drug abuse   \n",
            "4          drug abuse   DISEASE     12   22           Intravenous drug abuse   \n",
            "\n",
            "   row_idx source_column  \n",
            "0   163624    drug usage  \n",
            "1   163624    drug usage  \n",
            "2    90815    drug usage  \n",
            "3    43921    drug usage  \n",
            "4    84350    drug usage  \n",
            "\n",
            "=== Entity Labels Found in Drug Usage ===\n",
            "label\n",
            "CHEMICAL    447\n",
            "DISEASE     268\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Drug Usage Entities ===\n",
            "text\n",
            "drug abuse                             113\n",
            "cocaine                                 92\n",
            "substance abuse                         47\n",
            "cannabis                                39\n",
            "methamphetamine                         31\n",
            "Cocaine                                 27\n",
            "steroid                                 17\n",
            "alcohol                                 15\n",
            "Heroin                                  14\n",
            "Cannabis                                10\n",
            "steroids                                10\n",
            "ecstasy                                  9\n",
            "methadone                                8\n",
            "benzodiazepines                          7\n",
            "amphetamines                             7\n",
            "caffeine                                 6\n",
            "LSD                                      6\n",
            "Methamphetamine                          6\n",
            "Substance abuse                          6\n",
            "cannabis abuse                           6\n",
            "Denies substance abuse                   5\n",
            "pain                                     5\n",
            "Polysubstance abuse                      5\n",
            "amphetamine                              5\n",
            "ketamine                                 5\n",
            "testosterone                             5\n",
            "fenethylline                             5\n",
            "cocaine abuse                            4\n",
            "accidental or intentional poisoning      4\n",
            "MDMA                                     4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Analyzing drug usage entities for patterns...\n",
            "\n",
            "=== Testing Drug Usage Labeling Functions ===\n",
            "\n",
            "=== Drug Usage Labeling Function Coverage ===\n",
            "lf_no_drug_use: 49.2% coverage (704/1430)\n",
            "lf_alcohol_use: 1.4% coverage (20/1430)\n",
            "lf_tobacco_use: 2.3% coverage (33/1430)\n",
            "lf_cannabis_use: 12.1% coverage (173/1430)\n",
            "lf_opioid_use: 7.3% coverage (105/1430)\n",
            "lf_stimulant_use: 12.5% coverage (179/1430)\n",
            "lf_iv_drug_use: 9.4% coverage (134/1430)\n",
            "lf_prescription_abuse: 0.0% coverage (0/1430)\n",
            "lf_polysubstance_use: 3.6% coverage (52/1430)\n",
            "lf_past_drug_use: 24.8% coverage (354/1430)\n",
            "lf_current_drug_use: 7.6% coverage (108/1430)\n",
            "lf_drug_treatment: 25.0% coverage (358/1430)\n",
            "lf_drug_screen_result: 0.4% coverage (6/1430)\n",
            "\n",
            "=== Common Drug Usage Patterns ===\n",
            "No drug use mentions: 46\n",
            "Alcohol mentions: 19\n",
            "Tobacco mentions: 23\n",
            "Illicit drug mentions: 186\n",
            "Total drug usage records: 1430\n",
            "\n",
            "=== Drug Use Risk Stratification ===\n",
            "UNKNOWN_RISK        28325\n",
            "UNSPECIFIED_RISK      850\n",
            "LOW_RISK              308\n",
            "HIGH_RISK             216\n",
            "MODERATE_RISK          56\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Process drug usage using BC5CDR model (recognizes DISEASE and CHEMICAL)\n",
        "if __name__ == \"__main__\":\n",
        "    # Run extraction for the 'drug usage' column\n",
        "    # BC5CDR model will identify drugs/substances (CHEMICAL entities)\n",
        "    df_drug_usage_entities, drug_usage_summary, drug_usage_rules = run_medical_ner_extraction(\n",
        "        df_medical,  \n",
        "        text_column='drug usage',\n",
        "        model_name=\"en_ner_bc5cdr_md\",  # This model recognizes DISEASE and CHEMICAL entities\n",
        "        batch_size=300, \n",
        "        id_column='idx'  )\n",
        "\n",
        "    # Test the generated rules\n",
        "    print(\"\\nTesting generated labeling functions for drug usage...\")\n",
        "\n",
        "    # Select a sample row from the original df_medical to test the rules\n",
        "    if not df_medical.empty:\n",
        "        sample_row = df_medical.iloc[0]\n",
        "\n",
        "        for rule_name, rule_func in drug_usage_rules.items():\n",
        "            try:\n",
        "                test_result = rule_func(sample_row)\n",
        "                print(f\"{rule_name} applied to row 0: {test_result}\")\n",
        "            except KeyError as e:\n",
        "                print(f\"Error applying rule {rule_name}: {e}. Make sure the column 'drug usage' exists in df_medical.\")\n",
        "    else:\n",
        "        print(\"df_medical is empty, cannot test rules.\")\n",
        "\n",
        "    # Debug: Check extracted entities\n",
        "    print(\"\\n=== DEBUG: Check extracted drug usage entities ===\")\n",
        "    print(f\"Shape of df_drug_usage_entities: {df_drug_usage_entities.shape}\")\n",
        "    print(f\"\\nColumn names: {df_drug_usage_entities.columns.tolist()}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(df_drug_usage_entities.head())\n",
        "\n",
        "    # Check entity label distribution\n",
        "    print(\"\\n=== Entity Labels Found in Drug Usage ===\")\n",
        "    if not df_drug_usage_entities.empty:\n",
        "        print(df_drug_usage_entities['label'].value_counts())\n",
        "\n",
        "        # Look at the top entities\n",
        "        print(\"\\n=== Top Drug Usage Entities ===\")\n",
        "        drug_entities = df_drug_usage_entities['text'].value_counts().head(30)\n",
        "        print(drug_entities)\n",
        "\n",
        "# Create specific labeling functions for drug usage data\n",
        "def create_drug_usage_labeling_functions(entities_df):\n",
        "        \"\"\"Create specific labeling functions for drug usage\"\"\"\n",
        "\n",
        "        # Analyze entities to understand patterns\n",
        "        top_entities = entities_df['text'].value_counts().head(100)\n",
        "        print(f\"\\nAnalyzing drug usage entities for patterns...\")\n",
        "\n",
        "        def lf_no_drug_use(row):\n",
        "            \"\"\"Detect absence of drug use\"\"\"\n",
        "            text = str(row['drug usage']).lower()\n",
        "            no_drug_patterns = [\n",
        "                'no drug', 'denies', 'denied', 'no history', 'no illicit',\n",
        "                'no substance', 'no recreational', 'never', 'none',\n",
        "                'no personal history', 'negative'\n",
        "            ]\n",
        "            if any(pattern in text for pattern in no_drug_patterns):\n",
        "                return 'NO_DRUG_USE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_alcohol_use(row):\n",
        "            \"\"\"Detect alcohol use patterns\"\"\"\n",
        "            text = str(row['drug usage']).lower()\n",
        "            alcohol_patterns = [\n",
        "                'alcohol', 'drinking', 'beer', 'wine', 'liquor', 'spirits',\n",
        "                'ethanol', 'etoh', 'drinks per', 'social drinking'\n",
        "            ]\n",
        "            if any(pattern in text for pattern in alcohol_patterns):\n",
        "                return 'ALCOHOL_USE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_tobacco_use(row):\n",
        "            \"\"\"Detect tobacco/nicotine use\"\"\"\n",
        "            text = str(row['drug usage']).lower()\n",
        "            tobacco_patterns = [\n",
        "                'tobacco', 'smoking', 'cigarette', 'nicotine', 'pack',\n",
        "                'cigar', 'chewing tobacco', 'vaping', 'e-cigarette'\n",
        "            ]\n",
        "            if any(pattern in text for pattern in tobacco_patterns):\n",
        "                return 'TOBACCO_USE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_cannabis_use(row):\n",
        "            \"\"\"Detect cannabis/marijuana use\"\"\"\n",
        "            text = str(row['drug usage']).lower()\n",
        "            cannabis_patterns = [\n",
        "                'cannabis', 'marijuana', 'thc', 'weed', 'pot', 'hemp',\n",
        "                'mary jane', 'ganja', 'hash', 'cannabinoid'\n",
        "            ]\n",
        "            if any(pattern in text for pattern in cannabis_patterns):\n",
        "                return 'CANNABIS_USE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_opioid_use(row):\n",
        "            \"\"\"Detect opioid use\"\"\"\n",
        "            text = str(row['drug usage']).lower()\n",
        "            opioid_patterns = [\n",
        "                'opioid', 'opiate', 'heroin', 'morphine', 'oxycodone',\n",
        "                'hydrocodone', 'fentanyl', 'codeine', 'tramadol', 'methadone',\n",
        "                'percocet', 'vicodin', 'oxycontin'\n",
        "            ]\n",
        "            if any(pattern in text for pattern in opioid_patterns):\n",
        "                return 'OPIOID_USE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_stimulant_use(row):\n",
        "            \"\"\"Detect stimulant use\"\"\"\n",
        "            text = str(row['drug usage']).lower()\n",
        "            stimulant_patterns = [\n",
        "                'cocaine', 'crack', 'amphetamine', 'methamphetamine', 'meth',\n",
        "                'speed', 'crystal', 'adderall', 'ritalin', 'mdma', 'ecstasy'\n",
        "            ]\n",
        "            if any(pattern in text for pattern in stimulant_patterns):\n",
        "                return 'STIMULANT_USE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_iv_drug_use(row):\n",
        "            \"\"\"Detect intravenous drug use\"\"\"\n",
        "            text = str(row['drug usage']).lower()\n",
        "            iv_patterns = [\n",
        "                'iv drug', 'intravenous', 'injection', 'needle', 'inject',\n",
        "                'ivdu', 'shooting up'\n",
        "            ]\n",
        "            if any(pattern in text for pattern in iv_patterns):\n",
        "                return 'IV_DRUG_USE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_prescription_abuse(row):\n",
        "            \"\"\"Detect prescription drug abuse\"\"\"\n",
        "            text = str(row['drug usage']).lower()\n",
        "            if ('prescription' in text or 'prescribed' in text) and \\\n",
        "               any(abuse in text for abuse in ['abuse', 'misuse', 'dependency', 'addiction']):\n",
        "                return 'PRESCRIPTION_ABUSE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_polysubstance_use(row):\n",
        "            \"\"\"Detect multiple substance use\"\"\"\n",
        "            text = str(row['drug usage']).lower()\n",
        "            # Count different drug mentions\n",
        "            substances = ['alcohol', 'tobacco', 'cannabis', 'cocaine', 'heroin', 'meth']\n",
        "            substance_count = sum(1 for sub in substances if sub in text)\n",
        "            if substance_count >= 2:\n",
        "                return 'POLYSUBSTANCE_USE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_past_drug_use(row):\n",
        "            \"\"\"Detect past/former drug use\"\"\"\n",
        "            text = str(row['drug usage']).lower()\n",
        "            past_patterns = [\n",
        "                'former', 'past', 'history of', 'previously', 'quit',\n",
        "                'stopped', 'used to', 'years ago', 'in recovery', 'sober'\n",
        "            ]\n",
        "            if any(pattern in text for pattern in past_patterns) and \\\n",
        "               not any(current in text for current in ['current', 'active', 'ongoing']):\n",
        "                return 'PAST_DRUG_USE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_current_drug_use(row):\n",
        "            \"\"\"Detect current/active drug use\"\"\"\n",
        "            text = str(row['drug usage']).lower()\n",
        "            current_patterns = [\n",
        "                'current', 'active', 'ongoing', 'continues', 'daily',\n",
        "                'regular', 'frequent', 'occasional'\n",
        "            ]\n",
        "            if any(pattern in text for pattern in current_patterns):\n",
        "                return 'CURRENT_DRUG_USE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_drug_treatment(row):\n",
        "            \"\"\"Detect drug treatment/rehabilitation\"\"\"\n",
        "            text = str(row['drug usage']).lower()\n",
        "            treatment_patterns = [\n",
        "                'rehab', 'treatment', 'recovery', 'aa', 'na', 'methadone clinic',\n",
        "                'suboxone', 'detox', 'counseling', 'therapy'\n",
        "            ]\n",
        "            if any(pattern in text for pattern in treatment_patterns):\n",
        "                return 'DRUG_TREATMENT'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_drug_screen_result(row):\n",
        "            \"\"\"Detect drug screening results\"\"\"\n",
        "            text = str(row['drug usage']).lower()\n",
        "            if any(screen in text for screen in ['drug screen', 'urine test', 'tested positive', 'tested negative']):\n",
        "                return 'DRUG_SCREEN_MENTIONED'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        return [\n",
        "            lf_no_drug_use,\n",
        "            lf_alcohol_use,\n",
        "            lf_tobacco_use,\n",
        "            lf_cannabis_use,\n",
        "            lf_opioid_use,\n",
        "            lf_stimulant_use,\n",
        "            lf_iv_drug_use,\n",
        "            lf_prescription_abuse,\n",
        "            lf_polysubstance_use,\n",
        "            lf_past_drug_use,\n",
        "            lf_current_drug_use,\n",
        "            lf_drug_treatment,\n",
        "            lf_drug_screen_result\n",
        "        ]\n",
        "# Apply the drug usage-specific labeling functions\n",
        "drug_usage_lfs = create_drug_usage_labeling_functions(df_drug_usage_entities)\n",
        "\n",
        "print(\"\\n=== Testing Drug Usage Labeling Functions ===\")\n",
        "if not df_medical.empty and 'drug usage' in df_medical.columns:\n",
        "        # Test on multiple rows to see coverage\n",
        "        test_rows = min(10, len(df_medical))\n",
        "\n",
        "        for i in range(test_rows):\n",
        "            row = df_medical.iloc[i]\n",
        "            if pd.notna(row['drug usage']):\n",
        "                print(f\"\\nRow {i} drug usage: {row['drug usage'][:100]}...\")\n",
        "                for lf in drug_usage_lfs:\n",
        "                    result = lf(row)\n",
        "                    if result != 'ABSTAIN':\n",
        "                        print(f\"  {lf.__name__}: {result}\")\n",
        "\n",
        "    # Analyze coverage\n",
        "print(\"\\n=== Drug Usage Labeling Function Coverage ===\")\n",
        "total_non_na = df_medical['drug usage'].notna().sum()\n",
        "for lf in drug_usage_lfs:\n",
        "    labeled_count = sum(lf(row) != 'ABSTAIN' for _, row in df_medical.iterrows()\n",
        "                        if pd.notna(row.get('drug usage', '')))\n",
        "    coverage = (labeled_count / total_non_na * 100) if total_non_na > 0 else 0\n",
        "    print(f\"{lf.__name__}: {coverage:.1f}% coverage ({labeled_count}/{total_non_na})\")\n",
        "\n",
        "# Analyze specific patterns in drug usage\n",
        "print(\"\\n=== Common Drug Usage Patterns ===\")\n",
        "if 'drug usage' in df_medical.columns:\n",
        "    # Count specific substance mentions\n",
        "    no_drug_mentions = df_medical['drug usage'].str.contains('no drug|denied|no history', na=False, regex=True).sum()\n",
        "    alcohol_mentions = df_medical['drug usage'].str.contains('alcohol|drinking|beer|wine', na=False, regex=True).sum()\n",
        "    tobacco_mentions = df_medical['drug usage'].str.contains('tobacco|smoking|cigarette', na=False, regex=True).sum()\n",
        "    illicit_mentions = df_medical['drug usage'].str.contains('cocaine|heroin|meth|cannabis', na=False, regex=True).sum()\n",
        "\n",
        "    print(f\"No drug use mentions: {no_drug_mentions}\")\n",
        "    print(f\"Alcohol mentions: {alcohol_mentions}\")\n",
        "    print(f\"Tobacco mentions: {tobacco_mentions}\")\n",
        "    print(f\"Illicit drug mentions: {illicit_mentions}\")\n",
        "    print(f\"Total drug usage records: {df_medical['drug usage'].notna().sum()}\")\n",
        "\n",
        "# Create risk stratification based on drug usage\n",
        "def stratify_drug_use_risk(row):\n",
        "    \"\"\"Stratify risk based on drug usage patterns\"\"\"\n",
        "    if pd.isna(row.get('drug usage', '')):\n",
        "        return 'UNKNOWN_RISK'\n",
        "\n",
        "    text = str(row['drug usage']).lower()\n",
        "\n",
        "    # High risk indicators\n",
        "    high_risk = ['iv drug', 'heroin', 'cocaine', 'meth', 'overdose', 'daily use']\n",
        "    if any(risk in text for risk in high_risk):\n",
        "        return 'HIGH_RISK'\n",
        "\n",
        "    # Moderate risk\n",
        "    moderate_risk = ['alcohol', 'cannabis', 'prescription']\n",
        "    if any(risk in text for risk in moderate_risk):\n",
        "        return 'MODERATE_RISK'\n",
        "\n",
        "    # Low risk\n",
        "    if any(pattern in text for pattern in ['no drug', 'denied', 'none']):\n",
        "        return 'LOW_RISK'\n",
        "\n",
        "    return 'UNSPECIFIED_RISK'\n",
        "\n",
        "# Apply risk stratification\n",
        "print(\"\\n=== Drug Use Risk Stratification ===\")\n",
        "if 'drug usage' in df_medical.columns:\n",
        "    risk_levels = df_medical.apply(stratify_drug_use_risk, axis=1)\n",
        "    print(risk_levels.value_counts())\n",
        "\n",
        "# save result\n",
        "df_drug_usage_entities.to_csv('drug_usage_entities_comprehensive.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>source_column</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Diazepam</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>Diazepam and methadone overdose</td>\n",
              "      <td>163624</td>\n",
              "      <td>drug usage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>methadone overdose</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>13</td>\n",
              "      <td>31</td>\n",
              "      <td>Diazepam and methadone overdose</td>\n",
              "      <td>163624</td>\n",
              "      <td>drug usage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>zolpidem</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>9</td>\n",
              "      <td>17</td>\n",
              "      <td>Abuse of zolpidem</td>\n",
              "      <td>90815</td>\n",
              "      <td>drug usage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>drug abuse</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>11</td>\n",
              "      <td>21</td>\n",
              "      <td>History of drug abuse</td>\n",
              "      <td>43921</td>\n",
              "      <td>drug usage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>drug abuse</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>12</td>\n",
              "      <td>22</td>\n",
              "      <td>Intravenous drug abuse</td>\n",
              "      <td>84350</td>\n",
              "      <td>drug usage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>710</th>\n",
              "      <td>bipolar disorder</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>34</td>\n",
              "      <td>50</td>\n",
              "      <td>Remote history of lithium use for bipolar diso...</td>\n",
              "      <td>113022</td>\n",
              "      <td>drug usage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>711</th>\n",
              "      <td>cocaine</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>24</td>\n",
              "      <td>31</td>\n",
              "      <td>Occasional recreational cocaine use, most rece...</td>\n",
              "      <td>137819</td>\n",
              "      <td>drug usage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>712</th>\n",
              "      <td>cannabis</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>93</td>\n",
              "      <td>101</td>\n",
              "      <td>Heavy e-cigarette use for the previous 2 years...</td>\n",
              "      <td>99885</td>\n",
              "      <td>drug usage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>713</th>\n",
              "      <td>neck pain</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>61</td>\n",
              "      <td>70</td>\n",
              "      <td>Used heroin, street bought oral opiates to sel...</td>\n",
              "      <td>97753</td>\n",
              "      <td>drug usage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>714</th>\n",
              "      <td>cocaine</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>9</td>\n",
              "      <td>16</td>\n",
              "      <td>Previous cocaine abuse, ceased ten years ago</td>\n",
              "      <td>38570</td>\n",
              "      <td>drug usage</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>715 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   text     label  start  end  \\\n",
              "0              Diazepam  CHEMICAL      0    8   \n",
              "1    methadone overdose  CHEMICAL     13   31   \n",
              "2              zolpidem  CHEMICAL      9   17   \n",
              "3            drug abuse   DISEASE     11   21   \n",
              "4            drug abuse   DISEASE     12   22   \n",
              "..                  ...       ...    ...  ...   \n",
              "710    bipolar disorder   DISEASE     34   50   \n",
              "711             cocaine  CHEMICAL     24   31   \n",
              "712            cannabis  CHEMICAL     93  101   \n",
              "713           neck pain   DISEASE     61   70   \n",
              "714             cocaine  CHEMICAL      9   16   \n",
              "\n",
              "                                         original_text  row_idx source_column  \n",
              "0                      Diazepam and methadone overdose   163624    drug usage  \n",
              "1                      Diazepam and methadone overdose   163624    drug usage  \n",
              "2                                    Abuse of zolpidem    90815    drug usage  \n",
              "3                                History of drug abuse    43921    drug usage  \n",
              "4                               Intravenous drug abuse    84350    drug usage  \n",
              "..                                                 ...      ...           ...  \n",
              "710  Remote history of lithium use for bipolar diso...   113022    drug usage  \n",
              "711  Occasional recreational cocaine use, most rece...   137819    drug usage  \n",
              "712  Heavy e-cigarette use for the previous 2 years...    99885    drug usage  \n",
              "713  Used heroin, street bought oral opiates to sel...    97753    drug usage  \n",
              "714       Previous cocaine abuse, ceased ten years ago    38570    drug usage  \n",
              "\n",
              "[715 rows x 7 columns]"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_drug_usage_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVItZWQ_7Cb-"
      },
      "source": [
        "### Extracting Surgeries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        },
        "id": "h9RTUlzN7HRr",
        "outputId": "9ce66ad4-8450-41c5-ec06-ace74eb10761"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>has_surgery</th>\n",
              "      <th>reason</th>\n",
              "      <th>Type</th>\n",
              "      <th>time</th>\n",
              "      <th>outcome</th>\n",
              "      <th>details</th>\n",
              "      <th>combined_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155216</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>nan nan nan nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>133948</td>\n",
              "      <td>True</td>\n",
              "      <td>Idiopathic osteonecrosis of the femoral head</td>\n",
              "      <td>Total Hip Arthroplasty (THA)</td>\n",
              "      <td>After diagnosis</td>\n",
              "      <td>Discharged in good condition without specific ...</td>\n",
              "      <td>First THA on the left hip</td>\n",
              "      <td>Idiopathic osteonecrosis of the femoral head T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133948</td>\n",
              "      <td>True</td>\n",
              "      <td>Pain and limited ROM in the contralateral hip ...</td>\n",
              "      <td>Total Hip Arthroplasty (THA)</td>\n",
              "      <td>One year after the first THA</td>\n",
              "      <td>Discharged in good condition without specific ...</td>\n",
              "      <td>Second THA on the contralateral hip</td>\n",
              "      <td>Pain and limited ROM in the contralateral hip ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80176</td>\n",
              "      <td>True</td>\n",
              "      <td>Posttraumatic arthritis</td>\n",
              "      <td>Left elbow arthrodesis</td>\n",
              "      <td>At the age of 18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Elbow was fused at 90 degrees</td>\n",
              "      <td>Posttraumatic arthritis Left elbow arthrodesis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>80176</td>\n",
              "      <td>True</td>\n",
              "      <td>Hypertrophic nonunion of ulnar shaft fracture ...</td>\n",
              "      <td>Repair of nonunion and conversion of elbow art...</td>\n",
              "      <td>Three months after the fall and subsequent con...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The stem of the ulnar component would act as a...</td>\n",
              "      <td>Hypertrophic nonunion of ulnar shaft fracture ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35859</th>\n",
              "      <td>98004</td>\n",
              "      <td>True</td>\n",
              "      <td>Inferior segment elevation (ST) elevation myoc...</td>\n",
              "      <td>Primary percutaneous coronary intervention (dr...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Successful treatment of right coronary artery ...</td>\n",
              "      <td>Procedure complicated by Ventricular Fibrillat...</td>\n",
              "      <td>Inferior segment elevation (ST) elevation myoc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35860</th>\n",
              "      <td>133320</td>\n",
              "      <td>True</td>\n",
              "      <td>Leiomyosarcoma</td>\n",
              "      <td>Wide tumor resection</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Successful with no adjuvant chemotherapy and r...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Leiomyosarcoma Wide tumor resection nan Succes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35861</th>\n",
              "      <td>133320</td>\n",
              "      <td>True</td>\n",
              "      <td>Lung nodules</td>\n",
              "      <td>Excisional biopsy</td>\n",
              "      <td>One year and 3 months postoperatively</td>\n",
              "      <td>Histopathological diagnosis was consistent wit...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Lung nodules Excisional biopsy nan Histopathol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35862</th>\n",
              "      <td>133320</td>\n",
              "      <td>True</td>\n",
              "      <td>Bone metastasis of the right femur</td>\n",
              "      <td>Cryoablation under CT guidance</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ablation needles were inserted into the proxim...</td>\n",
              "      <td>Bone metastasis of the right femur Cryoablatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35863</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Acute severe aortic insufficiency from endocar...</td>\n",
              "      <td>Emergent mechanical aortic valve replacement s...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Uncomplicated postoperative course</td>\n",
              "      <td>Patient was extubated postoperative day 4, neu...</td>\n",
              "      <td>Acute severe aortic insufficiency from endocar...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35864 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          idx  has_surgery                                             reason  \\\n",
              "0      155216        False                                                NaN   \n",
              "1      133948         True       Idiopathic osteonecrosis of the femoral head   \n",
              "2      133948         True  Pain and limited ROM in the contralateral hip ...   \n",
              "3       80176         True                            Posttraumatic arthritis   \n",
              "4       80176         True  Hypertrophic nonunion of ulnar shaft fracture ...   \n",
              "...       ...          ...                                                ...   \n",
              "35859   98004         True  Inferior segment elevation (ST) elevation myoc...   \n",
              "35860  133320         True                                     Leiomyosarcoma   \n",
              "35861  133320         True                                       Lung nodules   \n",
              "35862  133320         True                 Bone metastasis of the right femur   \n",
              "35863   97973         True  Acute severe aortic insufficiency from endocar...   \n",
              "\n",
              "                                                    Type  \\\n",
              "0                                                    NaN   \n",
              "1                           Total Hip Arthroplasty (THA)   \n",
              "2                           Total Hip Arthroplasty (THA)   \n",
              "3                                 Left elbow arthrodesis   \n",
              "4      Repair of nonunion and conversion of elbow art...   \n",
              "...                                                  ...   \n",
              "35859  Primary percutaneous coronary intervention (dr...   \n",
              "35860                               Wide tumor resection   \n",
              "35861                                  Excisional biopsy   \n",
              "35862                     Cryoablation under CT guidance   \n",
              "35863  Emergent mechanical aortic valve replacement s...   \n",
              "\n",
              "                                                    time  \\\n",
              "0                                                    NaN   \n",
              "1                                        After diagnosis   \n",
              "2                           One year after the first THA   \n",
              "3                                       At the age of 18   \n",
              "4      Three months after the fall and subsequent con...   \n",
              "...                                                  ...   \n",
              "35859                                                NaN   \n",
              "35860                                                NaN   \n",
              "35861              One year and 3 months postoperatively   \n",
              "35862                                                NaN   \n",
              "35863                                                NaN   \n",
              "\n",
              "                                                 outcome  \\\n",
              "0                                                    NaN   \n",
              "1      Discharged in good condition without specific ...   \n",
              "2      Discharged in good condition without specific ...   \n",
              "3                                                    NaN   \n",
              "4                                                    NaN   \n",
              "...                                                  ...   \n",
              "35859  Successful treatment of right coronary artery ...   \n",
              "35860  Successful with no adjuvant chemotherapy and r...   \n",
              "35861  Histopathological diagnosis was consistent wit...   \n",
              "35862                                                NaN   \n",
              "35863                 Uncomplicated postoperative course   \n",
              "\n",
              "                                                 details  \\\n",
              "0                                                    NaN   \n",
              "1                              First THA on the left hip   \n",
              "2                    Second THA on the contralateral hip   \n",
              "3                          Elbow was fused at 90 degrees   \n",
              "4      The stem of the ulnar component would act as a...   \n",
              "...                                                  ...   \n",
              "35859  Procedure complicated by Ventricular Fibrillat...   \n",
              "35860                                                NaN   \n",
              "35861                                                NaN   \n",
              "35862  Ablation needles were inserted into the proxim...   \n",
              "35863  Patient was extubated postoperative day 4, neu...   \n",
              "\n",
              "                                           combined_text  \n",
              "0                                        nan nan nan nan  \n",
              "1      Idiopathic osteonecrosis of the femoral head T...  \n",
              "2      Pain and limited ROM in the contralateral hip ...  \n",
              "3      Posttraumatic arthritis Left elbow arthrodesis...  \n",
              "4      Hypertrophic nonunion of ulnar shaft fracture ...  \n",
              "...                                                  ...  \n",
              "35859  Inferior segment elevation (ST) elevation myoc...  \n",
              "35860  Leiomyosarcoma Wide tumor resection nan Succes...  \n",
              "35861  Lung nodules Excisional biopsy nan Histopathol...  \n",
              "35862  Bone metastasis of the right femur Cryoablatio...  \n",
              "35863  Acute severe aortic insufficiency from endocar...  \n",
              "\n",
              "[35864 rows x 8 columns]"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_surgery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "kPOQefZw9O04"
      },
      "outputs": [],
      "source": [
        "class TemporalStandardizer:\n",
        "    \"\"\"Extract and standardize temporal expressions from medical text\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Load spaCy model\n",
        "        try:\n",
        "            self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "        except:\n",
        "            self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "        # Conversion mappings - Define this BEFORE adding patterns\n",
        "        self.time_units = {\n",
        "            'day': 1, 'days': 1, 'd': 1,\n",
        "            'week': 7, 'weeks': 7, 'wk': 7, 'wks': 7,\n",
        "            'month': 30, 'months': 30, 'mo': 30, 'mos': 30,\n",
        "            'year': 365, 'years': 365, 'yr': 365, 'yrs': 365,\n",
        "            'hour': 1/24, 'hours': 1/24, 'hr': 1/24, 'hrs': 1/24,\n",
        "            'minute': 1/1440, 'minutes': 1/1440, 'min': 1/1440, 'mins': 1/1440\n",
        "        }\n",
        "\n",
        "        # Initialize matcher for temporal patterns\n",
        "        self.matcher = Matcher(self.nlp.vocab)\n",
        "        # Now call _add_temporal_patterns AFTER time_units is defined\n",
        "        self._add_temporal_patterns()\n",
        "\n",
        "\n",
        "    def _add_temporal_patterns(self):\n",
        "        \"\"\"Add temporal patterns to spaCy matcher\"\"\"\n",
        "\n",
        "        # Pattern: \"X days/weeks/months\"\n",
        "        pattern1 = [\n",
        "            {\"LIKE_NUM\": True},\n",
        "            # Access self.time_units here is now safe\n",
        "            {\"LOWER\": {\"IN\": list(self.time_units.keys())}}\n",
        "        ]\n",
        "        self.matcher.add(\"DURATION\", [pattern1])\n",
        "\n",
        "        # Pattern: \"past X days/weeks\"\n",
        "        pattern2 = [\n",
        "            {\"LOWER\": {\"IN\": [\"past\", \"last\", \"previous\"]}},\n",
        "            {\"LIKE_NUM\": True},\n",
        "            {\"LOWER\": {\"IN\": list(self.time_units.keys())}}\n",
        "        ]\n",
        "        self.matcher.add(\"PAST_DURATION\", [pattern2])\n",
        "\n",
        "        # Pattern: \"X days/weeks ago\"\n",
        "        pattern3 = [\n",
        "            {\"LIKE_NUM\": True},\n",
        "            {\"LOWER\": {\"IN\": list(self.time_units.keys())}},\n",
        "            {\"LOWER\": \"ago\"}\n",
        "        ]\n",
        "        self.matcher.add(\"AGO_DURATION\", [pattern3])\n",
        "\n",
        "    def extract_all_temporal_info(self, text):\n",
        "        \"\"\"Extract all temporal information from text\"\"\"\n",
        "        if pd.isna(text) or text == '':\n",
        "            return {\n",
        "                'duration_days': None,\n",
        "                'is_ongoing': False,\n",
        "                'has_date': False,\n",
        "                'temporal_type': None,\n",
        "                'original_text': text\n",
        "            }\n",
        "\n",
        "        text = str(text)\n",
        "        info = {\n",
        "            'duration_days': None,\n",
        "            'is_ongoing': False,\n",
        "            'has_date': False,\n",
        "            'temporal_type': None,\n",
        "            'original_text': text\n",
        "        }\n",
        "\n",
        "        # Check for ongoing conditions\n",
        "        ongoing_patterns = [\n",
        "            'persisting', 'continuing', 'ongoing', 'current',\n",
        "            'still', 'continues', 'persistent', 'chronic'\n",
        "        ]\n",
        "        info['is_ongoing'] = any(pattern in text.lower() for pattern in ongoing_patterns)\n",
        "\n",
        "        # Try to extract specific dates\n",
        "        dates = self._extract_dates(text)\n",
        "        if dates:\n",
        "            info['has_date'] = True\n",
        "            info['extracted_dates'] = dates\n",
        "\n",
        "        # Extract duration\n",
        "        duration = self._extract_duration(text)\n",
        "        if duration:\n",
        "            info['duration_days'] = duration\n",
        "\n",
        "        # Classify temporal type\n",
        "        info['temporal_type'] = self._classify_temporal_type(text)\n",
        "\n",
        "        return info\n",
        "\n",
        "    def _extract_dates(self, text):\n",
        "        \"\"\"Extract actual dates from text\"\"\"\n",
        "        dates = []\n",
        "\n",
        "        # Common date patterns\n",
        "        date_patterns = [\n",
        "            r'\\b\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}\\b',  # MM/DD/YYYY or MM-DD-YYYY\n",
        "            r'\\b\\d{4}[-/]\\d{1,2}[-/]\\d{1,2}\\b',    # YYYY-MM-DD\n",
        "            r'\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\\s+\\d{1,2},?\\s+\\d{4}\\b',  # Month DD, YYYY\n",
        "            r'\\b\\d{1,2}\\s+(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\\s+\\d{4}\\b',     # DD Month YYYY\n",
        "        ]\n",
        "\n",
        "        for pattern in date_patterns:\n",
        "            matches = re.finditer(pattern, text, re.IGNORECASE)\n",
        "            for match in matches:\n",
        "                try:\n",
        "                    parsed_date = parser.parse(match.group(), fuzzy=False)\n",
        "                    dates.append(parsed_date)\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        return dates\n",
        "\n",
        "    def _extract_duration(self, text):\n",
        "        \"\"\"Extract duration in days from temporal expressions\"\"\"\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        # Use regex to find duration patterns\n",
        "        patterns = [\n",
        "            # \"X days/weeks/months\"\n",
        "            r'(\\d+)\\s*(day|days|week|weeks|month|months|year|years|hour|hours)',\n",
        "            # \"a few days/weeks\"\n",
        "            r'(a few|several|couple of)\\s*(day|days|week|weeks|month|months)',\n",
        "            # Written numbers\n",
        "            r'(one|two|three|four|five|six|seven|eight|nine|ten)\\s*(day|days|week|weeks|month|months|year|years)',\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, text_lower)\n",
        "            if match:\n",
        "                # Extract number\n",
        "                number_text = match.group(1)\n",
        "                unit = match.group(2)\n",
        "\n",
        "                # Convert to number\n",
        "                if number_text.isdigit():\n",
        "                    number = int(number_text)\n",
        "                elif number_text in ['a few', 'several']:\n",
        "                    number = 3  # Approximate\n",
        "                elif number_text == 'couple of':\n",
        "                    number = 2\n",
        "                else:\n",
        "                    # Convert written numbers\n",
        "                    number_map = {\n",
        "                        'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5,\n",
        "                        'six': 6, 'seven': 7, 'eight': 8, 'nine': 9, 'ten': 10\n",
        "                    }\n",
        "                    number = number_map.get(number_text, 1)\n",
        "\n",
        "                # Convert to days\n",
        "                if unit in self.time_units:\n",
        "                    return number * self.time_units[unit]\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _classify_temporal_type(self, text):\n",
        "        \"\"\"Classify the type of temporal expression\"\"\"\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        if any(word in text_lower for word in ['ago', 'before', 'prior', 'previously']):\n",
        "            return 'past_reference'\n",
        "        elif any(word in text_lower for word in ['since', 'from', 'started']):\n",
        "            return 'onset_reference'\n",
        "        elif any(word in text_lower for word in ['for', 'duration', 'lasted']):\n",
        "            return 'duration_reference'\n",
        "        elif any(word in text_lower for word in ['until', 'through', 'to']):\n",
        "            return 'range_reference'\n",
        "        elif any(word in text_lower for word in ['after', 'following', 'post']):\n",
        "            return 'post_event'\n",
        "        elif re.search(r'\\d{4}', text):  # Contains year\n",
        "            return 'absolute_date'\n",
        "        else:\n",
        "            return 'unspecified'\n",
        "\n",
        "    def standardize_temporal_column(self, df, column_name):\n",
        "        \"\"\"Standardize an entire temporal column\"\"\"\n",
        "\n",
        "        print(f\"\\nProcessing temporal column: {column_name}\")\n",
        "\n",
        "        # Apply extraction to all values\n",
        "        temporal_data = df[column_name].apply(self.extract_all_temporal_info)\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        temporal_df = pd.DataFrame(temporal_data.tolist())\n",
        "\n",
        "        # Add prefix to column names\n",
        "        temporal_df.columns = [f\"{column_name}_{col}\" for col in temporal_df.columns]\n",
        "\n",
        "        # Concatenate with original dataframe\n",
        "        result_df = pd.concat([df, temporal_df], axis=1)\n",
        "\n",
        "        # Generate report\n",
        "        report = self._generate_temporal_report(temporal_df, column_name)\n",
        "\n",
        "        return result_df, report\n",
        "\n",
        "    def _generate_temporal_report(self, temporal_df, column_name):\n",
        "        \"\"\"Generate report on temporal extraction\"\"\"\n",
        "\n",
        "        duration_col = f\"{column_name}_duration_days\"\n",
        "        type_col = f\"{column_name}_temporal_type\"\n",
        "\n",
        "        report = {\n",
        "            'column': column_name,\n",
        "            'total_entries': len(temporal_df),\n",
        "            'extracted_durations': temporal_df[duration_col].notna().sum(),\n",
        "            'ongoing_conditions': temporal_df[f\"{column_name}_is_ongoing\"].sum(),\n",
        "            'has_specific_dates': temporal_df[f\"{column_name}_has_date\"].sum(),\n",
        "            'temporal_types': temporal_df[type_col].value_counts().to_dict()\n",
        "        }\n",
        "\n",
        "        # Duration statistics\n",
        "        if temporal_df[duration_col].notna().any():\n",
        "            report['duration_stats'] = {\n",
        "                'min_days': temporal_df[duration_col].min(),\n",
        "                'max_days': temporal_df[duration_col].max(),\n",
        "                'mean_days': temporal_df[duration_col].mean(),\n",
        "                'median_days': temporal_df[duration_col].median()\n",
        "            }\n",
        "\n",
        "        return report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZ9x09Gfp0aC",
        "outputId": "94333c67-b472-478f-d9fa-f10ad95c963b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing temporal column: time\n",
            "\n",
            "Temporal extraction results:\n",
            "Successfully extracted duration: 6388\n",
            "Temporal types: {'unspecified': 3554, 'absolute_date': 2836, 'post_event': 2806, 'past_reference': 2754, 'range_reference': 654, 'duration_reference': 261, 'onset_reference': 191}\n",
            "Loading en_ner_bionlp13cg_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 35864 texts in 120 batches...\n",
            "Using model: en_ner_bionlp13cg_md for column: combined_text\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   1%|          | 1/120 [00:02<04:31,  2.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   9%|▉         | 11/120 [00:16<02:34,  1.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 3000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  18%|█▊        | 21/120 [00:30<02:20,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 6000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  26%|██▌       | 31/120 [00:43<02:08,  1.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 9000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  34%|███▍      | 41/120 [00:57<01:52,  1.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 12000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  42%|████▎     | 51/120 [01:10<01:44,  1.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  51%|█████     | 61/120 [01:24<01:27,  1.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 18000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  59%|█████▉    | 71/120 [01:37<01:13,  1.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 21000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  68%|██████▊   | 81/120 [01:51<00:57,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 24000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  76%|███████▌  | 91/120 [02:04<00:43,  1.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 27000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  84%|████████▍ | 101/120 [02:18<00:29,  1.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 30000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  92%|█████████▎| 111/120 [02:31<00:14,  1.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 33000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 120/120 [02:42<00:00,  1.35s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3452 entities appearing >= 5 times\n",
            "\n",
            "=== Entity Types Found ===\n",
            "{'MULTI_TISSUE_STRUCTURE': 32237, 'CANCER': 17003, 'TISSUE': 16665, 'ORGAN': 14854, 'PATHOLOGICAL_FORMATION': 14321, 'ORGANISM_SUBDIVISION': 4084, 'GENE_OR_GENE_PRODUCT': 3097, 'CELL': 2784, 'SIMPLE_CHEMICAL': 2742, 'ORGANISM': 2378, 'IMMATERIAL_ANATOMICAL_ENTITY': 1800, 'CELLULAR_COMPONENT': 1777, 'ORGANISM_SUBSTANCE': 1306, 'AMINO_ACID': 111, 'ANATOMICAL_SYSTEM': 48, 'DEVELOPING_ANATOMICAL_STRUCTURE': 1}\n",
            "\n",
            "=== CUSTOM ANATOMY & PROCEDURE EXTRACTION ===\n",
            "\n",
            "Custom extraction found:\n",
            "label\n",
            "PROCEDURE     27822\n",
            "ANATOMY       18051\n",
            "LATERALITY    13550\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== COMBINED Entity Distribution ===\n",
            "label\n",
            "MULTI_TISSUE_STRUCTURE             32237\n",
            "PROCEDURE                          27822\n",
            "ANATOMY                            18051\n",
            "CANCER                             17003\n",
            "TISSUE                             16665\n",
            "ORGAN                              14854\n",
            "PATHOLOGICAL_FORMATION             14321\n",
            "LATERALITY                         13550\n",
            "ORGANISM_SUBDIVISION                4084\n",
            "GENE_OR_GENE_PRODUCT                3097\n",
            "CELL                                2784\n",
            "SIMPLE_CHEMICAL                     2742\n",
            "ORGANISM                            2378\n",
            "IMMATERIAL_ANATOMICAL_ENTITY        1800\n",
            "CELLULAR_COMPONENT                  1777\n",
            "ORGANISM_SUBSTANCE                  1306\n",
            "AMINO_ACID                           111\n",
            "ANATOMICAL_SYSTEM                     48\n",
            "DEVELOPING_ANATOMICAL_STRUCTURE        1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Anatomical Entities ===\n",
            "text\n",
            "artery      1940\n",
            "bone        1359\n",
            "vascular    1265\n",
            "disc        1207\n",
            "liver       1165\n",
            "vein        1055\n",
            "nerve        865\n",
            "muscle       863\n",
            "knee         648\n",
            "lung         635\n",
            "hip          634\n",
            "vessel       599\n",
            "cervical     572\n",
            "joint        570\n",
            "kidney       560\n",
            "tibia        450\n",
            "ligament     388\n",
            "heart        385\n",
            "femur        363\n",
            "tendon       357\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Anatomy by Category ===\n",
            "category\n",
            "vessel    4859\n",
            "organ     2922\n",
            "spine     2552\n",
            "bone      2158\n",
            "muscle    1608\n",
            "knee      1378\n",
            "nerve     1076\n",
            "hip        897\n",
            "joint      601\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Surgical Procedures ===\n",
            "text\n",
            "ectomy            6295\n",
            "resection         3950\n",
            "excision          2786\n",
            "removal           2572\n",
            "graft             1699\n",
            "repair            1573\n",
            "biopsy            1278\n",
            "implant           1062\n",
            "reconstruction    1039\n",
            "fixation           982\n",
            "replacement        785\n",
            "fusion             703\n",
            "exploration        549\n",
            "implantation       541\n",
            "transplant         538\n",
            "decompression      365\n",
            "arthroplasty       323\n",
            "diagnostic         269\n",
            "osteotomy          226\n",
            "release            206\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Procedures by Category ===\n",
            "category\n",
            "removal          15603\n",
            "repair            3594\n",
            "transplant        2778\n",
            "replacement       2170\n",
            "diagnostic        2096\n",
            "fusion             985\n",
            "decompression      596\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Testing surgical labeling functions:\n",
            "\n",
            "Row 0: nan...\n",
            "\n",
            "Row 1: Total Hip Arthroplasty (THA)...\n",
            "  lf_hip_surgery: HIP_SURGERY\n",
            "\n",
            "Row 2: Total Hip Arthroplasty (THA)...\n",
            "  lf_hip_surgery: HIP_SURGERY\n",
            "\n",
            "Row 3: Left elbow arthrodesis...\n",
            "  lf_emergency_procedure: EMERGENCY_SURGERY\n",
            "\n",
            "Row 4: Repair of nonunion and conversion of elbow arthrod...\n",
            "  lf_fracture_surgery: FRACTURE_SURGERY\n",
            "\n",
            "=== Extracting Surgical Relations ===\n",
            "Found 8501 surgical relations\n",
            "\n",
            "Sample relations:\n",
            "  repair -> patella\n",
            "  repair -> tendon\n",
            "  ectomy -> artery\n",
            "  implant -> vascular\n",
            "  implantation -> vascular\n",
            "  ectomy -> artery\n",
            "  ectomy -> artery\n",
            "  ectomy -> kidney\n",
            "  resection -> vein\n",
            "  resection -> liver\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "     # Apply temporal standardization\n",
        "    temporal_standardizer = TemporalStandardizer()\n",
        "    df_surgery_processed, temporal_report = temporal_standardizer.standardize_temporal_column(\n",
        "        df_surgery, \n",
        "        'time'\n",
        "    )\n",
        "   \n",
        "    print(f\"\\nTemporal extraction results:\")\n",
        "    print(f\"Successfully extracted duration: {temporal_report['extracted_durations']}\")\n",
        "    print(f\"Temporal types: {temporal_report['temporal_types']}\")\n",
        "\n",
        "    # Combine surgery text columns\n",
        "    df_surgery['combined_text'] = df_surgery.apply(\n",
        "        lambda row: f\"{row['reason']} {row['Type']} {row['details']} {row['outcome']}\",\n",
        "        axis=1\n",
        "    )\n",
        "    # Copy combined_text to processed dataframe\n",
        "    df_surgery_processed['combined_text'] = df_surgery['combined_text']\n",
        "\n",
        "    # Add temporal features to combined text\n",
        "    df_surgery_processed['combined_text_enriched'] = df_surgery_processed.apply(\n",
        "        lambda row: f\"{row['combined_text']} {'lasting ' + str(row.get('time_duration_days', '')) + ' days' if pd.notna(row.get('time_duration_days')) else ''}\",\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    df_surgery_entities, surgery_summary, surgery_rules = run_medical_ner_extraction(\n",
        "        df_surgery,\n",
        "        text_column='combined_text',\n",
        "        model_name='en_ner_bionlp13cg_md', \n",
        "        batch_size=300,\n",
        "        id_column='idx'\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== Entity Types Found ===\")\n",
        "    print(surgery_summary['entity_types'])\n",
        "\n",
        "    # Since BC5CDR doesn't extract anatomy/procedures, let's add custom extraction\n",
        "    print(\"\\n=== CUSTOM ANATOMY & PROCEDURE EXTRACTION ===\")\n",
        "\n",
        "    def extract_surgical_entities_custom(df_surgery):\n",
        "        \"\"\"Custom extraction for anatomy and procedures not caught by BC5CDR\"\"\"\n",
        "\n",
        "        custom_entities = []\n",
        "\n",
        "        # Define patterns for different entity types\n",
        "        anatomy_patterns = {\n",
        "            'hip': ['hip', 'acetabul', 'femoral head'],\n",
        "            'knee': ['knee', 'meniscus', 'patella', 'tibia'],\n",
        "            'bone': ['bone', 'femur', 'humerus', 'radius', 'ulna'],\n",
        "            'joint': ['joint', 'articulation'],\n",
        "            'spine': ['spine', 'vertebra', 'disc', 'lumbar', 'cervical'],\n",
        "            'organ': ['kidney', 'liver', 'heart', 'lung', 'spleen'],\n",
        "            'vessel': ['artery', 'vein', 'vessel', 'vascular'],\n",
        "            'nerve': ['nerve', 'neural', 'plexus'],\n",
        "            'muscle': ['muscle', 'tendon', 'ligament']\n",
        "        }\n",
        "\n",
        "        procedure_patterns = {\n",
        "            'replacement': ['arthroplasty', 'replacement', 'implant'],\n",
        "            'repair': ['repair', 'reconstruction', 'fixation'],\n",
        "            'removal': ['removal', 'excision', 'resection', 'ectomy'],\n",
        "            'fusion': ['fusion', 'arthrodesis', 'osteotomy'],\n",
        "            'diagnostic': ['biopsy', 'exploration', 'diagnostic'],\n",
        "            'decompression': ['decompression', 'release', 'neurolysis'],\n",
        "            'transplant': ['transplant', 'graft', 'implantation']\n",
        "        }\n",
        "\n",
        "        # Process each row\n",
        "        for idx, row in df_surgery.iterrows():\n",
        "            combined_text = str(row['combined_text']).lower()\n",
        "\n",
        "            # Extract anatomy\n",
        "            for category, terms in anatomy_patterns.items():\n",
        "                for term in terms:\n",
        "                    if term in combined_text:\n",
        "                        # Find the position in the original text\n",
        "                        start = combined_text.find(term)\n",
        "                        custom_entities.append({\n",
        "                            'text': term,\n",
        "                            'label': 'ANATOMY',\n",
        "                            'category': category,\n",
        "                            'start': start,\n",
        "                            'end': start + len(term),\n",
        "                            'original_text': row['combined_text'],\n",
        "                            'source': 'custom_extraction'\n",
        "                        })\n",
        "\n",
        "            # Extract procedures\n",
        "            for category, terms in procedure_patterns.items():\n",
        "                for term in terms:\n",
        "                    if term in combined_text:\n",
        "                        start = combined_text.find(term)\n",
        "                        custom_entities.append({\n",
        "                            'text': term,\n",
        "                            'label': 'PROCEDURE',\n",
        "                            'category': category,\n",
        "                            'start': start,\n",
        "                            'end': start + len(term),\n",
        "                            'original_text': row['combined_text'],\n",
        "                            'source': 'custom_extraction'\n",
        "                        })\n",
        "\n",
        "            # Extract laterality (important for surgery)\n",
        "            laterality_terms = ['left', 'right', 'bilateral', 'unilateral']\n",
        "            for term in laterality_terms:\n",
        "                if term in combined_text:\n",
        "                    start = combined_text.find(term)\n",
        "                    custom_entities.append({\n",
        "                        'text': term,\n",
        "                        'label': 'LATERALITY',\n",
        "                        'category': 'laterality',\n",
        "                        'start': start,\n",
        "                        'end': start + len(term),\n",
        "                        'original_text': row['combined_text'],\n",
        "                        'source': 'custom_extraction'\n",
        "                    })\n",
        "\n",
        "        return pd.DataFrame(custom_entities)\n",
        "\n",
        "    # Extract custom entities\n",
        "    df_custom_entities = extract_surgical_entities_custom(df_surgery)\n",
        "\n",
        "    print(f\"\\nCustom extraction found:\")\n",
        "    print(df_custom_entities['label'].value_counts())\n",
        "\n",
        "    # Combine BC5CDR and custom entities\n",
        "    df_all_surgery_entities = pd.concat([df_surgery_entities, df_custom_entities], ignore_index=True)\n",
        "\n",
        "    print(f\"\\n=== COMBINED Entity Distribution ===\")\n",
        "    print(df_all_surgery_entities['label'].value_counts())\n",
        "\n",
        "    # Analyze anatomy entities\n",
        "    anatomy_entities = df_all_surgery_entities[df_all_surgery_entities['label'] == 'ANATOMY']\n",
        "    if len(anatomy_entities) > 0:\n",
        "        print(f\"\\n=== Top Anatomical Entities ===\")\n",
        "        print(anatomy_entities['text'].value_counts().head(20))\n",
        "\n",
        "        # Group by category\n",
        "        if 'category' in anatomy_entities.columns:\n",
        "            print(f\"\\n=== Anatomy by Category ===\")\n",
        "            print(anatomy_entities['category'].value_counts())\n",
        "\n",
        "    # Analyze procedure entities\n",
        "    procedure_entities = df_all_surgery_entities[df_all_surgery_entities['label'] == 'PROCEDURE']\n",
        "    if len(procedure_entities) > 0:\n",
        "        print(f\"\\n=== Top Surgical Procedures ===\")\n",
        "        print(procedure_entities['text'].value_counts().head(20))\n",
        "\n",
        "        if 'category' in procedure_entities.columns:\n",
        "            print(f\"\\n=== Procedures by Category ===\")\n",
        "            print(procedure_entities['category'].value_counts())\n",
        "    # Create labeling functions\n",
        "def create_surgical_labeling_functions():\n",
        "    \"\"\"Create labeling functions specific to surgical data\"\"\"\n",
        "\n",
        "    def lf_hip_surgery(row):\n",
        "        text = str(row['combined_text']).lower()\n",
        "        if 'hip' in text and any(proc in text for proc in ['arthroplasty', 'replacement', 'repair']):\n",
        "            return 'HIP_SURGERY'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    def lf_knee_surgery(row):\n",
        "        text = str(row['combined_text']).lower()\n",
        "        if 'knee' in text and any(proc in text for proc in ['arthroplasty', 'replacement', 'arthroscopy']):\n",
        "            return 'KNEE_SURGERY'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    def lf_fracture_surgery(row):\n",
        "        text = str(row['combined_text']).lower()\n",
        "        if 'fracture' in text and any(proc in text for proc in ['fixation', 'repair', 'reduction']):\n",
        "            return 'FRACTURE_SURGERY'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    def lf_bilateral_procedure(row):\n",
        "        text = str(row['combined_text']).lower()\n",
        "        if 'bilateral' in text:\n",
        "            return 'BILATERAL_PROCEDURE'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    def lf_minimally_invasive(row):\n",
        "        text = str(row['combined_text']).lower()\n",
        "        if any(term in text for term in ['arthroscopic', 'endoscopic', 'laparoscopic', 'minimally invasive']):\n",
        "            return 'MINIMALLY_INVASIVE'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    def lf_emergency_procedure(row):\n",
        "        reason = str(row.get('reason', '')).lower()\n",
        "        if any(term in reason for term in ['emergency', 'urgent', 'acute', 'trauma']):\n",
        "            return 'EMERGENCY_SURGERY'\n",
        "        return 'ABSTAIN'\n",
        "\n",
        "    return [lf_hip_surgery, lf_knee_surgery, lf_fracture_surgery,\n",
        "            lf_bilateral_procedure, lf_minimally_invasive, lf_emergency_procedure]\n",
        "# Test labeling functions\n",
        "surgical_lfs = create_surgical_labeling_functions()\n",
        "\n",
        "print(\"\\nTesting surgical labeling functions:\")\n",
        "for i in range(min(5, len(df_surgery))):\n",
        "    row = df_surgery.iloc[i]\n",
        "    # Ensure the 'Type' column is treated as a string before slicing\n",
        "    # This handles potential NaN values by converting them to the string 'nan'\n",
        "    print(f\"\\nRow {i}: {str(row['Type'])[:50]}...\")\n",
        "    for lf in surgical_lfs:\n",
        "    # The labeling functions already handle potential NaN by converting to str\n",
        "        result = lf(row)\n",
        "        if result != 'ABSTAIN':\n",
        "            print(f\"  {lf.__name__}: {result}\")\n",
        "\n",
        "# Create anatomy-procedure relations\n",
        "print(\"\\n=== Extracting Surgical Relations ===\")\n",
        "\n",
        "def extract_surgical_relations(df_entities):\n",
        "    \"\"\"Extract relations between anatomy and procedures\"\"\"\n",
        "    relations = []\n",
        "\n",
        "    # Group entities by original text\n",
        "    grouped = df_entities.groupby('original_text')\n",
        "\n",
        "    for text, group in grouped:\n",
        "        anatomy_ents = group[group['label'] == 'ANATOMY']\n",
        "        procedure_ents = group[group['label'] == 'PROCEDURE']\n",
        "\n",
        "        # Create relations between anatomy and procedures in same text\n",
        "        for _, anat in anatomy_ents.iterrows():\n",
        "            for _, proc in procedure_ents.iterrows():\n",
        "                # Check if they're close to each other (within 50 characters)\n",
        "                if abs(anat['start'] - proc['start']) < 50:\n",
        "                    relations.append({\n",
        "                        'type': 'PROCEDURE_ON_ANATOMY',\n",
        "                        'procedure': proc['text'],\n",
        "                        'anatomy': anat['text'],\n",
        "                        'text': text[:100]\n",
        "                    })\n",
        "\n",
        "    return relations\n",
        "\n",
        "surgical_relations = extract_surgical_relations(df_all_surgery_entities)\n",
        "\n",
        "print(f\"Found {len(surgical_relations)} surgical relations\")\n",
        "if surgical_relations:\n",
        "    print(\"\\nSample relations:\")\n",
        "    for rel in surgical_relations[:10]:\n",
        "        print(f\"  {rel['procedure']} -> {rel['anatomy']}\")\n",
        "\n",
        "# Save results\n",
        "df_all_surgery_entities.to_csv('surgery_entities_comprehensive.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "id": "uniu23sqp0SV",
        "outputId": "a61f1782-077f-4077-8e0b-882c30d3ce70"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>source_column</th>\n",
              "      <th>category</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>femoral head</td>\n",
              "      <td>PATHOLOGICAL_FORMATION</td>\n",
              "      <td>32</td>\n",
              "      <td>44</td>\n",
              "      <td>Idiopathic osteonecrosis of the femoral head T...</td>\n",
              "      <td>133948.0</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>left hip</td>\n",
              "      <td>PATHOLOGICAL_FORMATION</td>\n",
              "      <td>91</td>\n",
              "      <td>99</td>\n",
              "      <td>Idiopathic osteonecrosis of the femoral head T...</td>\n",
              "      <td>133948.0</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>joint Total</td>\n",
              "      <td>MULTI_TISSUE_STRUCTURE</td>\n",
              "      <td>46</td>\n",
              "      <td>57</td>\n",
              "      <td>Pain and limited ROM in the contralateral hip ...</td>\n",
              "      <td>133948.0</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Left elbow</td>\n",
              "      <td>TISSUE</td>\n",
              "      <td>24</td>\n",
              "      <td>34</td>\n",
              "      <td>Posttraumatic arthritis Left elbow arthrodesis...</td>\n",
              "      <td>80176.0</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ulnar shaft</td>\n",
              "      <td>MULTI_TISSUE_STRUCTURE</td>\n",
              "      <td>25</td>\n",
              "      <td>36</td>\n",
              "      <td>Hypertrophic nonunion of ulnar shaft fracture ...</td>\n",
              "      <td>80176.0</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174626</th>\n",
              "      <td>bone</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Bone metastasis of the right femur Cryoablatio...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>bone</td>\n",
              "      <td>custom_extraction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174627</th>\n",
              "      <td>femur</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>29</td>\n",
              "      <td>34</td>\n",
              "      <td>Bone metastasis of the right femur Cryoablatio...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>bone</td>\n",
              "      <td>custom_extraction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174628</th>\n",
              "      <td>right</td>\n",
              "      <td>LATERALITY</td>\n",
              "      <td>23</td>\n",
              "      <td>28</td>\n",
              "      <td>Bone metastasis of the right femur Cryoablatio...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>laterality</td>\n",
              "      <td>custom_extraction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174629</th>\n",
              "      <td>disc</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>175</td>\n",
              "      <td>179</td>\n",
              "      <td>Acute severe aortic insufficiency from endocar...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>spine</td>\n",
              "      <td>custom_extraction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174630</th>\n",
              "      <td>replacement</td>\n",
              "      <td>PROCEDURE</td>\n",
              "      <td>85</td>\n",
              "      <td>96</td>\n",
              "      <td>Acute severe aortic insufficiency from endocar...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>replacement</td>\n",
              "      <td>custom_extraction</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>174631 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                text                   label  start  end  \\\n",
              "0       femoral head  PATHOLOGICAL_FORMATION     32   44   \n",
              "1           left hip  PATHOLOGICAL_FORMATION     91   99   \n",
              "2        joint Total  MULTI_TISSUE_STRUCTURE     46   57   \n",
              "3         Left elbow                  TISSUE     24   34   \n",
              "4        ulnar shaft  MULTI_TISSUE_STRUCTURE     25   36   \n",
              "...              ...                     ...    ...  ...   \n",
              "174626          bone                 ANATOMY      0    4   \n",
              "174627         femur                 ANATOMY     29   34   \n",
              "174628         right              LATERALITY     23   28   \n",
              "174629          disc                 ANATOMY    175  179   \n",
              "174630   replacement               PROCEDURE     85   96   \n",
              "\n",
              "                                            original_text   row_idx  \\\n",
              "0       Idiopathic osteonecrosis of the femoral head T...  133948.0   \n",
              "1       Idiopathic osteonecrosis of the femoral head T...  133948.0   \n",
              "2       Pain and limited ROM in the contralateral hip ...  133948.0   \n",
              "3       Posttraumatic arthritis Left elbow arthrodesis...   80176.0   \n",
              "4       Hypertrophic nonunion of ulnar shaft fracture ...   80176.0   \n",
              "...                                                   ...       ...   \n",
              "174626  Bone metastasis of the right femur Cryoablatio...       NaN   \n",
              "174627  Bone metastasis of the right femur Cryoablatio...       NaN   \n",
              "174628  Bone metastasis of the right femur Cryoablatio...       NaN   \n",
              "174629  Acute severe aortic insufficiency from endocar...       NaN   \n",
              "174630  Acute severe aortic insufficiency from endocar...       NaN   \n",
              "\n",
              "        source_column     category             source  \n",
              "0       combined_text          NaN                NaN  \n",
              "1       combined_text          NaN                NaN  \n",
              "2       combined_text          NaN                NaN  \n",
              "3       combined_text          NaN                NaN  \n",
              "4       combined_text          NaN                NaN  \n",
              "...               ...          ...                ...  \n",
              "174626            NaN         bone  custom_extraction  \n",
              "174627            NaN         bone  custom_extraction  \n",
              "174628            NaN   laterality  custom_extraction  \n",
              "174629            NaN        spine  custom_extraction  \n",
              "174630            NaN  replacement  custom_extraction  \n",
              "\n",
              "[174631 rows x 9 columns]"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_all_surgery_entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfeAuoQkp0H5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting Symptoms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 963
        },
        "id": "gfbXYJpJ7Rqj",
        "outputId": "086917d6-7022-4c5b-a9ae-7c754bbd349a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>has_symptom</th>\n",
              "      <th>name of symptom</th>\n",
              "      <th>intensity of symptom</th>\n",
              "      <th>location</th>\n",
              "      <th>time</th>\n",
              "      <th>temporalisation</th>\n",
              "      <th>behaviours affecting the symptom</th>\n",
              "      <th>details</th>\n",
              "      <th>duration_days</th>\n",
              "      <th>temporal_pattern</th>\n",
              "      <th>combined_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155216</td>\n",
              "      <td>True</td>\n",
              "      <td>Discomfort in the neck and lower back, restric...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Neck and lower back</td>\n",
              "      <td>Past four months</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Standing up from a sitting position</td>\n",
              "      <td>Head turned to the right and upwards due to su...</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>Discomfort in the neck and lower back, restric...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>133948</td>\n",
              "      <td>True</td>\n",
              "      <td>Pain</td>\n",
              "      <td>Severe</td>\n",
              "      <td>Left hip joint</td>\n",
              "      <td>Persisting for two months</td>\n",
              "      <td>Increased over the following three weeks</td>\n",
              "      <td>Aggravated by hip joint flexion or rotation</td>\n",
              "      <td>Also complained of pain and limited ROM in the...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Increased over the following three weeks</td>\n",
              "      <td>Pain with Severe intensity located in Left hip...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133948</td>\n",
              "      <td>True</td>\n",
              "      <td>Restricted range of motion</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Left hip joint</td>\n",
              "      <td>Persisting for two months</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>Restricted range of motion with nan intensity ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>133948</td>\n",
              "      <td>True</td>\n",
              "      <td>Gait disturbance</td>\n",
              "      <td>Severe</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Secondary to hip pain</td>\n",
              "      <td>Continued for two months and increased over th...</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>Gait disturbance with Severe intensity located...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>133948</td>\n",
              "      <td>True</td>\n",
              "      <td>Moderate moon face</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>Face</td>\n",
              "      <td>At the time of the second surgery</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Initially overlooked as weight gain</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>Moderate moon face with Moderate intensity loc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54939</th>\n",
              "      <td>137017</td>\n",
              "      <td>True</td>\n",
              "      <td>Left-sided weakness</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Left side</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>Left-sided weakness with nan intensity located...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54940</th>\n",
              "      <td>98004</td>\n",
              "      <td>True</td>\n",
              "      <td>Chest pain</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Chest</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Cardiac sounding</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>Chest pain with nan intensity located in Chest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54941</th>\n",
              "      <td>133320</td>\n",
              "      <td>True</td>\n",
              "      <td>Mass in right thigh</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Lateral side of the right thigh</td>\n",
              "      <td>Noticed four years prior to presentation</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Diameter of 4 cm, no adhesion with skin and no...</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>Mass in right thigh with nan intensity located...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54942</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Crushing substernal chest pressure</td>\n",
              "      <td>Acute onset</td>\n",
              "      <td>Substernal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Following 1-week-long febrile illness</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Accompanied by dyspnea and profuse sweating</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Following 1-week-long febrile illness</td>\n",
              "      <td>Crushing substernal chest pressure with Acute ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54943</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Dyspnea</td>\n",
              "      <td>Rapidly developed</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Patient developed dyspnea, tachypnea, and tach...</td>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>Dyspnea with Rapidly developed intensity locat...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>54944 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          idx  has_symptom                                    name of symptom  \\\n",
              "0      155216         True  Discomfort in the neck and lower back, restric...   \n",
              "1      133948         True                                               Pain   \n",
              "2      133948         True                         Restricted range of motion   \n",
              "3      133948         True                                   Gait disturbance   \n",
              "4      133948         True                                 Moderate moon face   \n",
              "...       ...          ...                                                ...   \n",
              "54939  137017         True                                Left-sided weakness   \n",
              "54940   98004         True                                         Chest pain   \n",
              "54941  133320         True                                Mass in right thigh   \n",
              "54942   97973         True                 Crushing substernal chest pressure   \n",
              "54943   97973         True                                            Dyspnea   \n",
              "\n",
              "      intensity of symptom                         location  \\\n",
              "0                      NaN              Neck and lower back   \n",
              "1                   Severe                   Left hip joint   \n",
              "2                      NaN                   Left hip joint   \n",
              "3                   Severe                              NaN   \n",
              "4                 Moderate                             Face   \n",
              "...                    ...                              ...   \n",
              "54939                  NaN                        Left side   \n",
              "54940                  NaN                            Chest   \n",
              "54941                  NaN  Lateral side of the right thigh   \n",
              "54942          Acute onset                       Substernal   \n",
              "54943    Rapidly developed                              NaN   \n",
              "\n",
              "                                           time  \\\n",
              "0                              Past four months   \n",
              "1                     Persisting for two months   \n",
              "2                     Persisting for two months   \n",
              "3                                           NaN   \n",
              "4             At the time of the second surgery   \n",
              "...                                         ...   \n",
              "54939                                       NaN   \n",
              "54940                                       NaN   \n",
              "54941  Noticed four years prior to presentation   \n",
              "54942                                       NaN   \n",
              "54943                                       NaN   \n",
              "\n",
              "                                temporalisation  \\\n",
              "0                                           NaN   \n",
              "1      Increased over the following three weeks   \n",
              "2                                           NaN   \n",
              "3                                           NaN   \n",
              "4                                           NaN   \n",
              "...                                         ...   \n",
              "54939                                       NaN   \n",
              "54940                                       NaN   \n",
              "54941                                       NaN   \n",
              "54942     Following 1-week-long febrile illness   \n",
              "54943                                       NaN   \n",
              "\n",
              "                  behaviours affecting the symptom  \\\n",
              "0              Standing up from a sitting position   \n",
              "1      Aggravated by hip joint flexion or rotation   \n",
              "2                                              NaN   \n",
              "3                            Secondary to hip pain   \n",
              "4                                              NaN   \n",
              "...                                            ...   \n",
              "54939                                          NaN   \n",
              "54940                                          NaN   \n",
              "54941                                          NaN   \n",
              "54942                                          NaN   \n",
              "54943                                          NaN   \n",
              "\n",
              "                                                 details  duration_days  \\\n",
              "0      Head turned to the right and upwards due to su...            NaN   \n",
              "1      Also complained of pain and limited ROM in the...            NaN   \n",
              "2                                                    NaN            NaN   \n",
              "3      Continued for two months and increased over th...            NaN   \n",
              "4                    Initially overlooked as weight gain            NaN   \n",
              "...                                                  ...            ...   \n",
              "54939                                                NaN            NaN   \n",
              "54940                                   Cardiac sounding            NaN   \n",
              "54941  Diameter of 4 cm, no adhesion with skin and no...            NaN   \n",
              "54942        Accompanied by dyspnea and profuse sweating            NaN   \n",
              "54943  Patient developed dyspnea, tachypnea, and tach...            NaN   \n",
              "\n",
              "                               temporal_pattern  \\\n",
              "0                                                 \n",
              "1      Increased over the following three weeks   \n",
              "2                                                 \n",
              "3                                                 \n",
              "4                                                 \n",
              "...                                         ...   \n",
              "54939                                             \n",
              "54940                                             \n",
              "54941                                             \n",
              "54942     Following 1-week-long febrile illness   \n",
              "54943                                             \n",
              "\n",
              "                                           combined_text  \n",
              "0      Discomfort in the neck and lower back, restric...  \n",
              "1      Pain with Severe intensity located in Left hip...  \n",
              "2      Restricted range of motion with nan intensity ...  \n",
              "3      Gait disturbance with Severe intensity located...  \n",
              "4      Moderate moon face with Moderate intensity loc...  \n",
              "...                                                  ...  \n",
              "54939  Left-sided weakness with nan intensity located...  \n",
              "54940  Chest pain with nan intensity located in Chest...  \n",
              "54941  Mass in right thigh with nan intensity located...  \n",
              "54942  Crushing substernal chest pressure with Acute ...  \n",
              "54943  Dyspnea with Rapidly developed intensity locat...  \n",
              "\n",
              "[54944 rows x 12 columns]"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_symptoms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m5jzEN8EPnX",
        "outputId": "3a06cf64-4e26-4781-93d0-c3c608e923f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing temporal column: time\n",
            "\n",
            "Temporal extraction results:\n",
            "Successfully extracted duration: 18893\n",
            "Temporal types: {'unspecified': 13201, 'post_event': 6146, 'range_reference': 5023, 'past_reference': 4704, 'duration_reference': 4063, 'onset_reference': 2904, 'absolute_date': 1164}\n",
            "Loading en_ner_bc5cdr_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 54944 texts in 184 batches...\n",
            "Using model: en_ner_bc5cdr_md for column: combined_text\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   1%|          | 1/184 [00:01<05:44,  1.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   6%|▌         | 11/184 [00:14<03:34,  1.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 3000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  11%|█▏        | 21/184 [00:25<03:16,  1.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 6000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  17%|█▋        | 31/184 [00:37<03:00,  1.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 9000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  22%|██▏       | 41/184 [00:48<02:51,  1.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 12000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  28%|██▊       | 51/184 [01:00<02:36,  1.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  33%|███▎      | 61/184 [01:11<02:28,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 18000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  39%|███▊      | 71/184 [01:23<02:15,  1.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 21000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  44%|████▍     | 81/184 [01:34<02:05,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 24000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  49%|████▉     | 91/184 [01:45<01:50,  1.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 27000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  55%|█████▍    | 101/184 [01:57<01:41,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 30000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  60%|██████    | 111/184 [02:08<01:28,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 33000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  66%|██████▌   | 121/184 [02:20<01:17,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 36000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  71%|███████   | 131/184 [02:31<01:05,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 39000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  77%|███████▋  | 141/184 [02:42<00:53,  1.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 42000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  82%|████████▏ | 151/184 [02:53<00:40,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 45000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  88%|████████▊ | 161/184 [03:05<00:29,  1.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 48000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  93%|█████████▎| 171/184 [03:16<00:16,  1.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 51000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  98%|█████████▊| 181/184 [03:28<00:03,  1.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 54000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 184/184 [03:30<00:00,  1.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1857 entities appearing >= 5 times\n",
            "\n",
            "=== BC5CDR Entity Types Found ===\n",
            "{'DISEASE': 84179, 'CHEMICAL': 2286}\n",
            "\n",
            "=== CUSTOM SYMPTOM ENTITY EXTRACTION ===\n",
            "\n",
            "Custom extraction found:\n",
            "label\n",
            "ANATOMY             60981\n",
            "SYMPTOM             53580\n",
            "SYMPTOM_TYPE        53273\n",
            "LATERALITY          21797\n",
            "TEMPORAL_PATTERN    14982\n",
            "SEVERITY             5306\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== COMBINED Entity Distribution ===\n",
            "label\n",
            "DISEASE             84179\n",
            "ANATOMY             60981\n",
            "SYMPTOM             53580\n",
            "SYMPTOM_TYPE        53273\n",
            "LATERALITY          21797\n",
            "TEMPORAL_PATTERN    14982\n",
            "SEVERITY             5306\n",
            "CHEMICAL             2286\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Symptoms ===\n",
            "text\n",
            "Pain                    1739\n",
            "Abdominal pain          1135\n",
            "Swelling                1123\n",
            "Fever                    775\n",
            "Headache                 690\n",
            "Chest pain               540\n",
            "Vomiting                 540\n",
            "Dyspnea                  493\n",
            "Shortness of breath      475\n",
            "Weight loss              443\n",
            "Nausea                   378\n",
            "Dysphagia                298\n",
            "Fatigue                  285\n",
            "Weakness                 277\n",
            "Cough                    260\n",
            "Back pain                245\n",
            "Pain and swelling        245\n",
            "Numbness                 215\n",
            "Dizziness                205\n",
            "Abdominal distension     199\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Symptom Locations ===\n",
            "text\n",
            "abdomen      2893\n",
            "head         2695\n",
            "chest        2376\n",
            "back         2043\n",
            "leg          2043\n",
            "face         1597\n",
            "neck         1541\n",
            "arm          1494\n",
            "Abdomen      1367\n",
            "hand         1232\n",
            "knee         1207\n",
            "joint         897\n",
            "hip           801\n",
            "thigh         789\n",
            "shoulder      761\n",
            "Chest         735\n",
            "foot          706\n",
            "finger        678\n",
            "Left eye      585\n",
            "Right eye     552\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Severity Distribution ===\n",
            "text\n",
            "severe         3508\n",
            "mild           1245\n",
            "significant     306\n",
            "moderate        196\n",
            "extreme          32\n",
            "minimal          19\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Creating Symptom-Specific Labeling Functions ===\n",
            "\n",
            "Testing symptom labeling functions:\n",
            "\n",
            "Row 0: Discomfort in the neck and lower back, restriction of body movements, inability to maintain an erect posture - Neck and lower back\n",
            "  lf_chronic_symptom: CHRONIC_SYMPTOM\n",
            "  lf_mobility_issue: MOBILITY_ISSUE\n",
            "\n",
            "Row 1: Pain - Left hip joint\n",
            "  lf_severe_pain: SEVERE_PAIN\n",
            "  lf_chronic_symptom: CHRONIC_SYMPTOM\n",
            "  lf_pain_with_location: HIP_PAIN\n",
            "\n",
            "Row 2: Restricted range of motion - Left hip joint\n",
            "  lf_chronic_symptom: CHRONIC_SYMPTOM\n",
            "\n",
            "Row 3: Gait disturbance - nan\n",
            "  lf_mobility_issue: MOBILITY_ISSUE\n",
            "\n",
            "Row 4: Moderate moon face - Face\n",
            "\n",
            "Row 5: Central obesity - Central body\n",
            "\n",
            "Row 6: Muscle mass reduction - Both the upper and lower limbs\n",
            "  lf_bilateral_symptom: BILATERAL_SYMPTOM\n",
            "\n",
            "Row 7: Pain - Left proximal forearm\n",
            "  lf_pain_with_location: LOCALIZED_PAIN\n",
            "\n",
            "Row 8: Pain - Medial aspect of the left knee, lateral aspect of the left knee, medial side of the right knee\n",
            "  lf_severe_pain: SEVERE_PAIN\n",
            "  lf_pain_with_location: KNEE_PAIN\n",
            "  lf_symptom_duration: CHRONIC_DURATION\n",
            "\n",
            "Row 9: Inability to walk - Legs\n",
            "  lf_chronic_symptom: CHRONIC_SYMPTOM\n",
            "  lf_neurological_symptom: NEUROLOGICAL\n",
            "  lf_progressive_symptom: PROGRESSIVE_SYMPTOM\n",
            "  lf_mobility_issue: MOBILITY_ISSUE\n",
            "  lf_symptom_duration: CHRONIC_DURATION\n",
            "\n",
            "=== Extracting Symptom Relations ===\n",
            "Found 73581 symptom relations\n",
            "\n",
            "Relation type distribution:\n",
            "type\n",
            "SYMPTOM_LOCATED_IN              33074\n",
            "SYMPTOM_HAS_SEVERITY            16909\n",
            "SYMPTOM_HAS_TEMPORAL_PATTERN    12813\n",
            "SYMPTOM_HAS_DURATION            10785\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sample relations:\n",
            "  Discomfort in the neck and lower back, restriction of body movements, inability to maintain an erect posture -> located in -> Neck and lower back\n",
            "  Pain -> located in -> Left hip joint\n",
            "  Pain -> has severity -> Severe\n",
            "  Restricted range of motion -> located in -> Left hip joint\n",
            "  Gait disturbance -> has severity -> Severe\n",
            "  Moderate moon face -> located in -> Face\n",
            "  Moderate moon face -> has severity -> Moderate\n",
            "  Central obesity -> located in -> Central body\n",
            "  Muscle mass reduction -> located in -> Both the upper and lower limbs\n",
            "\n",
            "=== Labeling Function Coverage Analysis ===\n",
            "\n",
            "Labeling function coverage:\n",
            "  lf_pain_with_location: 11383 labels (20.7% coverage)\n",
            "  lf_symptom_duration: 10785 labels (19.6% coverage)\n",
            "  lf_chronic_symptom: 10511 labels (19.1% coverage)\n",
            "  lf_neurological_symptom: 3804 labels (6.9% coverage)\n",
            "  lf_systemic_symptom: 3067 labels (5.6% coverage)\n",
            "  lf_progressive_symptom: 2725 labels (5.0% coverage)\n",
            "  lf_bilateral_symptom: 1796 labels (3.3% coverage)\n",
            "  lf_severe_pain: 1442 labels (2.6% coverage)\n",
            "  lf_acute_onset: 1340 labels (2.4% coverage)\n",
            "  lf_mobility_issue: 1159 labels (2.1% coverage)\n",
            "\n",
            "\n",
            "Symptom entity extraction and labeling complete!\n",
            "Saved 296384 entities and 73581 relations\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Apply temporal standardization\n",
        "    temporal_standardizer = TemporalStandardizer()\n",
        "    df_symptoms_processed, temporal_report = temporal_standardizer.standardize_temporal_column(\n",
        "        df_symptoms, \n",
        "        'time'\n",
        "    )\n",
        "   \n",
        "    print(f\"\\nTemporal extraction results:\")\n",
        "    print(f\"Successfully extracted duration: {temporal_report['extracted_durations']}\")\n",
        "    print(f\"Temporal types: {temporal_report['temporal_types']}\")\n",
        "\n",
        "    # Combine symptom information into comprehensive text\n",
        "    df_symptoms['combined_text'] = df_symptoms.apply(\n",
        "        lambda row: f\"{row['name of symptom']} with {row['intensity of symptom']} intensity located in {row['location']} lasting {row['time']} {row['temporalisation']} {row['details']}\",\n",
        "        axis=1\n",
        "    )\n",
        "    # Copy combined_text to processed dataframe\n",
        "    df_symptoms_processed['combined_text'] = df_surgery['combined_text']\n",
        "\n",
        "    # Add temporal features to combined text\n",
        "    df_symptoms_processed['combined_text_enriched'] = df_symptoms_processed.apply(\n",
        "        lambda row: f\"{row['combined_text']} {'lasting ' + str(row.get('time_duration_days', '')) + ' days' if pd.notna(row.get('time_duration_days')) else ''}\",\n",
        "        axis=1\n",
        "    )\n",
        "    # Run NER extraction with BC5CDR\n",
        "    df_symptoms_entities, symptoms_summary, symptoms_rules = run_medical_ner_extraction(\n",
        "        df_symptoms,\n",
        "        text_column='combined_text',\n",
        "        model_name=\"en_ner_bc5cdr_md\",\n",
        "        batch_size=300,\n",
        "        id_column='idx'\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== BC5CDR Entity Types Found ===\")\n",
        "    print(symptoms_summary['entity_types'])\n",
        "\n",
        "    # Custom entity extraction for symptoms-specific entities\n",
        "    print(\"\\n=== CUSTOM SYMPTOM ENTITY EXTRACTION ===\")\n",
        "\n",
        "    def extract_symptom_entities_custom(df_symptoms):\n",
        "        \"\"\"Extract symptom-specific entities not caught by BC5CDR\"\"\"\n",
        "\n",
        "        custom_entities = []\n",
        "\n",
        "        # Symptom type patterns\n",
        "        symptom_patterns = {\n",
        "            'pain': ['pain', 'ache', 'soreness', 'tenderness', 'discomfort'],\n",
        "            'neurological': ['numbness', 'tingling', 'weakness', 'paralysis', 'tremor'],\n",
        "            'mobility': ['inability to walk', 'gait disturbance', 'limited range of motion', 'stiffness'],\n",
        "            'swelling': ['swelling', 'edema', 'inflammation', 'mass', 'lump'],\n",
        "            'sensory': ['vision', 'hearing', 'taste', 'smell', 'sensation'],\n",
        "            'systemic': ['fever', 'fatigue', 'malaise', 'weight loss', 'night sweats'],\n",
        "            'respiratory': ['dyspnea', 'cough', 'wheezing', 'shortness of breath'],\n",
        "            'gi': ['nausea', 'vomiting', 'diarrhea', 'constipation', 'abdominal'],\n",
        "            'skin': ['rash', 'itching', 'lesion', 'discoloration', 'bruising']\n",
        "        }\n",
        "\n",
        "        # Anatomical location patterns\n",
        "        anatomy_patterns = {\n",
        "            'head_neck': ['head', 'neck', 'scalp', 'face', 'throat', 'cervical'],\n",
        "            'upper_extremity': ['shoulder', 'arm', 'elbow', 'forearm', 'wrist', 'hand', 'finger'],\n",
        "            'lower_extremity': ['hip', 'thigh', 'knee', 'leg', 'ankle', 'foot', 'toe'],\n",
        "            'trunk': ['chest', 'back', 'abdomen', 'pelvis', 'spine', 'lumbar'],\n",
        "            'joint': ['joint', 'articulation'],\n",
        "            'internal': ['heart', 'lung', 'liver', 'kidney', 'stomach']\n",
        "        }\n",
        "\n",
        "        # Severity/Intensity patterns\n",
        "        severity_patterns = ['mild', 'moderate', 'severe', 'extreme', 'minimal', 'significant']\n",
        "\n",
        "        # Temporal patterns\n",
        "        temporal_patterns = {\n",
        "            'acute': ['acute', 'sudden', 'abrupt', 'rapid'],\n",
        "            'chronic': ['chronic', 'persistent', 'ongoing', 'continuous'],\n",
        "            'intermittent': ['intermittent', 'episodic', 'recurrent', 'periodic'],\n",
        "            'progressive': ['progressive', 'worsening', 'increasing', 'deteriorating']\n",
        "        }\n",
        "\n",
        "        # Process each row\n",
        "        for idx, row in df_symptoms.iterrows():\n",
        "            # Get relevant text fields\n",
        "            symptom_name = str(row['name of symptom']).lower()\n",
        "            location = str(row['location']).lower()\n",
        "            intensity = str(row['intensity of symptom']).lower()\n",
        "            combined = str(row['combined_text']).lower()\n",
        "\n",
        "            # Extract symptom entities from name column\n",
        "            if symptom_name != 'nan':\n",
        "                custom_entities.append({\n",
        "                    'text': row['name of symptom'],\n",
        "                    'label': 'SYMPTOM',\n",
        "                    'category': 'primary_symptom',\n",
        "                    'start': 0,\n",
        "                    'end': len(symptom_name),\n",
        "                    'original_text': row['combined_text'],\n",
        "                    'source': 'symptom_name_column'\n",
        "                })\n",
        "\n",
        "            # Extract symptom types\n",
        "            for category, terms in symptom_patterns.items():\n",
        "                for term in terms:\n",
        "                    if term in combined:\n",
        "                        start = combined.find(term)\n",
        "                        custom_entities.append({\n",
        "                            'text': term,\n",
        "                            'label': 'SYMPTOM_TYPE',\n",
        "                            'category': category,\n",
        "                            'start': start,\n",
        "                            'end': start + len(term),\n",
        "                            'original_text': row['combined_text'],\n",
        "                            'source': 'pattern_matching'\n",
        "                        })\n",
        "\n",
        "            # Extract anatomical locations\n",
        "            if location != 'nan':\n",
        "                # First add the exact location\n",
        "                custom_entities.append({\n",
        "                    'text': row['location'],\n",
        "                    'label': 'ANATOMY',\n",
        "                    'category': 'symptom_location',\n",
        "                    'start': combined.find(location),\n",
        "                    'end': combined.find(location) + len(location),\n",
        "                    'original_text': row['combined_text'],\n",
        "                    'source': 'location_column'\n",
        "                })\n",
        "\n",
        "            # Extract additional anatomy from patterns\n",
        "            for category, terms in anatomy_patterns.items():\n",
        "                for term in terms:\n",
        "                    if term in combined:\n",
        "                        start = combined.find(term)\n",
        "                        custom_entities.append({\n",
        "                            'text': term,\n",
        "                            'label': 'ANATOMY',\n",
        "                            'category': category,\n",
        "                            'start': start,\n",
        "                            'end': start + len(term),\n",
        "                            'original_text': row['combined_text'],\n",
        "                            'source': 'pattern_matching'\n",
        "                        })\n",
        "\n",
        "            # Extract severity\n",
        "            if intensity != 'nan' and intensity in severity_patterns:\n",
        "                custom_entities.append({\n",
        "                    'text': intensity,\n",
        "                    'label': 'SEVERITY',\n",
        "                    'category': 'intensity',\n",
        "                    'start': combined.find(intensity),\n",
        "                    'end': combined.find(intensity) + len(intensity),\n",
        "                    'original_text': row['combined_text'],\n",
        "                    'source': 'intensity_column'\n",
        "                })\n",
        "\n",
        "            # Extract temporal patterns\n",
        "            temporal_text = str(row['temporalisation']).lower()\n",
        "            for category, terms in temporal_patterns.items():\n",
        "                for term in terms:\n",
        "                    if term in temporal_text or term in combined:\n",
        "                        start = combined.find(term) if term in combined else 0\n",
        "                        custom_entities.append({\n",
        "                            'text': term,\n",
        "                            'label': 'TEMPORAL_PATTERN',\n",
        "                            'category': category,\n",
        "                            'start': start,\n",
        "                            'end': start + len(term),\n",
        "                            'original_text': row['combined_text'],\n",
        "                            'source': 'temporal_extraction'\n",
        "                        })\n",
        "\n",
        "            # Extract laterality\n",
        "            laterality_terms = ['left', 'right', 'bilateral', 'both']\n",
        "            for term in laterality_terms:\n",
        "                if term in location or term in combined:\n",
        "                    start = combined.find(term)\n",
        "                    if start != -1:\n",
        "                        custom_entities.append({\n",
        "                            'text': term,\n",
        "                            'label': 'LATERALITY',\n",
        "                            'category': 'laterality',\n",
        "                            'start': start,\n",
        "                            'end': start + len(term),\n",
        "                            'original_text': row['combined_text'],\n",
        "                            'source': 'laterality_extraction'\n",
        "                        })\n",
        "\n",
        "        return pd.DataFrame(custom_entities)\n",
        "\n",
        "    # Extract custom entities\n",
        "    df_custom_symptom_entities = extract_symptom_entities_custom(df_symptoms)\n",
        "\n",
        "    print(f\"\\nCustom extraction found:\")\n",
        "    print(df_custom_symptom_entities['label'].value_counts())\n",
        "\n",
        "    # Combine all entities\n",
        "    df_all_symptom_entities = pd.concat([\n",
        "        df_symptoms_entities,\n",
        "        df_custom_symptom_entities\n",
        "    ], ignore_index=True)\n",
        "\n",
        "    print(f\"\\n=== COMBINED Entity Distribution ===\")\n",
        "    print(df_all_symptom_entities['label'].value_counts())\n",
        "\n",
        "    # Analyze symptom entities\n",
        "    symptom_entities = df_all_symptom_entities[df_all_symptom_entities['label'] == 'SYMPTOM']\n",
        "    if len(symptom_entities) > 0:\n",
        "        print(f\"\\n=== Top Symptoms ===\")\n",
        "        print(symptom_entities['text'].value_counts().head(20))\n",
        "\n",
        "    # Analyze anatomical locations\n",
        "    anatomy_entities = df_all_symptom_entities[df_all_symptom_entities['label'] == 'ANATOMY']\n",
        "    if len(anatomy_entities) > 0:\n",
        "        print(f\"\\n=== Top Symptom Locations ===\")\n",
        "        print(anatomy_entities['text'].value_counts().head(20))\n",
        "\n",
        "    # Analyze severity\n",
        "    severity_entities = df_all_symptom_entities[df_all_symptom_entities['label'] == 'SEVERITY']\n",
        "    if len(severity_entities) > 0:\n",
        "        print(f\"\\n=== Severity Distribution ===\")\n",
        "        print(severity_entities['text'].value_counts())\n",
        "\n",
        "    # Create symptom-specific labeling functions\n",
        "    print(\"\\n=== Creating Symptom-Specific Labeling Functions ===\")\n",
        "\n",
        "    def create_symptom_labeling_functions():\n",
        "        \"\"\"Create labeling functions for symptom patterns\"\"\"\n",
        "\n",
        "        def lf_severe_pain(row):\n",
        "            \"\"\"Identify severe pain symptoms\"\"\"\n",
        "            symptom = str(row.get('name of symptom', '')).lower()\n",
        "            intensity = str(row.get('intensity of symptom', '')).lower()\n",
        "\n",
        "            if 'pain' in symptom and intensity == 'severe':\n",
        "                return 'SEVERE_PAIN'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_chronic_symptom(row):\n",
        "            \"\"\"Identify chronic symptoms\"\"\"\n",
        "            temporal = str(row.get('temporalisation', '')).lower()\n",
        "            time_text = str(row.get('time', '')).lower()\n",
        "\n",
        "            chronic_indicators = ['chronic', 'persistent', 'ongoing', 'months', 'years']\n",
        "            if any(indicator in temporal + time_text for indicator in chronic_indicators):\n",
        "                return 'CHRONIC_SYMPTOM'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_neurological_symptom(row):\n",
        "            \"\"\"Identify neurological symptoms\"\"\"\n",
        "            symptom = str(row.get('name of symptom', '')).lower()\n",
        "            details = str(row.get('details', '')).lower()\n",
        "\n",
        "            neuro_terms = ['numbness', 'tingling', 'weakness', 'paralysis', 'sensation']\n",
        "            if any(term in symptom + details for term in neuro_terms):\n",
        "                return 'NEUROLOGICAL'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_bilateral_symptom(row):\n",
        "            \"\"\"Identify bilateral symptoms\"\"\"\n",
        "            location = str(row.get('location', '')).lower()\n",
        "            if any(term in location for term in ['bilateral', 'both', 'left and right']):\n",
        "                return 'BILATERAL_SYMPTOM'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_acute_onset(row):\n",
        "            \"\"\"Identify acute onset symptoms\"\"\"\n",
        "            temporal = str(row.get('temporalisation', '')).lower()\n",
        "            details = str(row.get('details', '')).lower()\n",
        "\n",
        "            acute_terms = ['sudden', 'acute', 'abrupt', 'rapid onset']\n",
        "            if any(term in temporal + details for term in acute_terms):\n",
        "                return 'ACUTE_ONSET'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_progressive_symptom(row):\n",
        "            \"\"\"Identify progressive symptoms\"\"\"\n",
        "            temporal = str(row.get('temporalisation', '')).lower()\n",
        "            details = str(row.get('details', '')).lower()\n",
        "\n",
        "            if any(term in temporal + details for term in ['worsening', 'progressive', 'increasing']):\n",
        "                return 'PROGRESSIVE_SYMPTOM'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_mobility_issue(row):\n",
        "            \"\"\"Identify mobility-related symptoms\"\"\"\n",
        "            symptom = str(row.get('name of symptom', '')).lower()\n",
        "            if any(term in symptom for term in ['walk', 'gait', 'mobility', 'movement']):\n",
        "                return 'MOBILITY_ISSUE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_pain_with_location(row):\n",
        "            \"\"\"Identify pain with specific location\"\"\"\n",
        "            symptom = str(row.get('name of symptom', '')).lower()\n",
        "            location = str(row.get('location', '')).lower()\n",
        "\n",
        "            if 'pain' in symptom and location != 'nan':\n",
        "                if 'hip' in location:\n",
        "                    return 'HIP_PAIN'\n",
        "                elif 'knee' in location:\n",
        "                    return 'KNEE_PAIN'\n",
        "                elif 'back' in location:\n",
        "                    return 'BACK_PAIN'\n",
        "                else:\n",
        "                    return 'LOCALIZED_PAIN'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_systemic_symptom(row):\n",
        "            \"\"\"Identify systemic symptoms\"\"\"\n",
        "            symptom = str(row.get('name of symptom', '')).lower()\n",
        "            systemic_terms = ['fever', 'fatigue', 'weight loss', 'malaise']\n",
        "\n",
        "            if any(term in symptom for term in systemic_terms):\n",
        "                return 'SYSTEMIC_SYMPTOM'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_symptom_duration(row):\n",
        "            \"\"\"Categorize by duration\"\"\"\n",
        "            duration = row.get('duration_days')\n",
        "\n",
        "            if pd.notna(duration):\n",
        "                if duration <= 7:\n",
        "                    return 'ACUTE_DURATION'\n",
        "                elif duration <= 30:\n",
        "                    return 'SUBACUTE_DURATION'\n",
        "                else:\n",
        "                    return 'CHRONIC_DURATION'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        return [\n",
        "            lf_severe_pain, lf_chronic_symptom, lf_neurological_symptom,\n",
        "            lf_bilateral_symptom, lf_acute_onset, lf_progressive_symptom,\n",
        "            lf_mobility_issue, lf_pain_with_location, lf_systemic_symptom,\n",
        "            lf_symptom_duration\n",
        "        ]\n",
        "\n",
        "    # Test labeling functions\n",
        "    symptom_lfs = create_symptom_labeling_functions()\n",
        "\n",
        "    print(\"\\nTesting symptom labeling functions:\")\n",
        "    for i in range(min(10, len(df_symptoms))):\n",
        "        row = df_symptoms.iloc[i]\n",
        "        print(f\"\\nRow {i}: {row['name of symptom']} - {row['location']}\")\n",
        "        for lf in symptom_lfs:\n",
        "            result = lf(row)\n",
        "            if result != 'ABSTAIN':\n",
        "                print(f\"  {lf.__name__}: {result}\")\n",
        "\n",
        "    # Extract symptom relations\n",
        "    print(\"\\n=== Extracting Symptom Relations ===\")\n",
        "\n",
        "    def extract_symptom_relations(df_symptoms, df_entities):\n",
        "        \"\"\"Extract relations between symptoms, locations, and attributes\"\"\"\n",
        "        relations = []\n",
        "\n",
        "        for idx, row in df_symptoms.iterrows():\n",
        "            symptom = row['name of symptom']\n",
        "            location = row['location']\n",
        "            intensity = row['intensity of symptom']\n",
        "\n",
        "            # SYMPTOM_LOCATED_IN relation\n",
        "            if pd.notna(symptom) and pd.notna(location) and location != 'NaN':\n",
        "                relations.append({\n",
        "                    'type': 'SYMPTOM_LOCATED_IN',\n",
        "                    'symptom': symptom,\n",
        "                    'location': location,\n",
        "                    'row_idx': idx\n",
        "                })\n",
        "\n",
        "            # SYMPTOM_HAS_SEVERITY relation\n",
        "            if pd.notna(symptom) and pd.notna(intensity) and intensity != 'NaN':\n",
        "                relations.append({\n",
        "                    'type': 'SYMPTOM_HAS_SEVERITY',\n",
        "                    'symptom': symptom,\n",
        "                    'severity': intensity,\n",
        "                    'row_idx': idx\n",
        "                })\n",
        "\n",
        "            # SYMPTOM_HAS_DURATION relation\n",
        "            if pd.notna(symptom) and pd.notna(row.get('duration_days')):\n",
        "                relations.append({\n",
        "                    'type': 'SYMPTOM_HAS_DURATION',\n",
        "                    'symptom': symptom,\n",
        "                    'duration_days': row['duration_days'],\n",
        "                    'row_idx': idx\n",
        "                })\n",
        "\n",
        "            # SYMPTOM_HAS_TEMPORAL_PATTERN relation\n",
        "            temporal = row.get('temporalisation', '')\n",
        "            if pd.notna(symptom) and pd.notna(temporal) and temporal != 'NaN':\n",
        "                relations.append({\n",
        "                    'type': 'SYMPTOM_HAS_TEMPORAL_PATTERN',\n",
        "                    'symptom': symptom,\n",
        "                    'pattern': temporal,\n",
        "                    'row_idx': idx\n",
        "                })\n",
        "\n",
        "        return relations\n",
        "\n",
        "    symptom_relations = extract_symptom_relations(df_symptoms, df_all_symptom_entities)\n",
        "\n",
        "    print(f\"Found {len(symptom_relations)} symptom relations\")\n",
        "    relation_types = pd.DataFrame(symptom_relations)['type'].value_counts()\n",
        "    print(\"\\nRelation type distribution:\")\n",
        "    print(relation_types)\n",
        "\n",
        "    # Sample relations\n",
        "    if symptom_relations:\n",
        "        print(\"\\nSample relations:\")\n",
        "        for rel in symptom_relations[:10]:\n",
        "            if rel['type'] == 'SYMPTOM_LOCATED_IN':\n",
        "                print(f\"  {rel['symptom']} -> located in -> {rel['location']}\")\n",
        "            elif rel['type'] == 'SYMPTOM_HAS_SEVERITY':\n",
        "                print(f\"  {rel['symptom']} -> has severity -> {rel['severity']}\")\n",
        "\n",
        "    # Coverage analysis\n",
        "    print(\"\\n=== Labeling Function Coverage Analysis ===\")\n",
        "\n",
        "    coverage_results = {}\n",
        "    for lf in symptom_lfs:\n",
        "        labeled = sum(1 for _, row in df_symptoms.iterrows() if lf(row) != 'ABSTAIN')\n",
        "        coverage = (labeled / len(df_symptoms)) * 100\n",
        "        coverage_results[lf.__name__] = {\n",
        "            'labeled': labeled,\n",
        "            'coverage': coverage\n",
        "        }\n",
        "\n",
        "    print(\"\\nLabeling function coverage:\")\n",
        "    for lf_name, stats in sorted(coverage_results.items(), key=lambda x: x[1]['coverage'], reverse=True):\n",
        "        print(f\"  {lf_name}: {stats['labeled']} labels ({stats['coverage']:.1f}% coverage)\")\n",
        "\n",
        "    # Save results\n",
        "    df_all_symptom_entities.to_csv('symptom_entities_comprehensive.csv', index=False)\n",
        "    pd.DataFrame(symptom_relations).to_csv('symptom_relations.csv', index=False)\n",
        "\n",
        "    print(\"\\n\\nSymptom entity extraction and labeling complete!\")\n",
        "    print(f\"Saved {len(df_all_symptom_entities)} entities and {len(symptom_relations)} relations\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>source_column</th>\n",
              "      <th>category</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pain</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Pain with Severe intensity located in Left hip...</td>\n",
              "      <td>133948.0</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pain</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>147</td>\n",
              "      <td>151</td>\n",
              "      <td>Pain with Severe intensity located in Left hip...</td>\n",
              "      <td>133948.0</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>weight gain</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>129</td>\n",
              "      <td>140</td>\n",
              "      <td>Moderate moon face with Moderate intensity loc...</td>\n",
              "      <td>133948.0</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Central obesity</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>Central obesity with nan intensity located in ...</td>\n",
              "      <td>133948.0</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Muscle mass reduction</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>Muscle mass reduction with nan intensity locat...</td>\n",
              "      <td>133948.0</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296379</th>\n",
              "      <td>chest</td>\n",
              "      <td>ANATOMY</td>\n",
              "      <td>20</td>\n",
              "      <td>25</td>\n",
              "      <td>Crushing substernal chest pressure with Acute ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>trunk</td>\n",
              "      <td>pattern_matching</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296380</th>\n",
              "      <td>acute</td>\n",
              "      <td>TEMPORAL_PATTERN</td>\n",
              "      <td>40</td>\n",
              "      <td>45</td>\n",
              "      <td>Crushing substernal chest pressure with Acute ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>acute</td>\n",
              "      <td>temporal_extraction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296381</th>\n",
              "      <td>Dyspnea</td>\n",
              "      <td>SYMPTOM</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>Dyspnea with Rapidly developed intensity locat...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>primary_symptom</td>\n",
              "      <td>symptom_name_column</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296382</th>\n",
              "      <td>dyspnea</td>\n",
              "      <td>SYMPTOM_TYPE</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>Dyspnea with Rapidly developed intensity locat...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>respiratory</td>\n",
              "      <td>pattern_matching</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296383</th>\n",
              "      <td>rapid</td>\n",
              "      <td>TEMPORAL_PATTERN</td>\n",
              "      <td>13</td>\n",
              "      <td>18</td>\n",
              "      <td>Dyspnea with Rapidly developed intensity locat...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>acute</td>\n",
              "      <td>temporal_extraction</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>296384 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         text             label  start  end  \\\n",
              "0                        Pain           DISEASE      0    4   \n",
              "1                        pain           DISEASE    147  151   \n",
              "2                 weight gain           DISEASE    129  140   \n",
              "3             Central obesity           DISEASE      0   15   \n",
              "4       Muscle mass reduction           DISEASE      0   21   \n",
              "...                       ...               ...    ...  ...   \n",
              "296379                  chest           ANATOMY     20   25   \n",
              "296380                  acute  TEMPORAL_PATTERN     40   45   \n",
              "296381                Dyspnea           SYMPTOM      0    7   \n",
              "296382                dyspnea      SYMPTOM_TYPE      0    7   \n",
              "296383                  rapid  TEMPORAL_PATTERN     13   18   \n",
              "\n",
              "                                            original_text   row_idx  \\\n",
              "0       Pain with Severe intensity located in Left hip...  133948.0   \n",
              "1       Pain with Severe intensity located in Left hip...  133948.0   \n",
              "2       Moderate moon face with Moderate intensity loc...  133948.0   \n",
              "3       Central obesity with nan intensity located in ...  133948.0   \n",
              "4       Muscle mass reduction with nan intensity locat...  133948.0   \n",
              "...                                                   ...       ...   \n",
              "296379  Crushing substernal chest pressure with Acute ...       NaN   \n",
              "296380  Crushing substernal chest pressure with Acute ...       NaN   \n",
              "296381  Dyspnea with Rapidly developed intensity locat...       NaN   \n",
              "296382  Dyspnea with Rapidly developed intensity locat...       NaN   \n",
              "296383  Dyspnea with Rapidly developed intensity locat...       NaN   \n",
              "\n",
              "        source_column         category               source  \n",
              "0       combined_text              NaN                  NaN  \n",
              "1       combined_text              NaN                  NaN  \n",
              "2       combined_text              NaN                  NaN  \n",
              "3       combined_text              NaN                  NaN  \n",
              "4       combined_text              NaN                  NaN  \n",
              "...               ...              ...                  ...  \n",
              "296379            NaN            trunk     pattern_matching  \n",
              "296380            NaN            acute  temporal_extraction  \n",
              "296381            NaN  primary_symptom  symptom_name_column  \n",
              "296382            NaN      respiratory     pattern_matching  \n",
              "296383            NaN            acute  temporal_extraction  \n",
              "\n",
              "[296384 rows x 9 columns]"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_all_symptom_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting Diagnosis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "id": "xK0iHDeMoHg6",
        "outputId": "0d334c5a-89db-43b8-be57-92d556df35e6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>has_diagnosis</th>\n",
              "      <th>test</th>\n",
              "      <th>severity</th>\n",
              "      <th>result</th>\n",
              "      <th>condition</th>\n",
              "      <th>time</th>\n",
              "      <th>details</th>\n",
              "      <th>combined_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155216</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>nan performed with nan severity showed nan ind...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>133948</td>\n",
              "      <td>True</td>\n",
              "      <td>Magnetic resonance imaging (MRI) scan</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Increased amount of joint fluid and bone marro...</td>\n",
              "      <td>Idiopathic osteonecrosis of the femoral head</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Patient did not complain of any pain on the co...</td>\n",
              "      <td>Magnetic resonance imaging (MRI) scan performe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133948</td>\n",
              "      <td>True</td>\n",
              "      <td>Repeat MRI</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Similar findings to those noted previously in ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>One year after the initial surgery and symptom...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Repeat MRI performed with nan severity showed ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80176</td>\n",
              "      <td>True</td>\n",
              "      <td>Radiographs</td>\n",
              "      <td>Minimally displaced</td>\n",
              "      <td>Proximal ulnar shaft fracture</td>\n",
              "      <td>Proximal ulnar shaft fracture, hypertrophic no...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Elbow arthrodesis at 90 degrees with retained ...</td>\n",
              "      <td>Radiographs performed with Minimally displaced...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72232</td>\n",
              "      <td>True</td>\n",
              "      <td>MRI</td>\n",
              "      <td>Moderate-sized</td>\n",
              "      <td>Focal area of marrow edema/contusion involving...</td>\n",
              "      <td>Bone marrow edema</td>\n",
              "      <td>September 2016, three months later, April 2017...</td>\n",
              "      <td>Involvement of medial femoral condyle in mid a...</td>\n",
              "      <td>MRI performed with Moderate-sized severity sho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61350</th>\n",
              "      <td>133320</td>\n",
              "      <td>True</td>\n",
              "      <td>Histopathological examination</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Consistent with lung metastasis of leiomyosarcoma</td>\n",
              "      <td>Lung metastasis of leiomyosarcoma</td>\n",
              "      <td>One year and 3 months postoperatively</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Histopathological examination performed with n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61351</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Electrocardiogram (ECG)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Diffuse ST depressions in all precordial leads</td>\n",
              "      <td>Consistent with an acute coronary syndrome</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Electrocardiogram (ECG) performed with nan sev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61352</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Transthoracic echocardiogram</td>\n",
              "      <td>Ejection fraction (EF) of 45% with severe aort...</td>\n",
              "      <td>Torn right coronary cusp</td>\n",
              "      <td>Severe aortic insufficiency</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Emergent transthoracic echocardiogram performed</td>\n",
              "      <td>Transthoracic echocardiogram performed with Ej...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61353</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Blood cultures</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Positive for S.\\nlugdunensis in both bottles</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Blood cultures performed with nan severity sho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61354</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Transesophageal echocardiogram</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Large vegetation prolapsing into the left vent...</td>\n",
              "      <td>Acute severe aortic insufficiency from endocar...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Performed while patient was intubated</td>\n",
              "      <td>Transesophageal echocardiogram performed with ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>61355 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          idx  has_diagnosis                                   test  \\\n",
              "0      155216          False                                    NaN   \n",
              "1      133948           True  Magnetic resonance imaging (MRI) scan   \n",
              "2      133948           True                             Repeat MRI   \n",
              "3       80176           True                            Radiographs   \n",
              "4       72232           True                                    MRI   \n",
              "...       ...            ...                                    ...   \n",
              "61350  133320           True          Histopathological examination   \n",
              "61351   97973           True                Electrocardiogram (ECG)   \n",
              "61352   97973           True           Transthoracic echocardiogram   \n",
              "61353   97973           True                         Blood cultures   \n",
              "61354   97973           True         Transesophageal echocardiogram   \n",
              "\n",
              "                                                severity  \\\n",
              "0                                                    NaN   \n",
              "1                                                    NaN   \n",
              "2                                                    NaN   \n",
              "3                                    Minimally displaced   \n",
              "4                                         Moderate-sized   \n",
              "...                                                  ...   \n",
              "61350                                                NaN   \n",
              "61351                                                NaN   \n",
              "61352  Ejection fraction (EF) of 45% with severe aort...   \n",
              "61353                                                NaN   \n",
              "61354                                                NaN   \n",
              "\n",
              "                                                  result  \\\n",
              "0                                                    NaN   \n",
              "1      Increased amount of joint fluid and bone marro...   \n",
              "2      Similar findings to those noted previously in ...   \n",
              "3                          Proximal ulnar shaft fracture   \n",
              "4      Focal area of marrow edema/contusion involving...   \n",
              "...                                                  ...   \n",
              "61350  Consistent with lung metastasis of leiomyosarcoma   \n",
              "61351     Diffuse ST depressions in all precordial leads   \n",
              "61352                           Torn right coronary cusp   \n",
              "61353       Positive for S.\\nlugdunensis in both bottles   \n",
              "61354  Large vegetation prolapsing into the left vent...   \n",
              "\n",
              "                                               condition  \\\n",
              "0                                                    NaN   \n",
              "1           Idiopathic osteonecrosis of the femoral head   \n",
              "2                                                    NaN   \n",
              "3      Proximal ulnar shaft fracture, hypertrophic no...   \n",
              "4                                      Bone marrow edema   \n",
              "...                                                  ...   \n",
              "61350                  Lung metastasis of leiomyosarcoma   \n",
              "61351         Consistent with an acute coronary syndrome   \n",
              "61352                        Severe aortic insufficiency   \n",
              "61353                                                NaN   \n",
              "61354  Acute severe aortic insufficiency from endocar...   \n",
              "\n",
              "                                                    time  \\\n",
              "0                                                    NaN   \n",
              "1                                                    NaN   \n",
              "2      One year after the initial surgery and symptom...   \n",
              "3                                                    NaN   \n",
              "4      September 2016, three months later, April 2017...   \n",
              "...                                                  ...   \n",
              "61350              One year and 3 months postoperatively   \n",
              "61351                                                NaN   \n",
              "61352                                                NaN   \n",
              "61353                                                NaN   \n",
              "61354                                                NaN   \n",
              "\n",
              "                                                 details  \\\n",
              "0                                                    NaN   \n",
              "1      Patient did not complain of any pain on the co...   \n",
              "2                                                    NaN   \n",
              "3      Elbow arthrodesis at 90 degrees with retained ...   \n",
              "4      Involvement of medial femoral condyle in mid a...   \n",
              "...                                                  ...   \n",
              "61350                                                NaN   \n",
              "61351                                                NaN   \n",
              "61352    Emergent transthoracic echocardiogram performed   \n",
              "61353                                                NaN   \n",
              "61354              Performed while patient was intubated   \n",
              "\n",
              "                                           combined_text  \n",
              "0      nan performed with nan severity showed nan ind...  \n",
              "1      Magnetic resonance imaging (MRI) scan performe...  \n",
              "2      Repeat MRI performed with nan severity showed ...  \n",
              "3      Radiographs performed with Minimally displaced...  \n",
              "4      MRI performed with Moderate-sized severity sho...  \n",
              "...                                                  ...  \n",
              "61350  Histopathological examination performed with n...  \n",
              "61351  Electrocardiogram (ECG) performed with nan sev...  \n",
              "61352  Transthoracic echocardiogram performed with Ej...  \n",
              "61353  Blood cultures performed with nan severity sho...  \n",
              "61354  Transesophageal echocardiogram performed with ...  \n",
              "\n",
              "[61355 rows x 9 columns]"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_diagnosis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing temporal column: time\n",
            "\n",
            "Temporal extraction results:\n",
            "Successfully extracted duration: 3879\n",
            "Temporal types: {'unspecified': 4734, 'post_event': 3354, 'absolute_date': 1766, 'past_reference': 1280, 'range_reference': 1258, 'duration_reference': 299, 'onset_reference': 155}\n",
            "Loading en_ner_bc5cdr_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 61355 texts in 205 batches...\n",
            "Using model: en_ner_bc5cdr_md for column: combined_text\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   0%|          | 1/205 [00:01<05:31,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   5%|▌         | 11/205 [00:15<04:40,  1.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 3000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  10%|█         | 21/205 [00:30<04:45,  1.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 6000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  15%|█▌        | 31/205 [00:44<04:20,  1.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 9000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  20%|██        | 41/205 [00:58<03:55,  1.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 12000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  25%|██▍       | 51/205 [01:12<03:37,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  30%|██▉       | 61/205 [01:26<03:26,  1.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 18000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  35%|███▍      | 71/205 [01:40<03:13,  1.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 21000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  40%|███▉      | 81/205 [01:54<02:57,  1.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 24000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  44%|████▍     | 91/205 [02:08<02:47,  1.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 27000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  49%|████▉     | 101/205 [02:22<02:35,  1.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 30000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  54%|█████▍    | 111/205 [02:36<02:19,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 33000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  59%|█████▉    | 121/205 [02:50<02:04,  1.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 36000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  64%|██████▍   | 131/205 [03:04<01:51,  1.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 39000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  69%|██████▉   | 141/205 [03:18<01:37,  1.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 42000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  74%|███████▎  | 151/205 [03:32<01:21,  1.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 45000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  79%|███████▊  | 161/205 [03:46<01:06,  1.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 48000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  83%|████████▎ | 171/205 [04:00<00:53,  1.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 51000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  88%|████████▊ | 181/205 [04:14<00:36,  1.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 54000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  93%|█████████▎| 191/205 [04:29<00:21,  1.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 57000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  98%|█████████▊| 201/205 [04:43<00:06,  1.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 60000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 205/205 [04:48<00:00,  1.41s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2745 entities appearing >= 5 times\n",
            "\n",
            "=== BC5CDR Entity Types Found ===\n",
            "{'DISEASE': 77150, 'CHEMICAL': 8577}\n",
            "\n",
            "=== CUSTOM DIAGNOSIS ENTITY EXTRACTION ===\n",
            "\n",
            "Custom extraction found:\n",
            "label\n",
            "TEST           56150\n",
            "TEST_TYPE      52665\n",
            "CONDITION      36529\n",
            "FINDING        25683\n",
            "ANATOMY        22056\n",
            "LATERALITY     18239\n",
            "MEASUREMENT    13021\n",
            "SEVERITY        1054\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== COMBINED Entity Distribution ===\n",
            "label\n",
            "DISEASE        77150\n",
            "TEST           56150\n",
            "TEST_TYPE      52665\n",
            "CONDITION      36529\n",
            "FINDING        25683\n",
            "ANATOMY        22056\n",
            "LATERALITY     18239\n",
            "MEASUREMENT    13021\n",
            "CHEMICAL        8577\n",
            "SEVERITY        1054\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Diagnostic Tests ===\n",
            "text\n",
            "MRI                                 1005\n",
            "CT scan                              786\n",
            "Biopsy                               634\n",
            "Magnetic resonance imaging (MRI)     625\n",
            "Histopathological examination        566\n",
            "Chest X-ray                          431\n",
            "Laboratory tests                     383\n",
            "Computed tomography (CT)             379\n",
            "Computed tomography (CT) scan        373\n",
            "Radiographs                          313\n",
            "Blood tests                          311\n",
            "Histological examination             295\n",
            "Ultrasound                           246\n",
            "Colonoscopy                          235\n",
            "Histopathology                       233\n",
            "Brain MRI                            229\n",
            "Blood cultures                       214\n",
            "Incisional biopsy                    213\n",
            "Pathological examination             209\n",
            "Electrocardiogram                    207\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Diagnostic Findings ===\n",
            "text\n",
            "mass            4690\n",
            "lesion          4106\n",
            "tumor           1982\n",
            "cyst            1931\n",
            "carcinoma       1637\n",
            "fracture        1406\n",
            "aneurysm         966\n",
            "stenosis         723\n",
            "nodule           716\n",
            "edema            674\n",
            "hemorrhage       548\n",
            "effusion         518\n",
            "metastasis       512\n",
            "malignant        485\n",
            "necrosis         470\n",
            "occlusion        446\n",
            "infiltration     408\n",
            "inflammation     361\n",
            "sarcoma          351\n",
            "thrombosis       295\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Diagnosed Conditions ===\n",
            "text\n",
            "Infection                  169\n",
            "Squamous cell carcinoma    106\n",
            "Anemia                     106\n",
            "Coronary artery disease    101\n",
            "Adenocarcinoma              83\n",
            "Tuberculosis                71\n",
            "Metastatic disease          70\n",
            "Malignant melanoma          65\n",
            "Stroke                      62\n",
            "Pseudoaneurysm              60\n",
            "Osteosarcoma                57\n",
            "COVID-19                    55\n",
            "Pregnancy                   52\n",
            "Metastatic melanoma         51\n",
            "Tumor                       50\n",
            "HIV                         48\n",
            "Pulmonary embolism          47\n",
            "Breast cancer               44\n",
            "Fracture                    41\n",
            "Prostate cancer             40\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Creating Diagnosis-Specific Labeling Functions ===\n",
            "\n",
            "Testing diagnosis labeling functions:\n",
            "\n",
            "Row 0: nan - nan\n",
            "\n",
            "Row 1: Magnetic resonance imaging (MRI) scan - Idiopathic osteonecrosis of the femoral head\n",
            "  lf_imaging_test: IMAGING_TEST\n",
            "  lf_bone_pathology: BONE_PATHOLOGY\n",
            "  lf_inflammatory_finding: INFLAMMATORY_FINDING\n",
            "\n",
            "Row 2: Repeat MRI - nan\n",
            "  lf_imaging_test: IMAGING_TEST\n",
            "\n",
            "Row 3: Radiographs - Proximal ulnar shaft fracture, hypertrophic nonunion\n",
            "  lf_imaging_test: IMAGING_TEST\n",
            "  lf_fracture_diagnosis: FRACTURE_PRESENT\n",
            "  lf_bone_pathology: BONE_PATHOLOGY\n",
            "\n",
            "Row 4: MRI - Bone marrow edema\n",
            "  lf_imaging_test: IMAGING_TEST\n",
            "  lf_bone_pathology: BONE_PATHOLOGY\n",
            "  lf_inflammatory_finding: INFLAMMATORY_FINDING\n",
            "\n",
            "Row 5: nan - Osteomalacia\n",
            "\n",
            "Row 6: Computed tomography (CT) of thorax - Diaphragmatic defect\n",
            "  lf_imaging_test: IMAGING_TEST\n",
            "  lf_normal_finding: NORMAL_FINDING\n",
            "\n",
            "Row 7: Imaging - Polyostotic fibrous dysplasia\n",
            "  lf_fracture_diagnosis: FRACTURE_PRESENT\n",
            "  lf_neoplastic_finding: NEOPLASTIC_FINDING\n",
            "  lf_bone_pathology: BONE_PATHOLOGY\n",
            "  lf_bilateral_finding: BILATERAL_FINDING\n",
            "\n",
            "Row 8: Magnetic resonance scanning - Fibrous dysplasia of the proximal femur shaft, sub-capital fracture of femur neck\n",
            "  lf_imaging_test: IMAGING_TEST\n",
            "  lf_fracture_diagnosis: FRACTURE_PRESENT\n",
            "  lf_bone_pathology: BONE_PATHOLOGY\n",
            "  lf_vascular_finding: VASCULAR_FINDING\n",
            "\n",
            "Row 9: Blood and serum biochemical investigations - nan\n",
            "  lf_normal_finding: NORMAL_FINDING\n",
            "\n",
            "=== Extracting Diagnosis Relations ===\n",
            "\n",
            "Found 125865 diagnosis relations\n",
            "\n",
            "Relation type distribution:\n",
            "type\n",
            "TEST_REVEALS            53912\n",
            "TEST_DIAGNOSES          34501\n",
            "FINDING_INDICATES       33304\n",
            "FINDING_HAS_SEVERITY     4148\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sample relations:\n",
            "  Magnetic resonance imaging (MRI) scan -> reveals -> Increased amount of joint fluid and bone marrow edema in the left hip, and femoral head necrosis on the contralateral side\n",
            "  Magnetic resonance imaging (MRI) scan -> diagnoses -> Idiopathic osteonecrosis of the femoral head\n",
            "  Repeat MRI -> reveals -> Similar findings to those noted previously in the left hip\n",
            "  Radiographs -> reveals -> Proximal ulnar shaft fracture\n",
            "  Radiographs -> diagnoses -> Proximal ulnar shaft fracture, hypertrophic nonunion\n",
            "  MRI -> reveals -> Focal area of marrow edema/contusion involving the medial femoral condyle, bone marrow edema involving the lateral femoral condyle, extensive marrow edema involving the medial femoral condyle\n",
            "  MRI -> diagnoses -> Bone marrow edema\n",
            "\n",
            "=== Test-Finding Pattern Analysis ===\n",
            "\n",
            "Common test-finding patterns:\n",
            "  Chest X-ray -> Normal: 53 occurrences\n",
            "  Blood cultures -> Negative: 43 occurrences\n",
            "  Complete blood count -> Normal: 30 occurrences\n",
            "  Chest radiograph -> Normal: 28 occurrences\n",
            "  Blood tests -> Normal: 25 occurrences\n",
            "  HIV test -> Negative: 25 occurrences\n",
            "  Liver function tests -> Normal: 25 occurrences\n",
            "  Mantoux test -> Negative: 24 occurrences\n",
            "  Laboratory tests -> Normal: 22 occurrences\n",
            "  Thyroid function tests -> Normal: 19 occurrences\n",
            "\n",
            "=== Labeling Function Coverage Analysis ===\n",
            "\n",
            "Labeling function coverage:\n",
            "  lf_imaging_test: 25761 labels (42.0% coverage)\n",
            "  lf_neoplastic_finding: 14057 labels (22.9% coverage)\n",
            "  lf_normal_finding: 10924 labels (17.8% coverage)\n",
            "  lf_vascular_finding: 6262 labels (10.2% coverage)\n",
            "  lf_inflammatory_finding: 3110 labels (5.1% coverage)\n",
            "  lf_bone_pathology: 2771 labels (4.5% coverage)\n",
            "  lf_bilateral_finding: 1826 labels (3.0% coverage)\n",
            "  lf_fracture_diagnosis: 1707 labels (2.8% coverage)\n",
            "  lf_followup_needed: 408 labels (0.7% coverage)\n",
            "  lf_critical_finding: 177 labels (0.3% coverage)\n",
            "\n",
            "=== Diagnostic Summary ===\n",
            "\n",
            "Test types distribution:\n",
            "category\n",
            "imaging       42370\n",
            "laboratory     7822\n",
            "functional     1395\n",
            "endoscopy      1078\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Finding categories:\n",
            "category\n",
            "structural      16393\n",
            "neoplastic       3575\n",
            "vascular         2356\n",
            "inflammatory     2313\n",
            "degenerative     1046\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n",
            "Diagnosis entity extraction and labeling complete!\n",
            "Saved 311124 entities and 125865 relations\n",
            "Diagnostic patterns exported to diagnostic_patterns.json\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    # Apply temporal standardization\n",
        "    temporal_standardizer = TemporalStandardizer()\n",
        "    df_diagnosis_processed, temporal_report = temporal_standardizer.standardize_temporal_column(\n",
        "        df_diagnosis, \n",
        "        'time'\n",
        "    )\n",
        "   \n",
        "    print(f\"\\nTemporal extraction results:\")\n",
        "    print(f\"Successfully extracted duration: {temporal_report['extracted_durations']}\")\n",
        "    print(f\"Temporal types: {temporal_report['temporal_types']}\")\n",
        "\n",
        "    # Combine surgery text columns\n",
        "    df_diagnosis['combined_text'] = df_diagnosis.apply(\n",
        "        lambda row: f\"{row['test']} performed with {row['severity']} severity showed {row['result']} indicating {row['condition']} {row['details']} at {row['time']}\",\n",
        "        axis=1        \n",
        "    )\n",
        "    # Copy combined_text to processed dataframe\n",
        "    df_diagnosis_processed['combined_text'] = df_diagnosis['combined_text']\n",
        "\n",
        "    # Add temporal features to combined text\n",
        "    df_diagnosis_processed['combined_text_enriched'] = df_diagnosis_processed.apply(\n",
        "        lambda row: f\"{row['combined_text']} {'lasting ' + str(row.get('time_duration_days', '')) + ' days' if pd.notna(row.get('time_duration_days')) else ''}\",\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Run NER extraction with BC5CDR\n",
        "    df_diagnosis_entities, diagnosis_summary, diagnosis_rules = run_medical_ner_extraction(\n",
        "        df_diagnosis,\n",
        "        text_column='combined_text',\n",
        "        model_name=\"en_ner_bc5cdr_md\",\n",
        "        batch_size=300, \n",
        "        id_column='idx'\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== BC5CDR Entity Types Found ===\")\n",
        "    print(diagnosis_summary['entity_types'])\n",
        "\n",
        "    # Custom entity extraction for diagnosis-specific entities\n",
        "    print(\"\\n=== CUSTOM DIAGNOSIS ENTITY EXTRACTION ===\")\n",
        "\n",
        "    def extract_diagnosis_entities_custom(df_diagnosis):\n",
        "        \"\"\"Extract diagnosis-specific entities not caught by BC5CDR\"\"\"\n",
        "\n",
        "        custom_entities = []\n",
        "\n",
        "        # Test/Procedure patterns\n",
        "        test_patterns = {\n",
        "            'imaging': [\n",
        "                'mri', 'magnetic resonance', 'ct', 'computed tomography',\n",
        "                'x-ray', 'radiograph', 'ultrasound', 'sonography', 'scan',\n",
        "                'pet', 'spect', 'angiography', 'mammography'\n",
        "            ],\n",
        "            'laboratory': [\n",
        "                'blood test', 'serum', 'plasma', 'biochemical', 'hematology',\n",
        "                'urinalysis', 'culture', 'biopsy', 'cytology', 'pathology'\n",
        "            ],\n",
        "            'functional': [\n",
        "                'ecg', 'ekg', 'electrocardiogram', 'eeg', 'electroencephalogram',\n",
        "                'emg', 'electromyography', 'spirometry', 'pulmonary function'\n",
        "            ],\n",
        "            'endoscopy': [\n",
        "                'endoscopy', 'colonoscopy', 'gastroscopy', 'bronchoscopy',\n",
        "                'cystoscopy', 'arthroscopy', 'laparoscopy'\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        # Finding/Result patterns\n",
        "        finding_patterns = {\n",
        "            'structural': [\n",
        "                'fracture', 'lesion', 'mass', 'tumor', 'cyst', 'nodule',\n",
        "                'stenosis', 'occlusion', 'herniation', 'displacement'\n",
        "            ],\n",
        "            'inflammatory': [\n",
        "                'inflammation', 'edema', 'swelling', 'effusion', 'congestion',\n",
        "                'infiltration', 'consolidation'\n",
        "            ],\n",
        "            'degenerative': [\n",
        "                'degeneration', 'atrophy', 'necrosis', 'fibrosis', 'sclerosis',\n",
        "                'osteoarthritis', 'spondylosis'\n",
        "            ],\n",
        "            'vascular': [\n",
        "                'ischemia', 'infarction', 'hemorrhage', 'aneurysm', 'thrombosis',\n",
        "                'embolism', 'vasculitis'\n",
        "            ],\n",
        "            'neoplastic': [\n",
        "                'malignant', 'benign', 'metastasis', 'carcinoma', 'sarcoma',\n",
        "                'lymphoma', 'adenoma'\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        # Anatomical patterns specific to diagnosis\n",
        "        anatomy_patterns = {\n",
        "            'bone': ['femur', 'tibia', 'fibula', 'humerus', 'radius', 'ulna', 'vertebra'],\n",
        "            'joint': ['hip', 'knee', 'shoulder', 'elbow', 'ankle', 'wrist'],\n",
        "            'organ': ['liver', 'kidney', 'heart', 'lung', 'brain', 'pancreas', 'spleen'],\n",
        "            'vessel': ['artery', 'vein', 'aorta', 'carotid', 'coronary'],\n",
        "            'region': ['parietal', 'temporal', 'frontal', 'occipital', 'cervical', 'lumbar']\n",
        "        }\n",
        "\n",
        "        # Severity/Grade patterns\n",
        "        severity_patterns = {\n",
        "            'mild': ['mild', 'minimal', 'slight', 'minor'],\n",
        "            'moderate': ['moderate', 'medium', 'intermediate'],\n",
        "            'severe': ['severe', 'significant', 'marked', 'extensive'],\n",
        "            'critical': ['critical', 'life-threatening', 'emergency']\n",
        "        }\n",
        "\n",
        "        # Process each row\n",
        "        for idx, row in df_diagnosis.iterrows():\n",
        "            test_text = str(row['test']).lower()\n",
        "            result_text = str(row['result']).lower()\n",
        "            condition_text = str(row['condition']).lower()\n",
        "            combined = str(row['combined_text']).lower()\n",
        "\n",
        "            # Extract test entities\n",
        "            if test_text != 'nan':\n",
        "                # Add the exact test name\n",
        "                custom_entities.append({\n",
        "                    'text': row['test'],\n",
        "                    'label': 'TEST',\n",
        "                    'category': 'diagnostic_test',\n",
        "                    'original_text': row['combined_text'],\n",
        "                    'source': 'test_column'\n",
        "                })\n",
        "\n",
        "                # Categorize test type\n",
        "                for category, terms in test_patterns.items():\n",
        "                    for term in terms:\n",
        "                        if term in test_text:\n",
        "                            custom_entities.append({\n",
        "                                'text': term,\n",
        "                                'label': 'TEST_TYPE',\n",
        "                                'category': category,\n",
        "                                'original_text': row['combined_text'],\n",
        "                                'source': 'pattern_matching'\n",
        "                            })\n",
        "\n",
        "            # Extract findings from result\n",
        "            if result_text != 'nan':\n",
        "                for category, terms in finding_patterns.items():\n",
        "                    for term in terms:\n",
        "                        if term in result_text:\n",
        "                            custom_entities.append({\n",
        "                                'text': term,\n",
        "                                'label': 'FINDING',\n",
        "                                'category': category,\n",
        "                                'original_text': row['combined_text'],\n",
        "                                'source': 'result_extraction'\n",
        "                            })\n",
        "\n",
        "            # Extract condition entities\n",
        "            if condition_text != 'nan':\n",
        "                custom_entities.append({\n",
        "                    'text': row['condition'],\n",
        "                    'label': 'CONDITION',\n",
        "                    'category': 'diagnosis',\n",
        "                    'original_text': row['combined_text'],\n",
        "                    'source': 'condition_column'\n",
        "                })\n",
        "\n",
        "            # Extract anatomy\n",
        "            for category, terms in anatomy_patterns.items():\n",
        "                for term in terms:\n",
        "                    if term in combined:\n",
        "                        custom_entities.append({\n",
        "                            'text': term,\n",
        "                            'label': 'ANATOMY',\n",
        "                            'category': category,\n",
        "                            'original_text': row['combined_text'],\n",
        "                            'source': 'anatomy_extraction'\n",
        "                        })\n",
        "\n",
        "            # Extract severity\n",
        "            severity_text = str(row['severity']).lower()\n",
        "            if severity_text != 'nan':\n",
        "                for category, terms in severity_patterns.items():\n",
        "                    if severity_text in terms:\n",
        "                        custom_entities.append({\n",
        "                            'text': row['severity'],\n",
        "                            'label': 'SEVERITY',\n",
        "                            'category': category,\n",
        "                            'original_text': row['combined_text'],\n",
        "                            'source': 'severity_column'\n",
        "                        })\n",
        "\n",
        "            # Extract laterality\n",
        "            laterality_terms = ['left', 'right', 'bilateral']\n",
        "            for term in laterality_terms:\n",
        "                if term in combined:\n",
        "                    custom_entities.append({\n",
        "                        'text': term,\n",
        "                        'label': 'LATERALITY',\n",
        "                        'category': 'laterality',\n",
        "                        'original_text': row['combined_text'],\n",
        "                        'source': 'laterality_extraction'\n",
        "                    })\n",
        "\n",
        "            # Extract measurement values\n",
        "            measurement_pattern = r'\\d+\\.?\\d*\\s*(mm|cm|ml|mg|%)'\n",
        "            measurements = re.findall(measurement_pattern, combined)\n",
        "            for measurement in measurements:\n",
        "                custom_entities.append({\n",
        "                    'text': measurement,\n",
        "                    'label': 'MEASUREMENT',\n",
        "                    'category': 'quantitative',\n",
        "                    'original_text': row['combined_text'],\n",
        "                    'source': 'measurement_extraction'\n",
        "                })\n",
        "\n",
        "        return pd.DataFrame(custom_entities)\n",
        "\n",
        "    # Extract custom entities\n",
        "    df_custom_diagnosis_entities = extract_diagnosis_entities_custom(df_diagnosis)\n",
        "\n",
        "    print(f\"\\nCustom extraction found:\")\n",
        "    print(df_custom_diagnosis_entities['label'].value_counts())\n",
        "\n",
        "    # Combine all entities\n",
        "    df_all_diagnosis_entities = pd.concat([\n",
        "        df_diagnosis_entities,\n",
        "        df_custom_diagnosis_entities\n",
        "    ], ignore_index=True)\n",
        "\n",
        "    print(f\"\\n=== COMBINED Entity Distribution ===\")\n",
        "    print(df_all_diagnosis_entities['label'].value_counts())\n",
        "\n",
        "    # Analyze test entities\n",
        "    test_entities = df_all_diagnosis_entities[df_all_diagnosis_entities['label'] == 'TEST']\n",
        "    if len(test_entities) > 0:\n",
        "        print(f\"\\n=== Top Diagnostic Tests ===\")\n",
        "        print(test_entities['text'].value_counts().head(20))\n",
        "\n",
        "    # Analyze findings\n",
        "    finding_entities = df_all_diagnosis_entities[df_all_diagnosis_entities['label'] == 'FINDING']\n",
        "    if len(finding_entities) > 0:\n",
        "        print(f\"\\n=== Top Diagnostic Findings ===\")\n",
        "        print(finding_entities['text'].value_counts().head(20))\n",
        "\n",
        "    # Analyze conditions\n",
        "    condition_entities = df_all_diagnosis_entities[df_all_diagnosis_entities['label'] == 'CONDITION']\n",
        "    if len(condition_entities) > 0:\n",
        "        print(f\"\\n=== Top Diagnosed Conditions ===\")\n",
        "        print(condition_entities['text'].value_counts().head(20))\n",
        "\n",
        "    # Create diagnosis-specific labeling functions\n",
        "    print(\"\\n=== Creating Diagnosis-Specific Labeling Functions ===\")\n",
        "\n",
        "    def create_diagnosis_labeling_functions():\n",
        "        \"\"\"Create labeling functions for diagnosis patterns\"\"\"\n",
        "\n",
        "        def lf_imaging_test(row):\n",
        "            \"\"\"Identify imaging tests\"\"\"\n",
        "            test = str(row.get('test', '')).lower()\n",
        "            imaging_keywords = ['mri', 'ct', 'x-ray', 'radiograph', 'ultrasound', 'scan']\n",
        "\n",
        "            if any(keyword in test for keyword in imaging_keywords):\n",
        "                return 'IMAGING_TEST'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_fracture_diagnosis(row):\n",
        "            \"\"\"Identify fracture diagnoses\"\"\"\n",
        "            result = str(row.get('result', '')).lower()\n",
        "            condition = str(row.get('condition', '')).lower()\n",
        "\n",
        "            if 'fracture' in result or 'fracture' in condition:\n",
        "                if 'no fracture' in result or 'no fracture' in condition:\n",
        "                    return 'NO_FRACTURE'\n",
        "                else:\n",
        "                    return 'FRACTURE_PRESENT'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_neoplastic_finding(row):\n",
        "            \"\"\"Identify neoplastic findings\"\"\"\n",
        "            combined = str(row.get('combined_text', '')).lower()\n",
        "            neoplastic_terms = ['tumor', 'mass', 'lesion', 'malignant', 'benign', 'metastasis']\n",
        "\n",
        "            if any(term in combined for term in neoplastic_terms):\n",
        "                return 'NEOPLASTIC_FINDING'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_normal_finding(row):\n",
        "            \"\"\"Identify normal/negative findings\"\"\"\n",
        "            result = str(row.get('result', '')).lower()\n",
        "            normal_terms = ['normal', 'negative', 'no abnormality', 'unremarkable']\n",
        "\n",
        "            if any(term in result for term in normal_terms):\n",
        "                return 'NORMAL_FINDING'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_critical_finding(row):\n",
        "            \"\"\"Identify critical findings\"\"\"\n",
        "            severity = str(row.get('severity', '')).lower()\n",
        "            details = str(row.get('details', '')).lower()\n",
        "\n",
        "            critical_terms = ['critical', 'emergency', 'urgent', 'life-threatening']\n",
        "            if any(term in severity + details for term in critical_terms):\n",
        "                return 'CRITICAL_FINDING'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_bone_pathology(row):\n",
        "            \"\"\"Identify bone-related pathology\"\"\"\n",
        "            combined = str(row.get('combined_text', '')).lower()\n",
        "            bone_terms = ['bone', 'osseous', 'fracture', 'osteo', 'marrow']\n",
        "            pathology_terms = ['lesion', 'edema', 'necrosis', 'fracture']\n",
        "\n",
        "            has_bone = any(bone in combined for bone in bone_terms)\n",
        "            has_pathology = any(path in combined for path in pathology_terms)\n",
        "\n",
        "            if has_bone and has_pathology:\n",
        "                return 'BONE_PATHOLOGY'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_vascular_finding(row):\n",
        "            \"\"\"Identify vascular findings\"\"\"\n",
        "            combined = str(row.get('combined_text', '')).lower()\n",
        "            vascular_terms = ['vascular', 'artery', 'vein', 'aneurysm', 'stenosis', 'occlusion']\n",
        "\n",
        "            if any(term in combined for term in vascular_terms):\n",
        "                return 'VASCULAR_FINDING'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_inflammatory_finding(row):\n",
        "            \"\"\"Identify inflammatory findings\"\"\"\n",
        "            combined = str(row.get('combined_text', '')).lower()\n",
        "            inflammatory_terms = ['inflammation', 'inflammatory', 'edema', 'effusion', 'swelling']\n",
        "\n",
        "            if any(term in combined for term in inflammatory_terms):\n",
        "                return 'INFLAMMATORY_FINDING'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_bilateral_finding(row):\n",
        "            \"\"\"Identify bilateral findings\"\"\"\n",
        "            combined = str(row.get('combined_text', '')).lower()\n",
        "\n",
        "            if 'bilateral' in combined:\n",
        "                return 'BILATERAL_FINDING'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_followup_needed(row):\n",
        "            \"\"\"Identify cases needing follow-up\"\"\"\n",
        "            details = str(row.get('details', '')).lower()\n",
        "\n",
        "            followup_terms = ['follow-up', 'followup', 'repeat', 'monitor', 'reassess']\n",
        "            if any(term in details for term in followup_terms):\n",
        "                return 'FOLLOWUP_NEEDED'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        return [\n",
        "            lf_imaging_test, lf_fracture_diagnosis, lf_neoplastic_finding,\n",
        "            lf_normal_finding, lf_critical_finding, lf_bone_pathology,\n",
        "            lf_vascular_finding, lf_inflammatory_finding, lf_bilateral_finding,\n",
        "            lf_followup_needed\n",
        "        ]\n",
        "\n",
        "    # Test labeling functions\n",
        "    diagnosis_lfs = create_diagnosis_labeling_functions()\n",
        "\n",
        "    print(\"\\nTesting diagnosis labeling functions:\")\n",
        "    for i in range(min(10, len(df_diagnosis))):\n",
        "        row = df_diagnosis.iloc[i]\n",
        "        print(f\"\\nRow {i}: {row['test']} - {row['condition']}\")\n",
        "        for lf in diagnosis_lfs:\n",
        "            result = lf(row)\n",
        "            if result != 'ABSTAIN':\n",
        "                print(f\"  {lf.__name__}: {result}\")\n",
        "\n",
        "    # Extract diagnosis relations\n",
        "    print(\"\\n=== Extracting Diagnosis Relations ===\")\n",
        "\n",
        "    def extract_diagnosis_relations(df_diagnosis):\n",
        "        \"\"\"Extract relations between tests, findings, and conditions\"\"\"\n",
        "        relations = []\n",
        "\n",
        "        for idx, row in df_diagnosis.iterrows():\n",
        "            test = row['test']\n",
        "            result = row['result']\n",
        "            condition = row['condition']\n",
        "            severity = row['severity']\n",
        "\n",
        "            # TEST_REVEALS_FINDING relation\n",
        "            if pd.notna(test) and pd.notna(result) and result != 'NaN':\n",
        "                relations.append({\n",
        "                    'type': 'TEST_REVEALS',\n",
        "                    'test': test,\n",
        "                    'finding': result,\n",
        "                    'row_idx': idx\n",
        "                })\n",
        "\n",
        "            # TEST_DIAGNOSES_CONDITION relation\n",
        "            if pd.notna(test) and pd.notna(condition) and condition != 'NaN':\n",
        "                relations.append({\n",
        "                    'type': 'TEST_DIAGNOSES',\n",
        "                    'test': test,\n",
        "                    'condition': condition,\n",
        "                    'row_idx': idx\n",
        "                })\n",
        "\n",
        "            # FINDING_INDICATES_CONDITION relation\n",
        "            if pd.notna(result) and pd.notna(condition) and result != 'NaN' and condition != 'NaN':\n",
        "                relations.append({\n",
        "                    'type': 'FINDING_INDICATES',\n",
        "                    'finding': result,\n",
        "                    'condition': condition,\n",
        "                    'row_idx': idx\n",
        "                })\n",
        "\n",
        "            # FINDING_HAS_SEVERITY relation\n",
        "            if pd.notna(result) and pd.notna(severity) and severity != 'NaN':\n",
        "                relations.append({\n",
        "                    'type': 'FINDING_HAS_SEVERITY',\n",
        "                    'finding': result,\n",
        "                    'severity': severity,\n",
        "                    'row_idx': idx\n",
        "                })\n",
        "\n",
        "            # Temporal relations\n",
        "            temporal_info = row.get('temporal_info')\n",
        "            if temporal_info and pd.notna(test):\n",
        "                relations.append({\n",
        "                    'type': 'TEST_PERFORMED_AT',\n",
        "                    'test': test,\n",
        "                    'time': row['time'],\n",
        "                    'temporal_type': temporal_info.get('type'),\n",
        "                    'row_idx': idx\n",
        "                })\n",
        "\n",
        "        return relations\n",
        "\n",
        "    diagnosis_relations = extract_diagnosis_relations(df_diagnosis)\n",
        "\n",
        "    print(f\"\\nFound {len(diagnosis_relations)} diagnosis relations\")\n",
        "    relation_types = pd.DataFrame(diagnosis_relations)['type'].value_counts()\n",
        "    print(\"\\nRelation type distribution:\")\n",
        "    print(relation_types)\n",
        "\n",
        "    # Sample relations\n",
        "    if diagnosis_relations:\n",
        "        print(\"\\nSample relations:\")\n",
        "        for rel in diagnosis_relations[:10]:\n",
        "            if rel['type'] == 'TEST_REVEALS':\n",
        "                print(f\"  {rel['test']} -> reveals -> {rel['finding']}\")\n",
        "            elif rel['type'] == 'TEST_DIAGNOSES':\n",
        "                print(f\"  {rel['test']} -> diagnoses -> {rel['condition']}\")\n",
        "\n",
        "    # Analyze test-finding patterns\n",
        "    print(\"\\n=== Test-Finding Pattern Analysis ===\")\n",
        "\n",
        "    test_finding_pairs = {}\n",
        "    for rel in diagnosis_relations:\n",
        "        if rel['type'] == 'TEST_REVEALS':\n",
        "            pair = f\"{rel['test']} -> {rel['finding']}\"\n",
        "            test_finding_pairs[pair] = test_finding_pairs.get(pair, 0) + 1\n",
        "\n",
        "    print(\"\\nCommon test-finding patterns:\")\n",
        "    for pair, count in sorted(test_finding_pairs.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
        "        print(f\"  {pair}: {count} occurrences\")\n",
        "\n",
        "    # Coverage analysis\n",
        "    print(\"\\n=== Labeling Function Coverage Analysis ===\")\n",
        "\n",
        "    coverage_results = {}\n",
        "    for lf in diagnosis_lfs:\n",
        "        labeled = sum(1 for _, row in df_diagnosis.iterrows() if lf(row) != 'ABSTAIN')\n",
        "        coverage = (labeled / len(df_diagnosis)) * 100\n",
        "        coverage_results[lf.__name__] = {\n",
        "            'labeled': labeled,\n",
        "            'coverage': coverage\n",
        "        }\n",
        "\n",
        "    print(\"\\nLabeling function coverage:\")\n",
        "    for lf_name, stats in sorted(coverage_results.items(), key=lambda x: x[1]['coverage'], reverse=True):\n",
        "        print(f\"  {lf_name}: {stats['labeled']} labels ({stats['coverage']:.1f}% coverage)\")\n",
        "\n",
        "    # Create diagnostic summary\n",
        "    print(\"\\n=== Diagnostic Summary ===\")\n",
        "\n",
        "    # Test type distribution\n",
        "    if 'TEST_TYPE' in df_custom_diagnosis_entities['label'].values:\n",
        "        test_types = df_custom_diagnosis_entities[\n",
        "            df_custom_diagnosis_entities['label'] == 'TEST_TYPE'\n",
        "        ]['category'].value_counts()\n",
        "        print(\"\\nTest types distribution:\")\n",
        "        print(test_types)\n",
        "\n",
        "    # Finding category distribution\n",
        "    if 'FINDING' in df_custom_diagnosis_entities['label'].values:\n",
        "        finding_categories = df_custom_diagnosis_entities[\n",
        "            df_custom_diagnosis_entities['label'] == 'FINDING'\n",
        "        ]['category'].value_counts()\n",
        "        print(\"\\nFinding categories:\")\n",
        "        print(finding_categories)\n",
        "\n",
        "    # Save results\n",
        "    df_all_diagnosis_entities.to_csv('diagnosis_entities_comprehensive.csv', index=False)\n",
        "    pd.DataFrame(diagnosis_relations).to_csv('diagnosis_relations.csv', index=False)\n",
        "\n",
        "    # Export diagnostic patterns for future use\n",
        "    diagnostic_patterns = {\n",
        "        'common_tests': test_entities['text'].value_counts().head(20).to_dict() if len(test_entities) > 0 else {},\n",
        "        'common_findings': finding_entities['text'].value_counts().head(20).to_dict() if len(finding_entities) > 0 else {},\n",
        "        'test_finding_pairs': test_finding_pairs\n",
        "    }\n",
        "\n",
        "    import json\n",
        "    with open('diagnostic_patterns.json', 'w') as f:\n",
        "        json.dump(diagnostic_patterns, f, indent=2)\n",
        "\n",
        "    print(\"\\n\\nDiagnosis entity extraction and labeling complete!\")\n",
        "    print(f\"Saved {len(df_all_diagnosis_entities)} entities and {len(diagnosis_relations)} relations\")\n",
        "    print(\"Diagnostic patterns exported to diagnostic_patterns.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>source_column</th>\n",
              "      <th>category</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bone marrow edema</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>109.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>Magnetic resonance imaging (MRI) scan performe...</td>\n",
              "      <td>133948.0</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>femoral head necrosis</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>148.0</td>\n",
              "      <td>169.0</td>\n",
              "      <td>Magnetic resonance imaging (MRI) scan performe...</td>\n",
              "      <td>133948.0</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Idiopathic osteonecrosis of the femoral head P...</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>207.0</td>\n",
              "      <td>263.0</td>\n",
              "      <td>Magnetic resonance imaging (MRI) scan performe...</td>\n",
              "      <td>133948.0</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pain</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>284.0</td>\n",
              "      <td>288.0</td>\n",
              "      <td>Magnetic resonance imaging (MRI) scan performe...</td>\n",
              "      <td>133948.0</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fracture</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>84.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>Radiographs performed with Minimally displaced...</td>\n",
              "      <td>80176.0</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311119</th>\n",
              "      <td>Blood cultures</td>\n",
              "      <td>TEST</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Blood cultures performed with nan severity sho...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>diagnostic_test</td>\n",
              "      <td>test_column</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311120</th>\n",
              "      <td>culture</td>\n",
              "      <td>TEST_TYPE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Blood cultures performed with nan severity sho...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>laboratory</td>\n",
              "      <td>pattern_matching</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311121</th>\n",
              "      <td>Transesophageal echocardiogram</td>\n",
              "      <td>TEST</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Transesophageal echocardiogram performed with ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>diagnostic_test</td>\n",
              "      <td>test_column</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311122</th>\n",
              "      <td>Acute severe aortic insufficiency from endocar...</td>\n",
              "      <td>CONDITION</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Transesophageal echocardiogram performed with ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>diagnosis</td>\n",
              "      <td>condition_column</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311123</th>\n",
              "      <td>left</td>\n",
              "      <td>LATERALITY</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Transesophageal echocardiogram performed with ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>laterality</td>\n",
              "      <td>laterality_extraction</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>311124 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text       label  start  \\\n",
              "0                                       bone marrow edema     DISEASE  109.0   \n",
              "1                                   femoral head necrosis     DISEASE  148.0   \n",
              "2       Idiopathic osteonecrosis of the femoral head P...     DISEASE  207.0   \n",
              "3                                                    pain     DISEASE  284.0   \n",
              "4                                                fracture     DISEASE   84.0   \n",
              "...                                                   ...         ...    ...   \n",
              "311119                                     Blood cultures        TEST    NaN   \n",
              "311120                                            culture   TEST_TYPE    NaN   \n",
              "311121                     Transesophageal echocardiogram        TEST    NaN   \n",
              "311122  Acute severe aortic insufficiency from endocar...   CONDITION    NaN   \n",
              "311123                                               left  LATERALITY    NaN   \n",
              "\n",
              "          end                                      original_text   row_idx  \\\n",
              "0       126.0  Magnetic resonance imaging (MRI) scan performe...  133948.0   \n",
              "1       169.0  Magnetic resonance imaging (MRI) scan performe...  133948.0   \n",
              "2       263.0  Magnetic resonance imaging (MRI) scan performe...  133948.0   \n",
              "3       288.0  Magnetic resonance imaging (MRI) scan performe...  133948.0   \n",
              "4        92.0  Radiographs performed with Minimally displaced...   80176.0   \n",
              "...       ...                                                ...       ...   \n",
              "311119    NaN  Blood cultures performed with nan severity sho...       NaN   \n",
              "311120    NaN  Blood cultures performed with nan severity sho...       NaN   \n",
              "311121    NaN  Transesophageal echocardiogram performed with ...       NaN   \n",
              "311122    NaN  Transesophageal echocardiogram performed with ...       NaN   \n",
              "311123    NaN  Transesophageal echocardiogram performed with ...       NaN   \n",
              "\n",
              "        source_column         category                 source  \n",
              "0       combined_text              NaN                    NaN  \n",
              "1       combined_text              NaN                    NaN  \n",
              "2       combined_text              NaN                    NaN  \n",
              "3       combined_text              NaN                    NaN  \n",
              "4       combined_text              NaN                    NaN  \n",
              "...               ...              ...                    ...  \n",
              "311119            NaN  diagnostic_test            test_column  \n",
              "311120            NaN       laboratory       pattern_matching  \n",
              "311121            NaN  diagnostic_test            test_column  \n",
              "311122            NaN        diagnosis       condition_column  \n",
              "311123            NaN       laterality  laterality_extraction  \n",
              "\n",
              "[311124 rows x 9 columns]"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_all_diagnosis_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting Treatments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>has_treatments</th>\n",
              "      <th>name</th>\n",
              "      <th>related condition</th>\n",
              "      <th>dosage</th>\n",
              "      <th>time</th>\n",
              "      <th>frequency</th>\n",
              "      <th>duration</th>\n",
              "      <th>reason for taking</th>\n",
              "      <th>reaction to treatment</th>\n",
              "      <th>details</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155216</td>\n",
              "      <td>True</td>\n",
              "      <td>Olanzapine tablets</td>\n",
              "      <td>Bipolar affective disorder</td>\n",
              "      <td>5 mg per day</td>\n",
              "      <td>Past four months</td>\n",
              "      <td>Daily</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Control of exacerbated mental illness</td>\n",
              "      <td>Pain and discomfort in neck, sustained and abn...</td>\n",
              "      <td>Previously managed with olanzapine tablets in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>155216</td>\n",
              "      <td>True</td>\n",
              "      <td>Trihexyphenidyl</td>\n",
              "      <td>Rigidity in upper limbs</td>\n",
              "      <td>4 mg per day</td>\n",
              "      <td>Brief period of around three weeks</td>\n",
              "      <td>Daily</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Rigidity in upper limbs</td>\n",
              "      <td>Good response</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133948</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80176</td>\n",
              "      <td>True</td>\n",
              "      <td>Closed treatment in a cast</td>\n",
              "      <td>Proximal ulnar shaft fracture</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Initially after the fall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>To treat the ulnar shaft fracture</td>\n",
              "      <td>Developed a hypertrophic nonunion</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>80176</td>\n",
              "      <td>True</td>\n",
              "      <td>Conservative treatment</td>\n",
              "      <td>Ulna nonunion</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Three months after the fall</td>\n",
              "      <td>NaN</td>\n",
              "      <td>An additional three months</td>\n",
              "      <td>To treat the ulna nonunion</td>\n",
              "      <td>Worsening motion through the nonunion site</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50421</th>\n",
              "      <td>98004</td>\n",
              "      <td>True</td>\n",
              "      <td>Hypovolaemic shock treatment</td>\n",
              "      <td>Haemodynamic instability and hypovolaemic shock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>To maintain blood pressure and treat shock</td>\n",
              "      <td>Required large doses of vasopressor and blood ...</td>\n",
              "      <td>Treatment given after becoming haemodynamicall...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50422</th>\n",
              "      <td>133320</td>\n",
              "      <td>True</td>\n",
              "      <td>Systemic chemotherapy</td>\n",
              "      <td>Lung and bone metastases</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>To treat lung and bone metastases</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Using doxorubicin and ifosfamide</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50423</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Rapid sequence intubation</td>\n",
              "      <td>Cardiogenic shock and flash pulmonary edema</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>To manage suspected cardiogenic shock and flas...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50424</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Advanced cardiac life support (ACLS) protocol</td>\n",
              "      <td>Cardiac arrest</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13 min</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>To restore return of spontaneous circulation a...</td>\n",
              "      <td>Return of spontaneous circulation was restored</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50425</th>\n",
              "      <td>97973</td>\n",
              "      <td>True</td>\n",
              "      <td>Intravenous nafcillin</td>\n",
              "      <td>Endocarditis</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Postoperative</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>To treat S.\\nlugdunensis infection</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Patient was discharged home on intravenous naf...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50426 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          idx  has_treatments                                           name  \\\n",
              "0      155216            True                             Olanzapine tablets   \n",
              "1      155216            True                                Trihexyphenidyl   \n",
              "2      133948           False                                            NaN   \n",
              "3       80176            True                     Closed treatment in a cast   \n",
              "4       80176            True                         Conservative treatment   \n",
              "...       ...             ...                                            ...   \n",
              "50421   98004            True                   Hypovolaemic shock treatment   \n",
              "50422  133320            True                          Systemic chemotherapy   \n",
              "50423   97973            True                      Rapid sequence intubation   \n",
              "50424   97973            True  Advanced cardiac life support (ACLS) protocol   \n",
              "50425   97973            True                          Intravenous nafcillin   \n",
              "\n",
              "                                     related condition        dosage  \\\n",
              "0                           Bipolar affective disorder  5 mg per day   \n",
              "1                              Rigidity in upper limbs  4 mg per day   \n",
              "2                                                  NaN           NaN   \n",
              "3                        Proximal ulnar shaft fracture           NaN   \n",
              "4                                        Ulna nonunion           NaN   \n",
              "...                                                ...           ...   \n",
              "50421  Haemodynamic instability and hypovolaemic shock           NaN   \n",
              "50422                         Lung and bone metastases           NaN   \n",
              "50423      Cardiogenic shock and flash pulmonary edema           NaN   \n",
              "50424                                   Cardiac arrest           NaN   \n",
              "50425                                     Endocarditis           NaN   \n",
              "\n",
              "                                     time frequency  \\\n",
              "0                        Past four months     Daily   \n",
              "1      Brief period of around three weeks     Daily   \n",
              "2                                     NaN       NaN   \n",
              "3                Initially after the fall       NaN   \n",
              "4             Three months after the fall       NaN   \n",
              "...                                   ...       ...   \n",
              "50421                                 NaN       NaN   \n",
              "50422                                 NaN       NaN   \n",
              "50423                                 NaN       NaN   \n",
              "50424                              13 min       NaN   \n",
              "50425                       Postoperative       NaN   \n",
              "\n",
              "                         duration  \\\n",
              "0                             NaN   \n",
              "1                             NaN   \n",
              "2                             NaN   \n",
              "3                             NaN   \n",
              "4      An additional three months   \n",
              "...                           ...   \n",
              "50421                         NaN   \n",
              "50422                         NaN   \n",
              "50423                         NaN   \n",
              "50424                         NaN   \n",
              "50425                         NaN   \n",
              "\n",
              "                                       reason for taking  \\\n",
              "0                  Control of exacerbated mental illness   \n",
              "1                                Rigidity in upper limbs   \n",
              "2                                                    NaN   \n",
              "3                      To treat the ulnar shaft fracture   \n",
              "4                             To treat the ulna nonunion   \n",
              "...                                                  ...   \n",
              "50421         To maintain blood pressure and treat shock   \n",
              "50422                  To treat lung and bone metastases   \n",
              "50423  To manage suspected cardiogenic shock and flas...   \n",
              "50424  To restore return of spontaneous circulation a...   \n",
              "50425                 To treat S.\\nlugdunensis infection   \n",
              "\n",
              "                                   reaction to treatment  \\\n",
              "0      Pain and discomfort in neck, sustained and abn...   \n",
              "1                                          Good response   \n",
              "2                                                    NaN   \n",
              "3                      Developed a hypertrophic nonunion   \n",
              "4             Worsening motion through the nonunion site   \n",
              "...                                                  ...   \n",
              "50421  Required large doses of vasopressor and blood ...   \n",
              "50422                                                NaN   \n",
              "50423                                                NaN   \n",
              "50424     Return of spontaneous circulation was restored   \n",
              "50425                                                NaN   \n",
              "\n",
              "                                                 details  \n",
              "0      Previously managed with olanzapine tablets in ...  \n",
              "1                                                    NaN  \n",
              "2                                                    NaN  \n",
              "3                                                    NaN  \n",
              "4                                                    NaN  \n",
              "...                                                  ...  \n",
              "50421  Treatment given after becoming haemodynamicall...  \n",
              "50422                   Using doxorubicin and ifosfamide  \n",
              "50423                                                NaN  \n",
              "50424                                                NaN  \n",
              "50425  Patient was discharged home on intravenous naf...  \n",
              "\n",
              "[50426 rows x 11 columns]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_treatments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_treatment_text(row):\n",
        "    \"\"\"Create comprehensive text from treatment row\"\"\"\n",
        "    parts = []\n",
        "    \n",
        "    if pd.notna(row.get('name')) and str(row['name']) != 'NaN':\n",
        "        parts.append(f\"Treatment: {row['name']}\")\n",
        "    \n",
        "    if pd.notna(row.get('related condition')) and str(row['related condition']) != 'NaN':\n",
        "        parts.append(f\"for {row['related condition']}\")\n",
        "    \n",
        "    if pd.notna(row.get('dosage')) and str(row['dosage']) != 'NaN':\n",
        "        parts.append(f\"dosage {row['dosage']}\")\n",
        "    \n",
        "    if pd.notna(row.get('frequency')) and str(row['frequency']) != 'NaN':\n",
        "        parts.append(f\"frequency {row['frequency']}\")\n",
        "    \n",
        "    if pd.notna(row.get('time')) and str(row['time']) != 'NaN':\n",
        "        parts.append(f\"time {row['time']}\")\n",
        "    \n",
        "    if pd.notna(row.get('duration')) and str(row['duration']) != 'NaN':\n",
        "        parts.append(f\"duration {row['duration']}\")\n",
        "    \n",
        "    if pd.notna(row.get('reason for taking')) and str(row['reason for taking']) != 'NaN':\n",
        "        parts.append(f\"reason: {row['reason for taking']}\")\n",
        "    \n",
        "    if pd.notna(row.get('reaction to treatment')) and str(row['reaction to treatment']) != 'NaN':\n",
        "        parts.append(f\"reaction: {row['reaction to treatment']}\")\n",
        "    \n",
        "    if pd.notna(row.get('details')) and str(row['details']) != 'NaN':\n",
        "        parts.append(f\"details: {row['details']}\")\n",
        "    \n",
        "    return \" \".join(parts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing temporal column: time\n",
            "\n",
            "Processing temporal column: duration\n",
            "\n",
            "Temporal extraction results:\n",
            "Duration extracted from 'time' column: 5037 rows\n",
            "Temporal types: {'unspecified': 6645, 'post_event': 5777, 'range_reference': 2315, 'past_reference': 2193, 'onset_reference': 2007, 'absolute_date': 1267, 'duration_reference': 914}\n",
            "Loading en_ner_bc5cdr_md...\n",
            "Model loaded. Active pipes: ['tok2vec', 'ner']\n",
            "Stamping row identifier from column: 'idx'\n",
            "Processing 50426 texts in 169 batches...\n",
            "Using model: en_ner_bc5cdr_md for column: combined_text\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   1%|          | 1/169 [00:02<06:22,  2.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:   7%|▋         | 11/169 [00:15<03:36,  1.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 3000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  12%|█▏        | 21/169 [00:28<03:24,  1.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 6000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  18%|█▊        | 31/169 [00:42<03:12,  1.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 9000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  24%|██▍       | 41/169 [00:55<02:57,  1.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 12000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  30%|███       | 51/169 [01:08<02:41,  1.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 15000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  36%|███▌      | 61/169 [01:21<02:25,  1.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 18000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  42%|████▏     | 71/169 [01:34<02:18,  1.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 21000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  48%|████▊     | 81/169 [01:47<02:03,  1.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 24000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  54%|█████▍    | 91/169 [02:00<01:51,  1.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 27000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  60%|█████▉    | 101/169 [02:14<01:39,  1.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 30000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  66%|██████▌   | 111/169 [02:27<01:23,  1.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 33000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  72%|███████▏  | 121/169 [02:40<01:10,  1.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 36000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  78%|███████▊  | 131/169 [02:53<00:56,  1.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 39000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  83%|████████▎ | 141/169 [03:07<00:42,  1.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 42000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  89%|████████▉ | 151/169 [03:21<00:27,  1.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 45000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches:  95%|█████████▌| 161/169 [03:34<00:12,  1.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checkpoint saved at batch 48000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 169/169 [03:43<00:00,  1.32s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3696 entities appearing >= 5 times\n",
            "\n",
            "=== BC5CDR Entity Types Found ===\n",
            "{'DISEASE': 80940, 'CHEMICAL': 37907}\n",
            "\n",
            "=== CUSTOM SYMPTOM ENTITY EXTRACTION ===\n",
            "\n",
            "=== COMBINED Entity Distribution ===\n",
            "label\n",
            "DISEASE               80940\n",
            "TREATMENT             44086\n",
            "CONDITION             43157\n",
            "CHEMICAL              37907\n",
            "TREATMENT_TYPE        23652\n",
            "ROUTE                 18590\n",
            "TREATMENT_REASON      16765\n",
            "CONDITION_TYPE        13410\n",
            "DOSAGE                12320\n",
            "TEMPORAL_PATTERN      12264\n",
            "TREATMENT_RESPONSE     7463\n",
            "FREQUENCY              6705\n",
            "MEDICATION             1921\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Treatments ===\n",
            "text\n",
            "Antibiotics                502\n",
            "Chemotherapy               499\n",
            "Surgery                    272\n",
            "Conservative treatment     271\n",
            "Aspirin                    268\n",
            "Surgical excision          263\n",
            "Blood transfusion          251\n",
            "Conservative management    244\n",
            "Prednisone                 206\n",
            "Surgical resection         170\n",
            "Intravenous antibiotics    159\n",
            "Radiotherapy               153\n",
            "Adjuvant chemotherapy      149\n",
            "Prednisolone               146\n",
            "Dexamethasone              137\n",
            "Radiation therapy          133\n",
            "Warfarin                   133\n",
            "Surgical treatment         131\n",
            "Surgical intervention      131\n",
            "Intubation                 120\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Medications ===\n",
            "text\n",
            "vancomycin         326\n",
            "ceftriaxone        263\n",
            "amoxicillin        199\n",
            "ibuprofen          127\n",
            "acetaminophen      120\n",
            "risperidone        103\n",
            "morphine            98\n",
            "olanzapine          97\n",
            "penicillin          92\n",
            "vasopressor         81\n",
            "haloperidol         71\n",
            "fentanyl            64\n",
            "quetiapine          63\n",
            "oxycodone           45\n",
            "clozapine           40\n",
            "baclofen            33\n",
            "beta blocker        32\n",
            "inotrope            23\n",
            "trihexyphenidyl     17\n",
            "ace inhibitor       15\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Top Conditions Treated ===\n",
            "text\n",
            "Hypertension            419\n",
            "Pain management         112\n",
            "Hypotension             111\n",
            "Seizures                109\n",
            "Breast cancer           108\n",
            "Infection               108\n",
            "Respiratory distress    102\n",
            "Epilepsy                102\n",
            "Cardiac arrest           99\n",
            "Postoperative care       92\n",
            "Atrial fibrillation      90\n",
            "Schizophrenia            90\n",
            "Suspected infection      84\n",
            "Anemia                   84\n",
            "Hypothyroidism           74\n",
            "Abdominal pain           74\n",
            "Septic shock             73\n",
            "Pneumonia                69\n",
            "Metastatic melanoma      69\n",
            "Headache                 66\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Dosage Distribution ===\n",
            "text\n",
            "daily      1088\n",
            "/day        939\n",
            "10 mg       531\n",
            "500 mg      506\n",
            "100 mg      505\n",
            "50 mg       466\n",
            "5 mg        435\n",
            "20 mg       393\n",
            "40 mg       340\n",
            "per day     333\n",
            "1 mg        286\n",
            "200 mg      275\n",
            "400 mg      266\n",
            "60 mg       230\n",
            "300 mg      219\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Treatment Response Distribution ===\n",
            "category\n",
            "positive    3402\n",
            "neutral     2262\n",
            "negative    1615\n",
            "partial      184\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Treatment Type Distribution ===\n",
            "category\n",
            "procedure       11834\n",
            "medication       3602\n",
            "chemotherapy     3338\n",
            "supportive       2558\n",
            "conservative      933\n",
            "emergency         905\n",
            "diagnostic        482\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Creating Treatment-Specific Labeling Functions ===\n",
            "\n",
            "Testing treatment labeling functions:\n",
            "\n",
            "Row 0: Olanzapine tablets for Bipolar affective disorder\n",
            "  lf_has_treatment: HAS_TREATMENT\n",
            "  lf_medication_treatment: MEDICATION_TREATMENT\n",
            "  lf_psychiatric_treatment: PSYCHIATRIC_TREATMENT\n",
            "  lf_chronic_treatment: CHRONIC_TREATMENT\n",
            "  lf_daily_medication: DAILY_MEDICATION\n",
            "\n",
            "Row 1: Trihexyphenidyl for Rigidity in upper limbs\n",
            "  lf_has_treatment: HAS_TREATMENT\n",
            "  lf_medication_treatment: MEDICATION_TREATMENT\n",
            "  lf_psychiatric_treatment: PSYCHIATRIC_TREATMENT\n",
            "  lf_daily_medication: DAILY_MEDICATION\n",
            "  lf_positive_response: POSITIVE_RESPONSE\n",
            "\n",
            "Row 2: nan for nan\n",
            "  lf_has_treatment: NO_TREATMENT\n",
            "\n",
            "Row 3: Closed treatment in a cast for Proximal ulnar shaft fracture\n",
            "  lf_has_treatment: HAS_TREATMENT\n",
            "  lf_conservative_treatment: CONSERVATIVE_TREATMENT\n",
            "\n",
            "Row 4: Conservative treatment for Ulna nonunion\n",
            "  lf_has_treatment: HAS_TREATMENT\n",
            "  lf_chronic_treatment: CHRONIC_TREATMENT\n",
            "  lf_conservative_treatment: CONSERVATIVE_TREATMENT\n",
            "  lf_treatment_duration: LONG_TERM_TREATMENT\n",
            "\n",
            "Row 5: Diclofenac sodium for Bone marrow edema\n",
            "  lf_has_treatment: HAS_TREATMENT\n",
            "  lf_medication_treatment: MEDICATION_TREATMENT\n",
            "  lf_daily_medication: DAILY_MEDICATION\n",
            "  lf_positive_response: POSITIVE_RESPONSE\n",
            "\n",
            "Row 6: NSAIDs and physiotherapy for Bone marrow edema\n",
            "  lf_has_treatment: HAS_TREATMENT\n",
            "  lf_chronic_treatment: CHRONIC_TREATMENT\n",
            "\n",
            "Row 7: Conservative treatment for Bone marrow edema\n",
            "  lf_has_treatment: HAS_TREATMENT\n",
            "  lf_conservative_treatment: CONSERVATIVE_TREATMENT\n",
            "\n",
            "Row 8: Calcium and vitamin D for Osteomalacia\n",
            "  lf_has_treatment: HAS_TREATMENT\n",
            "\n",
            "Row 9: Calcitriol for Osteomalacia\n",
            "  lf_has_treatment: HAS_TREATMENT\n",
            "  lf_medication_treatment: MEDICATION_TREATMENT\n",
            "\n",
            "=== Extracting Treatment Relations ===\n",
            "Found 152806 treatment relations\n",
            "\n",
            "Relation type distribution:\n",
            "type\n",
            "TREATMENT_FOR_CONDITION       42750\n",
            "TREATMENT_HAS_REASON          41924\n",
            "TREATMENT_HAS_RESPONSE        21548\n",
            "TREATMENT_TEMPORAL_PATTERN    21101\n",
            "TREATMENT_HAS_DOSAGE          11968\n",
            "TREATMENT_HAS_FREQUENCY        9343\n",
            "TREATMENT_HAS_DURATION         4172\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sample relations:\n",
            "  Olanzapine tablets -> treats -> Bipolar affective disorder\n",
            "  Olanzapine tablets -> dosage -> 5 mg per day\n",
            "  Olanzapine tablets -> response -> Pain and discomfort in neck, sustained and abnormal contraction of neck muscles, requiring assistance in daily chores\n",
            "  Trihexyphenidyl -> treats -> Rigidity in upper limbs\n",
            "  Trihexyphenidyl -> dosage -> 4 mg per day\n",
            "  Trihexyphenidyl -> response -> Good response\n",
            "\n",
            "=== Labeling Function Coverage Analysis ===\n",
            "\n",
            "Labeling function coverage:\n",
            "  lf_has_treatment: 50426 labels (100.0% coverage)\n",
            "  lf_medication_treatment: 8350 labels (16.6% coverage)\n",
            "  lf_cancer_treatment: 4864 labels (9.6% coverage)\n",
            "  lf_surgical_treatment: 4502 labels (8.9% coverage)\n",
            "  lf_infection_treatment: 4194 labels (8.3% coverage)\n",
            "  lf_treatment_duration: 4173 labels (8.3% coverage)\n",
            "  lf_chronic_treatment: 3880 labels (7.7% coverage)\n",
            "  lf_daily_medication: 3569 labels (7.1% coverage)\n",
            "  lf_positive_response: 3336 labels (6.6% coverage)\n",
            "  lf_emergency_treatment: 1377 labels (2.7% coverage)\n",
            "  lf_cardiovascular_treatment: 1197 labels (2.4% coverage)\n",
            "  lf_conservative_treatment: 736 labels (1.5% coverage)\n",
            "  lf_psychiatric_treatment: 733 labels (1.5% coverage)\n",
            "\n",
            "=== Additional Treatment Analysis ===\n",
            "\n",
            "Has treatments distribution:\n",
            "has_treatments\n",
            "True     44790\n",
            "False     5636\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Frequency Distribution ===\n",
            "text\n",
            "daily           3367\n",
            "every           1064\n",
            "once             771\n",
            "twice daily      585\n",
            "three times      343\n",
            "continuous       208\n",
            "as needed        164\n",
            "bid               92\n",
            "intermittent      52\n",
            "tid               35\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Route of Administration ===\n",
            "text\n",
            "iv               6823\n",
            "im               4937\n",
            "intravenous      2817\n",
            "oral             2738\n",
            "topical           520\n",
            "nasal             229\n",
            "subcutaneous      221\n",
            "intramuscular     160\n",
            "inhaled            94\n",
            "rectal             51\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n",
            "Treatment entity extraction and labeling complete!\n",
            "Saved 319180 entities and 152806 relations\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Use the global TemporalStandardizer class \n",
        "    temporal_standardizer = TemporalStandardizer()\n",
        "\n",
        "    # Process temporal information using the standardize_temporal_column method\n",
        "    df_treatments_processed, temporal_report = temporal_standardizer.standardize_temporal_column(\n",
        "        df_treatments, \n",
        "        'time'\n",
        "    )\n",
        "    \n",
        "    # Process duration column as well\n",
        "    df_treatments_processed, duration_report = temporal_standardizer.standardize_temporal_column(\n",
        "        df_treatments_processed, \n",
        "        'duration'\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTemporal extraction results:\")\n",
        "    print(f\"Duration extracted from 'time' column: {temporal_report['extracted_durations']} rows\")\n",
        "    print(f\"Temporal types: {temporal_report['temporal_types']}\")\n",
        "\n",
        "    # Combine treatments information into comprehensive text\n",
        "    df_treatments_processed['combined_text'] = df_treatments_processed.apply(\n",
        "        lambda row: create_treatment_text(row),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Run NER extraction with BC5CDR\n",
        "    df_treatments_entities, treatments_summary, treatments_rules = run_medical_ner_extraction(\n",
        "        df_treatments_processed,\n",
        "        text_column='combined_text',\n",
        "        model_name=\"en_ner_bc5cdr_md\",\n",
        "        batch_size=300,\n",
        "        id_column='idx'\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== BC5CDR Entity Types Found ===\")\n",
        "    print(treatments_summary['entity_types'])\n",
        "\n",
        "    # Custom entity extraction for symptoms-specific entities\n",
        "    print(\"\\n=== CUSTOM SYMPTOM ENTITY EXTRACTION ===\")\n",
        "\n",
        "    def extract_treatment_entities_custom(df_treatments):\n",
        "        \"\"\"Extract treatment-specific entities not caught by BC5CDR\"\"\"\n",
        "        \n",
        "        custom_entities = []\n",
        "        \n",
        "        # Treatment type patterns - adapted for treatments\n",
        "        treatment_type_patterns = {\n",
        "            'medication': ['tablet', 'tablets', 'pill', 'pills', 'capsule', 'injection', 'infusion', 'medication', 'drug'],\n",
        "            'procedure': ['surgery', 'surgical', 'operation', 'procedure', 'therapy', 'intubation', 'resection', 'removal'],\n",
        "            'supportive': ['support', 'life support', 'ventilation', 'oxygen', 'fluid', 'nutrition', 'acls', 'protocol'],\n",
        "            'chemotherapy': ['chemotherapy', 'chemo', 'cytotoxic', 'antineoplastic', 'systemic chemotherapy'],\n",
        "            'conservative': ['conservative', 'non-operative', 'non-surgical', 'observation', 'closed treatment'],\n",
        "            'emergency': ['emergency', 'urgent', 'rapid', 'resuscitation', 'life-saving'],\n",
        "            'diagnostic': ['biopsy', 'exploration', 'diagnostic', 'assessment']\n",
        "        }\n",
        "        \n",
        "        # Drug/medication patterns - specific medications found in treatments\n",
        "        medication_patterns = {\n",
        "            'antipsychotic': ['olanzapine', 'risperidone', 'quetiapine', 'haloperidol', 'clozapine'],\n",
        "            'muscle_relaxant': ['trihexyphenidyl', 'baclofen', 'tizanidine', 'cyclobenzaprine'],\n",
        "            'antibiotic': ['nafcillin', 'vancomycin', 'ceftriaxone', 'penicillin', 'amoxicillin'],\n",
        "            'cardiovascular': ['vasopressor', 'inotrope', 'beta blocker', 'ace inhibitor', 'hypovolaemic'],\n",
        "            'analgesic': ['morphine', 'fentanyl', 'oxycodone', 'acetaminophen', 'ibuprofen']\n",
        "        }\n",
        "        \n",
        "        # Medical condition patterns - conditions being treated\n",
        "        condition_patterns = {\n",
        "            'psychiatric': ['bipolar', 'affective disorder', 'psychosis', 'mania', 'depression', 'mental illness'],\n",
        "            'orthopedic': ['fracture', 'joint', 'bone', 'hip', 'knee', 'spine', 'ulnar shaft'],\n",
        "            'cardiovascular': ['cardiac', 'heart', 'arrhythmia', 'shock', 'arrest', 'hypovolaemic', 'endocarditis'],\n",
        "            'oncological': ['cancer', 'metastases', 'tumor', 'malignancy', 'carcinoma'],\n",
        "            'neurological': ['rigidity', 'tremor', 'paralysis', 'nerve', 'neurological'],\n",
        "            'infectious': ['infection', 'sepsis', 'endocarditis', 'abscess', 'pneumonia']\n",
        "        }\n",
        "        \n",
        "        # Dosage unit patterns\n",
        "        dosage_patterns = {\n",
        "            'mg': r'(\\d+\\.?\\d*)\\s*mg',\n",
        "            'mcg': r'(\\d+\\.?\\d*)\\s*mcg',\n",
        "            'units': r'(\\d+\\.?\\d*)\\s*units?',\n",
        "            'ml': r'(\\d+\\.?\\d*)\\s*ml',\n",
        "            'per_day': r'per\\s*day|/day|daily',\n",
        "            'min': r'(\\d+\\.?\\d*)\\s*min(?:utes?)?'\n",
        "        }\n",
        "        \n",
        "        # Frequency patterns\n",
        "        frequency_patterns = ['daily', 'twice daily', 'three times', 'qid', 'bid', 'tid', 'prn', \n",
        "                             'as needed', 'every', 'once', 'continuous', 'intermittent']\n",
        "        \n",
        "        # Route of administration patterns\n",
        "        route_patterns = ['oral', 'intravenous', 'iv', 'im', 'intramuscular', 'subcutaneous', \n",
        "                         'topical', 'inhaled', 'nasal', 'rectal']\n",
        "        \n",
        "        # Treatment response/outcome patterns\n",
        "        response_patterns = {\n",
        "            'positive': ['good response', 'improved', 'resolved', 'successful', 'effective', \n",
        "                        'restored', 'return of', 'recovered'],\n",
        "            'negative': ['worsening', 'failed', 'no response', 'adverse', 'side effect', \n",
        "                        'complication', 'deterioration'],\n",
        "            'neutral': ['no change', 'stable', 'maintained', 'sustained', 'continued'],\n",
        "            'partial': ['partial response', 'some improvement', 'limited response']\n",
        "        }\n",
        "        \n",
        "        # Temporal patterns specific to treatments\n",
        "        temporal_patterns = {\n",
        "            'acute': ['acute', 'sudden', 'rapid', 'emergency', 'immediate'],\n",
        "            'chronic': ['chronic', 'long-term', 'maintenance', 'ongoing', 'continuous'],\n",
        "            'perioperative': ['preoperative', 'postoperative', 'intraoperative', 'perioperative'],\n",
        "            'duration': ['months', 'weeks', 'days', 'hours', 'years']\n",
        "        }\n",
        "        \n",
        "        # Process each row\n",
        "        for idx, row in df_treatments.iterrows():\n",
        "            # Get relevant text fields with safe string conversion\n",
        "            name = str(row.get('name', '')).lower() if pd.notna(row.get('name')) else ''\n",
        "            condition = str(row.get('related condition', '')).lower() if pd.notna(row.get('related condition')) else ''\n",
        "            dosage = str(row.get('dosage', '')).lower() if pd.notna(row.get('dosage')) else ''\n",
        "            frequency = str(row.get('frequency', '')).lower() if pd.notna(row.get('frequency')) else ''\n",
        "            time = str(row.get('time', '')).lower() if pd.notna(row.get('time')) else ''\n",
        "            duration = str(row.get('duration', '')).lower() if pd.notna(row.get('duration')) else ''\n",
        "            reason = str(row.get('reason for taking', '')).lower() if pd.notna(row.get('reason for taking')) else ''\n",
        "            reaction = str(row.get('reaction to treatment', '')).lower() if pd.notna(row.get('reaction to treatment')) else ''\n",
        "            details = str(row.get('details', '')).lower() if pd.notna(row.get('details')) else ''\n",
        "            combined = str(row.get('combined_text', '')).lower() if 'combined_text' in row else ''\n",
        "            \n",
        "            # Extract treatment name as primary entity\n",
        "            if name and name != 'nan':\n",
        "                custom_entities.append({\n",
        "                    'text': row['name'],\n",
        "                    'label': 'TREATMENT',\n",
        "                    'category': 'primary_treatment',\n",
        "                    'start': 0,\n",
        "                    'end': len(row['name']),\n",
        "                    'original_text': combined if combined else row['name'],\n",
        "                    'source': 'name_column',\n",
        "                    'row_idx': idx\n",
        "                })\n",
        "            \n",
        "            # Extract condition as entity\n",
        "            if condition and condition != 'nan':\n",
        "                custom_entities.append({\n",
        "                    'text': row['related condition'],\n",
        "                    'label': 'CONDITION',\n",
        "                    'category': 'treatment_indication',\n",
        "                    'start': combined.find(condition) if condition in combined else 0,\n",
        "                    'end': (combined.find(condition) + len(condition)) if condition in combined else len(condition),\n",
        "                    'original_text': combined if combined else row['related condition'],\n",
        "                    'source': 'condition_column',\n",
        "                    'row_idx': idx\n",
        "                })\n",
        "            \n",
        "            # Extract treatment types\n",
        "            for category, terms in treatment_type_patterns.items():\n",
        "                for term in terms:\n",
        "                    if term in name or term in details:\n",
        "                        text_source = name if term in name else details\n",
        "                        start = text_source.find(term)\n",
        "                        custom_entities.append({\n",
        "                            'text': term,\n",
        "                            'label': 'TREATMENT_TYPE',\n",
        "                            'category': category,\n",
        "                            'start': start,\n",
        "                            'end': start + len(term),\n",
        "                            'original_text': combined if combined else text_source,\n",
        "                            'source': 'pattern_matching',\n",
        "                            'row_idx': idx\n",
        "                        })\n",
        "            \n",
        "            # Extract specific medications\n",
        "            for drug_class, drugs in medication_patterns.items():\n",
        "                for drug in drugs:\n",
        "                    if drug in name.lower():\n",
        "                        start = name.lower().find(drug)\n",
        "                        custom_entities.append({\n",
        "                            'text': drug,\n",
        "                            'label': 'MEDICATION',\n",
        "                            'category': drug_class,\n",
        "                            'start': start,\n",
        "                            'end': start + len(drug),\n",
        "                            'original_text': name,\n",
        "                            'source': 'medication_pattern',\n",
        "                            'row_idx': idx\n",
        "                        })\n",
        "            \n",
        "            # Extract dosage information with regex\n",
        "            if dosage and dosage != 'nan':\n",
        "                for unit, pattern in dosage_patterns.items():\n",
        "                    matches = re.finditer(pattern, dosage, re.IGNORECASE)\n",
        "                    for match in matches:\n",
        "                        custom_entities.append({\n",
        "                            'text': match.group(0),\n",
        "                            'label': 'DOSAGE',\n",
        "                            'category': unit,\n",
        "                            'start': match.start(),\n",
        "                            'end': match.end(),\n",
        "                            'original_text': dosage,\n",
        "                            'source': 'dosage_column',\n",
        "                            'row_idx': idx\n",
        "                        })\n",
        "            \n",
        "            # Extract frequency\n",
        "            if frequency and frequency != 'nan':\n",
        "                for freq_term in frequency_patterns:\n",
        "                    if freq_term in frequency:\n",
        "                        start = frequency.find(freq_term)\n",
        "                        custom_entities.append({\n",
        "                            'text': freq_term,\n",
        "                            'label': 'FREQUENCY',\n",
        "                            'category': 'dosing_frequency',\n",
        "                            'start': start,\n",
        "                            'end': start + len(freq_term),\n",
        "                            'original_text': frequency,\n",
        "                            'source': 'frequency_column',\n",
        "                            'row_idx': idx\n",
        "                        })\n",
        "            \n",
        "            # Extract route of administration\n",
        "            all_text = ' '.join([name, dosage, details])\n",
        "            for route in route_patterns:\n",
        "                if route in all_text:\n",
        "                    start = all_text.find(route)\n",
        "                    custom_entities.append({\n",
        "                        'text': route,\n",
        "                        'label': 'ROUTE',\n",
        "                        'category': 'administration_route',\n",
        "                        'start': start,\n",
        "                        'end': start + len(route),\n",
        "                        'original_text': all_text,\n",
        "                        'source': 'route_extraction',\n",
        "                        'row_idx': idx\n",
        "                    })\n",
        "            \n",
        "            # Extract treatment response/outcome\n",
        "            response_text = ' '.join([reaction, details])\n",
        "            for response_type, patterns in response_patterns.items():\n",
        "                for pattern in patterns:\n",
        "                    if pattern in response_text:\n",
        "                        start = response_text.find(pattern)\n",
        "                        custom_entities.append({\n",
        "                            'text': pattern,\n",
        "                            'label': 'TREATMENT_RESPONSE',\n",
        "                            'category': response_type,\n",
        "                            'start': start,\n",
        "                            'end': start + len(pattern),\n",
        "                            'original_text': response_text,\n",
        "                            'source': 'response_extraction',\n",
        "                            'row_idx': idx\n",
        "                        })\n",
        "            \n",
        "            # Extract condition categories\n",
        "            for condition_type, condition_terms in condition_patterns.items():\n",
        "                for term in condition_terms:\n",
        "                    if term in condition or term in reason:\n",
        "                        text_source = condition if term in condition else reason\n",
        "                        start = text_source.find(term)\n",
        "                        custom_entities.append({\n",
        "                            'text': term,\n",
        "                            'label': 'CONDITION_TYPE',\n",
        "                            'category': condition_type,\n",
        "                            'start': start,\n",
        "                            'end': start + len(term),\n",
        "                            'original_text': text_source,\n",
        "                            'source': 'condition_pattern',\n",
        "                            'row_idx': idx\n",
        "                        })\n",
        "            \n",
        "            # Extract temporal patterns\n",
        "            temporal_text = ' '.join([time, duration, details])\n",
        "            for temp_category, temp_terms in temporal_patterns.items():\n",
        "                for term in temp_terms:\n",
        "                    if term in temporal_text:\n",
        "                        start = temporal_text.find(term)\n",
        "                        custom_entities.append({\n",
        "                            'text': term,\n",
        "                            'label': 'TEMPORAL_PATTERN',\n",
        "                            'category': temp_category,\n",
        "                            'start': start,\n",
        "                            'end': start + len(term),\n",
        "                            'original_text': temporal_text,\n",
        "                            'source': 'temporal_extraction',\n",
        "                            'row_idx': idx\n",
        "                        })\n",
        "            \n",
        "            # Extract specific treatment reasons\n",
        "            if reason and reason != 'nan':\n",
        "                # Look for \"to treat\", \"to manage\", \"control of\" patterns\n",
        "                reason_patterns = [\n",
        "                    (r'to\\s+treat\\s+(\\w+(?:\\s+\\w+)*)', 'treatment_goal'),\n",
        "                    (r'to\\s+manage\\s+(\\w+(?:\\s+\\w+)*)', 'management_goal'),\n",
        "                    (r'control\\s+of\\s+(\\w+(?:\\s+\\w+)*)', 'control_goal'),\n",
        "                    (r'for\\s+(\\w+(?:\\s+\\w+)*)', 'indication')\n",
        "                ]\n",
        "                \n",
        "                for pattern, category in reason_patterns:\n",
        "                    matches = re.finditer(pattern, reason, re.IGNORECASE)\n",
        "                    for match in matches:\n",
        "                        custom_entities.append({\n",
        "                            'text': match.group(0),\n",
        "                            'label': 'TREATMENT_REASON',\n",
        "                            'category': category,\n",
        "                            'start': match.start(),\n",
        "                            'end': match.end(),\n",
        "                            'original_text': reason,\n",
        "                            'source': 'reason_column',\n",
        "                            'row_idx': idx\n",
        "                        })\n",
        "        \n",
        "        return pd.DataFrame(custom_entities)\n",
        "    # Extract custom entities\n",
        "    df_custom_treatments_entities = extract_treatment_entities_custom(df_treatments_processed)\n",
        "\n",
        "\n",
        "    # Combine all entities\n",
        "    df_all_treatments_entities = pd.concat([\n",
        "        df_treatments_entities,\n",
        "        df_custom_treatments_entities\n",
        "    ], ignore_index=True)\n",
        "\n",
        "    print(f\"\\n=== COMBINED Entity Distribution ===\")\n",
        "    print(df_all_treatments_entities['label'].value_counts())\n",
        "\n",
        "# Analyze treatment entities\n",
        "    treatment_entities = df_all_treatments_entities[df_all_treatments_entities['label'] == 'TREATMENT']\n",
        "    if len(treatment_entities) > 0:\n",
        "        print(f\"\\n=== Top Treatments ===\")\n",
        "        print(treatment_entities['text'].value_counts().head(20))\n",
        "\n",
        "    # Analyze medications\n",
        "    medication_entities = df_all_treatments_entities[df_all_treatments_entities['label'] == 'MEDICATION']\n",
        "    if len(medication_entities) > 0:\n",
        "        print(f\"\\n=== Top Medications ===\")\n",
        "        print(medication_entities['text'].value_counts().head(20))\n",
        "\n",
        "    # Analyze conditions being treated\n",
        "    condition_entities = df_all_treatments_entities[df_all_treatments_entities['label'] == 'CONDITION']\n",
        "    if len(condition_entities) > 0:\n",
        "        print(f\"\\n=== Top Conditions Treated ===\")\n",
        "        print(condition_entities['text'].value_counts().head(20))\n",
        "\n",
        "    # Analyze dosages\n",
        "    dosage_entities = df_all_treatments_entities[df_all_treatments_entities['label'] == 'DOSAGE']\n",
        "    if len(dosage_entities) > 0:\n",
        "        print(f\"\\n=== Dosage Distribution ===\")\n",
        "        print(dosage_entities['text'].value_counts().head(15))\n",
        "\n",
        "    # Analyze treatment responses\n",
        "    response_entities = df_all_treatments_entities[df_all_treatments_entities['label'] == 'TREATMENT_RESPONSE']\n",
        "    if len(response_entities) > 0:\n",
        "        print(f\"\\n=== Treatment Response Distribution ===\")\n",
        "        print(response_entities['category'].value_counts())\n",
        "\n",
        "    # Analyze treatment types\n",
        "    treatment_type_entities = df_all_treatments_entities[df_all_treatments_entities['label'] == 'TREATMENT_TYPE']\n",
        "    if len(treatment_type_entities) > 0:\n",
        "        print(f\"\\n=== Treatment Type Distribution ===\")\n",
        "        print(treatment_type_entities['category'].value_counts())\n",
        "\n",
        "    # Create treatment-specific labeling functions\n",
        "    print(\"\\n=== Creating Treatment-Specific Labeling Functions ===\")\n",
        "\n",
        "    def create_treatment_labeling_functions():\n",
        "        \"\"\"Create labeling functions for treatment patterns\"\"\"\n",
        "\n",
        "        def lf_has_treatment(row):\n",
        "            \"\"\"Identify rows with actual treatment\"\"\"\n",
        "            if row.get('has_treatments') == True:\n",
        "                return 'HAS_TREATMENT'\n",
        "            elif row.get('has_treatments') == False:\n",
        "                return 'NO_TREATMENT'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_medication_treatment(row):\n",
        "            \"\"\"Identify medication treatments\"\"\"\n",
        "            name = str(row.get('name', '')).lower()\n",
        "            dosage = str(row.get('dosage', '')).lower()\n",
        "            \n",
        "            medication_terms = ['tablet', 'tablets', 'pill', 'mg', 'mcg', 'capsule', 'injection', 'infusion']\n",
        "            if any(term in name + dosage for term in medication_terms):\n",
        "                return 'MEDICATION_TREATMENT'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_surgical_treatment(row):\n",
        "            \"\"\"Identify surgical treatments\"\"\"\n",
        "            name = str(row.get('name', '')).lower()\n",
        "            details = str(row.get('details', '')).lower()\n",
        "            \n",
        "            surgical_terms = ['surgery', 'surgical', 'operation', 'resection', 'removal', 'repair', 'intubation']\n",
        "            if any(term in name + details for term in surgical_terms):\n",
        "                return 'SURGICAL_TREATMENT'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_emergency_treatment(row):\n",
        "            \"\"\"Identify emergency/critical treatments\"\"\"\n",
        "            name = str(row.get('name', '')).lower()\n",
        "            condition = str(row.get('related condition', '')).lower()\n",
        "            details = str(row.get('details', '')).lower()\n",
        "            \n",
        "            emergency_terms = ['emergency', 'urgent', 'cardiac arrest', 'shock', 'life support', \n",
        "                             'acls', 'resuscitation', 'rapid sequence']\n",
        "            if any(term in name + condition + details for term in emergency_terms):\n",
        "                return 'EMERGENCY_TREATMENT'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_cancer_treatment(row):\n",
        "            \"\"\"Identify cancer-related treatments\"\"\"\n",
        "            name = str(row.get('name', '')).lower()\n",
        "            condition = str(row.get('related condition', '')).lower()\n",
        "            reason = str(row.get('reason for taking', '')).lower()\n",
        "            \n",
        "            cancer_terms = ['chemotherapy', 'cancer', 'metastases', 'tumor', 'oncology', 'malignant', 'carcinoma']\n",
        "            if any(term in name + condition + reason for term in cancer_terms):\n",
        "                return 'CANCER_TREATMENT'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_psychiatric_treatment(row):\n",
        "            \"\"\"Identify psychiatric treatments\"\"\"\n",
        "            name = str(row.get('name', '')).lower()\n",
        "            condition = str(row.get('related condition', '')).lower()\n",
        "            \n",
        "            psych_drugs = ['olanzapine', 'risperidone', 'haloperidol', 'quetiapine', 'trihexyphenidyl']\n",
        "            psych_conditions = ['bipolar', 'psychosis', 'mania', 'depression', 'anxiety', 'affective disorder']\n",
        "            \n",
        "            if any(drug in name for drug in psych_drugs) or any(cond in condition for cond in psych_conditions):\n",
        "                return 'PSYCHIATRIC_TREATMENT'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_chronic_treatment(row):\n",
        "            \"\"\"Identify chronic/long-term treatments\"\"\"\n",
        "            time = str(row.get('time', '')).lower()\n",
        "            duration = str(row.get('duration', '')).lower()\n",
        "            \n",
        "            chronic_indicators = ['months', 'years', 'chronic', 'long-term', 'maintenance', 'past four months']\n",
        "            if any(indicator in time + duration for indicator in chronic_indicators):\n",
        "                return 'CHRONIC_TREATMENT'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_daily_medication(row):\n",
        "            \"\"\"Identify daily medications\"\"\"\n",
        "            frequency = str(row.get('frequency', '')).lower()\n",
        "            \n",
        "            if 'daily' in frequency or 'every day' in frequency or 'per day' in frequency:\n",
        "                return 'DAILY_MEDICATION'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_positive_response(row):\n",
        "            \"\"\"Identify treatments with positive response\"\"\"\n",
        "            reaction = str(row.get('reaction to treatment', '')).lower()\n",
        "            details = str(row.get('details', '')).lower()\n",
        "            \n",
        "            positive_terms = ['good response', 'improved', 'resolved', 'successful', 'effective', \n",
        "                            'restored', 'return of', 'recovered']\n",
        "            if any(term in reaction + details for term in positive_terms):\n",
        "                return 'POSITIVE_RESPONSE'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_conservative_treatment(row):\n",
        "            \"\"\"Identify conservative/non-invasive treatments\"\"\"\n",
        "            name = str(row.get('name', '')).lower()\n",
        "            \n",
        "            if 'conservative' in name or 'non-operative' in name or 'closed treatment' in name:\n",
        "                return 'CONSERVATIVE_TREATMENT'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_infection_treatment(row):\n",
        "            \"\"\"Identify infection treatments\"\"\"\n",
        "            name = str(row.get('name', '')).lower()\n",
        "            condition = str(row.get('related condition', '')).lower()\n",
        "            reason = str(row.get('reason for taking', '')).lower()\n",
        "            \n",
        "            infection_terms = ['antibiotic', 'infection', 'endocarditis', 'sepsis', 'nafcillin', 'antimicrobial']\n",
        "            if any(term in name + condition + reason for term in infection_terms):\n",
        "                return 'INFECTION_TREATMENT'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_cardiovascular_treatment(row):\n",
        "            \"\"\"Identify cardiovascular treatments\"\"\"\n",
        "            name = str(row.get('name', '')).lower()\n",
        "            condition = str(row.get('related condition', '')).lower()\n",
        "            \n",
        "            cardio_terms = ['cardiac', 'heart', 'hypovolaemic', 'shock', 'arrest', 'vasopressor', 'arrhythmia']\n",
        "            if any(term in name + condition for term in cardio_terms):\n",
        "                return 'CARDIOVASCULAR_TREATMENT'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        def lf_treatment_duration(row):\n",
        "            \"\"\"Categorize by treatment duration\"\"\"\n",
        "            # Use the extracted duration from the global TemporalStandardizer\n",
        "            duration = row.get('duration_duration_days') or row.get('time_duration_days')\n",
        "            \n",
        "            if pd.notna(duration):\n",
        "                if duration <= 7:\n",
        "                    return 'SHORT_TERM_TREATMENT'\n",
        "                elif duration <= 30:\n",
        "                    return 'MEDIUM_TERM_TREATMENT'\n",
        "                else:\n",
        "                    return 'LONG_TERM_TREATMENT'\n",
        "            return 'ABSTAIN'\n",
        "\n",
        "        return [\n",
        "            lf_has_treatment, lf_medication_treatment, lf_surgical_treatment,\n",
        "            lf_emergency_treatment, lf_cancer_treatment, lf_psychiatric_treatment,\n",
        "            lf_chronic_treatment, lf_daily_medication, lf_positive_response,\n",
        "            lf_conservative_treatment, lf_infection_treatment, lf_cardiovascular_treatment,\n",
        "            lf_treatment_duration\n",
        "        ]\n",
        "\n",
        "    # Test labeling functions\n",
        "    treatment_lfs = create_treatment_labeling_functions()\n",
        "\n",
        "    print(\"\\nTesting treatment labeling functions:\")\n",
        "    for i in range(min(10, len(df_treatments_processed))):\n",
        "        row = df_treatments_processed.iloc[i]\n",
        "        treatment_name = row.get('name', 'No treatment')\n",
        "        condition = row.get('related condition', 'No condition')\n",
        "        print(f\"\\nRow {i}: {treatment_name} for {condition}\")\n",
        "        for lf in treatment_lfs:\n",
        "            result = lf(row)\n",
        "            if result != 'ABSTAIN':\n",
        "                print(f\"  {lf.__name__}: {result}\")\n",
        "\n",
        "    # Extract treatment relations\n",
        "    print(\"\\n=== Extracting Treatment Relations ===\")\n",
        "\n",
        "    def extract_treatment_relations(df_treatments, df_entities):\n",
        "        \"\"\"Extract relations between treatments, conditions, and outcomes\"\"\"\n",
        "        relations = []\n",
        "\n",
        "        for idx, row in df_treatments.iterrows():\n",
        "            treatment = row.get('name')\n",
        "            condition = row.get('related condition')\n",
        "            dosage = row.get('dosage')\n",
        "            frequency = row.get('frequency')\n",
        "            reaction = row.get('reaction to treatment')\n",
        "            reason = row.get('reason for taking')\n",
        "\n",
        "            # TREATMENT_FOR_CONDITION relation\n",
        "            if pd.notna(treatment) and pd.notna(condition) and str(condition) != 'NaN':\n",
        "                relations.append({\n",
        "                    'type': 'TREATMENT_FOR_CONDITION',\n",
        "                    'treatment': treatment,\n",
        "                    'condition': condition,\n",
        "                    'row_idx': idx\n",
        "                })\n",
        "\n",
        "            # TREATMENT_HAS_DOSAGE relation\n",
        "            if pd.notna(treatment) and pd.notna(dosage) and str(dosage) != 'NaN':\n",
        "                relations.append({\n",
        "                    'type': 'TREATMENT_HAS_DOSAGE',\n",
        "                    'treatment': treatment,\n",
        "                    'dosage': dosage,\n",
        "                    'row_idx': idx\n",
        "                })\n",
        "\n",
        "            # TREATMENT_HAS_FREQUENCY relation\n",
        "            if pd.notna(treatment) and pd.notna(frequency) and str(frequency) != 'NaN':\n",
        "                relations.append({\n",
        "                    'type': 'TREATMENT_HAS_FREQUENCY',\n",
        "                    'treatment': treatment,\n",
        "                    'frequency': frequency,\n",
        "                    'row_idx': idx\n",
        "                })\n",
        "\n",
        "            # TREATMENT_HAS_RESPONSE relation\n",
        "            if pd.notna(treatment) and pd.notna(reaction) and str(reaction) != 'NaN':\n",
        "                relations.append({\n",
        "                    'type': 'TREATMENT_HAS_RESPONSE',\n",
        "                    'treatment': treatment,\n",
        "                    'response': reaction,\n",
        "                    'row_idx': idx\n",
        "                })\n",
        "\n",
        "            # TREATMENT_HAS_DURATION relation - using the extracted duration from global class\n",
        "            duration_days = row.get('duration_duration_days') or row.get('time_duration_days')\n",
        "            if pd.notna(treatment) and pd.notna(duration_days):\n",
        "                relations.append({\n",
        "                    'type': 'TREATMENT_HAS_DURATION',\n",
        "                    'treatment': treatment,\n",
        "                    'duration_days': duration_days,\n",
        "                    'row_idx': idx\n",
        "                })\n",
        "\n",
        "            # TREATMENT_HAS_REASON relation\n",
        "            if pd.notna(treatment) and pd.notna(reason) and str(reason) != 'NaN':\n",
        "                relations.append({\n",
        "                    'type': 'TREATMENT_HAS_REASON',\n",
        "                    'treatment': treatment,\n",
        "                    'reason': reason,\n",
        "                    'row_idx': idx\n",
        "                })\n",
        "\n",
        "            # TREATMENT_TEMPORAL_PATTERN relation\n",
        "            time_info = row.get('time', '')\n",
        "            if pd.notna(treatment) and pd.notna(time_info) and str(time_info) != 'NaN':\n",
        "                relations.append({\n",
        "                    'type': 'TREATMENT_TEMPORAL_PATTERN',\n",
        "                    'treatment': treatment,\n",
        "                    'temporal_info': time_info,\n",
        "                    'row_idx': idx\n",
        "                })\n",
        "\n",
        "        return relations\n",
        "\n",
        "    treatment_relations = extract_treatment_relations(df_treatments_processed, df_all_treatments_entities)\n",
        "\n",
        "    print(f\"Found {len(treatment_relations)} treatment relations\")\n",
        "    if treatment_relations:\n",
        "        relation_types = pd.DataFrame(treatment_relations)['type'].value_counts()\n",
        "        print(\"\\nRelation type distribution:\")\n",
        "        print(relation_types)\n",
        "\n",
        "        # Sample relations\n",
        "        print(\"\\nSample relations:\")\n",
        "        for rel in treatment_relations[:10]:\n",
        "            if rel['type'] == 'TREATMENT_FOR_CONDITION':\n",
        "                print(f\"  {rel['treatment']} -> treats -> {rel['condition']}\")\n",
        "            elif rel['type'] == 'TREATMENT_HAS_DOSAGE':\n",
        "                print(f\"  {rel['treatment']} -> dosage -> {rel['dosage']}\")\n",
        "            elif rel['type'] == 'TREATMENT_HAS_RESPONSE':\n",
        "                print(f\"  {rel['treatment']} -> response -> {rel['response']}\")\n",
        "\n",
        "    # Coverage analysis\n",
        "    print(\"\\n=== Labeling Function Coverage Analysis ===\")\n",
        "\n",
        "    coverage_results = {}\n",
        "    for lf in treatment_lfs:\n",
        "        labeled = sum(1 for _, row in df_treatments_processed.iterrows() if lf(row) != 'ABSTAIN')\n",
        "        coverage = (labeled / len(df_treatments_processed)) * 100 if len(df_treatments_processed) > 0 else 0\n",
        "        coverage_results[lf.__name__] = {\n",
        "            'labeled': labeled,\n",
        "            'coverage': coverage\n",
        "        }\n",
        "\n",
        "    print(\"\\nLabeling function coverage:\")\n",
        "    for lf_name, stats in sorted(coverage_results.items(), key=lambda x: x[1]['coverage'], reverse=True):\n",
        "        print(f\"  {lf_name}: {stats['labeled']} labels ({stats['coverage']:.1f}% coverage)\")\n",
        "\n",
        "    # Additional analysis for treatments\n",
        "    print(\"\\n=== Additional Treatment Analysis ===\")\n",
        "    \n",
        "    # Analyze treatment has_treatments distribution\n",
        "    if 'has_treatments' in df_treatments_processed.columns:\n",
        "        print(\"\\nHas treatments distribution:\")\n",
        "        print(df_treatments_processed['has_treatments'].value_counts())\n",
        "    \n",
        "    # Analyze frequency distribution\n",
        "    if 'frequency' in df_treatments_processed.columns:\n",
        "        freq_entities = df_all_treatments_entities[df_all_treatments_entities['label'] == 'FREQUENCY']\n",
        "        if len(freq_entities) > 0:\n",
        "            print(\"\\n=== Frequency Distribution ===\")\n",
        "            print(freq_entities['text'].value_counts().head(10))\n",
        "    \n",
        "    # Analyze route of administration\n",
        "    route_entities = df_all_treatments_entities[df_all_treatments_entities['label'] == 'ROUTE']\n",
        "    if len(route_entities) > 0:\n",
        "        print(\"\\n=== Route of Administration ===\")\n",
        "        print(route_entities['text'].value_counts())\n",
        "\n",
        "    # Save results\n",
        "    df_all_treatments_entities.to_csv('treatment_entities_comprehensive.csv', index=False)\n",
        "    pd.DataFrame(treatment_relations).to_csv('treatment_relations.csv', index=False)\n",
        "\n",
        "    print(\"\\n\\nTreatment entity extraction and labeling complete!\")\n",
        "    print(f\"Saved {len(df_all_treatments_entities)} entities and {len(treatment_relations)} relations\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>source_column</th>\n",
              "      <th>category</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Olanzapine</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>11</td>\n",
              "      <td>21</td>\n",
              "      <td>Treatment: Olanzapine tablets for Bipolar affe...</td>\n",
              "      <td>155216</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bipolar affective disorder</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>34</td>\n",
              "      <td>60</td>\n",
              "      <td>Treatment: Olanzapine tablets for Bipolar affe...</td>\n",
              "      <td>155216</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mental illness reaction</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>150</td>\n",
              "      <td>173</td>\n",
              "      <td>Treatment: Olanzapine tablets for Bipolar affe...</td>\n",
              "      <td>155216</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pain</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>175</td>\n",
              "      <td>179</td>\n",
              "      <td>Treatment: Olanzapine tablets for Bipolar affe...</td>\n",
              "      <td>155216</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>olanzapine</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>326</td>\n",
              "      <td>336</td>\n",
              "      <td>Treatment: Olanzapine tablets for Bipolar affe...</td>\n",
              "      <td>155216</td>\n",
              "      <td>combined_text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319175</th>\n",
              "      <td>endocarditis</td>\n",
              "      <td>CONDITION_TYPE</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>endocarditis</td>\n",
              "      <td>50425</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cardiovascular</td>\n",
              "      <td>condition_pattern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319176</th>\n",
              "      <td>infection</td>\n",
              "      <td>CONDITION_TYPE</td>\n",
              "      <td>24</td>\n",
              "      <td>33</td>\n",
              "      <td>to treat s.\\nlugdunensis infection</td>\n",
              "      <td>50425</td>\n",
              "      <td>NaN</td>\n",
              "      <td>infectious</td>\n",
              "      <td>condition_pattern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319177</th>\n",
              "      <td>endocarditis</td>\n",
              "      <td>CONDITION_TYPE</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>endocarditis</td>\n",
              "      <td>50425</td>\n",
              "      <td>NaN</td>\n",
              "      <td>infectious</td>\n",
              "      <td>condition_pattern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319178</th>\n",
              "      <td>postoperative</td>\n",
              "      <td>TEMPORAL_PATTERN</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>postoperative  patient was discharged home on ...</td>\n",
              "      <td>50425</td>\n",
              "      <td>NaN</td>\n",
              "      <td>perioperative</td>\n",
              "      <td>temporal_extraction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319179</th>\n",
              "      <td>to treat s</td>\n",
              "      <td>TREATMENT_REASON</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>to treat s.\\nlugdunensis infection</td>\n",
              "      <td>50425</td>\n",
              "      <td>NaN</td>\n",
              "      <td>treatment_goal</td>\n",
              "      <td>reason_column</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>319180 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                              text             label  start  end  \\\n",
              "0                       Olanzapine          CHEMICAL     11   21   \n",
              "1       Bipolar affective disorder           DISEASE     34   60   \n",
              "2          mental illness reaction           DISEASE    150  173   \n",
              "3                             Pain           DISEASE    175  179   \n",
              "4                       olanzapine          CHEMICAL    326  336   \n",
              "...                            ...               ...    ...  ...   \n",
              "319175                endocarditis    CONDITION_TYPE      0   12   \n",
              "319176                   infection    CONDITION_TYPE     24   33   \n",
              "319177                endocarditis    CONDITION_TYPE      0   12   \n",
              "319178               postoperative  TEMPORAL_PATTERN      0   13   \n",
              "319179                  to treat s  TREATMENT_REASON      0   10   \n",
              "\n",
              "                                            original_text  row_idx  \\\n",
              "0       Treatment: Olanzapine tablets for Bipolar affe...   155216   \n",
              "1       Treatment: Olanzapine tablets for Bipolar affe...   155216   \n",
              "2       Treatment: Olanzapine tablets for Bipolar affe...   155216   \n",
              "3       Treatment: Olanzapine tablets for Bipolar affe...   155216   \n",
              "4       Treatment: Olanzapine tablets for Bipolar affe...   155216   \n",
              "...                                                   ...      ...   \n",
              "319175                                       endocarditis    50425   \n",
              "319176                 to treat s.\\nlugdunensis infection    50425   \n",
              "319177                                       endocarditis    50425   \n",
              "319178  postoperative  patient was discharged home on ...    50425   \n",
              "319179                 to treat s.\\nlugdunensis infection    50425   \n",
              "\n",
              "        source_column        category               source  \n",
              "0       combined_text             NaN                  NaN  \n",
              "1       combined_text             NaN                  NaN  \n",
              "2       combined_text             NaN                  NaN  \n",
              "3       combined_text             NaN                  NaN  \n",
              "4       combined_text             NaN                  NaN  \n",
              "...               ...             ...                  ...  \n",
              "319175            NaN  cardiovascular    condition_pattern  \n",
              "319176            NaN      infectious    condition_pattern  \n",
              "319177            NaN      infectious    condition_pattern  \n",
              "319178            NaN   perioperative  temporal_extraction  \n",
              "319179            NaN  treatment_goal        reason_column  \n",
              "\n",
              "[319180 rows x 9 columns]"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_all_treatments_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155216</td>\n",
              "      <td>Sixteen years old</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133948</td>\n",
              "      <td>36 years old</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80176</td>\n",
              "      <td>49</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72232</td>\n",
              "      <td>47</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>31864</td>\n",
              "      <td>24 years</td>\n",
              "      <td>Female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>39279</td>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>137017</td>\n",
              "      <td>82</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>98004</td>\n",
              "      <td>54</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>133320</td>\n",
              "      <td>49</td>\n",
              "      <td>Woman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>97973</td>\n",
              "      <td>31</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29755 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          idx                age     sex\n",
              "0      155216  Sixteen years old  Female\n",
              "2      133948       36 years old  Female\n",
              "3       80176                 49    male\n",
              "4       72232                 47    Male\n",
              "5       31864           24 years  Female\n",
              "...       ...                ...     ...\n",
              "29995   39279                 28    male\n",
              "29996  137017                 82    Male\n",
              "29997   98004                 54    Male\n",
              "29998  133320                 49   Woman\n",
              "29999   97973                 31    male\n",
              "\n",
              "[29755 rows x 3 columns]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sex\n",
              "Female                                                             10077\n",
              "Male                                                                9974\n",
              "male                                                                4588\n",
              "Woman                                                               2486\n",
              "female                                                               993\n",
              "man                                                                  497\n",
              "woman                                                                391\n",
              "boy                                                                  190\n",
              "Boy                                                                   78\n",
              "Girl                                                                  77\n",
              "girl                                                                  72\n",
              "Man                                                                   68\n",
              "Gentleman                                                              7\n",
              "Trans man                                                              6\n",
              "gentleman                                                              6\n",
              "Trans woman                                                            5\n",
              "Neutered male                                                          4\n",
              "lady                                                                   3\n",
              "Entire male                                                            2\n",
              "Female neutered                                                        2\n",
              "Male for the first patient, Female for the second patient              2\n",
              "Male for both patients                                                 2\n",
              "Castrated male                                                         2\n",
              "Female phenotype                                                       1\n",
              "Twin A (sex not specified)                                             1\n",
              "Male and Female                                                        1\n",
              "Transgender woman                                                      1\n",
              "Not specified                                                          1\n",
              "Phenotypical male                                                      1\n",
              "Male (after legal gender change)                                       1\n",
              "Male (transgender)                                                     1\n",
              "Female (social gender)                                                 1\n",
              "Female (46,XX)                                                         1\n",
              "Lady                                                                   1\n",
              "Female, spayed                                                         1\n",
              "neutered male                                                          1\n",
              "Male for the second and third cases, Female for the fourth case        1\n",
              "Female spayed                                                          1\n",
              "Neutered female                                                        1\n",
              "Sex not specified                                                      1\n",
              "Two men and one woman                                                  1\n",
              "Female; Male; Male                                                     1\n",
              "Assigned female at birth, raised as male                               1\n",
              "Male; Female                                                           1\n",
              "Female / Male                                                          1\n",
              "One female and one male                                                1\n",
              "Female and Male                                                        1\n",
              "Cisgender woman                                                        1\n",
              "Brother (male) and sister (female)                                     1\n",
              "man, woman, woman                                                      1\n",
              "female spayed                                                          1\n",
              "Biological male                                                        1\n",
              "Male (Geminus A)                                                       1\n",
              "Male neutered                                                          1\n",
              "Female for Patient Case 1, Male for Patient Case 2                     1\n",
              "Assigned female at birth                                               1\n",
              "Designated female at birth, transitioned to male                       1\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_info['sex'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "age\n",
              "62                                                                                  474\n",
              "65                                                                                  465\n",
              "35                                                                                  432\n",
              "63                                                                                  432\n",
              "45                                                                                  429\n",
              "                                                                                   ... \n",
              "Initially 21 years old, 33 years old at last mention                                  1\n",
              "29 at first admission, 55 at the time of the last mentioned clinical examination      1\n",
              "18 yr old                                                                             1\n",
              "37-years old                                                                          1\n",
              "Almost three-year old                                                                 1\n",
              "Name: count, Length: 1296, dtype: int64"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_info['age'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Standardized Sex Distribution:\n",
            "sex_standardized\n",
            "Male                15429\n",
            "Female              14129\n",
            "Multiple_Records        5\n",
            "Other                   3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Age Distribution:\n",
            "age_category\n",
            "Adult         19376\n",
            "Elderly        6153\n",
            "Child          2566\n",
            "Adolescent     1489\n",
            "Infant           89\n",
            "Unknown          82\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Special Cases:\n",
            "Veterinary cases: 13\n",
            "Multiple patient records: 5\n",
            "Complex age descriptions: 120\n"
          ]
        }
      ],
      "source": [
        "def standardize_sex(sex_str):\n",
        "    \"\"\"\n",
        "    Standardize sex/gender values based on the variations in your data.\n",
        "    \n",
        "    Special cases handled:\n",
        "    - Veterinary cases (neutered/castrated)\n",
        "    - Multiple patients in one record\n",
        "    - Trans individuals\n",
        "    - Various capitalizations and terms\n",
        "    \"\"\"\n",
        "    if pd.isna(sex_str):\n",
        "        return None\n",
        "    \n",
        "    sex_str = str(sex_str).strip().lower()\n",
        "    \n",
        "    # Handle multiple patients first\n",
        "    if 'both' in sex_str or 'second patient' in sex_str or 'patient case' in sex_str:\n",
        "        return 'Multiple_Patients'\n",
        "    \n",
        "    # Map variations to standard values\n",
        "    female_terms = ['female', 'woman', 'girl', 'lady']\n",
        "    male_terms = ['male', 'man', 'boy', 'gentleman']\n",
        "    \n",
        "    # Check for trans individuals\n",
        "    if 'trans' in sex_str:\n",
        "        if 'trans man' in sex_str or 'transitioned to male' in sex_str:\n",
        "            return 'Trans_Male'\n",
        "        elif 'trans woman' in sex_str:\n",
        "            return 'Trans_Female'\n",
        "    \n",
        "    # Check for assigned at birth\n",
        "    if 'assigned female at birth' in sex_str:\n",
        "        return 'AFAB'\n",
        "    \n",
        "    # Check for phenotype mentions\n",
        "    if 'phenotype' in sex_str:\n",
        "        if 'female' in sex_str:\n",
        "            return 'Female_Phenotype'\n",
        "    \n",
        "    # Check for veterinary cases (neutered/castrated)\n",
        "    if 'neutered' in sex_str or 'castrated' in sex_str or 'entire' in sex_str:\n",
        "        if any(term in sex_str for term in female_terms):\n",
        "            if 'neutered' in sex_str:\n",
        "                return 'Female_Neutered'\n",
        "            else:\n",
        "                return 'Female_Intact'\n",
        "        elif any(term in sex_str for term in male_terms):\n",
        "            if 'neutered' in sex_str or 'castrated' in sex_str:\n",
        "                return 'Male_Neutered'\n",
        "            else:\n",
        "                return 'Male_Intact'\n",
        "    \n",
        "    # Standard cases\n",
        "    for term in female_terms:\n",
        "        if term == sex_str:\n",
        "            return 'Female'\n",
        "    \n",
        "    for term in male_terms:\n",
        "        if term == sex_str:\n",
        "            return 'Male'\n",
        "    \n",
        "    # If we can't classify, return as unclassified\n",
        "    return 'Unclassified'\n",
        "\n",
        "\n",
        "def standardize_sex_simple(sex_str):\n",
        "    \"\"\"\n",
        "    Simplified version that maps to just Male/Female/Other categories\n",
        "    \"\"\"\n",
        "    if pd.isna(sex_str):\n",
        "        return None\n",
        "    \n",
        "    sex_str = str(sex_str).strip().lower()\n",
        "    \n",
        "    # Handle multiple patients\n",
        "    if 'both' in sex_str or 'second patient' in sex_str or 'patient case' in sex_str:\n",
        "        return 'Multiple_Records'\n",
        "    \n",
        "    # Simple mapping\n",
        "    female_terms = ['female', 'woman', 'girl', 'lady', 'trans woman', 'female phenotype']\n",
        "    male_terms = ['male', 'man', 'boy', 'gentleman', 'trans man']\n",
        "    \n",
        "    # Check for main terms\n",
        "    for term in female_terms:\n",
        "        if term in sex_str:\n",
        "            return 'Female'\n",
        "    \n",
        "    for term in male_terms:\n",
        "        if term in sex_str:\n",
        "            return 'Male'\n",
        "    \n",
        "    return 'Other'\n",
        "\n",
        "\n",
        "def extract_age_from_text(age_str):\n",
        "    \"\"\"\n",
        "    Extract numeric age from various text formats in your data.\n",
        "    \n",
        "    Handles cases like:\n",
        "    - Simple numbers: \"62\", \"35\"\n",
        "    - Years old format: \"18 yr old\", \"37-years old\"\n",
        "    - Written numbers: \"Sixteen years old\", \"Almost three-year old\"\n",
        "    - Complex cases: \"Initially 21 years old, 33 years old at last mention\"\n",
        "    - Age ranges: \"29 at first admission, 55 at the time of the last mentioned clinical examination\"\n",
        "    \"\"\"\n",
        "    if pd.isna(age_str):\n",
        "        return None\n",
        "    \n",
        "    age_str = str(age_str).strip()\n",
        "    \n",
        "    # First check if it's already a simple number\n",
        "    if age_str.isdigit():\n",
        "        return int(age_str)\n",
        "    \n",
        "    # Convert written numbers to digits\n",
        "    written_numbers = {\n",
        "        'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5,\n",
        "        'six': 6, 'seven': 7, 'eight': 8, 'nine': 9, 'ten': 10,\n",
        "        'eleven': 11, 'twelve': 12, 'thirteen': 13, 'fourteen': 14,\n",
        "        'fifteen': 15, 'sixteen': 16, 'seventeen': 17, 'eighteen': 18,\n",
        "        'nineteen': 19, 'twenty': 20, 'thirty': 30, 'forty': 40,\n",
        "        'fifty': 50, 'sixty': 60, 'seventy': 70, 'eighty': 80,\n",
        "        'ninety': 90\n",
        "    }\n",
        "    \n",
        "    # Replace written numbers with digits\n",
        "    age_str_lower = age_str.lower()\n",
        "    for word, num in written_numbers.items():\n",
        "        age_str_lower = age_str_lower.replace(word, str(num))\n",
        "    \n",
        "    # Handle compound written numbers (e.g., \"twenty-one\")\n",
        "    age_str_lower = re.sub(r'(\\d+)\\s*-\\s*(\\d+)', lambda m: str(int(m.group(1)) + int(m.group(2))), age_str_lower)\n",
        "    \n",
        "    # Extract all numbers from the text\n",
        "    numbers = re.findall(r'\\d+', age_str_lower)\n",
        "    \n",
        "    if not numbers:\n",
        "        return None\n",
        "    \n",
        "    # For multiple ages (patient history), typically want the first mentioned age\n",
        "    # You might want to change this logic based on your needs\n",
        "    if 'initially' in age_str_lower or 'first' in age_str_lower:\n",
        "        # Return the first number\n",
        "        return int(numbers[0])\n",
        "    elif 'last' in age_str_lower or 'current' in age_str_lower:\n",
        "        # Return the last number\n",
        "        return int(numbers[-1])\n",
        "    else:\n",
        "        # Default to first number found\n",
        "        return int(numbers[0])\n",
        "\n",
        "\n",
        "def get_age_category(age):\n",
        "    \"\"\"\n",
        "    Categorize age into standard medical categories\n",
        "    \"\"\"\n",
        "    if pd.isna(age):\n",
        "        return 'Unknown'\n",
        "    \n",
        "    if age < 2:\n",
        "        return 'Infant'\n",
        "    elif age < 13:\n",
        "        return 'Child'\n",
        "    elif age < 18:\n",
        "        return 'Adolescent'\n",
        "    elif age < 65:\n",
        "        return 'Adult'\n",
        "    else:\n",
        "        return 'Elderly'\n",
        "\n",
        "\n",
        "def standardize_demographics(df):\n",
        "    \"\"\"\n",
        "    Apply all standardization to the dataframe\n",
        "    \"\"\"\n",
        "    # Create a copy to avoid modifying original\n",
        "    df_clean = df.copy()\n",
        "    \n",
        "    # Standardize sex - both detailed and simple versions\n",
        "    df_clean['sex_detailed'] = df_clean['sex'].apply(standardize_sex)\n",
        "    df_clean['sex_standardized'] = df_clean['sex'].apply(standardize_sex_simple)\n",
        "    \n",
        "    # Extract numeric age\n",
        "    df_clean['age_numeric'] = df_clean['age'].apply(extract_age_from_text)\n",
        "    \n",
        "    # Add age category\n",
        "    df_clean['age_category'] = df_clean['age_numeric'].apply(get_age_category)\n",
        "    \n",
        "    # Create flags for special cases\n",
        "    df_clean['is_veterinary'] = df_clean['sex_detailed'].str.contains('Neutered|Intact', na=False)\n",
        "    df_clean['is_multiple_patients'] = df_clean['sex_detailed'] == 'Multiple_Patients'\n",
        "    df_clean['has_complex_age'] = df_clean['age'].str.contains('initially|first|last|mention', case=False, na=False)\n",
        "    \n",
        "    return df_clean\n",
        "\n",
        "\n",
        "    \n",
        "# Apply to your dataframe:\n",
        "df_info_clean = standardize_demographics(df_info)\n",
        "\n",
        "# View results:\n",
        "print(\"\\nStandardized Sex Distribution:\")\n",
        "print(df_info_clean['sex_standardized'].value_counts())\n",
        "print(\"\\nAge Distribution:\")\n",
        "print(df_info_clean['age_category'].value_counts())\n",
        "print(\"\\nSpecial Cases:\")\n",
        "print(f\"Veterinary cases: {df_info_clean['is_veterinary'].sum()}\")\n",
        "print(f\"Multiple patient records: {df_info_clean['is_multiple_patients'].sum()}\")\n",
        "print(f\"Complex age descriptions: {df_info_clean['has_complex_age'].sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>sex_detailed</th>\n",
              "      <th>sex_standardized</th>\n",
              "      <th>age_numeric</th>\n",
              "      <th>age_category</th>\n",
              "      <th>is_veterinary</th>\n",
              "      <th>is_multiple_patients</th>\n",
              "      <th>has_complex_age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>155216</td>\n",
              "      <td>Sixteen years old</td>\n",
              "      <td>Female</td>\n",
              "      <td>Female</td>\n",
              "      <td>Female</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Child</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133948</td>\n",
              "      <td>36 years old</td>\n",
              "      <td>Female</td>\n",
              "      <td>Female</td>\n",
              "      <td>Female</td>\n",
              "      <td>36.0</td>\n",
              "      <td>Adult</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80176</td>\n",
              "      <td>49</td>\n",
              "      <td>male</td>\n",
              "      <td>Male</td>\n",
              "      <td>Male</td>\n",
              "      <td>49.0</td>\n",
              "      <td>Adult</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72232</td>\n",
              "      <td>47</td>\n",
              "      <td>Male</td>\n",
              "      <td>Male</td>\n",
              "      <td>Male</td>\n",
              "      <td>47.0</td>\n",
              "      <td>Adult</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>31864</td>\n",
              "      <td>24 years</td>\n",
              "      <td>Female</td>\n",
              "      <td>Female</td>\n",
              "      <td>Female</td>\n",
              "      <td>24.0</td>\n",
              "      <td>Adult</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>39279</td>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>Male</td>\n",
              "      <td>Male</td>\n",
              "      <td>28.0</td>\n",
              "      <td>Adult</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>137017</td>\n",
              "      <td>82</td>\n",
              "      <td>Male</td>\n",
              "      <td>Male</td>\n",
              "      <td>Male</td>\n",
              "      <td>82.0</td>\n",
              "      <td>Elderly</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>98004</td>\n",
              "      <td>54</td>\n",
              "      <td>Male</td>\n",
              "      <td>Male</td>\n",
              "      <td>Male</td>\n",
              "      <td>54.0</td>\n",
              "      <td>Adult</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>133320</td>\n",
              "      <td>49</td>\n",
              "      <td>Woman</td>\n",
              "      <td>Female</td>\n",
              "      <td>Female</td>\n",
              "      <td>49.0</td>\n",
              "      <td>Adult</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>97973</td>\n",
              "      <td>31</td>\n",
              "      <td>male</td>\n",
              "      <td>Male</td>\n",
              "      <td>Male</td>\n",
              "      <td>31.0</td>\n",
              "      <td>Adult</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29755 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          idx                age     sex sex_detailed sex_standardized  \\\n",
              "0      155216  Sixteen years old  Female       Female           Female   \n",
              "2      133948       36 years old  Female       Female           Female   \n",
              "3       80176                 49    male         Male             Male   \n",
              "4       72232                 47    Male         Male             Male   \n",
              "5       31864           24 years  Female       Female           Female   \n",
              "...       ...                ...     ...          ...              ...   \n",
              "29995   39279                 28    male         Male             Male   \n",
              "29996  137017                 82    Male         Male             Male   \n",
              "29997   98004                 54    Male         Male             Male   \n",
              "29998  133320                 49   Woman       Female           Female   \n",
              "29999   97973                 31    male         Male             Male   \n",
              "\n",
              "       age_numeric age_category  is_veterinary  is_multiple_patients  \\\n",
              "0              6.0        Child          False                 False   \n",
              "2             36.0        Adult          False                 False   \n",
              "3             49.0        Adult          False                 False   \n",
              "4             47.0        Adult          False                 False   \n",
              "5             24.0        Adult          False                 False   \n",
              "...            ...          ...            ...                   ...   \n",
              "29995         28.0        Adult          False                 False   \n",
              "29996         82.0      Elderly          False                 False   \n",
              "29997         54.0        Adult          False                 False   \n",
              "29998         49.0        Adult          False                 False   \n",
              "29999         31.0        Adult          False                 False   \n",
              "\n",
              "       has_complex_age  \n",
              "0                False  \n",
              "2                False  \n",
              "3                False  \n",
              "4                False  \n",
              "5                False  \n",
              "...                ...  \n",
              "29995            False  \n",
              "29996            False  \n",
              "29997            False  \n",
              "29998            False  \n",
              "29999            False  \n",
              "\n",
              "[29755 rows x 10 columns]"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_info_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(910897, 4) label\n",
            "AgeSex    707568\n",
            "Age       203321\n",
            "Sex            8\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# df_info_clean has: idx, age, sex, sex_detailed, sex_standardized, age_numeric, ...\n",
        "\n",
        "info = df_info_clean.rename(columns={\"idx\":\"row_idx\"}).copy()\n",
        "\n",
        "def age_variants(n: int):\n",
        "    n = int(n)\n",
        "    return [\n",
        "        f\"{n} years old\", f\"{n} year old\",\n",
        "        f\"{n}-year-old\", f\"{n} yo\", f\"{n} y/o\", f\"aged {n}\"\n",
        "    ]\n",
        "\n",
        "SEX_SYNONYMS = {\n",
        "    \"female\": [\"female\", \"woman\", \"female patient\", \"women\"],\n",
        "    \"male\":   [\"male\", \"man\", \"male patient\", \"men\"],\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for r in info.itertuples(index=False):\n",
        "    rid = r.row_idx\n",
        "\n",
        "    # 1) Use the raw age text if present\n",
        "    if isinstance(r.age, str) and r.age.strip():\n",
        "        rows.append({\"row_idx\": rid, \"text\": r.age.strip(), \"label\": \"Age\", \"table\": \"info\"})\n",
        "\n",
        "    # 2) Generate common age variants from numeric\n",
        "    if pd.notna(r.age_numeric):\n",
        "        for t in age_variants(r.age_numeric):\n",
        "            rows.append({\"row_idx\": rid, \"text\": t, \"label\": \"Age\", \"table\": \"info\"})\n",
        "\n",
        "    # 3) Sex synonyms (driven by standardized sex if available)\n",
        "    sex_std = None\n",
        "    for s in (getattr(r, \"sex_standardized\", None), getattr(r, \"sex_detailed\", None), getattr(r, \"sex\", None)):\n",
        "        if isinstance(s, str) and s.strip():\n",
        "            sex_std = s.strip().lower()\n",
        "            break\n",
        "    if sex_std in SEX_SYNONYMS:\n",
        "        for t in SEX_SYNONYMS[sex_std]:\n",
        "            rows.append({\"row_idx\": nid, \"text\": t, \"label\": \"Sex\", \"table\": \"info\"})\n",
        "\n",
        "        # 4) Age+sex combos (very common in narratives, e.g., \"36-year-old female\")\n",
        "        if pd.notna(r.age_numeric):\n",
        "            for av in age_variants(r.age_numeric):\n",
        "                for sx in SEX_SYNONYMS[sex_std]:\n",
        "                    rows.append({\"row_idx\": rid, \"text\": f\"{av} {sx}\", \"label\": \"AgeSex\", \"table\": \"info\"})\n",
        "\n",
        "df_info_entities = pd.DataFrame(rows).drop_duplicates([\"row_idx\",\"text\",\"label\"])\n",
        "print(df_info_entities.shape, df_info_entities.label.value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total entities across all tables: 2,064,778\n",
            "\n",
            "Entity distribution by table:\n",
            "table\n",
            "info             910897\n",
            "treatments       319180\n",
            "diagnosis        311124\n",
            "symptoms         296384\n",
            "surgery          174631\n",
            "physiological     47382\n",
            "psychological      3402\n",
            "allergies           934\n",
            "drug_usage          715\n",
            "vaccination         129\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Entity types found:\n",
            "label\n",
            "AgeSex                             707568\n",
            "DISEASE                            281269\n",
            "Age                                203321\n",
            "ANATOMY                            111305\n",
            "CONDITION                           79686\n",
            "TEST                                56150\n",
            "LATERALITY                          53586\n",
            "SYMPTOM                             53580\n",
            "SYMPTOM_TYPE                        53273\n",
            "TEST_TYPE                           52665\n",
            "CHEMICAL                            51222\n",
            "TREATMENT                           44086\n",
            "MULTI_TISSUE_STRUCTURE              32237\n",
            "PROCEDURE                           27822\n",
            "TEMPORAL_PATTERN                    27246\n",
            "FINDING                             25683\n",
            "TREATMENT_TYPE                      23652\n",
            "ROUTE                               18590\n",
            "CANCER                              17003\n",
            "TREATMENT_REASON                    16765\n",
            "TISSUE                              16665\n",
            "ORGAN                               14854\n",
            "PATHOLOGICAL_FORMATION              14321\n",
            "CONDITION_TYPE                      13410\n",
            "MEASUREMENT                         13021\n",
            "DOSAGE                              12320\n",
            "TREATMENT_RESPONSE                   7463\n",
            "FREQUENCY                            6705\n",
            "SEVERITY                             6360\n",
            "ORGANISM_SUBDIVISION                 4084\n",
            "GENE_OR_GENE_PRODUCT                 3097\n",
            "CELL                                 2784\n",
            "SIMPLE_CHEMICAL                      2742\n",
            "ORGANISM                             2378\n",
            "MEDICATION                           1921\n",
            "IMMATERIAL_ANATOMICAL_ENTITY         1800\n",
            "CELLULAR_COMPONENT                   1777\n",
            "ORGANISM_SUBSTANCE                   1306\n",
            "ANATOMY_WITH_LATERALITY               893\n",
            "AMINO_ACID                            111\n",
            "ANATOMICAL_SYSTEM                      48\n",
            "Sex                                     8\n",
            "DEVELOPING_ANATOMICAL_STRUCTURE         1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "all_entities = pd.concat([\n",
        "    df_all_physiological_entities.assign(table='physiological'),\n",
        "    df_psychological_entities.assign(table='psychological'),\n",
        "    df_vaccination_entities.assign(table='vaccination'),\n",
        "    df_allergies_entities.assign(table='allergies'),\n",
        "    df_drug_usage_entities.assign(table='drug_usage'),\n",
        "    df_all_surgery_entities.assign(table='surgery'),\n",
        "    df_all_symptom_entities.assign(table='symptoms'),\n",
        "    df_all_diagnosis_entities.assign(table='diagnosis'),\n",
        "    df_all_treatments_entities.assign(table='treatments'),\n",
        "    df_info_entities.assign(table='info')\n",
        "], ignore_index=True)\n",
        "\n",
        "print(f\"Total entities across all tables: {len(all_entities):,}\")\n",
        "print(\"\\nEntity distribution by table:\")\n",
        "print(all_entities['table'].value_counts())\n",
        "print(\"\\nEntity types found:\")\n",
        "print(all_entities['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>original_text</th>\n",
              "      <th>row_idx</th>\n",
              "      <th>source_column</th>\n",
              "      <th>table</th>\n",
              "      <th>category</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>posttraumatic arthritis</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>48.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>History of left elbow arthrodesis performed fo...</td>\n",
              "      <td>80176.0</td>\n",
              "      <td>physiological context</td>\n",
              "      <td>physiological</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pain</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>116.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>Inability to walk since babyhood, did not walk...</td>\n",
              "      <td>31864.0</td>\n",
              "      <td>physiological context</td>\n",
              "      <td>physiological</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fracture</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>151.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>Inability to walk since babyhood, did not walk...</td>\n",
              "      <td>31864.0</td>\n",
              "      <td>physiological context</td>\n",
              "      <td>physiological</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Coxa vara deformity</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>Coxa vara deformity of bilateral hips, bilater...</td>\n",
              "      <td>149866.0</td>\n",
              "      <td>physiological context</td>\n",
              "      <td>physiological</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fracture</td>\n",
              "      <td>DISEASE</td>\n",
              "      <td>75.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>Coxa vara deformity of bilateral hips, bilater...</td>\n",
              "      <td>149866.0</td>\n",
              "      <td>physiological context</td>\n",
              "      <td>physiological</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2064773</th>\n",
              "      <td>31 y/o men</td>\n",
              "      <td>AgeSex</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>97973.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>info</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2064774</th>\n",
              "      <td>aged 31 male</td>\n",
              "      <td>AgeSex</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>97973.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>info</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2064775</th>\n",
              "      <td>aged 31 man</td>\n",
              "      <td>AgeSex</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>97973.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>info</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2064776</th>\n",
              "      <td>aged 31 male patient</td>\n",
              "      <td>AgeSex</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>97973.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>info</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2064777</th>\n",
              "      <td>aged 31 men</td>\n",
              "      <td>AgeSex</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>97973.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>info</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2064778 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            text    label  start    end  \\\n",
              "0        posttraumatic arthritis  DISEASE   48.0   71.0   \n",
              "1                           pain  DISEASE  116.0  120.0   \n",
              "2                       fracture  DISEASE  151.0  159.0   \n",
              "3            Coxa vara deformity  DISEASE    0.0   19.0   \n",
              "4                       fracture  DISEASE   75.0   83.0   \n",
              "...                          ...      ...    ...    ...   \n",
              "2064773               31 y/o men   AgeSex    NaN    NaN   \n",
              "2064774             aged 31 male   AgeSex    NaN    NaN   \n",
              "2064775              aged 31 man   AgeSex    NaN    NaN   \n",
              "2064776     aged 31 male patient   AgeSex    NaN    NaN   \n",
              "2064777              aged 31 men   AgeSex    NaN    NaN   \n",
              "\n",
              "                                             original_text   row_idx  \\\n",
              "0        History of left elbow arthrodesis performed fo...   80176.0   \n",
              "1        Inability to walk since babyhood, did not walk...   31864.0   \n",
              "2        Inability to walk since babyhood, did not walk...   31864.0   \n",
              "3        Coxa vara deformity of bilateral hips, bilater...  149866.0   \n",
              "4        Coxa vara deformity of bilateral hips, bilater...  149866.0   \n",
              "...                                                    ...       ...   \n",
              "2064773                                                NaN   97973.0   \n",
              "2064774                                                NaN   97973.0   \n",
              "2064775                                                NaN   97973.0   \n",
              "2064776                                                NaN   97973.0   \n",
              "2064777                                                NaN   97973.0   \n",
              "\n",
              "                 source_column          table category source  \n",
              "0        physiological context  physiological      NaN    NaN  \n",
              "1        physiological context  physiological      NaN    NaN  \n",
              "2        physiological context  physiological      NaN    NaN  \n",
              "3        physiological context  physiological      NaN    NaN  \n",
              "4        physiological context  physiological      NaN    NaN  \n",
              "...                        ...            ...      ...    ...  \n",
              "2064773                    NaN           info      NaN    NaN  \n",
              "2064774                    NaN           info      NaN    NaN  \n",
              "2064775                    NaN           info      NaN    NaN  \n",
              "2064776                    NaN           info      NaN    NaN  \n",
              "2064777                    NaN           info      NaN    NaN  \n",
              "\n",
              "[2064778 rows x 10 columns]"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_entities = pd.DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_entities.to_csv('all_entities.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp_clinical",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
