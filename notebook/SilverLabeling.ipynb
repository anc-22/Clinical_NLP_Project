{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0ac7ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp_clinical/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling.model.label_model import LabelModel\n",
    "import pandas as pd\n",
    "import re\n",
    "from hashlib import md5\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer\n",
    "import datasets as ds\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, DataCollatorForTokenClassification\n",
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "import numpy as np\n",
    "import datasets as ds\n",
    "import json, os\n",
    "import os, json, numpy as np, torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForTokenClassification,\n",
    "    DataCollatorForTokenClassification, TrainingArguments, Trainer,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "import datasets as ds\n",
    "from seqeval.metrics import f1_score, precision_score, recall_score\n",
    "import re, math\n",
    "from collections import Counter, defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07e4fe9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7m/wfwdc8s14pgch1s3hgyyg6080000gn/T/ipykernel_40097/4072654494.py:5: DtypeWarning: Columns (4,6,7,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_entities = pd.read_csv(all_entities_file)\n"
     ]
    }
   ],
   "source": [
    "ROOT = Path.cwd().parent\n",
    "df_lean_file = ROOT / \"data\" / \"clean\" / 'augmented_notes_30K.csv'\n",
    "df_lean = pd.read_csv(df_lean_file).reset_index(drop=True)\n",
    "all_entities_file = ROOT / \"data\" / \"clean\" / 'all_entities.csv'\n",
    "all_entities = pd.read_csv(all_entities_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9d365d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "      <th>full_note</th>\n",
       "      <th>idx</th>\n",
       "      <th>note</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Doctor: Good morning, what brings you to the O...</td>\n",
       "      <td>A a sixteen year-old girl, presented to our Ou...</td>\n",
       "      <td>155216</td>\n",
       "      <td>A a sixteen year-old girl, presented to our Ou...</td>\n",
       "      <td>{\\n\"visit motivation\": \"Discomfort in the neck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Doctor: Hi, how are you feeling today?\\nPatien...</td>\n",
       "      <td>This is the case of a 56-year-old man that was...</td>\n",
       "      <td>77465</td>\n",
       "      <td>This is the case of a 56-year-old man that was...</td>\n",
       "      <td>{\\n\"visit motivation\": \"Complaints of a dull p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Doctor: Hello, what brings you to the hospital...</td>\n",
       "      <td>A 36-year old female patient visited our hospi...</td>\n",
       "      <td>133948</td>\n",
       "      <td>A 36-year old female patient visited our hospi...</td>\n",
       "      <td>{\\n\"visit motivation\": \"Pain and restricted ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Doctor: Good morning, Mr. [Patient's Name]. I'...</td>\n",
       "      <td>A 49-year-old male presented with a complaint ...</td>\n",
       "      <td>80176</td>\n",
       "      <td>A 49-year-old male presented with a complaint ...</td>\n",
       "      <td>{\\n\"visit motivation\": \"Pain in the left proxi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Doctor: Good morning, how are you feeling toda...</td>\n",
       "      <td>A 47-year-old male patient was referred to the...</td>\n",
       "      <td>72232</td>\n",
       "      <td>A 47-year-old male patient was referred to the...</td>\n",
       "      <td>{\\n\"visit motivation\": \"Recurrent attacks of p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>Doctor: Good morning, sir. Can you tell me wha...</td>\n",
       "      <td>A 28-year-old male was admitted to the emergen...</td>\n",
       "      <td>39279</td>\n",
       "      <td>A 28-year-old male was admitted to the emergen...</td>\n",
       "      <td>{\\n\"visit motivation\": \"Stab wound under left ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>Doctor: Good morning, sir. I am Dr. John. How ...</td>\n",
       "      <td>An 82-year-old man (64.5 kg, 175 cm) diagnosed...</td>\n",
       "      <td>137017</td>\n",
       "      <td>An 82-year-old man (64.5 kg, 175 cm) diagnosed...</td>\n",
       "      <td>{\\n\"visit motivation\": \"Diagnosed with falcine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>Doctor: Good morning, how are you feeling toda...</td>\n",
       "      <td>A 54 year-old man with no past medical history...</td>\n",
       "      <td>98004</td>\n",
       "      <td>A 54 year-old man with no past medical history...</td>\n",
       "      <td>{\\n\"visit motivation\": \"Cardiac sounding chest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>Doctor: Good morning, how can I help you today...</td>\n",
       "      <td>A 49-year-old woman visited the clinic due to ...</td>\n",
       "      <td>133320</td>\n",
       "      <td>A 49-year-old woman visited the clinic due to ...</td>\n",
       "      <td>{\\n\"visit motivation\": \"Mass in her right thig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>Doctor: Good morning, what brings you to the e...</td>\n",
       "      <td>A 31-year-old male with no significant past me...</td>\n",
       "      <td>97973</td>\n",
       "      <td>A 31-year-old male with no significant past me...</td>\n",
       "      <td>{\\n\"visit motivation\": \"Acute onset crushing s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            conversation  \\\n",
       "0      Doctor: Good morning, what brings you to the O...   \n",
       "1      Doctor: Hi, how are you feeling today?\\nPatien...   \n",
       "2      Doctor: Hello, what brings you to the hospital...   \n",
       "3      Doctor: Good morning, Mr. [Patient's Name]. I'...   \n",
       "4      Doctor: Good morning, how are you feeling toda...   \n",
       "...                                                  ...   \n",
       "29995  Doctor: Good morning, sir. Can you tell me wha...   \n",
       "29996  Doctor: Good morning, sir. I am Dr. John. How ...   \n",
       "29997  Doctor: Good morning, how are you feeling toda...   \n",
       "29998  Doctor: Good morning, how can I help you today...   \n",
       "29999  Doctor: Good morning, what brings you to the e...   \n",
       "\n",
       "                                               full_note     idx  \\\n",
       "0      A a sixteen year-old girl, presented to our Ou...  155216   \n",
       "1      This is the case of a 56-year-old man that was...   77465   \n",
       "2      A 36-year old female patient visited our hospi...  133948   \n",
       "3      A 49-year-old male presented with a complaint ...   80176   \n",
       "4      A 47-year-old male patient was referred to the...   72232   \n",
       "...                                                  ...     ...   \n",
       "29995  A 28-year-old male was admitted to the emergen...   39279   \n",
       "29996  An 82-year-old man (64.5 kg, 175 cm) diagnosed...  137017   \n",
       "29997  A 54 year-old man with no past medical history...   98004   \n",
       "29998  A 49-year-old woman visited the clinic due to ...  133320   \n",
       "29999  A 31-year-old male with no significant past me...   97973   \n",
       "\n",
       "                                                    note  \\\n",
       "0      A a sixteen year-old girl, presented to our Ou...   \n",
       "1      This is the case of a 56-year-old man that was...   \n",
       "2      A 36-year old female patient visited our hospi...   \n",
       "3      A 49-year-old male presented with a complaint ...   \n",
       "4      A 47-year-old male patient was referred to the...   \n",
       "...                                                  ...   \n",
       "29995  A 28-year-old male was admitted to the emergen...   \n",
       "29996  An 82-year-old man (64.5 kg, 175 cm) diagnosed...   \n",
       "29997  A 54 year-old man with no past medical history...   \n",
       "29998  A 49-year-old woman visited the clinic due to ...   \n",
       "29999  A 31-year-old male with no significant past me...   \n",
       "\n",
       "                                                 summary  \n",
       "0      {\\n\"visit motivation\": \"Discomfort in the neck...  \n",
       "1      {\\n\"visit motivation\": \"Complaints of a dull p...  \n",
       "2      {\\n\"visit motivation\": \"Pain and restricted ra...  \n",
       "3      {\\n\"visit motivation\": \"Pain in the left proxi...  \n",
       "4      {\\n\"visit motivation\": \"Recurrent attacks of p...  \n",
       "...                                                  ...  \n",
       "29995  {\\n\"visit motivation\": \"Stab wound under left ...  \n",
       "29996  {\\n\"visit motivation\": \"Diagnosed with falcine...  \n",
       "29997  {\\n\"visit motivation\": \"Cardiac sounding chest...  \n",
       "29998  {\\n\"visit motivation\": \"Mass in her right thig...  \n",
       "29999  {\\n\"visit motivation\": \"Acute onset crushing s...  \n",
       "\n",
       "[30000 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfc6c383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "      <th>full_note</th>\n",
       "      <th>idx</th>\n",
       "      <th>note</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8900</th>\n",
       "      <td>Doctor: Hi, I'm Dr. X. Can you tell me what ha...</td>\n",
       "      <td>A 42-year-old woman with a past medical histor...</td>\n",
       "      <td>100017</td>\n",
       "      <td>A 42-year-old woman with a past medical histor...</td>\n",
       "      <td>{\\n\"visit motivation\": \"Mechanical fall\",\\n\"ad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           conversation  \\\n",
       "8900  Doctor: Hi, I'm Dr. X. Can you tell me what ha...   \n",
       "\n",
       "                                              full_note     idx  \\\n",
       "8900  A 42-year-old woman with a past medical histor...  100017   \n",
       "\n",
       "                                                   note  \\\n",
       "8900  A 42-year-old woman with a past medical histor...   \n",
       "\n",
       "                                                summary  \n",
       "8900  {\\n\"visit motivation\": \"Mechanical fall\",\\n\"ad...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lean[df_lean['idx'] == 100017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9020c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entities = all_entities.rename(columns={\"row_idx\": \"idx\"})\n",
    "\n",
    "all_entities = all_entities[[\"idx\",\"text\",\"label\",\"table\",\"original_text\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bead66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>table</th>\n",
       "      <th>original_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80176</td>\n",
       "      <td>posttraumatic arthritis</td>\n",
       "      <td>DISEASE</td>\n",
       "      <td>physiological</td>\n",
       "      <td>History of left elbow arthrodesis performed fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31864</td>\n",
       "      <td>pain</td>\n",
       "      <td>DISEASE</td>\n",
       "      <td>physiological</td>\n",
       "      <td>Inability to walk since babyhood, did not walk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31864</td>\n",
       "      <td>fracture</td>\n",
       "      <td>DISEASE</td>\n",
       "      <td>physiological</td>\n",
       "      <td>Inability to walk since babyhood, did not walk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149866</td>\n",
       "      <td>Coxa vara deformity</td>\n",
       "      <td>DISEASE</td>\n",
       "      <td>physiological</td>\n",
       "      <td>Coxa vara deformity of bilateral hips, bilater...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>149866</td>\n",
       "      <td>fracture</td>\n",
       "      <td>DISEASE</td>\n",
       "      <td>physiological</td>\n",
       "      <td>Coxa vara deformity of bilateral hips, bilater...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113052</th>\n",
       "      <td>97973</td>\n",
       "      <td>31 y/o men</td>\n",
       "      <td>AgeSex</td>\n",
       "      <td>info</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113053</th>\n",
       "      <td>97973</td>\n",
       "      <td>aged 31 male</td>\n",
       "      <td>AgeSex</td>\n",
       "      <td>info</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113054</th>\n",
       "      <td>97973</td>\n",
       "      <td>aged 31 man</td>\n",
       "      <td>AgeSex</td>\n",
       "      <td>info</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113055</th>\n",
       "      <td>97973</td>\n",
       "      <td>aged 31 male patient</td>\n",
       "      <td>AgeSex</td>\n",
       "      <td>info</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113056</th>\n",
       "      <td>97973</td>\n",
       "      <td>aged 31 men</td>\n",
       "      <td>AgeSex</td>\n",
       "      <td>info</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2113057 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            idx                     text    label          table  \\\n",
       "0         80176  posttraumatic arthritis  DISEASE  physiological   \n",
       "1         31864                     pain  DISEASE  physiological   \n",
       "2         31864                 fracture  DISEASE  physiological   \n",
       "3        149866      Coxa vara deformity  DISEASE  physiological   \n",
       "4        149866                 fracture  DISEASE  physiological   \n",
       "...         ...                      ...      ...            ...   \n",
       "2113052   97973               31 y/o men   AgeSex           info   \n",
       "2113053   97973             aged 31 male   AgeSex           info   \n",
       "2113054   97973              aged 31 man   AgeSex           info   \n",
       "2113055   97973     aged 31 male patient   AgeSex           info   \n",
       "2113056   97973              aged 31 men   AgeSex           info   \n",
       "\n",
       "                                             original_text  \n",
       "0        History of left elbow arthrodesis performed fo...  \n",
       "1        Inability to walk since babyhood, did not walk...  \n",
       "2        Inability to walk since babyhood, did not walk...  \n",
       "3        Coxa vara deformity of bilateral hips, bilater...  \n",
       "4        Coxa vara deformity of bilateral hips, bilater...  \n",
       "...                                                    ...  \n",
       "2113052                                                NaN  \n",
       "2113053                                                NaN  \n",
       "2113054                                                NaN  \n",
       "2113055                                                NaN  \n",
       "2113056                                                NaN  \n",
       "\n",
       "[2113057 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6870f1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     80176\n",
       "1     31864\n",
       "2     31864\n",
       "3    149866\n",
       "4    149866\n",
       "Name: idx, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_entities['idx'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01c07699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DISEASE', 'CHEMICAL', 'ANATOMY', 'ANATOMY_WITH_LATERALITY',\n",
       "       'PATHOLOGICAL_FORMATION', 'MULTI_TISSUE_STRUCTURE', 'TISSUE',\n",
       "       'ORGANISM_SUBDIVISION', 'CELL', 'ORGAN', 'CANCER',\n",
       "       'ORGANISM_SUBSTANCE', 'ORGANISM', 'IMMATERIAL_ANATOMICAL_ENTITY',\n",
       "       'GENE_OR_GENE_PRODUCT', 'SIMPLE_CHEMICAL', 'CELLULAR_COMPONENT',\n",
       "       'AMINO_ACID', 'ANATOMICAL_SYSTEM',\n",
       "       'DEVELOPING_ANATOMICAL_STRUCTURE', 'PROCEDURE', 'LATERALITY',\n",
       "       'SYMPTOM', 'SYMPTOM_TYPE', 'SEVERITY', 'TEMPORAL_PATTERN', 'TEST',\n",
       "       'TEST_TYPE', 'FINDING', 'CONDITION', 'MEASUREMENT', 'TREATMENT',\n",
       "       'TREATMENT_TYPE', 'MEDICATION', 'DOSAGE', 'FREQUENCY', 'ROUTE',\n",
       "       'TREATMENT_RESPONSE', 'CONDITION_TYPE', 'TREATMENT_REASON', 'Age',\n",
       "       'Sex', 'AgeSex'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_entities['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e150197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the text the model should read\n",
    "TEXT_COL = \"note\"         \n",
    "assert \"idx\" in df_lean.columns, \"df must contain idx\"\n",
    "assert TEXT_COL in df_lean.columns, f\"'{TEXT_COL}' not found in df\"\n",
    "\n",
    "df_lean = df_lean[[\"idx\", TEXT_COL]].dropna(subset=[TEXT_COL]).copy()\n",
    "df_lean[TEXT_COL] = df_lean[TEXT_COL].astype(str)\n",
    "\n",
    "# sanity check for all_entities\n",
    "need = {\"idx\",\"text\",\"label\"}\n",
    "missing = need.difference(all_entities.columns)\n",
    "assert not missing, f\"all_entities is missing columns: {missing}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2aa168",
   "metadata": {},
   "source": [
    "#### Normalize labels & phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e59cbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate phrases: (1805939, 3)\n",
      "\n",
      "Schema label distribution:\n",
      " label\n",
      "AgeSex               707568\n",
      "Problem              372982\n",
      "Age                  203321\n",
      "Anatomy              147999\n",
      "TestName              55700\n",
      "Medication            46450\n",
      "TreatmentName         44086\n",
      "TestType              42025\n",
      "Laterality            41044\n",
      "TemporalPattern       25025\n",
      "TreatmentType         23652\n",
      "Procedure             19639\n",
      "Route                 18590\n",
      "TreatmentReason       16764\n",
      "Dosage                11733\n",
      "Measurement            9676\n",
      "TreatmentResponse      7463\n",
      "Frequency              6705\n",
      "Severity               5509\n",
      "Sex                       8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Upstream labels not kept (after mapping):\n",
      " label\n",
      "PATHOLOGICAL_FORMATION    14321\n",
      "GENE_OR_GENE_PRODUCT       3097\n",
      "ORGANISM                   2378\n",
      "ORGANISM_SUBSTANCE         1306\n",
      "AMINO_ACID                  111\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Map upstream labels to the schema\n",
    "LABEL_MAP = {\n",
    "    # Problems / conditions\n",
    "    \"DISEASE\": \"Problem\",\n",
    "    \"SYMPTOM\": \"Problem\",\n",
    "    \"CONDITION\": \"Problem\",\n",
    "    \"CONDITION_TYPE\": \"Problem\",\n",
    "    \"CANCER\": \"Problem\",\n",
    "    \"FINDING\": \"Problem\",          \n",
    "\n",
    "    # Anatomy (broad)\n",
    "    \"ANATOMY\": \"Anatomy\",\n",
    "    \"ANATOMY_WITH_LATERALITY\": \"Anatomy\",  # keep as Anatomy; Laterality is its own span\n",
    "    \"TISSUE\": \"Anatomy\",\n",
    "    \"MULTI_TISSUE_STRUCTURE\": \"Anatomy\",\n",
    "    \"ORGAN\": \"Anatomy\",\n",
    "    \"ANATOMICAL_SYSTEM\": \"Anatomy\",\n",
    "    \"ORGANISM_SUBDIVISION\": \"Anatomy\",\n",
    "    \"DEVELOPING_ANATOMICAL_STRUCTURE\": \"Anatomy\",\n",
    "    \"IMMATERIAL_ANATOMICAL_ENTITY\": \"Anatomy\",\n",
    "    \"CELL\": \"Anatomy\",\n",
    "    \"CELLULAR_COMPONENT\": \"Anatomy\",\n",
    "\n",
    "    # Medications / substances\n",
    "    \"CHEMICAL\": \"Medication\",\n",
    "    \"SIMPLE_CHEMICAL\": \"Medication\",\n",
    "    \"MEDICATION\": \"Medication\",\n",
    "\n",
    "    # Other bio entities (keep separate in case you want to use later; otherwise map to 'Anatomy' or drop)\n",
    "    \"GENE_OR_GENE_PRODUCT\": \"Substance\",\n",
    "    \"AMINO_ACID\": \"Substance\",\n",
    "    \"ORGANISM\": \"Substance\",\n",
    "    \"ORGANISM_SUBSTANCE\": \"Substance\",\n",
    "\n",
    "    # Procedures & tests\n",
    "    \"PROCEDURE\": \"Procedure\",\n",
    "    \"TEST\": \"TestName\",\n",
    "    \"TEST_TYPE\": \"TestType\",\n",
    "\n",
    "    # Attributes / modifiers\n",
    "    \"LATERALITY\": \"Laterality\",\n",
    "    \"SEVERITY\": \"Severity\",\n",
    "    \"TEMPORAL_PATTERN\": \"TemporalPattern\",\n",
    "    \"MEASUREMENT\": \"Measurement\",\n",
    "\n",
    "    # Treatment-related (keep distinct; useful for relations)\n",
    "    \"TREATMENT\": \"TreatmentName\",          # generic treatment/therapy names\n",
    "    \"TREATMENT_TYPE\": \"TreatmentType\",\n",
    "    \"TREATMENT_RESPONSE\": \"TreatmentResponse\",\n",
    "    \"TREATMENT_REASON\": \"TreatmentReason\",\n",
    "\n",
    "    # Dosing\n",
    "    \"DOSAGE\": \"Dosage\",\n",
    "    \"FREQUENCY\": \"Frequency\",\n",
    "    \"ROUTE\": \"Route\",\n",
    "\n",
    "    # Symptom subtype -> usually just a Problem\n",
    "    \"SYMPTOM_TYPE\": \"Problem\",\n",
    "\n",
    "    # Information-related (keep distinct; useful for relations)\n",
    "    \"AGE\": \"Age\",\n",
    "    \"SEX\": \"Sex\",\n",
    "    \"AGESEX\": \"AgeSex\",\n",
    "}\n",
    "ALLOWED_LABELS = {\n",
    "    \"Problem\",\"Anatomy\",\"Medication\",\"Procedure\",\n",
    "    \"TestName\",\"TestType\",\"Laterality\",\"Severity\",\"TemporalPattern\",\n",
    "    \"Measurement\",\"Dosage\",\"Frequency\",\"Route\",\n",
    "    \"TreatmentName\",\"TreatmentType\",\"TreatmentResponse\",\"TreatmentReason\",\n",
    "    \"Age\",\"Sex\",\"AgeSex\"}\n",
    "\n",
    "def normalize_label(lbl: str) -> str:\n",
    "    if not isinstance(lbl, str): \n",
    "        return \"\"\n",
    "    base = lbl.strip().upper()\n",
    "    # map Age/Sex variants\n",
    "    if base == \"AGE\": return \"Age\"\n",
    "    if base == \"SEX\": return \"Sex\"\n",
    "    if base in (\"AGESEX\",\"AGE_SEX\"): return \"AgeSex\"\n",
    "    mapped = LABEL_MAP.get(base, base)\n",
    "    return mapped\n",
    "\n",
    "def normalize_phrase(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", str(s).strip())\n",
    "\n",
    "# keep only phrase-like rows, keep idx intact\n",
    "ae = all_entities.dropna(subset=[\"text\",\"label\"]).copy()\n",
    "ae[\"text\"]  = ae[\"text\"].astype(str).map(normalize_phrase)\n",
    "ae[\"label\"] = ae[\"label\"].astype(str).map(normalize_label)\n",
    "\n",
    "# filter to allowed schema and remove super short tokens\n",
    "ae = ae[(ae[\"text\"].str.len() >= 2) & (ae[\"label\"].isin(ALLOWED_LABELS))]\n",
    "\n",
    "# de-duplicate\n",
    "ae = ae[[\"idx\",\"text\",\"label\"]].drop_duplicates()\n",
    "\n",
    "print(\"Candidate phrases:\", ae.shape)\n",
    "print(\"\\nSchema label distribution:\\n\", ae[\"label\"].value_counts().head(20))\n",
    "\n",
    "# Debug: see which upstream labels were dropped or mapped to unknown\n",
    "upstream_leftovers = (\n",
    "    all_entities.assign(__norm=all_entities[\"label\"].astype(str).map(lambda x: LABEL_MAP.get(x.strip().upper(), x.strip().upper())))\n",
    "    .loc[~all_entities[\"label\"].astype(str).map(lambda x: LABEL_MAP.get(x.strip().upper(), x.strip().upper()) in ALLOWED_LABELS), \"label\"]\n",
    "    .astype(str).str.upper().value_counts()\n",
    ")\n",
    "print(\"\\nUpstream labels not kept (after mapping):\\n\", upstream_leftovers.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c070955",
   "metadata": {},
   "source": [
    "#### Match candidate phrases back into the note text â†’ silver spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbc90e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notes with â‰¥1 span: 29776/30000 = 99.3%\n"
     ]
    }
   ],
   "source": [
    "def find_all(text: str, phrase: str):\n",
    "    \"\"\"All case-insensitive exact matches (start,end).\"\"\"\n",
    "    return [(m.start(), m.end()) for m in re.finditer(re.escape(phrase), text, flags=re.IGNORECASE)]\n",
    "\n",
    "def dedupe_overlaps(spans):\n",
    "    \"\"\"\n",
    "    Keep one span per overlapping region per label (prefer longer).\n",
    "    spans: list of dicts [{start,end,label,text}, ...]\n",
    "    \"\"\"\n",
    "    spans = sorted(spans, key=lambda x: (x[\"label\"], x[\"start\"], -(x[\"end\"]-x[\"start\"])))\n",
    "    kept = []\n",
    "    for sp in spans:\n",
    "        conflict = False\n",
    "        for kp in kept:\n",
    "            if sp[\"label\"] == kp[\"label\"] and not (sp[\"end\"] <= kp[\"start\"] or sp[\"start\"] >= kp[\"end\"]):\n",
    "                conflict = True\n",
    "                # prefer longer\n",
    "                if (sp[\"end\"]-sp[\"start\"]) > (kp[\"end\"]-kp[\"start\"]):\n",
    "                    kp.update(sp)\n",
    "                break\n",
    "        if not conflict:\n",
    "            kept.append(sp)\n",
    "    return kept\n",
    "\n",
    "# pre-group for speed\n",
    "ents_by_idx = {k: g[[\"text\",\"label\"]].to_dict(\"records\") for k,g in ae.groupby(\"idx\")}\n",
    "\n",
    "silver_rows = []\n",
    "matched_notes = 0\n",
    "\n",
    "for r in df_lean.itertuples(index=False):\n",
    "    note_id = r.idx\n",
    "    text    = getattr(r, TEXT_COL)\n",
    "    spans = []\n",
    "    for ent in ents_by_idx.get(note_id, []):\n",
    "        for (s,e) in find_all(text, ent[\"text\"]):\n",
    "            spans.append({\"start\": s, \"end\": e, \"label\": ent[\"label\"], \"text\": text[s:e]})\n",
    "    spans = dedupe_overlaps(spans)\n",
    "    matched_notes += int(len(spans) > 0)\n",
    "    silver_rows.append({\"idx\": note_id, \"text\": text, \"silver_spans\": spans})\n",
    "\n",
    "silver_df = pd.DataFrame(silver_rows)\n",
    "silver_df[\"n_spans\"] = silver_df[\"silver_spans\"].str.len()\n",
    "print(f\"Notes with â‰¥1 span: {matched_notes}/{len(silver_df)} = {matched_notes/len(silver_df):.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e49e8c2",
   "metadata": {},
   "source": [
    "#### Quick audit / save silver spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32867e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top labels in matched spans: [('Problem', 322501), ('Anatomy', 236202), ('TestType', 105973), ('Laterality', 103713), ('Medication', 56871), ('TestName', 53364), ('Age', 29947), ('Procedure', 24026), ('AgeSex', 17599), ('TemporalPattern', 15126)]\n",
      "\n",
      "--- idx: 57947  ---\n",
      "A 64-year-old caucasian woman with a past medical history of scleroderma with pulmonary fibrosis, renal transplant 18 years ago, chronic pericardial effusion, and hypertension presented to the hospital with two days of right-sided neck pain and stiff â€¦\n",
      "spans: [{'start': 2, 'end': 13, 'label': 'Age', 'text': '64-year-old'}, {'start': 78, 'end': 87, 'label': 'Anatomy', 'text': 'pulmonary'}, {'start': 98, 'end': 103, 'label': 'Anatomy', 'text': 'renal'}, {'start': 219, 'end': 235, 'label': 'Anatomy', 'text': 'right-sided neck'}]\n",
      "\n",
      "--- idx: 46382  ---\n",
      "We describe a case of a 78-year-old male who 24 hours after an anterior rectum surgical resection with a terminoterminal anastomosis for a rectal neoplasm,showed sudden pain among the soft tissues of right flank and fever (39Â°C).\n",
      "The patient did not  â€¦\n",
      "spans: [{'start': 24, 'end': 35, 'label': 'Age', 'text': '78-year-old'}, {'start': 24, 'end': 40, 'label': 'AgeSex', 'text': '78-year-old male'}, {'start': 200, 'end': 211, 'label': 'Anatomy', 'text': 'right flank'}, {'start': 556, 'end': 567, 'label': 'Anatomy', 'text': 'right flank'}]\n",
      "\n",
      "--- idx: 199787  ---\n",
      "A 79-year-old male with a medical history of cholelithiasis, for which he underwent cholecystectomy 11 years ago, hyperlipidemia, essential hypertension, and paroxysmal atrial fibrillation was admitted for mild acute pancreatitis. His presentation in â€¦\n",
      "spans: [{'start': 2, 'end': 13, 'label': 'Age', 'text': '79-year-old'}, {'start': 2, 'end': 18, 'label': 'AgeSex', 'text': '79-year-old male'}, {'start': 297, 'end': 301, 'label': 'Anatomy', 'text': 'back'}, {'start': 724, 'end': 736, 'label': 'Medication', 'text': 'atorvastatin'}]\n",
      "\n",
      "--- idx: 18526  ---\n",
      "A 65-year-old woman with a medical history significant for anal cancer presented for mediport removal. Past surgical history included an elective thyroidectomy two years prior for multinodular goiter. The port was placed 11 years prior for chemothera â€¦\n",
      "spans: [{'start': 2, 'end': 13, 'label': 'Age', 'text': '65-year-old'}, {'start': 2, 'end': 19, 'label': 'AgeSex', 'text': '65-year-old woman'}, {'start': 638, 'end': 642, 'label': 'Anatomy', 'text': 'left'}, {'start': 652, 'end': 664, 'label': 'Anatomy', 'text': 'jugular vein'}]\n",
      "\n",
      "--- idx: 7462  ---\n",
      "A 51-year-old woman with history of RAA in surveillance attended a cardiologist due to dyspnea and palpitation. The patient underwent a computer tomography (CT) evaluation which confirmed RAA with a common origin of both carotid arteries, a separate  â€¦\n",
      "spans: [{'start': 2, 'end': 13, 'label': 'Age', 'text': '51-year-old'}, {'start': 2, 'end': 19, 'label': 'AgeSex', 'text': '51-year-old woman'}, {'start': 221, 'end': 237, 'label': 'Anatomy', 'text': 'carotid arteries'}, {'start': 270, 'end': 287, 'label': 'Anatomy', 'text': 'subclavian artery'}]\n"
     ]
    }
   ],
   "source": [
    "# label distribution\n",
    "lab_counts = Counter(sp[\"label\"] for L in silver_df[\"silver_spans\"] for sp in L)\n",
    "print(\"Top labels in matched spans:\", lab_counts.most_common(10))\n",
    "\n",
    "# sample for eyeballing\n",
    "sample = silver_df[silver_df[\"n_spans\"]>0].sample(5, random_state=13)\n",
    "for row in sample.itertuples(index=False):\n",
    "    print(\"\\n--- idx:\", row.idx, \" ---\")\n",
    "    print(row.text[:250], \"â€¦\")\n",
    "    print(\"spans:\", row.silver_spans[:4])\n",
    "\n",
    "# save for reuse\n",
    "silver_df.to_parquet(\"silver_spans.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba05d47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rapidfuzz in /opt/anaconda3/envs/nlp_clinical/lib/python3.9/site-packages (3.13.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7m/wfwdc8s14pgch1s3hgyyg6080000gn/T/ipykernel_40097/3921894254.py:33: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  silver_df = cand.groupby(\"idx\").apply(rebuild).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notes with â‰¥1 span: 1.0\n"
     ]
    }
   ],
   "source": [
    "%pip install rapidfuzz\n",
    "\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "# explode to candidate rows\n",
    "rows = []\n",
    "for r in silver_df.itertuples(index=False):\n",
    "    for sp in r.silver_spans:\n",
    "        rows.append({\"idx\": r.idx, \"note_text\": r.text, **sp})\n",
    "cand = pd.DataFrame(rows)\n",
    "\n",
    "# simple priors: frequency + local fuzzy + case exact\n",
    "freq = (cand.groupby([\"label\",\"text\"]).size()/len(silver_df)).to_dict()\n",
    "\n",
    "def conf_score(row):\n",
    "    s = 0.0\n",
    "    s += 0.45 * freq.get((row[\"label\"], row[\"text\"]), 0)\n",
    "    s += 0.25 * (1.0 if row[\"note_text\"][row[\"start\"]:row[\"end\"]] == row[\"text\"] else 0.0)\n",
    "    local = row[\"note_text\"][max(0,row[\"start\"]-40):min(len(row[\"note_text\"]),row[\"end\"]+40)]\n",
    "    s += 0.30 * (fuzz.partial_ratio(row[\"text\"].lower(), local.lower())/100.0)\n",
    "    return min(s,1.0)\n",
    "\n",
    "cand[\"conf\"] = cand.apply(conf_score, axis=1)\n",
    "cand = cand[cand[\"conf\"] >= 0.35]\n",
    "\n",
    "# rebuild silver_df_filtered\n",
    "def rebuild(group):\n",
    "    spans = group[[\"start\",\"end\",\"label\",\"text\"]].to_dict(\"records\")\n",
    "    return pd.Series({\"text\": group[\"note_text\"].iloc[0], \"silver_spans\": spans})\n",
    "\n",
    "silver_df = cand.groupby(\"idx\").apply(rebuild).reset_index()\n",
    "silver_df[\"n_spans\"] = silver_df[\"silver_spans\"].str.len()\n",
    "print(\"Notes with â‰¥1 span:\", (silver_df[\"n_spans\"]>0).mean())\n",
    "silver_df.to_parquet(\"silver_spans_filtered.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a56aec",
   "metadata": {},
   "source": [
    "#### Convert silver spans â†’ BIO sequences for Hugging Face NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe6c80dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity set: ['Age', 'AgeSex', 'Anatomy', 'Dosage', 'Frequency', 'Laterality', 'Measurement', 'Medication', 'Problem', 'Procedure', 'Route', 'Severity', 'Sex', 'TemporalPattern', 'TestName', 'TestType', 'TreatmentName', 'TreatmentReason', 'TreatmentResponse', 'TreatmentType']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenize + BIO: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29776/29776 [01:02<00:00, 475.27 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25309/25309 [00:00<00:00, 130313.02 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4467/4467 [00:00<00:00, 113064.73 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['idx', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 25309\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['idx', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 4467\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 4.1 label space\n",
    "entity_labels = sorted({sp[\"label\"] for L in silver_df[\"silver_spans\"] for sp in L})\n",
    "id2label = [\"O\"] + sum(([f\"B-{l}\", f\"I-{l}\"] for l in entity_labels), [])\n",
    "label2id = {l:i for i,l in enumerate(id2label)}\n",
    "print(\"Entity set:\", entity_labels)\n",
    "\n",
    "# 4.2 tokenizer\n",
    "MODEL_NAME = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "MAX_LEN = 256\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def to_bio(example):\n",
    "    text, spans = example[\"text\"], example[\"silver_spans\"]\n",
    "    enc = tok(text, truncation=True, max_length=MAX_LEN, return_offsets_mapping=True)\n",
    "    tags = [\"O\"] * len(enc[\"offset_mapping\"])\n",
    "\n",
    "    for sp in spans:\n",
    "        s, e, lab = sp[\"start\"], sp[\"end\"], sp[\"label\"]\n",
    "        began = False\n",
    "        for i, (a, b) in enumerate(enc[\"offset_mapping\"]):\n",
    "            if a == b:         # special tokens like [CLS]/[SEP]\n",
    "                continue\n",
    "            if a >= s and b <= e:\n",
    "                tags[i] = f\"I-{lab}\" if began else f\"B-{lab}\"\n",
    "                began = True\n",
    "\n",
    "    enc[\"labels\"] = [label2id[t] for t in tags]\n",
    "    enc[\"idx\"] = example[\"idx\"]         # <â€” keep idx in the HF example\n",
    "    enc.pop(\"offset_mapping\", None)\n",
    "    return enc\n",
    "\n",
    "# 4.3 build HF dataset (keeping idx)\n",
    "hf = ds.Dataset.from_pandas(silver_df[[\"idx\",\"text\",\"silver_spans\"]], preserve_index=False)\n",
    "hf = hf.map(to_bio, remove_columns=[\"text\",\"silver_spans\"], desc=\"Tokenize + BIO\")\n",
    "\n",
    "# 4.4 split & save (idx stays inside the dataset)\n",
    "splits = hf.train_test_split(test_size=0.15, seed=42)\n",
    "splits.save_to_disk(\"ds_ner_silver_with_idx\")\n",
    "\n",
    "# persist label maps for training/eval later\n",
    "with open(\"ner_label_space.json\",\"w\") as f:\n",
    "    json.dump({\"id2label\": id2label, \"label2id\": label2id}, f, indent=2)\n",
    "\n",
    "print(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b54ce63",
   "metadata": {},
   "source": [
    "#### Train a NER model (HF Trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d35d0134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– transformers version: 4.55.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/7m/wfwdc8s14pgch1s3hgyyg6080000gn/T/ipykernel_40097/42040209.py:129: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/opt/anaconda3/envs/nlp_clinical/lib/python3.9/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4746' max='4746' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4746/4746 5:03:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.252400</td>\n",
       "      <td>0.247244</td>\n",
       "      <td>0.559288</td>\n",
       "      <td>0.716138</td>\n",
       "      <td>0.628069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.220300</td>\n",
       "      <td>0.232989</td>\n",
       "      <td>0.582861</td>\n",
       "      <td>0.742173</td>\n",
       "      <td>0.652939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.205900</td>\n",
       "      <td>0.223240</td>\n",
       "      <td>0.606255</td>\n",
       "      <td>0.733174</td>\n",
       "      <td>0.663702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp_clinical/lib/python3.9/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/envs/nlp_clinical/lib/python3.9/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/envs/nlp_clinical/lib/python3.9/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22324031591415405, 'eval_precision': 0.6062553130416543, 'eval_recall': 0.7331740076636537, 'eval_f1': 0.6637015192351853, 'eval_runtime': 284.0717, 'eval_samples_per_second': 15.725, 'eval_steps_per_second': 0.986, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('model_ner_best/tokenizer_config.json',\n",
       " 'model_ner_best/special_tokens_map.json',\n",
       " 'model_ner_best/vocab.txt',\n",
       " 'model_ner_best/added_tokens.json',\n",
       " 'model_ner_best/tokenizer.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json, numpy as np, torch, datasets as ds\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForTokenClassification,\n",
    "    DataCollatorForTokenClassification, TrainingArguments, Trainer,\n",
    "    EarlyStoppingCallback, __version__ as HF_VER\n",
    ")\n",
    "from seqeval.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "print(\"ðŸ¤– transformers version:\", HF_VER)\n",
    "\n",
    "# --- Data ---\n",
    "splits = ds.load_from_disk(\"ds_ner_silver_with_idx\")\n",
    "if \"labels\" not in splits[\"train\"].features:\n",
    "    if \"ner_tags\" in splits[\"train\"].features:\n",
    "        splits = splits.rename_column(\"ner_tags\", \"labels\")\n",
    "    else:\n",
    "        raise ValueError(f\"Need a 'labels' (or 'ner_tags') column. Got: {list(splits['train'].features)}\")\n",
    "\n",
    "with open(\"ner_label_space.json\") as f:\n",
    "    maps = json.load(f)\n",
    "\n",
    "id2label_list = maps[\"id2label\"]\n",
    "# normalize types for robustness\n",
    "label2id = {str(k): int(v) for k, v in maps[\"label2id\"].items()}\n",
    "id2label = {i: l for i, l in enumerate(id2label_list)}\n",
    "\n",
    "# --- Model / Tokenizer ---\n",
    "MODEL_NAME = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(id2label),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "# --- TrainingArguments (version-safe) ---\n",
    "use_cuda = torch.cuda.is_available()\n",
    "TA_fields = set(TrainingArguments.__dataclass_fields__.keys())\n",
    "ta = dict(\n",
    "    output_dir=\"ckpt/ner\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    ")\n",
    "\n",
    "# warmup_ratio if supported\n",
    "if \"warmup_ratio\" in TA_fields:\n",
    "    ta[\"warmup_ratio\"] = 0.1\n",
    "# fp16 only if supported\n",
    "if \"fp16\" in TA_fields:\n",
    "    ta[\"fp16\"] = use_cuda\n",
    "# report_to if supported\n",
    "if \"report_to\" in TA_fields:\n",
    "    ta[\"report_to\"] = \"none\"\n",
    "# save_total_limit if supported\n",
    "if \"save_total_limit\" in TA_fields:\n",
    "    ta[\"save_total_limit\"] = 2\n",
    "\n",
    "# Evaluation/saving strategy compatibility\n",
    "if \"evaluation_strategy\" in TA_fields and \"save_strategy\" in TA_fields:\n",
    "    ta[\"evaluation_strategy\"] = \"epoch\"\n",
    "    ta[\"save_strategy\"] = \"epoch\"\n",
    "elif \"evaluate_during_training\" in TA_fields:\n",
    "    # very old versions use this boolean instead\n",
    "    ta[\"evaluate_during_training\"] = True\n",
    "    # fall back to step-based saving if epoch strategy isn't available\n",
    "    if \"save_steps\" in TA_fields:\n",
    "        ta[\"save_steps\"] = 500\n",
    "\n",
    "# Best-model logic compatibility\n",
    "if \"load_best_model_at_end\" in TA_fields:\n",
    "    ta[\"load_best_model_at_end\"] = True\n",
    "    # metric_for_best_model name must match the logged key (eval_f1)\n",
    "    if \"metric_for_best_model\" in TA_fields:\n",
    "        ta[\"metric_for_best_model\"] = \"eval_f1\"\n",
    "    if \"greater_is_better\" in TA_fields:\n",
    "        ta[\"greater_is_better\"] = True\n",
    "\n",
    "# --- ensure eval/save strategies MATCH across HF versions ---\n",
    "TA_FIELDS = set(TrainingArguments.__dataclass_fields__.keys())\n",
    "\n",
    "# pick the correct key name for evaluation strategy\n",
    "eval_key = \"eval_strategy\" if \"eval_strategy\" in TA_FIELDS else (\n",
    "    \"evaluation_strategy\" if \"evaluation_strategy\" in TA_FIELDS else None\n",
    ")\n",
    "\n",
    "if eval_key:\n",
    "    ta[eval_key] = \"epoch\"        # evaluate each epoch\n",
    "if \"save_strategy\" in TA_FIELDS:\n",
    "    ta[\"save_strategy\"] = \"epoch\" # save each epoch\n",
    "\n",
    "# remove step-based settings so they don't force 'steps' behavior\n",
    "for k in (\"save_steps\", \"eval_steps\"):\n",
    "    if k in ta:\n",
    "        ta.pop(k)\n",
    "args = TrainingArguments(**ta)\n",
    "\n",
    "# --- Metrics ---\n",
    "def align_and_decode(preds, labels):\n",
    "    pred_labels, true_labels = [], []\n",
    "    for p, t in zip(preds, labels):\n",
    "        p = np.array(p); t = np.array(t)\n",
    "        mask = t != -100\n",
    "        p = p[mask]; t = t[mask]\n",
    "        pred_labels.append([id2label[i] for i in p])\n",
    "        true_labels.append([id2label[i] for i in t])\n",
    "    return pred_labels, true_labels\n",
    "\n",
    "def compute_metrics(p):\n",
    "    logits, labels = p.predictions, p.label_ids\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    pred_tags, true_tags = align_and_decode(preds, labels)\n",
    "    return {\n",
    "        \"precision\": precision_score(true_tags, pred_tags),\n",
    "        \"recall\":    recall_score(true_tags, pred_tags),\n",
    "        \"f1\":        f1_score(true_tags, pred_tags),\n",
    "    }\n",
    "\n",
    "# --- Trainer ---\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=splits[\"train\"],\n",
    "    eval_dataset=splits.get(\"validation\", splits.get(\"test\")),\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "\n",
    "train_output = trainer.train()\n",
    "eval_output  = trainer.evaluate()\n",
    "print(eval_output)\n",
    "\n",
    "trainer.save_model(\"model_ner_best\")\n",
    "tokenizer.save_pretrained(\"model_ner_best\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806d2ed3",
   "metadata": {},
   "source": [
    "#### Detailed Eval - Seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8f7d056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp_clinical/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/nlp_clinical/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              B-Age      0.919     0.947     0.933      1697\n",
      "           B-AgeSex      0.993     1.000     0.996      2680\n",
      "          B-Anatomy      0.589     0.590     0.590     12177\n",
      "        B-Frequency      0.000     0.000     0.000         8\n",
      "       B-Laterality      0.834     0.961     0.893      8580\n",
      "      B-Measurement      0.552     0.682     0.610       726\n",
      "       B-Medication      0.772     0.848     0.808      3456\n",
      "          B-Problem      0.689     0.760     0.723     29669\n",
      "        B-Procedure      0.819     0.960     0.884      1607\n",
      "            B-Route      0.000     0.000     0.000        42\n",
      "         B-Severity      0.643     0.839     0.728       818\n",
      "  B-TemporalPattern      0.753     0.926     0.831      1663\n",
      "         B-TestName      0.535     0.541     0.538      2550\n",
      "         B-TestType      0.631     0.833     0.718      4715\n",
      "    B-TreatmentName      0.000     0.000     0.000         1\n",
      "B-TreatmentResponse      0.000     0.000     0.000         3\n",
      "    B-TreatmentType      0.000     0.000     0.000        39\n",
      "              I-Age      0.953     0.976     0.964      5650\n",
      "           I-AgeSex      0.994     1.000     0.997     13523\n",
      "          I-Anatomy      0.563     0.594     0.579     20452\n",
      "       I-Laterality      0.000     0.000     0.000        28\n",
      "      I-Measurement      0.581     0.678     0.626      1254\n",
      "       I-Medication      0.813     0.902     0.855      9767\n",
      "          I-Problem      0.720     0.766     0.742     70801\n",
      "        I-Procedure      0.808     0.968     0.881      1353\n",
      "            I-Route      0.000     0.000     0.000        18\n",
      "  I-TemporalPattern      0.753     0.926     0.830       394\n",
      "         I-TestName      0.562     0.544     0.553     11651\n",
      "         I-TestType      0.620     0.833     0.711      5341\n",
      "    I-TreatmentName      0.000     0.000     0.000         1\n",
      "    I-TreatmentType      0.000     0.000     0.000        13\n",
      "                  O      0.960     0.943     0.951    932875\n",
      "\n",
      "           accuracy                          0.911   1143552\n",
      "          macro avg      0.533     0.594     0.561   1143552\n",
      "       weighted avg      0.915     0.911     0.912   1143552\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp_clinical/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "pred = trainer.predict(splits[\"test\"])\n",
    "pred_ids = pred.predictions.argmax(-1)\n",
    "\n",
    "def align(ids, gold):\n",
    "    p_tags, t_tags = [], []\n",
    "    for p, t in zip(ids, gold):\n",
    "        mask = (t != -100)\n",
    "        p = p[mask]; t = t[mask]\n",
    "        p_tags.append([id2label[i] for i in p])\n",
    "        t_tags.append([id2label[i] for i in t])\n",
    "    return p_tags, t_tags\n",
    "\n",
    "p_tags, t_tags = align(pred_ids, pred.label_ids)\n",
    "# Flatten the lists of tags for sklearn compatibility\n",
    "flat_true = [tag for seq in t_tags for tag in seq]\n",
    "flat_pred = [tag for seq in p_tags for tag in seq]\n",
    "print(classification_report(flat_true, flat_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcd7f3e",
   "metadata": {},
   "source": [
    "#### Inference Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1773692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/var/folders/7m/wfwdc8s14pgch1s3hgyyg6080000gn/T/ipykernel_40097/867186477.py:108: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  records = pred_df.head(20).applymap(convert_types).to_dict(orient=\"records\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "import torch, pandas as pd, json, re\n",
    "\n",
    "# ---- model & pipeline ----\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "tok   = AutoTokenizer.from_pretrained(\"model_ner_best\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"model_ner_best\")\n",
    "ner_pipe = pipeline(\"token-classification\", model=model, tokenizer=tok,\n",
    "                    aggregation_strategy=\"simple\", device=device)\n",
    "\n",
    "# ---- helpers for windowed mode ----\n",
    "def merge_overlaps(ents):\n",
    "    ents = sorted(ents, key=lambda e: (e[\"start\"], e[\"end\"]))\n",
    "    merged = []\n",
    "    for e in ents:\n",
    "        if merged and e[\"start\"] <= merged[-1][\"end\"] and e[\"entity_group\"] == merged[-1][\"entity_group\"]:\n",
    "            merged[-1][\"end\"]   = max(merged[-1][\"end\"], e[\"end\"])\n",
    "            merged[-1][\"score\"] = max(merged[-1][\"score\"], e[\"score\"])\n",
    "            # merged[-1][\"word\"] can be recomputed from text if you want exact text\n",
    "        else:\n",
    "            merged.append(e)\n",
    "    return merged\n",
    "\n",
    "def ner_with_windows(text, max_length=512, stride=128):\n",
    "    enc = tok(\n",
    "        text, return_offsets_mapping=True, return_overflowing_tokens=True,\n",
    "        truncation=True, max_length=max_length, stride=stride\n",
    "    )\n",
    "    all_ents = []\n",
    "    for offsets in enc[\"offset_mapping\"]:\n",
    "        valid = [(a, b) for (a, b) in offsets if b > a]\n",
    "        if not valid:\n",
    "            continue\n",
    "        start_char = valid[0][0]\n",
    "        end_char   = valid[-1][1]\n",
    "        chunk      = text[start_char:end_char]\n",
    "        ents = ner_pipe(chunk)\n",
    "        for e in ents:\n",
    "            e[\"start\"] += start_char\n",
    "            e[\"end\"]   += start_char\n",
    "        all_ents.extend(ents)\n",
    "    return merge_overlaps(all_ents)\n",
    "\n",
    "# ---- unified runner ----\n",
    "def run_ner(df_notes, text_col, strategy=\"auto\", max_length=512, stride=128):\n",
    "    \"\"\"\n",
    "    strategy:\n",
    "      - 'truncate' : fast, may drop content > max_length\n",
    "      - 'window'   : slower, covers full text with overlap\n",
    "      - 'auto'     : use windowed only when needed (len(tokens) > max_length)\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for r in df_notes.itertuples(index=False):\n",
    "        text = getattr(r, text_col) or \"\"\n",
    "        if strategy == \"truncate\":\n",
    "            ents = ner_pipe(text)\n",
    "        elif strategy == \"window\":\n",
    "            ents = ner_with_windows(text, max_length=max_length, stride=stride)\n",
    "        else:  # auto\n",
    "            # estimate token count; if close to limit, switch to windowed\n",
    "            approx_len = len(tok(text, add_special_tokens=False)[\"input_ids\"])\n",
    "            if approx_len > max_length - 8:\n",
    "                ents = ner_with_windows(text, max_length=max_length, stride=stride)\n",
    "            else:\n",
    "                ents = ner_pipe(text)\n",
    "        rows.append({\"idx\": r.idx, \"text\": text, \"pred_entities\": ents})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Fast smoke test:\n",
    "pred_df = run_ner(df_lean[[\"idx\",\"note\"]].head(10), \"note\", strategy=\"truncate\")\n",
    "\n",
    "# Full dataset, robust:\n",
    "# pred_df = run_ner(df_lean[[\"idx\",\"note\"]], \"note\", strategy=\"window\")\n",
    "\n",
    "# Auto mode (fast on short notes, robust on long ones):\n",
    "pred_df = run_ner(df_lean[[\"idx\",\"note\"]], \"note\", strategy=\"auto\")\n",
    "\n",
    "pred_df.to_parquet(\"ner_predictions.parquet\", index=False)\n",
    "\n",
    "# Convert all numpy types to native Python types for JSON serialization\n",
    "import numpy as np\n",
    "def convert_types(obj):\n",
    "    if isinstance(obj, (np.generic, np.floating, np.integer)):\n",
    "        return obj.item()\n",
    "    return obj\n",
    "# ---- JSON-safe conversion helpers ----\n",
    "import torch\n",
    "def to_jsonable(x):\n",
    "    # numpy scalars -> Python scalars\n",
    "    if isinstance(x, np.generic):\n",
    "        return x.item()\n",
    "    # numpy arrays -> lists\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return x.tolist()\n",
    "    # torch tensors -> lists\n",
    "    if torch.is_tensor(x):\n",
    "        return x.detach().cpu().tolist()\n",
    "    # pandas timestamps/timedeltas -> ISO strings\n",
    "    if isinstance(x, pd.Timestamp):\n",
    "        return x.isoformat()\n",
    "    # recurse into containers\n",
    "    if isinstance(x, dict):\n",
    "        return {k: to_jsonable(v) for k, v in x.items()}\n",
    "    if isinstance(x, (list, tuple, set)):\n",
    "        return [to_jsonable(v) for v in x]\n",
    "    return x\n",
    "\n",
    "records = pred_df.head(20).applymap(convert_types).to_dict(orient=\"records\")\n",
    "with open(\"ner_predictions_sample.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        pred_df.head(20).to_dict(orient=\"records\"),\n",
    "        f,\n",
    "        indent=2,\n",
    "        allow_nan=False,\n",
    "        default=to_jsonable  # will be invoked for np.float32, tensors, etc.\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a25639b",
   "metadata": {},
   "source": [
    "##### Post-process to structured JSON (merges & med bundles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edeeb790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def sent_split(text): return re.split(r'(?<=[\\.\\!\\?])\\s+|\\n+', text)\n",
    "\n",
    "def to_structured(note_text, ents):\n",
    "    ents_sorted = sorted(ents, key=lambda x: (x[\"start\"], x[\"end\"]))\n",
    "    merged=[]; i=0\n",
    "    while i<len(ents_sorted):\n",
    "        e=ents_sorted[i]\n",
    "        if e[\"entity_group\"]==\"Laterality\" and i+1<len(ents_sorted) and ents_sorted[i+1][\"entity_group\"]==\"Anatomy\":\n",
    "            nxt=ents_sorted[i+1]\n",
    "            merged.append({\"entity_group\":\"Anatomy\",\"start\":e[\"start\"],\"end\":nxt[\"end\"],\n",
    "                           \"word\":note_text[e[\"start\"]:nxt[\"end\"]].strip(),\n",
    "                           \"score\":(e[\"score\"]+nxt[\"score\"])/2})\n",
    "            i+=2\n",
    "        else:\n",
    "            merged.append(e); i+=1\n",
    "\n",
    "    sents = sent_split(note_text); bounds=[]; pos=0\n",
    "    for s in sents: bounds.append((pos,pos+len(s))); pos+=len(s)+1\n",
    "    def sid(s): \n",
    "        for k,(a,b) in enumerate(bounds):\n",
    "            if a<=s<b: return k\n",
    "        return -1\n",
    "    for e in merged: e[\"_sid\"]=sid(e[\"start\"])\n",
    "\n",
    "    meds=[]\n",
    "    for m in [x for x in merged if x[\"entity_group\"]==\"Medication\"]:\n",
    "        s=m[\"_sid\"]\n",
    "        meds.append({\n",
    "            \"name\": m[\"word\"], \"span\":[m[\"start\"],m[\"end\"]],\n",
    "            \"dosage\":[x[\"word\"] for x in merged if x[\"_sid\"]==s and x[\"entity_group\"]==\"Dosage\"],\n",
    "            \"frequency\":[x[\"word\"] for x in merged if x[\"_sid\"]==s and x[\"entity_group\"]==\"Frequency\"],\n",
    "            \"route\":[x[\"word\"] for x in merged if x[\"_sid\"]==s and x[\"entity_group\"]==\"Route\"]\n",
    "        })\n",
    "    problems=[x for x in merged if x[\"entity_group\"]==\"Problem\"]\n",
    "    anatomy=[x for x in merged if x[\"entity_group\"]==\"Anatomy\"]\n",
    "    temporal=[x for x in merged if x[\"entity_group\"]==\"TemporalPattern\"]\n",
    "\n",
    "    return {\"problems\":[{\"text\":p[\"word\"],\"span\":[p[\"start\"],p[\"end\"]]} for p in problems],\n",
    "            \"anatomy\":[{\"text\":a[\"word\"],\"span\":[a[\"start\"],a[\"end\"]]} for a in anatomy],\n",
    "            \"temporal\":[{\"text\":t[\"word\"],\"span\":[t[\"start\"],t[\"end\"]]} for t in temporal],\n",
    "            \"medications\": meds}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f650975d",
   "metadata": {},
   "source": [
    "##### Relation candidates (by sentence, typed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d735b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import pandas as pd\n",
    "\n",
    "def relation_candidates(note_text, merged_ents):\n",
    "    # expects entities like in previous cell (merged)\n",
    "    # assign sid\n",
    "    sents = sent_split(note_text); bounds=[]; pos=0\n",
    "    for s in sents: bounds.append((pos,pos+len(s))); pos+=len(s)+1\n",
    "    def sid(s):\n",
    "        for k,(a,b) in enumerate(bounds):\n",
    "            if a<=s<b: return k\n",
    "        return -1\n",
    "    for e in merged_ents: e[\"_sid\"]=sid(e[\"start\"])\n",
    "\n",
    "    types_ok = {\n",
    "        (\"Problem\",\"Anatomy\"): \"has_location\",\n",
    "        (\"Problem\",\"TemporalPattern\"): \"has_duration\",\n",
    "        (\"Medication\",\"Dosage\"): \"has_dosage\",\n",
    "        (\"Medication\",\"Frequency\"): \"has_frequency\",\n",
    "        (\"Medication\",\"Route\"): \"has_route\",\n",
    "        (\"Medication\",\"Problem\"): \"treated_for\",\n",
    "    }\n",
    "    rels=[]\n",
    "    for i,h in enumerate(merged_ents):\n",
    "        for j,t in enumerate(merged_ents):\n",
    "            if j<=i: continue\n",
    "            if h[\"_sid\"]==-1 or t[\"_sid\"]==-1 or h[\"_sid\"]!=t[\"_sid\"]: continue\n",
    "            k=(h[\"entity_group\"], t[\"entity_group\"])\n",
    "            if k in types_ok:\n",
    "                rels.append({\"type\":types_ok[k], \"head\":i, \"tail\":j})\n",
    "            k=(t[\"entity_group\"], h[\"entity_group\"])\n",
    "            if k in types_ok:\n",
    "                rels.append({\"type\":types_ok[k], \"head\":j, \"tail\":i})\n",
    "    return rels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b57d66",
   "metadata": {},
   "source": [
    "##### Run model end-to-end on a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7c717b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same text column you trained on (e.g., 'note' or 'full_note')\n",
    "sample = df_lean[[\"idx\",\"note\"]].head(10).copy()\n",
    "pred = run_ner(sample, \"note\")\n",
    "\n",
    "structured_rows=[]\n",
    "for r in pred.itertuples(index=False):\n",
    "    st = to_structured(r.text, r.pred_entities)\n",
    "    # prepare flat entity list for relation candidates\n",
    "    flat = []\n",
    "    for pe in r.pred_entities:\n",
    "        flat.append({\"entity_group\":pe[\"entity_group\"],\"start\":pe[\"start\"],\"end\":pe[\"end\"],\"word\":pe[\"word\"]})\n",
    "    rels = relation_candidates(r.text, flat)\n",
    "    structured_rows.append({\"idx\": r.idx, \"entities\": r.pred_entities, \"structured\": st, \"relations\": rels})\n",
    "\n",
    "pd.DataFrame(structured_rows).to_json(\"inference_sample.json\", orient=\"records\", lines=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_clinical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
